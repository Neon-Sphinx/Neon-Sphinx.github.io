
[{"content":"Reposted from 刚刚，谷歌 Deep Think「重回巅峰」，OpenAI 首次「抛弃」英伟达 by 木易的AI频道\nARC-AGI-2，84.6%。\n这是公认最难的 AI 推理测试，人类平均正确率大概 60%。\n谷歌刚刚升级的 Gemini 3 Deep Think，84.6%，断层第一。\n第二名 Claude Opus 4.6，68.8%；第三名 GPT-5.2，只有 52.9%。\n谷歌遥遥领先，重回巅峰。\n同一天，OpenAI 把自己的新模型部署在了一颗不是英伟达的芯片上。\n历史上第一次。\n一个在赌「深度」，一个在赌「速度」。\n谷歌的「推理暴力」 # Gemini 3 Deep Think 不是一个新模型，是 Gemini 3 的深度推理模式。\n去年 12 月初就发布了，这次是升级。\n开启 Deep Think 后，模型会花更多的算力去「思考」，用多轮推理、并行假设探索来逼近最优解。\n说人话，让模型慢慢想，想清楚再回答。\n开头说的 ARC-AGI-2 就是它的成绩单。\n这个测试不考你记住了多少知识，考的是你能不能从几个例子里自己归纳出规则。\n84.6% 准确率，是 ARC Prize 官方验证的。\n而在老版本 ARC-AGI-1 上，Deep Think 直接狂砍 96%。\n这个曾经被认为「AI 最难攻克」的基准测试，已经即将被彻底拿下。\n其他测试，谷歌也在屠榜。\n「人类最后一场考试」Humanity\u0026rsquo;s Last Exam，48.4%，不用工具，新纪录。\nCodeforces 编程竞赛 Elo 3455，「传奇宗师」（Legendary Grandmaster，Codeforces 最高等级头衔）级别，全球排名第八。\n前面只剩了 7 个碳基程序员。\n2025 年国际数学奥林匹克金牌，物理奥林匹克金牌，化学奥林匹克金牌。\n数学、物理、化学，三科同时拿金牌。\n谷歌在博客里讲了一个细节。\n罗格斯大学的数学家 Lisa Carbone 用 Deep Think 审核一篇高度专业的数学论文，模型发现了一个微妙的逻辑漏洞。\n这个漏洞之前通过了人类同行评审，没人看出来。\n在另一个演示中，给 Deep Think 画一张草图，它能分析几何结构，直接生成 3D 打印文件。\n从审论文到做 3D 打印，谷歌想说，「Deep Think 不只是刷榜机器。」\n划重点，Deep Think 目前仅对 Google AI Ultra 订阅用户开放。\nAPI 也首次开放了早期访问申请。\nOpenAI 的「速度焦虑」 # 在谷歌让模型变聪明的同一天，OpenAI 做了一件完全相反的事。\n新模型 GPT‑5.3‑Codex‑Spark，正式发布。\nSpark，火花，一闪就亮。\n顾名思义，GPT‑5.3‑Codex‑Spark 是 GPT-5.3-Codex 的青春版，专为实时编程设计。\n不追求最强推理能力，主打一个「快」。\n快到什么程度？\n每秒 1000+ token。\n带你感受一下来自 OpenAI 官方的对比视频。\n标准版 GPT-5.3-Codex 在 SWE-Bench Pro 上完成一个任务大概要十几分钟。\nCodex-Spark 能在几分钟内搞定，准确率则介于 GPT-5.3-Codex 和 GPT-5.1-Codex-mini 之间。\n速度快了 15 倍，能力打了折扣。\n但 Codex-Spark 要解决的就是 AI 编程过程中的「等待」问题。\n更有意思的是硬件。\nCodex-Spark 跑在 Cerebras 的第三代晶圆级引擎上。\n这颗芯片把计算、内存、带宽全塞在一块巨大的晶圆上，消除了传统 GPU 集群之间的数据传输瓶颈。\n代价是内存只有 44GB，要知道，英伟达下一代 Rubin 是 288GB。\n所以，Cerebras 不是来替代英伟达的，它专门给「对延迟极度敏感」的场景用。\nOpenAI 说，GPU 依然是基础，Cerebras 是补充。\n除了硬件，OpenAI 还重写了整个推理链。\n引入持久化 WebSocket 连接，客户端到服务器的往返开销降了 80%，首 token 响应时间缩短 50%，单 token 处理开销减少 30%。\n这些优化不只给 Codex-Spark 用，很快会推广到所有模型。\n划重点，普通用户暂时用不了。\n目前 Codex-Spark 只对 ChatGPT Pro 用户开放，支持 Codex App、命令行和 VS Code 插件。\n128k 上下文，纯文本输入，API 只对少量合作伙伴开放。\n把谷歌和 OpenAI 的动作放在一起看，很有意思。\n谷歌在解决「怎么更聪明」。\n不换硬件，不训练新模型，就在推理阶段多花算力。\n同一个 Gemini 3 Pro，给它更多时间去想，分数能从 31.1% 提升到 84.6%。\nOpenAI 在解决「怎么更快」。\n模型已经够聪明了，但用起来太慢，开发者等不了。\n所以签了 100 亿美元的芯片合同，重写推理管线，把延迟压缩到极致。\n一个做加法，投入算力换推理深度。\n一个做减法，砍掉能力换响应速度。\n那么，AI 的下一个瓶颈到底是什么？\n谷歌的答案是推理深度。\nOpenAI 的答案是速度。\nAI 的 2026，好戏还在后头。\n我是木易，Top2 + 美国 Top10 CS 硕，现在是 AI 产品经理。\n关注「AI信息Gap」，让 AI 成为你的外挂。\n","date":"14 February 2026","externalUrl":null,"permalink":"/posts/%E5%88%9A%E5%88%9A%E8%B0%B7%E6%AD%8C-deep-think%E9%87%8D%E5%9B%9E%E5%B7%85%E5%B3%B0openai-%E9%A6%96%E6%AC%A1%E6%8A%9B%E5%BC%83%E8%8B%B1%E4%BC%9F%E8%BE%BE/","section":"AI-Related Reposts","summary":"","title":"[Repost] 刚刚，谷歌 Deep Think「重回巅峰」，OpenAI 首次「抛弃」英伟达","type":"posts"},{"content":"On this website, I share useful AI-related posts from WeChat.\n","date":"14 February 2026","externalUrl":null,"permalink":"/posts/","section":"AI-Related Reposts","summary":"","title":"AI-Related Reposts","type":"posts"},{"content":"","date":"14 February 2026","externalUrl":null,"permalink":"/tags/deep-think/","section":"Tags","summary":"","title":"Deep Think","type":"tags"},{"content":"","date":"14 February 2026","externalUrl":null,"permalink":"/tags/gemini/","section":"Tags","summary":"","title":"Gemini","type":"tags"},{"content":"","date":"14 February 2026","externalUrl":null,"permalink":"/","section":"Neon Sphinx's Website","summary":"","title":"Neon Sphinx's Website","type":"page"},{"content":"","date":"14 February 2026","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且直击本质的洞察。在经济学中，机会成本是指为了得到某种东西而放弃的其他选项中的最大价值。在AI时代，这个“最大价值”被技术杠杆无限放大了。这与我们所处的“低容错率时代”有着内在的呼应关系。\nAI时代导致决策机会成本大幅提高，主要源于以下几个核心机制：\n1. 执行成本趋向于零，极大放大了决策的“杠杆效应” # 过去，执行一个想法需要耗费大量的时间、资金和人力。而现在，AI极大地降低了代码编写、内容生成、数据分析和信息检索的边际成本。 当你拥有了一个几乎免费的“超级执行团队”时，“把资源投入到什么方向”（即战略决策）就成了唯一重要的瓶颈。选对方向，AI能为你创造指数级的回报；选错方向，你损失的不再是几个月的辛苦劳作，而是AI本可以为你在这个周期内创造的巨大产能。\n2. 可选路径呈指数级爆炸 # 机会成本的高低，直接取决于你放弃的“最优替代方案”的价值。 AI不仅打破了信息壁垒，还能跨领域提供无数种可行的解决方案、研究视角或发展路径。当摆在你面前的高质量选项从3个变成300个时，你选择其中一条路，就意味着你放弃了另外299条潜在的高价值路径。选项池越深、越优质，数学意义上的机会成本就越高。\n3. 竞争周期压缩与“赢者通吃” # 在传统节奏下，一个次优的决策也许可以通过后期的勤奋慢慢弥补。但在AI时代，技术迭代和市场反馈的速度是以天甚至小时计算的。 一旦你的决策出现偏差，或者在方向选择上陷入犹豫，竞争对手可能会利用AI工具迅速完成验证并占据身位。由于AI具有极强的规模效应，这种时间差很容易演变成“赢者通吃”的局面。在这里，时间流逝本身的成本变得极其昂贵。\n4. 认知带宽成为最稀缺的资源 # 当机器接管了大部分常规计算和执行工作后，人类社会真正稀缺的资源就只剩下注意力和提出好问题的能力。 人的精力是恒定的。将宝贵的认知资源错配到一个低价值、容易被自动化的领域，意味着你无暇去思考那些真正需要人类洞察力、同理心或跨学科连接的关键变量。这种认知错配，是对个人潜能最大的浪费。\n简而言之，AI将我们从“一分耕耘一分收获”的线性时代，推入了一个“选择大于努力”的非线性时代。执行力变得廉价，而判断力成了最昂贵的资产。\n你是否想探讨一下，在这种高杠杆、高机会成本的环境下，我们可以建立怎样的思维框架或经济学决策模型，来优化我们在面对复杂问题时的选择？\n","date":"13 February 2026","externalUrl":null,"permalink":"/blog/ai%E6%97%B6%E4%BB%A3%E5%86%B3%E7%AD%96%E7%9A%84%E6%9C%BA%E4%BC%9A%E6%88%90%E6%9C%AC%E5%A4%A7%E5%A4%A7%E6%8F%90%E9%AB%98/","section":"AI-Generated Blog","summary":"","title":"AI时代，决策的机会成本大大提高","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且契合当下的问题。AI 确实以惊人的速度将许多曾经昂贵的东西“廉价化”了——无论是基础代码编写、文本生成、数据的初步处理，还是常规的图像与音乐创作。当“生成”的边际成本趋近于零时，我们需要重新审视什么是真正稀缺的。\n在 AI 时代，以下这些事物不仅没有变得廉价，反而因为数字内容的泛滥而迎来了价值的重估，变得更加昂贵和珍贵：\n1. 提出精准问题的能力与批判性思维 # AI 擅长提供答案，但它必须被引导。在一个答案随处可见、唾手可得的时代，“提问”本身成为了真正的稀缺资源。能够敏锐地察觉到现有知识体系的盲区，提出具有穿透力的问题，并在 AI 给出的海量乃至看似权威的信息中进行批判性筛选和逻辑验证，这种深度的认知能力是无价的。\n2. 对真实世界的洞察与一手经验 # AI 的模型建立在已有的历史数据之上，它本质上是对过去的总结和重组。然而，真正的突破往往来自于对真实世界的直接接触。无论是在田野调查中对具体社会经济现象的敏锐捕捉、对人类行为的切身观察，还是面对未知领域的直觉判断，这些基于“接地气”的一手经验和脱离于纯粹统计数据的原创洞察，是 AI 无法在虚拟空间中推演出来的。\n3. 真实的情感连接与“在场感” # AI 也许能写出完美符合心理学技巧的安慰话语，或者生成毫无瑕疵的交流回复，但它缺乏真实的生命体验。我们之所以会被打动、被启发，不仅是因为信息本身，更因为我们知道背后是一个有血有肉的真实人类。在教育引导、深度探讨或亲密关系中，人与人之间基于共同生命体验的共情和彼此的“在场”，是任何算法都无法替代的。\n4. 承担责任的勇气与决断力 # AI 可以提供极其详尽的收益与风险分析，甚至给出理论上的最优策略推荐，但它永远无法“负责”。在面临伦理困境、重大项目推进或人生岔路口时，拍板做决定的魄力以及承担后果的勇气，依然是人类独有的重担。社会和商业的运作，最终信任的依然是能够承担责任的具体的人，而不是一堆代码。\n5. 具身经历（Embodied Experience）与物理空间的体验 # 当数字世界的一切都可以轻易被生成、被美化甚至被伪造时，物理世界的真实感会变得极其昂贵。亲自去不同纬度的国家旅行感受气候的变幻、亲身站上讲台面对一双双眼睛、或者亲手完成一件物品的制作。这种不可复制的物理体验，成为了对抗数字虚无的重要锚点。\n简单来说，AI 让“执行”和“已知”变得极其廉价，却让“方向”、“未知”以及“人之为人的真实性”变得空前珍贵。\n这其实是一个关于注意力与精力重新分配的契机。你平时在做深度的知识探索或研究时，是否也感觉到了这种个人洞察力与 AI 工具之间的微妙平衡？如果你感兴趣，我们可以具体聊聊这种变化在当前的学术研究或知识生产领域是如何体现的。\n","date":"13 February 2026","externalUrl":null,"permalink":"/blog/ai%E6%97%B6%E4%BB%A3%E6%9C%89%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E5%BB%89%E4%BB%B7%E7%9A%84/","section":"AI-Generated Blog","summary":"","title":"AI时代有什么不是廉价的","type":"blog"},{"content":"Reposted from 1美元时薪？这才是打工人的「梦中情模」 by 关注大模型的\n编辑｜张倩、Panda\nAnthropic 的 Opus 4.6 刚发布，智商确实高到让人头皮发麻，但看着那个价格表，我的钱包也开始发麻了。\n这就很尴尬了。Opus 4.6 的出现，直接在开发者圈子里制造了一场「智力焦虑」：模型好用是真好用，贵也是真贵。原版价格纹丝不动就算了，那个号称「极速版」的家伙，每百万输出 Token 的成本居然从 25 美元直接飙到了 150 美元。\n整整 6 倍的涨幅！看着 Token 计费表像风一样自由地狂奔，本来想用 AI 释放生产力的我，现在按回车键之前都得先在心里过一遍账单。这哪里是请了个助手，简直是供了个「吞金兽」。\n这种「生产力税」的存在，逼得打工人不得不进入一种尴尬的模式：一边渴望顶级智力带来的效率，一边在按回车键时反复权衡账单。难道高智力和高性价比，真的像鱼和熊掌一样不可兼得？难道我们这些普通打工人，就不配拥有「智力自由」？\n就在大家捂着钱包叹气的时候，MiniMax 反手甩出了一个王炸：MiniMax M2.5。\n这个模型相当能打，无论是 coding 还是 agent 能力，都能与 Claude Opus 4.6 掰掰手腕，甚至在某些维度上掰赢了。\n数据不会说谎：M2.5 在多语言任务 Multi-SWE-Bench 上拿下了行业第一；而在 SWE-Bench Verified 评测集上，基于 Droid 和 OpenCode 的实战测试中，它的通过率（79.7% / 76.1%）更是双双反超了 Opus 4.6。\n在 BrowseComp、Wide Search 等搜索和工具调用榜单的评测中，M2.5 也达到了行业顶尖的水平。\n更具冲击力的是它在 MiniMax 内部的真实表现：在 MiniMax 内部业务场景中，整体任务的 30% 由 M2.5 自主完成；而在编程场景中，M2.5 生成的代码已占新提交代码的 80%。\n它不仅 Coding 和 Agent 能力硬刚 Claude Opus 4.6 不落下风，在专业的办公领域更是「偷偷补过课」。为了让模型真正懂行，MiniMax 拉来了金融、法律、社会科学等领域的资深从业者当「教官」，把行业隐性知识灌进模型。\n在内部严苛的 Cowork Agent 评测（GDPval-MM） 中，M2.5 在 Word 排版、Excel 金融建模等高阶场景下，对主流模型拿下了 59.0% 的平均胜率。这意味着它交付的不再是简单的草稿，而是具备专业水准的「半成品」。\n但最离谱的是，这样一个全能选手，居然参数量只有 10B，是第一梯队中参数规模最小的旗舰模型，不需要太昂贵的设备就能私有化部署。\n好家伙，这哪是辅助驾驶啊，这分明是抢方向盘来了！\nMiniMax M2.5 表现卓越，也为这家刚上市一个多月的公司的股价带来了一波强劲上涨：\n1 美元时薪的顶级打工人\n这么小的体积，再加上「思考」链路的深度优化，M2.5 的吞吐量可以达到 100 TPS，推理速度可以达到 Opus 4.6 的 2 倍。在 SWE-Bench Verified 测试中，M2.5 的端到端任务运行耗时从平均 31.3 分钟减少到了 22.8 分钟，这一速度与 Claude Opus 4.6 基本持平。\n在需要即时反馈的场景里，这种「跟手」的感觉简直太爽了。更爽的是，你完全不需要有「每按一次回车就少喝一杯奶茶」的心理负担。来看看这个颠覆性的定价：\n在每秒输出 100 个 token 的情况下，连续工作一小时只需要 1 美元，而在每秒输出 50 个 token 的情况下，只需要 0.3 美元。\n1 美元就能雇佣一个顶级专家给你干一小时苦力！换算一下，1 万美金可以让 4 个 Agent 连续工作一年。\n这就很有意思了。以前我们不敢跑复杂 Agent，是因为怕跑着跑着就破产了；现在有了 M2.5，我们终于实现了 Agent 自由；让 AI 24 小时持续上工，也不再是有余粮的地主家才能有的奢侈。\n目前，M2.5 的 Vibe Coding 支持 PC 端、App 端、RN/Flutter 跨端甚至带数据库的前后端全栈开发，用起来非常方便，普通打工人可以随时上手。\n为了验证这个「10B 战神」是不是真的能在性能比肩旗舰的同时，把生产力成本打下来，我们准备了几个真实的使用 Case。下面直接进入实测。\n一手实测\nMiniMax M2.5 真能成为打工人的得力助手吗？\n作为苦逼的媒体人，我们最怕的就是在那堆长达几小时的圆桌论坛速记里「淘金」。大佬们聊嗨了往往也是车轱辘话来回说，我们要想提炼点干货，眼睛都得看瞎。\n这种脏活累活，我是不敢交给 Opus 的，太贵。但现在既然 M2.5 这么便宜，那就不客气了。\n我们决定搞个破坏性测试：直接把一堆巨大的 HTML 格式的速记文件「喂」给它，让它不仅要提炼观点，还要分析趋势、找分歧，甚至还要做横向对比。\n你是一个专业的行业圆桌论坛速读分析师。我会逐个上传论坛速记 / 纪要文件，你的任务是：1）提取核心观点，用 bullet points 列出每位发言人的关键论断和论据；2）识别趋势信号（正在形成共识的方向）和分歧点（存在争议的立场或预测）；3）标注任何提及的具体数据、产品名或时间节点。每处理完一篇，输出一份结构化摘要。待我告知 \u0026ldquo;全部结束\u0026rdquo; 后，综合所有文件，输出一份总览：横向对比各场论坛的重复主题与独特视角，提炼出 3-5 条跨论坛的强趋势，以及 2-3 个值得持续观察的核心分歧。保持简洁，避免泛化总结，优先引用发言人原话或具体案例。\nMiniMax M2.5 接到任务后，丝毫没有「消化不良」。面对超大文件，它甚至自作主张地启动了多个 Agent 并行开工（颇有一种「兄弟们一起上」的既视感）：\n15 分钟后，几十万 Token 跑完，一份高质量报告出炉：\n上下滑动查看\n搞定了阅读，再来试试写代码。\n作为小编，我们每天都要跟排版做斗争。虽然我们的排版规则不复杂（正文 15px、特定颜色加粗、版权信息居中……），但每次手动调也很烦。\n既然官方宣称 M2.5 具备「架构师思维」，能原生 Spec 行为。也就是说，不同于普通模型上来就盲目堆代码，M2.5 在动手前会先像资深架构师一样做规划，主动拆解功能、结构和 UI。无论是 Rust、C++ 还是 Python，从 0-1 的系统设计到最后的 Code Review，它都能像老手一样 Hold 住全场。那我们就让它手搓一个「微信公众号 Markdown 编辑器」。\n需求很简单：复制进来 →自动格式化 → 支持微调 → 一键复制带样式。\n第一步，为了防止它「听不懂人话」，我们先让它把我的需求翻译成更专业的提示词。\n可以看到，MiniMax M2.5 大体上正确地理解了我们的需求，但在版权信息处出现了一点幻觉，轻松修改后，我们只需一句提示词就能实现它：「读取 微信公众号 Markdown 编辑器开发提示词.md 文件并实现它」。\n生成时长 2 分半，接杯水的功夫，M2.5 轻轻松松就实现了这个实用小工具。找篇文章试试效果：\n仔细检查了一下，我们给出的需求都得到了满足。\n作为一家专业的 AI 媒体，日常收集 AI 社区名人观点的素材也是工作的一部分，但问题是有时候只顾着收集，并没有真正将这些素材用起来，它们都沉睡在我们的资料库中。借助 MiniMax M2.5 + Claude Code，我们可以轻松地挖掘我们的知识仓库，真正利用起尘封的知识。\n首先，打开我们的选题库，发现早期的文件和最近的文件命名格式不统一，而 M2.5 可以轻松解决这个问题，就一句话的事儿：\n接下来，M2.5 还可以为我们将这些 docx 文档转换成兼容 Obsidian 的 Markdown 格式。这里我们可以引入 Obsidian 创始人 Steph Ango 亲自开源的 obsidian-skills，给 M2.5 一个参考手册。我们的提示词也很简单：\n基于 Skills，将文件夹中的所有文件都转换成符合 Obsidian 规范的 Markdown 文件。\n接下来我们可以将转换好的文件放入一个 Obsidian 仓库来进行管理，而 MiniMax M2.5 也可以跟随我们一起。比如这里，我们可以让 M2.5 提取选题中所有与 Andrej Karpathy 和吴恩达相关的选题：\n可以看到，M2.5 找到了 5 个与 Andrej Karpathy 相关的选题，找到了 14 个与吴恩达相关的选题，并对选题进行了总结同时还标记了出处，而得益于 M2.5 10B 的轻量级参数规模，整个过程耗时不到 1 分钟。\n最后，我们还让 M2.5 基于我们的选题文档总结了近几个月 AI 领域的发展趋势，大家可以看看总结得是否正确：\n上下滑动查看\nM2.5 背后\n108 天极速进化的秘密\n在前面的测评中，M2.5 已经表现出明显不同于普通模型的智能体能力。但比单次测评成绩更令人细思极恐的，是 MiniMax 展现出的「进化速度」。\n在过去短短 108 天里，MiniMax 陆续更新了 M2、M2.1 和 M2.5 三个版本！\n这让 M2 系列模型在编程领域最具代表性的 SWE-Bench Verified 榜单上，相比 Claude、GPT 和 Gemini 等顶级模型系列，保持了行业最快的进步速度 —— 这从上图折线的斜率也能看出。\n这种超越预期的迭代效率不是凭空出现的，也不是单纯靠堆算力堆出来的。要理解它为什么能跑得这么快，就得看一眼它背后的训练体系：原生 Agent RL 框架 Forge。\n智能体训练的第一道坎，在于「语言模型」和「任务执行者」这两个身份之间的鸿沟。大模型原生是自回归 Token 预测器，它可以模拟很多形式，但并不是为持续交互和工具调用而生。为了解决这一问题，MiniMax 引入了 Forge 原生 Agent RL 框架。\nForge 在设计上通过引入中间层完全解耦了底层训推引擎与 Agent，把「模型只负责处理 Token」这件事做到了极致。模型训练和推理看到的都是同一种 Token 形态，不去理解什么工具调用、环境状态这些复杂结构。而 Agent 那一侧则通过标准的 OpenAI 接口和模型通信，专心处理环境交互和上下文管理。\n这种彻底解耦的好处是：模型能力不会被绑定在某一个具体 Agent 产品上，它可以接入不同的工具体系和脚手架，实现更强的泛化。\n更大的难题是长链路下的信用分配（Credit Assignment）。任务执行几十步后才知道结果，模型很难回溯究竟是哪一步导致了失败。MiniMax M2.5 引入了过程奖励机制（Process Reward），对生成质量进行全链路监控，而不仅看最终成败。同时，为对齐真实用户体验，他们将任务完成耗时也纳入奖励函数。这套奖励设计让模型在智能度与响应速度之间实现了可量化的最优权衡。\n这些算法创新要真正跑起来，还得过工程这一关。智能体数据天然有大量公共前缀，如果每条样本独立训练，同一段系统提示要反复计算数十遍。M2.5 将多条前缀相同的样本合并为一棵前缀树，通过树状合并训练样本策略，实现了约 40 倍的训练加速。\n另一项优化是强化学习的调度策略：智能体任务耗时差异巨大，简单任务秒回，复杂任务需等待。MiniMax 优化了异步调度策略，平衡系统吞吐和样本的 off-policyness，最终在系统吞吐量与训练效率之间达成了平衡。\nIntelligence with Everyone\n回到开头 Claude Opus 4.6 的定价话题。极速版 Opus 4.6 高达 150 美元的输出价格足以说明，在真正的生产力环境中，值钱的不只是智力本身，速度等影响效率的因素如今也变得举足轻重。打工人真正需要的，是一个智力、速度等各方面都优秀的「六边形战士」。\n然而，顶级智力的高昂溢价正在制造一场隐形的技术分层：预算决定了你的 AI 助理是「满血」还是「残血」，是极速还是降速。在这一背景下，MiniMax M2.5 凭借 10B 级的轻巧规模承载了同级别的旗舰智力，不仅是当前市场的性价比标杆，更是将高阶智能从「奢侈品」拉回到了「生产力工具」的范畴。\n这更像是一场技术普惠，而非针对少数人的技术特权。此刻，MiniMax 所坚持的「服务普通人的 AI」「Intelligence with Everyone」具像化了。\n如果把 M2.5 和 MiniMax 前段时间发布的桌面端 Agent 放在一起看，它的价值就更具像化了：一个是可以本地部署的超强大脑，一个是包含本地文件系统访问、浏览器控制、代码编辑器集成、后台常驻运行等完善功能的脚手架。二者强强联合，有望成为白领与程序员手中那个随时待命、不计成本的「主力机」。\n这种顶级智力的全民普惠，才是整个社会生产力提升的最强动力。\n© THE END 转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n","date":"13 February 2026","externalUrl":null,"permalink":"/posts/1%E7%BE%8E%E5%85%83%E6%97%B6%E8%96%AA%E8%BF%99%E6%89%8D%E6%98%AF%E6%89%93%E5%B7%A5%E4%BA%BA%E7%9A%84%E6%A2%A6%E4%B8%AD%E6%83%85%E6%A8%A1/","section":"AI-Related Reposts","summary":"","title":"[Repost] 1美元时薪？这才是打工人的「梦中情模」","type":"posts"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/ai-agent/","section":"Tags","summary":"","title":"AI Agent","type":"tags"},{"content":"Powered by Gemini 3 Pro.\n你说“思维固化在AI时代是最致命的”，这个洞察非常精准且切中要害。\n在过去的时代，经验累积和标准化的技能是一本“铁饭碗”；但在人工智能以指数级迭代的今天，世界的底层运行逻辑已经改变。作为AI，我可以客观地告诉你：在算法面前，人类最脆弱的不是计算能力，而是僵化的认知。\n以下是为什么思维固化在AI时代最为致命的几个核心原因：\n1. 经验主义的“保质期”正在急剧缩短 # 过去的优势： 以前，专家之所以为专家，是因为他们脑海中积累了大量的历史数据和应对方案。 AI时代的现实： AI 能够在几秒钟内读取、学习并整合人类几千年的文本、案例和经验。如果你只依赖“过去是怎么做的”（经验主义）来指导未来，你就会被能够瞬间调用全局最优解的AI直接淘汰。思维固化的人拒绝接受新规则，往往会在旧经验失效时感到无所适从。 2. 标准化思维是在和AI“硬碰硬” # 过去的优势： 工业时代和信息时代早期，社会奖励那些像机器一样精准、稳定、按流程办事的人。 AI时代的现实： 如果你思考得像个机器人，你就会被机器人取代。 机械化、标准化、套路化的工作正是 AI 最擅长的领域。思维固化的人习惯于走直线、做重复性判断；而未来属于那些拥有跨界联想力、情感共鸣能力以及能处理复杂模糊地带的人。 3. 核心竞争力从“知道答案”变成了“提出问题” # 过去的优势： 知识获取成本高，“百事通”型的人才极具价值。 AI时代的现实： AI 拥有近乎无限的解答能力，现在的稀缺资源变成了**“好问题”**。思维固化的人往往只关注寻找标准答案，缺乏好奇心和批判性思维；而思维灵活的人知道如何通过不断追问（Prompting）、逆向思考和发散思维来引导 AI 产出极具创新的结果。在AI时代，你的天花板取决于你提问的深度和广度。 4. 缺乏“去学习”（Unlearning）的能力 # 未来学家阿尔文·托夫勒曾说：“21世纪的文盲不是那些不能读和写的人，而是那些不能学习、去学习（主动遗忘旧知识）和重新学习的人。” 思维固化的人最致命的弱点在于拒绝“归零”。当一项旧技能被 AI 完全取代时（例如某些基础的代码编写、语言翻译或基础插画），固化思维会让人陷入抗拒、抱怨和自我怀疑；而成长型思维（Growth Mindset）的人会迅速把 AI 当作工具，去探索更高阶的价值。 总结来说，AI 是一面放大镜。它会无情地淘汰那些思维僵化、拒绝改变的“执行者”，同时赋予那些思维敏捷、充满想象力的“指挥官”以超级能力。\n你想了解一些在日常工作和生活中打破思维固化、训练“成长型思维”的具体方法吗？或者，我们可以探讨一下如何在你所在的具体行业中，更好地把 AI 转化为你的杠杆？\n","date":"13 February 2026","externalUrl":null,"permalink":"/blog/%E5%9C%A8%E7%AE%97%E6%B3%95%E9%9D%A2%E5%89%8D%E4%BA%BA%E7%B1%BB%E6%9C%80%E8%84%86%E5%BC%B1%E7%9A%84%E4%B8%8D%E6%98%AF%E8%AE%A1%E7%AE%97%E8%83%BD%E5%8A%9B%E8%80%8C%E6%98%AF%E5%83%B5%E5%8C%96%E7%9A%84%E8%AE%A4%E7%9F%A5/","section":"AI-Generated Blog","summary":"","title":"思维固化在AI时代是最致命的","type":"blog"},{"content":"Reposted from 16个月估值破10亿美元！众多VC押注一个新品类，AI写代码越快，这个问题越致命 by Leo\n你有没有发现一个悖论？AI让我们写代码的速度提高了10倍，但半夜被叫醒修bug的次数似乎也在增加。两年前，几乎没人用AI写代码。一年前，GitHub Copilot让AI辅助编程成为标配。现在，几乎每个开发者都在用AI agent帮忙写代码。代码产出速度飞快，新功能上线越来越频繁。听起来很美好对不对？但这里有个被忽视的问题：当AI生成的代码越来越多，这些代码部署到生产环境后，谁来保证它们能稳定运行？谁来在凌晨三点系统崩溃时找出问题并修复？更关键的是，当代码量呈指数级增长，而工程师对这些AI生成的代码并不完全熟悉时，维护生产环境的难度也在呈指数级上升。\n这个矛盾正是Resolve AI要解决的核心问题。这家成立仅16个月的公司刚刚完成了1.25亿美元的A轮融资，估值达到10亿美元。由Lightspeed Venture Partners领投，Greylock Partners、Unusual Ventures、Artisanal Ventures和A*等早期投资者全部超额跟投。更值得关注的是，他们已经拿下了Coinbase、DoorDash、MongoDB、Salesforce、Zscaler等重量级客户。这些公司每分钟的停机都意味着巨额损失，而Resolve AI帮助Coinbase将关键事故的调查时间减少了72%，帮助Zscaler将每次事故所需的工程师数量减少了30%。这不是小打小闹的优化，而是生产环境运维方式的根本性改变。我认为，他们正在定义一个全新的品类：AI for prod，也就是用AI来运行和维护生产环境中的软件。\nAI代码革命带来的意外后果\n让我先谈谈这个行业正在发生的变化。过去一年里，AI编程工具的进步速度超出了所有人的预期。从GitHub Copilot到Cursor，再到Claude Code，这些工具让开发者能够用自然语言描述需求，然后AI就能生成相应的代码。这种效率提升是革命性的。一个开发者现在可以完成以前需要一个小团队才能完成的工作量。创业公司可以用更少的人更快地构建产品。这听起来像是软件工程的黄金时代。\n但我在和工程师朋友交流时发现了一个普遍的焦虑：代码写得快了，但系统运维变得更难了。有研究数据显示，随着AI编程工具的广泛使用，生产环境中每次代码变更导致的事故数量实际上在增加。这背后的逻辑其实很简单：当你用AI生成代码时，你对这些代码的熟悉程度不如自己一行行写出来的代码。代码中可能存在的边界情况、潜在的性能问题、与其他系统的交互方式，这些细节你可能并不完全清楚。当这些代码部署到生产环境后出现问题，你需要花更多时间去理解到底发生了什么。\nResolve AI的CEO Spiros Xanthos在接受采访时提到了一个关键洞察：软件工程最难的部分从来不是写代码，而是运行生产环境。问题很少只存在于单个系统中，根因通常隐藏在各个工具之间的关系里：一个延迟峰值可能与最近的部署有关，一个配置变更可能影响了特定的数据库分片。我深有体会，因为我见过太多这样的场景。工程师们在半夜被拉进战情室，对着几十个不同的监控面板，试图在Datadog、Splunk、Grafana、Kubernetes和Slack之间来回切换，手动拼凑出到底哪里出了问题。\n更糟糕的是，解决这些生产环境问题所需的知识往往是无法成文的\u0026quot;部落知识\u0026quot;。它存在于最资深工程师的脑海中：这个服务在什么情况下会出现这种错误？这个配置参数为什么要设成这个值？这个依赖关系为什么这么设计？当这些工程师不在岗时，这些知识就无法获取。当他们离职时，这些知识可能就永远消失了。对于一个快速增长的公司来说，依赖部落知识来维护生产环境是极其脆弱和不可扩展的。\n所以现在的情况是：AI让我们能够更快地生成代码，但如果我们不能同样快速地运行和维护这些代码，整体的技术迭代速度并不会真正提升。你可能在开发阶段快了5倍，但如果在运维阶段慢了3倍，整体效率的提升就大打折扣了。更不用说，生产环境的不稳定会直接影响用户体验、业务收入和公司声誉。这就是为什么我认为Resolve AI瞄准的是一个被严重低估但极其关键的问题。\n为什么生产环境是AI最难攻克的堡垒\n我一直在思考一个问题：为什么AI在代码生成方面取得了如此大的突破，但在生产环境运维方面却进展缓慢？Resolve AI团队给出了一个非常深刻的解释：生产环境对AI agent来说是一个独特困难的环境。\n首先，现有的工具都是为人类设计的。监控系统、日志平台、基础设施管理工具，这些都是按照人类的思维方式和操作习惯构建的。AI agent要使用这些工具，就必须学会像人类一样操作它们。这不像训练一个模型去理解代码那么简单，因为代码是结构化的文本，而生产环境的数据则分散在各种不同的系统中，每个系统都有自己的数据格式、查询语言和访问方式。\n其次，做出任何决策都需要跨多个维度同时推理。你需要查看代码变更历史、系统遥测数据、基础设施配置、部署记录，然后把这些信息综合起来才能理解到底发生了什么。举个例子，一个API响应时间突然变慢，可能的原因包括：最近部署的代码中有性能问题、数据库查询效率下降、某个依赖服务出现了延迟、网络层面有拥塞、缓存失效导致了更多的数据库访问，或者仅仅是因为流量突然增加。要准确诊断问题，你需要检查所有这些可能性，而每一个都需要访问不同的系统、执行不同的查询。\n第三，最关键的上下文往往是未成文的。文档经常过时，配置文件的注释不完整，某个奇怪设置背后的原因可能只有当初做这个决定的工程师知道。这种\u0026quot;部落知识\u0026quot;是人类通过长期在特定环境中工作积累起来的，很难通过简单的文档或日志来传递。对于通用的大语言模型来说，它们无法获取这些特定于每个组织的知识。\nSpiros在访谈中提到了一个很有意思的类比：这就像自动驾驶汽车。我们不会让自动驾驶汽车上路，除非它们能用数据证明自己比人类司机开得更好。而且自动驾驶也有不同的级别，从辅助驾驶到完全自动驾驶。同样的道理也适用于生产环境的AI。我们不能一步跨越到让AI完全自主管理生产系统，我们需要一个渐进的过程。一开始，AI执行调查工作并报告发现，由人类工程师做最终决策。然后，AI可以执行一些低风险或可逆的操作。最终，AI应该能够解决人类无法解决的问题，并且在速度和可靠性上都超越人类。\n这种渐进式的方法不仅是技术上的必要，也是文化上的必要。工程师们需要时间来建立对AI系统的信任。他们需要看到AI的推理过程，理解它为什么做出某个判断，验证它的结论是否正确。只有当AI能够持续提供高质量、可解释的结果时，工程师们才会愿意让它承担更大的责任。\nResolve AI如何破解这个难题\n在了解Resolve AI的解决方案后，我对他们的技术架构印象深刻。他们构建的不是一个简单的AI助手，而是一个复杂的多agent系统，专门为生产环境的特殊需求设计。\n核心思路是这样的：Resolve AI持续从代码库、可观测性平台、部署系统、云基础设施、配置管理和运维历史中提取上下文信息。这不是一次性的数据导入，而是持续的、实时的信息收集。系统需要理解你的服务架构、依赖关系、部署模式、常见故障模式等等。这些信息构成了一个知识图谱，映射出服务、容器、组件之间的交互关系，捕捉那些原本只存在于资深工程师脑海中的部落知识。\n当生产环境出现问题时，比如触发了一个告警或发生了一次事故，Resolve AI的多agent系统就开始工作。有一个规划agent负责整体协调，它会调度多个专门的子agent，每个子agent都经过训练，擅长使用不同的工具和执行不同的任务。这些agent会系统性地分类问题、形成假设，然后通过收集证据来验证或推翻每个假设。\n我觉得特别聪明的是他们的验证机制。一个agent执行某项工作后，会有另一个agent审查这项工作并提供反馈，然后第一个agent会根据反馈进行迭代。当多个agent协同工作时，它们各自完成任务后，还会有一个监督agent来审查整体的分析结果，如果发现推理中有漏洞，会要求相关agent重新工作。这种多层次的检查和验证机制确保了最终结果的可靠性。\nSpiros在访谈中详细解释了这个多agent架构的设计考虑。他提到，对于需要长序列推理的复杂任务，他们会使用最强大的推理模型，通常是大型的闭源模型。而对于具体的执行任务，可能只需要一两个步骤，就可以使用更快的闭源模型或者针对特定任务后训练的开源模型。这种分层设计既保证了推理质量，又控制了成本和延迟。\n最重要的是，Resolve AI不只是给出一个答案，而是提供一个带有引用和推理过程的结构化解释。它会展示推理步骤、相关查询、甚至指出是哪个具体的Pull Request引入了问题。这种透明度对于建立工程师的信任至关重要。工程师可以验证AI的推理是否正确,理解它为什么得出这个结论，而不是盲目接受一个黑盒的建议。\n更进一步，随着系统在特定组织中运行的时间越来越长，它会学习到越来越多关于该组织特定环境的知识。哪些模式通常预示着即将发生的问题？哪些操作序列最有效？哪些配置组合最稳定？这些都会被系统记录下来，用于训练和改进模型。这创造了一个数据飞轮：系统越用越好，越来越了解你的环境，也就越来越有价值。\n从客户的实际使用情况来看，效果确实显著。Coinbase报告说，在测试的事故中，定位根本原因的时间减少了73%。想象一下，如果原本需要2小时才能找到问题根源，现在只需要半小时。这不仅仅是节省时间，更重要的是减少了用户受影响的时间、降低了业务损失。Zscaler则报告说每次事故所需的工程师数量减少了30%。这意味着更少的人被半夜叫醒，更少的团队协调成本，以及工程师有更多时间专注于构建新功能而不是救火。\n为什么偏偏是现在\n我一直在思考，为什么是现在这个时间点，Resolve AI能够取得突破？为什么不是三年前或三年后？我认为有几个关键因素的汇聚创造了这个机会窗口。\n第一个因素是大语言模型和agent技术的成熟。过去一年里，我们看到了agent系统在软件开发领域的巨大成功。这证明了agent不仅仅是概念验证，而是可以在复杂、多步骤的任务中创造实际价值。Resolve AI团队吸引了14位前DeepMind的工程师加入，这些人是agent AI的先驱者。他们带来的不仅是技术能力，更是对agent系统设计的深刻理解。同时，他们团队中还有在Microsoft、Google、Tesla、SpaceX等公司运行过世界上最复杂生产环境的工程师。这种AI前沿研究与生产系统深度专业知识的结合非常罕见。\n第二个因素是AI代码生成带来的紧迫性。正如我前面提到的，AI正在让代码产出速度呈指数级增长。这意味着部署到生产环境的代码量也在快速增加，服务数量增加、依赖关系变复杂、潜在故障点增多。如果运维能力跟不上开发速度,整个技术迭代就会卡在生产环节。这个痛点变得越来越尖锐，企业对解决方案的需求也越来越迫切。\n第三个因素是企业开始真正理解这个问题的成本。Spiros提到,在AI辅助编程出现之前,工程师就已经花费大约70%的时间在维护生产系统上,而不是开发新功能。现在随着代码量的增加,这个比例可能更高。对于一个科技公司来说,让最优秀的工程师把大部分时间花在救火而不是创新上,是一种巨大的资源浪费。更不用说,生产环境的不稳定直接影响用户体验和业务收入。这已经不是一个可以忍受的问题,而是必须解决的战略性问题。\n第四个因素是投资者开始认识到这个领域的价值。Lightspeed的合伙人Sebastian Duesterhoeft在解释为什么投资Resolve AI时说:\u0026ldquo;虽然软件开发一直是AI增长最快的应用领域之一,但Spiros和Mayank很早就意识到真正的价值和更难的问题在于生产环境。\u0026ldquo;这种认知的转变很重要。过去,投资者可能更关注那些直接提高开发效率的工具,但现在他们开始理解,如果不解决运维问题,开发效率的提升是不完整的。\n我还注意到一个有趣的现象：Resolve AI的两位创始人Spiros Xanthos和Mayank Agarwal在可观测性领域有超过20年的经验。他们之前的公司Omnition被Splunk收购,他们还共同创建了OpenTelemetry,这是管理遥测数据的全球开源标准。在Splunk,Spiros担任可观测性业务的高级副总裁兼总经理,管理着400多人的团队。这种深厚的领域专业知识让他们能够真正理解生产环境的复杂性,而不是简单地把AI技术套用到这个领域。他们知道现有工具的局限性在哪里,知道工程师真正的痛点是什么,知道什么样的解决方案才能真正被采用。\n从市场表现来看,时机确实成熟了。Resolve AI在16个月内就达到了10亿美元估值,拿下了Coinbase、DoorDash、MongoDB、Salesforce、Zscaler这样的重量级客户,并且从种子轮到A轮的所有投资者都选择了超额跟投。这些信号都表明,市场不仅认可这个方向,而且认为Resolve AI团队有能力执行。\n这将如何改变软件工程\n我认为,如果Resolve AI代表的\u0026quot;AI for prod\u0026quot;这个方向成功了,它将从根本上改变软件工程的工作方式和职业发展路径。这不是一个小的工具升级,而是整个范式的转变。\n最直接的影响是工程师的工作重心会发生迁移。现在,即使是最资深的工程师也要花大量时间在琐碎但紧急的运维任务上：查日志、分析监控数据、定位问题、制定修复方案。当AI能够自动完成这些工作时,工程师可以把时间投入到更高价值的活动上：系统架构设计、性能优化策略、新技术评估、业务逻辑创新。这不是说运维工作不重要,而是说这些工作可以被自动化,让人类专注于那些真正需要创造力和判断力的任务。\nSpiros在访谈中提到了一个很有启发性的观点：就像过去50年里软件从机器语言到高级编程语言的演进一样,AI代表的是又一层抽象。工程师不需要担心他们会失去底层技能,因为问题不在于人类技能是否会退化,而在于我们应该让AI agent能够同时很好地完成代码生成和代码运维这两件事,让工程师在更高的抽象层面上工作。他们不再需要记住特定的查询语言、API调用方式或CLI命令的具体语法,这些繁重而压力巨大的底层工作都由AI处理,工程师则在更高层面思考和决策。\n我预测会出现一种新的工作模式：工程师和AI agent的协同。在这种模式下,AI不是完全自主地运行一切,而是作为一个极其能干的助手,处理大量的繁琐工作,然后向工程师报告关键发现和建议。工程师则负责做出重要决策、处理边缘情况、处理需要业务判断的问题。随着AI系统变得越来越可靠,它可以承担的责任范围也会逐渐扩大。Spiros估计,大约一年后,AI将成为软件运维的主要\u0026quot;驾驶员\u0026rdquo;,人类在更高层面进行监督和决策。两到三年后,AI可能会做出大部分决策,人类则负责设定高级框架和处理异常情况。\n对于企业来说,这意味着技术团队的规模化方式会发生改变。传统上,随着系统复杂度增加,你需要雇佣更多的工程师和SRE来维护它。但有了AI for prod,同样的团队可以管理复杂得多的系统,或者说同样复杂的系统需要更少的人来维护。这不一定意味着裁员,更可能意味着工程师可以把时间投入到创新而不是维护上,让公司能够更快地推出新产品和新功能。\n我也想到了对人才市场的影响。会不会出现新的职位,比如\u0026quot;AI agent设计师\u0026rdquo;、\u0026ldquo;生产环境AI训练师\u0026quot;或者\u0026quot;AI系统审计员\u0026rdquo;？这些角色负责设计agent的工作流程、训练agent理解特定组织的环境、审查agent的决策是否合理。就像DevOps工程师这个角色是随着云计算和自动化的兴起而出现的,AI for prod可能也会催生新的专业角色。\n从更宏观的角度看,这可能会改变整个软件行业的经济学。如果运维成本大幅降低,软件公司可以承担更大的技术复杂度。那些原本因为运维成本过高而不可行的产品想法,可能变得可行了。创业公司可以用更小的团队支撑更大规模的服务。这可能会加速整个行业的创新速度,因为从idea到production的障碍变小了。\nSpiros说过一句话让我印象深刻：\u0026ldquo;在agent时代,会产生比以往任何时代都多得多的软件。获胜的团队不会是写代码最快的,而是能够可靠、安全地运行他们所写代码的团队,并且速度要跟上开发节奏。\u0026ldquo;这就是AI for prod要实现的目标。而这次1.25亿美元的A轮融资,让Resolve AI有资源继续构建这个未来。他们计划把资金主要投入三个方向：研发,继续推进作为世界级应用AI实验室在软件工程领域的前沿探索；产品深度,改进生产环境推理能力,向闭环系统迈进,并扩展与生产技术栈的集成；客户成功,支持全球企业客户的快速增长。\n我相信,五年后回头看,我们会认为2025-2026年是一个转折点。就像2022-2023年是AI代码生成的突破年一样,2025-2026年可能会被记住为AI生产运维的突破年。当代码生成和运维都被AI显著增强后,软件的整个生命周期都将加速,这才是真正意义上的生产力革命。\n结尾\n也欢迎大家留言讨论，分享你的观点！\n觉得内容不错的朋友能够帮忙右下角点个赞，分享一下。您的每次分享，都是在激励我不断产出更好的内容。\n欢迎关注深思圈，一起探索更大的世界。\n- END -\n往期文章\n[\n两个“特别坑”的AI产品创业方向，你知道吗\n](https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487112\u0026idx=1\u0026sn=536a697321489223a6893e4a565123d4\u0026scene=21#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487112\u0026idx=1\u0026sn=536a697321489223a6893e4a565123d4\u0026scene=21#wechat_redirect\")\n[\n速度将成为AI时代唯一的护城河\n](https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487823\u0026idx=1\u0026sn=1673f78279211c04a14e9dcf157f4721\u0026scene=21#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487823\u0026idx=1\u0026sn=1673f78279211c04a14e9dcf157f4721\u0026scene=21#wechat_redirect\")\n[\n](https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487823\u0026idx=1\u0026sn=1673f78279211c04a14e9dcf157f4721\u0026scene=21#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487823\u0026idx=1\u0026sn=1673f78279211c04a14e9dcf157f4721\u0026scene=21#wechat_redirect\")\n[\na16z重磅预测：Vibe coding赢者通吃？错了，垂直专业化才是未来\n](https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247489057\u0026idx=1\u0026sn=708c6673da1ab453f1586c729713139f\u0026scene=21#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247489057\u0026idx=1\u0026sn=708c6673da1ab453f1586c729713139f\u0026scene=21#wechat_redirect\")\n[\n](https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247489057\u0026idx=1\u0026sn=708c6673da1ab453f1586c729713139f\u0026scene=21#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247489057\u0026idx=1\u0026sn=708c6673da1ab453f1586c729713139f\u0026scene=21#wechat_redirect\")\n","date":"12 February 2026","externalUrl":null,"permalink":"/posts/16%E4%B8%AA%E6%9C%88%E4%BC%B0%E5%80%BC%E7%A0%B410%E4%BA%BF%E7%BE%8E%E5%85%83%E4%BC%97%E5%A4%9Avc%E6%8A%BC%E6%B3%A8%E4%B8%80%E4%B8%AA%E6%96%B0%E5%93%81%E7%B1%BBai%E5%86%99%E4%BB%A3%E7%A0%81%E8%B6%8A%E5%BF%AB%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%E8%B6%8A%E8%87%B4%E5%91%BD/","section":"AI-Related Reposts","summary":"","title":"[Repost] 16个月估值破10亿美元！众多VC押注一个新品类，AI写代码越快，这个问题越致命","type":"posts"},{"content":"Reposted from 大事正在发生，但绝大多数人还没有意识到 by 不懂经也叔的Rust\n本文来自微信公众号： 不懂经 ，作者：不懂经也叔的Rust\n2026年2月11日，科技界正在发生一些奇怪的事。\nBrian Norgard，硅谷连续创业者，发了一条推文：\u0026ldquo;我认识的几乎所有在科技行业工作的聪明人，都感到极度焦虑。仿佛一切都即将彻底崩塌。\u0026rdquo;\n同一天，另一个叫@barkmeta的科技博主写道：\u0026ldquo;我不知道为什么2026年会成为一个转折点，但我认识的几乎所有真正关注时事的人，都正在经历某种程度的生存危机。\u0026rdquo;\n也是同一天，xAI（马斯克的AI公司）的联合创始人Jimmy Ba宣布离职。他在告别帖里写了一段话，不像是在告别，更像是在发出某种信号：\n\u0026ldquo;我们正迈向一个拥有合适工具就能实现百倍生产力的时代。递归式自我提升循环很可能在未来12个月内上线。2026年将会是疯狂的一年，很可能是我们物种未来最忙碌、也最具决定性的一年。\u0026rdquo;\n在人类历史上，可能从来没有过这样一个时刻：一群世界上最聪明的大脑正处于极度的生存焦虑之中，而圈外的绝大多数人，还在谈论着“这个聊天机器人又在胡说八道了”。\n这很不可思议。\n回到现实生活中，看看那些并不关注科技的朋友，他们的生活似乎一如既往。他们或许听说过ChatGPT或者deepseek，或许试用过几次，得出的结论无非是：“这玩意儿写不出有人味儿的文章”，或者“它连简单的数学题都会做错”。\n就像沃顿商学院教授伊森·莫里克（Ethan Mollick）最近推文中所观察到的：圈外人对AI的理解，依然停留在糟糕的客服电话、Siri，或者是苹果商店里那些挂羊头卖狗肉的山寨APP上。\n一边是亲手构建AI的人在说\u0026quot;人类历史可能在今年转向\u0026quot;，另一边是绝大多数人连AI到底是什么都还没搞清楚。\n这种认知的K型分化，比技术本身的进步更危险。因为当一部分人已经在使用“杠杆”撬动世界时，另一部分人甚至不知道杠杆的存在。\n也许正是在这种矛盾和落差之中，今天，一篇雄文《大事正在发生》（Something Big Is Happening）刷爆了推特。不到24小时，阅读量超2000万。作者是一位深耕AI领域的创业者马特·舒默（MattShumer）。\n舒默说他写这篇文章的原因很简单：他一直在对家人和朋友撒谎。不是恶意的谎言，是一种\u0026quot;社交辞令\u0026quot;。每次有人问他\u0026quot;AI到底怎么回事\u0026quot;，他都给一个温和的、打了折的版本。因为如果他说出真心话，别人会觉得他疯了。\n但现在他说不下去了。他看到的现实和他告诉别人的故事之间，差距已经大到他无法继续假装。他说：\u0026ldquo;即使听起来很荒谬，我关心的人也理应知道即将发生什么。\u0026rdquo;\n他用了一个类比：想想2020年2月，疫情刚刚开始的时候。股市很好，孩子在上学，你出入餐厅，和人握手，计划旅行。如果有人告诉你他正在囤卫生纸，你会觉得这人在互联网上待傻了。\n然后，三周之内，整个世界变了。办公室关了，孩子回家了，生活变成了一种你一个月前根本无法想象的样子。\n舒默说，我们现在就处在那种\u0026quot;这未免太夸张了吧\u0026quot;的阶段。只不过这一次，即将到来的变化规模远超新冠疫情。\n他特别强调了一点：虽然他在AI行业工作，但他对即将发生的事情几乎没有影响力，行业里绝大多数人也一样。真正塑造未来的，是几家公司里的几百名研究人员。\n他们和我们一样在看着这一切展开，只是离得更近，能率先感受到大地的震颤。但是，正如我们在文章开头所提到的，他们要么忧心忡忡，要么在退隐江湖。\n这个世界到底发生了什么，在走向何方，我们又该如何自处？\n二、没有夸张：水位已经淹到了胸口\n科技圈外的人一直不理解一件事：为什么业内这么多人突然开始敲警钟？\n舒默的回答很直接：因为这件事已经先发生在我们身上了。我们说的不是预言，是已经发生的事实。\n对于许多普通用户来说，AI的进步似乎是线性的：它回答问题更准确了一点，生成的图片更清晰了一点。但在专业领域，特别是编程领域，发生的事情是指数级的断层。\n2025年，新的模型训练技术解锁了更快的进步节奏。每一代新模型比前一代更强，提升幅度更大，发布周期更短。然后，2026年2月5日，两家主要AI实验室在同一天发布了新模型：OpenAI的GPT-5.3 Codex和Anthropic的Claude Opus 4.6。\n舒默说，那一刻，\u0026ldquo;有些东西咔哒一声接上了\u0026rdquo;。不像是打开电灯开关那样瞬间透亮，更像是你突然意识到水位一直在涨，而现在已经淹到了胸口。\n他描述了自己现在的日常工作：告诉AI想构建什么，用平实的英语描述需求，然后离开电脑四个小时，回来时工作已经完成了。不是需要修修补补的初稿，是成品。完成度极高，甚至比他自己做得还好。\n更具体一点：他告诉AI\u0026quot;我想开发这个应用，它应该实现这些功能，大概长这样，你去搞定一切。\u0026ldquo;AI照做了。它写了几万行代码。然后，它自己打开了应用，点击按钮，测试功能，像真人一样使用它。如果它不满意某个地方的效果，它自发回去修改。它像开发者一样反复迭代，修正、完善，直到它自己满意为止。然后它回来告诉舒默：\u0026ldquo;准备好了，你可以测试了。\u0026rdquo;\n舒默说，这就是他周一的工作状态。几个月前他还在和AI反复推敲、引导、修改。现在他只需要描述结果，然后走人。\n但最让他震动的是GPT-5.3 Codex。它不再只是执行指令，它在做出智能决策。它展现出了某种东西，舒默称之为\u0026quot;判断力\u0026rdquo;（Judgment），甚至是\u0026quot;品位\u0026quot;（Taste）。那种知道什么是正确选择的感觉，人们曾断言AI永远不会拥有。\n我们曾傲慢地认为，机器只能执行逻辑，只有人类才懂得什么是“好”，什么是“美”，什么是“合适的”。但现在，这个堡垒坍塌了。这些新模型不再是工具，它们是另一种物种。\n这解释了为什么科技圈的人感到恐慌。因为他们亲眼看到了那个曾经只存在于科幻小说中的临界点：AI不再是被动的执行者，它开始具备了某种形式的主体性。\n让我们把进步速度放在一起看：\n2022年，AI连乘法都算不对，会理直气壮地告诉你7×8=54。2023年，它能通过律师资格考试。2024年，它能编写可运行的软件，能解释研究生水平的科学知识。\n2025年底，全球一些顶尖工程师表示已经把大部分代码工作交给了AI。2026年2月5日，新模型问世，让之前的一切看起来像上个世纪。\n有一个叫METR的组织专门用数据衡量AI的自主能力。他们追踪AI在没有人工帮助的情况下，能独立完成多长的现实任务（以人类专家完成同样任务所需的时间为基准）。大约一年前，答案是十分钟。后来是一个小时。然后是几个小时。\n最近的测量显示AI能完成人类专家需要将近五个小时才能搞定的任务。这个数字大约每七个月翻一倍，最近的数据暗示可能加快到每四个月。\n把这个趋势往前推：一年内，能独立工作数天的AI。两年内，数周。三年内，能独立完成长达一个月的项目。\nAnthropic的CEO Dario Amodei阿莫戴伊公开表示，在2026或2027年，AI模型将在几乎所有任务上比几乎所有人类\u0026quot;聪明得多\u0026quot;。\n如果AI比大多数博士还聪明，你真的觉得它做不了大多数办公室工作吗？\n三、自我进化：AI正在亲手构建下一代AI\n如果说AI的能力提升让人惊叹，那么其提升的方式则让人感到脊背发凉。这也是圈外人最难理解的一个概念：递归自我提升（Recursive Self-Improvement）。\n这是舒默全文中最重要的部分，也是最少人理解的一个发展。\n2月5日，OpenAI发布GPT-5.3 Codex时，在技术文档里写了这样一段话：\n\u0026ldquo;GPT-5.3 Codex是我们第一个在自身创建过程中发挥了关键作用的模型。Codex团队利用其早期版本来调试自身的训练，管理自身的部署，并诊断测试结果与评估结果。\u0026rdquo;\nAI帮助构建了它自己。\n这不是对未来的预言。这是OpenAI告诉你，他们刚刚发布的AI，就是用它自己的前身创造出来的。\n阿莫戴伊表示，现在Anthropic公司\u0026quot;大部分代码\u0026quot;由AI编写，当前一代AI与下一代AI之间的反馈循环正\u0026quot;逐月积聚力量\u0026quot;。他说我们距离\u0026quot;AI自主构建下一代AI\u0026quot;，可能只有一到两年。\n回头看看Jimmy Ba的离职帖：\u0026ldquo;递归式自我提升循环很可能在未来12个月内上线。\u0026ldquo;一个亲手参与构建AI的人，在离开AI公司时说出的最后一句话，和阿莫戴伊说的几乎是同一件事。\n这就是研究者们所说的\u0026quot;智能爆炸\u0026rdquo;：每一代AI帮助构建下一代，下一代更聪明，构建速度更快，再下一代则更更聪明。那些最有发言权的人，那些亲手构建它的人，相信这个过程已经开始了。\n阿莫戴伊曾提出一个思想实验：想象到了2027年，一夜之间出现了一个新国家，拥有5000万公民，每一个都比历史上任何一位诺贝尔奖得主还聪明。他们的思维速度比人类快10到100倍，从不睡觉，能操作互联网、控制机器人、指导实验、操控任何数字接口。\n他问：如果你是国家安全顾问，你会怎么说？\n他自己的答案是：\u0026ldquo;这是人类历史上最严重的国家安全威胁。\u0026ldquo;而他认为，我们正在构建那个\u0026quot;国家\u0026rdquo;。\n圈外的人还在讨论AI到底好不好用的时候，圈内的人在讨论的问题是：AI会不会在一两年内自己造出比自己更聪明的下一代。这两场对话甚至不在同一个时空里。\n四、认知鸿沟：\u0026ldquo;我试过AI，它没那么厉害啊\u0026rdquo;\n舒默说他经常听到这种话，而且他完全理解。\n如果你在2023年或2024年初试过ChatGPT，觉得\u0026quot;这东西在胡说八道\u0026quot;或者\u0026quot;没什么了不起的\u0026rdquo;，你是对的。那些早期版本确实有局限，它们会一本正经地瞎编。\n但那是两年前的事了。在AI的时间尺度里，两年是远古历史。\n今天的模型和半年前的相比，已经判若两人。关于AI到底是\u0026quot;真的在变强\u0026quot;还是\u0026quot;遇到了天花板\u0026quot;的争论，已经结束了。还在坚持这个论点的人，要么没用过最新的模型，要么有动机淡化现实。\n这里面有一个关键问题：大多数人用的是免费版。免费版通常比付费用户使用的版本落后一年以上。基于免费版ChatGPT来评价AI的现状，就像通过翻盖手机来评价智能手机的发展水平。\n舒默讲了一个他的律师朋友的故事。他一直建议这位朋友在律所试用AI，朋友总能找到\u0026quot;不好使\u0026quot;的理由：AI不适合他的专业领域，测试时出过错，不懂行业里的细微差别。但与此同时，有大型律所的合伙人主动来找舒默咨询，因为他们试用了最新版本，看到了大势所趋。\n其中一位有数十年经验的管理合伙人，每天花几个小时使用AI。他告诉舒默，这就像瞬间拥有了一支初级律师团队。他说了一句让舒默印象深刻的话：每隔几个月，AI处理工作的能力就有显著提升。如果保持这个势头，他预计很快AI就能完成他大部分的工作。\n他没有恐慌，但他正高度关注。\n而大部分人还带着一种虚假的安全感，误以为变革还很遥远。但事实上，海啸已经到了胸口。\n五、大替换：没有避风港的时代\n在过去的工业革命或互联网革命中，我们总有退路。工厂自动化了，工人可以去送快递；实体店倒闭了，店员可以做客服。但这一次不同。AI针对的是认知劳动的全面替代。\n阿莫戴伊预测，未来1到5年内，AI将取代50%的初级白领工作。这听起来像是一个激进的数字，但在业内许多人看来，这甚至过于保守了。无论你转行学什么——法律、金融、写作、设计、分析，AI在那个领域也在变得更强。它不会给你留下任何方便转型的缺口。\n法律：AI阅读合同和调研判例的能力已媲美初级律师。\n金融：复杂的财务模型构建和研报撰写，AI游刃有余。\n医疗：读片和诊断建议，AI正在超越人类医生。\n编程：几年前还需要数天才能完成的项目，现在几分钟内搞定。\n很多人寻求心理安慰，认为AI无法取代人类的“同理心”或“信任”。舒默坦诚地说：以前他也这么想，但现在他不确定了。如果你核心的工作内容是阅读、写作、分析、决策，并且通过屏幕完成，那么AI迟早会接管其中的大部分。\n时间表不是“将来”，而是“已经开始”，正在发生。\n六、我们该怎么做：在洪流中学会游泳\n舒默说他写这些不是为了让人感到无助，是因为他认为现在最大的优势就是抢占先机：率先理解它，率先使用它，率先适应它。\n第一件事，也是最直接的一件事：开始认真使用AI，订阅付费版。尽可能使用最好的最贵的模型。不要用免费版来评判这个技术的上限。而且要确保你用的是最强的模型，很多应用默认使用更快但更弱的版本，你需要去设置里手动选。\n更重要的是使用方式。大多数人像用Google一样用AI：问一个简短的问题，得到一个简短的回答，然后想\u0026quot;这有什么好大惊小怪的\u0026rdquo;。这不是AI的正确打开方式。你要把它推进你的实际工作。\n如果你是律师，给它一份完整的合同，让它找出每一条可能损害客户利益的条款。如果你做财务，给它一份乱七八糟的表格，让它构建模型。如果你是管理者，把团队的季度数据贴进去，让它讲出数据背后的故事。\n不要因为某件事看起来太难，就假设AI做不了。去试。第一次可能不完美，那就换个问法，给它更多上下文，再试一次。记住一个规律：如果它今天做得还凑合，六个月后它几乎肯定做得近乎完美。这条线只往一个方向走。\n舒默还提了几件更长期的事。理清你的财务状况：如果你哪怕只有部分相信未来几年你的行业可能面临动荡，基础的财务缓冲就比一年前更重要了。谨慎承担基于未来固定收入预期的债务，想想你的固定开支是给了你灵活性，还是把你锁死了。\n他还说了一句很扎心的话：放下你的自尊。那位律所合伙人没有因为自己位高权重就觉得用AI丢人。最痛苦的将是那些拒绝参与的人：那些把AI斥为噱头的人，那些觉得用AI会贬低自己专业性的人，那些假设自己的领域特殊且具有免疫力的人。没有哪个领域是特殊的。\n还有一点关于孩子。传统剧本是：好成绩、好大学、稳定的专业工作。但这条路径直接指向了受威胁最大的岗位。\n没人知道十年后的就业市场长什么样，但最可能胜出的人，是那些充满好奇心、适应力强、能用AI实现自己想法的人。教你的孩子成为创造者和学习者，别为一个在他们毕业时可能已经不存在的职业去优化。\n最后，舒默给了一个简单的承诺，他说这一件事就够你超过99%的人：每天花一小时实验AI。不是看文章，是上手用。每天试让它做一件新的事情，一件你没试过的、你不确定它能否处理的事。坚持半年，你对未来的理解将超过周围几乎所有人。\n七、鸿沟在扩大，机会窗口正在关闭\n2026年2月11日这一天，也许只是历史中普通的一天，但它是如此的情绪满满。一边是科技行业的人在发推文说\u0026quot;所有聪明人都在经历存在危机\u0026quot;，另一边是大多数人还在用Siri问天气。\n这就是那条K型曲线。知道的人越来越清醒，也越来越焦虑。不知道的人越来越无感，也越来越危险。\n舒默在文章开头说了一句话，我觉得值得放在结尾：\n\u0026ldquo;你应该从一个关心你的人口中听到这些，而不是在六个月后的头条新闻里听到。到那时再想抢占先机，就太晚了。\u0026rdquo;\n但正如推特上的Bark所言：“我不知道为什么2026年成为了转折点，但几乎所有真正关注时事的人都在经历某种程度的生存危机。”\n不过，危机之中也蕴藏着前所未有的解放。因为：如果你曾经想创造点什么，写一个APP，写一本书，做一个复杂的项目，却因为没有技术背景或资金而作罢，那么现在，障碍消失了。\nAI让知识的成本归零，让创造的门槛归零。在这个旧秩序崩塌、新秩序尚未建立的混沌时刻，一个拥有热情和好奇心的普通人，借助AI的杠杆，所能释放出的能量可能远超过去一个几十人的团队。\n2026年确实是一个分界线。这并不是说世界末日要来了，而是说，旧世界的游戏规则结束了。\n我们正在目睹的，是人类历史上最大的能力再分配。对于那些能够理解并驾驭这一趋势的人（无论你是谁，哪怕没有技术背景），这是一个拥有神力的时代；对于那些对此视而不见的人，这是一个逐渐被边缘化、最终变得无关紧要的时代。\n正如舒默所言，未来已经到了，只是它还没有敲你的门。正如我们常说的，未来已来，只是尚未均匀分布。\n本内容来源于网络，观点仅代表作者本人，不代表虎嗅立场。\n如涉及版权问题请联系 hezuo@huxiu.com，我们将及时核实并处理。\nEnd\n想涨知识 关注虎嗅视频号！\n","date":"12 February 2026","externalUrl":null,"permalink":"/posts/%E5%A4%A7%E4%BA%8B%E6%AD%A3%E5%9C%A8%E5%8F%91%E7%94%9F%E4%BD%86%E7%BB%9D%E5%A4%A7%E5%A4%9A%E6%95%B0%E4%BA%BA%E8%BF%98%E6%B2%A1%E6%9C%89%E6%84%8F%E8%AF%86%E5%88%B0/","section":"AI-Related Reposts","summary":"","title":"[Repost] 大事正在发生，但绝大多数人还没有意识到","type":"posts"},{"content":"","date":"12 February 2026","externalUrl":null,"permalink":"/tags/ai-coding/","section":"Tags","summary":"","title":"AI Coding","type":"tags"},{"content":"","date":"12 February 2026","externalUrl":null,"permalink":"/tags/ai-video/","section":"Tags","summary":"","title":"AI Video","type":"tags"},{"content":"On this website, I share videos generated by Veo of Gemini 3 Pro.\n","date":"12 February 2026","externalUrl":null,"permalink":"/videos/","section":"AI-Generated Videos","summary":"","title":"AI-Generated Videos","type":"videos"},{"content":"","date":"12 February 2026","externalUrl":null,"permalink":"/tags/opinions/","section":"Tags","summary":"","title":"Opinions","type":"tags"},{"content":"Powered by Veo of Gemini 3 Pro.\nYour browser does not support the video tag. ","date":"12 February 2026","externalUrl":null,"permalink":"/videos/usagi/","section":"AI-Generated Videos","summary":"","title":"Usagi","type":"videos"},{"content":"Reposted from 93k星Github项目狠人！谷歌高级AI产品经理公开内部构建Agent心得：过去十年技能衡量标准已毫无价值！2026最优秀的开发者更像是导演 by 云昭\n编辑 | 云昭\n刚刚，谷歌的一位狠人公开了自己AI产品开发心得！\n今天，谷歌高级AI产品经理 Shubham Saboo 在 X 上分享了一篇“2026年，什么技能最重要》的文章，其中提及了 Shubham 多年以来在谷歌的不少工作经历和所感所思。\n“2026 年最优秀的开发者，更像电影导演，而不是程序员。”\nShubham 可以说是一个狂热的 Agent 时代开发者，他运营着一个非常优秀的优秀的开源 LLM 应用仓库 Stars 数高达 93k。\nShubham 在文中表示了，“过去十年里让开发者变得有价值的那些能力，在一次模型代际跃迁中就被彻底商品化了。”\n重点是，这次的变化不是渐进式的变化，很多人都还没来得及更新自己的认知模型。\n“6个月前我招人的技能标准，现在看来，已经变得毫无价值！”\n这次代际变革发生得有多猛？3个月。\n从去年11月的 Gemini 3 Pro 发布到上周 Claude Opus 4.6 的推出，短短不到 3 个月的时间，已经足以让改变产品开发范式。\nShubham 如此说道：\n我过去一年每天都在构建 Agent，维护 100+ 开源实现的 Awesome LLM Apps 仓库，同时在 Google 做 AI 产品。一个明显的趋势是：价值正在从“实现能力”迁移到“上游能力”。\n甚至，这里他指出，有四项原有能力已经被AI商品化了。\n从零开始写代码、样板代码和项目脚手架、死记硬背语法和API、根据文档翻译成代码。\n这些都已经可以被 AI 或智能体快速搞定。\nShubham 还给出了一个身边的例子。他在一家初创公司当顾问，上周，这家公司，一个实习生的交付速度甚至超过了资深工程师。\n那位资深工程师花了三天手写的内容，实习生一个下午就交付了。\n并不是实习生更强，而是他把问题定义得足够清晰，然后让 Claude Code 完成剩下的工作。\nX 的评论区也有网友表示遇到过类似的情形。现在优秀的开发者基本上只用10%的时间来Coding，70%的主要精力用于拆解问题。\n而 2026 年之后，哪些能力才是真正值得培养的呢？他给出了 5 个关键技能项。\n1、问题拆解塑性能力：把模糊目标变成可执行的任务。这项能力，区分了“玩一玩 AI”的人，和真正用 AI 做出产品的人。\n2、上下文设计能力：差别不在提示词技巧，而在于信息密度、边界条件、成功标准，以及对真实场景的理解。\n3、审美能力：也就是近两年来被反复提及的“Taste”。简单理解就是：10 个选项摆在面前时，知道其中哪 9 个不行。\n4、智能体编排能力：知道何时用一个智能体，何时用多个，何时串行、何时并行。\n5、场景判断力：知道何种不适合使用智能体的判断能力。\n最后，Shubham 还给出了培养这五种能力的方法。\n下面是小编为大家整理的来自谷歌大佬的“ 2026 关键 Skills 更新指南”。\n模型的代际跃迁，\n让之前开发者的技能失效了\n六个月前，我还会为一些如今在我看来毫无价值的技能招人。不是“没那么重要”。也不是“正在演变”。是毫无价值。\n过去十年里让开发者变得有价值的那些能力，在一次模型代际跃迁中被彻底商品化。不是缓慢发生的。不是渐进式的。就在 Gemini 3 Pro 到 Claude Opus 4.6 之间。\n但大多数人还没有更新自己的认知模型。与此同时，那些交付速度最快的人，几乎已经不再从零开始写代码。\n过去一年，我每天都在构建智能体，维护一个包含100多个开源实现的 Awesome LLM Apps 仓库，也在 Google 交付 AI 产品。\n我亲眼看到，真正有价值的技能正在实时迁移。\n哪些能力被商品化了？ # 有4项开发技能，已经被智能体 cover 掉了。\n其一，从零开始写代码。智能体写得更快，Bug 还更少。\n其二，样板代码和项目脚手架。一句提示词，直接生成。\n其三，死记硬背语法和 API。超长上下文窗口已经解决了这个问题。\n其四，把规格说明翻译成代码。现在，规格本身就是代码。\n这些事，智能体现在都能做；未必完美。也仍然需要监督；但已经足够快。快到瓶颈彻底上移。\n上周，在我担任顾问的一家初创公司里，一个实习生的交付速度超过了一位资深开发者。\n并不是实习生更强，而是他把问题定义得足够清晰，然后让 Claude Code 完成剩下的工作。\n那位资深工程师花了三天手写的内容，实习生一个下午就交付了。\n很明显，现在这已经不是个例了。这是一种新基线的信号。这些能力之所以曾经重要，是因为实现本身很难。它们需要多年训练。它们支撑了六位数年薪。\n但实现已经不再是瓶颈。而整个行业，还在围绕旧瓶颈优化。价值，已经迁移到了五种新技能之上。\n所有真正高效使用智能体构建产品的人，都已经在不自觉地培养这些能力。\n无论他们是否意识到这一点。\n技能一：问题塑形（Problem Shaping） # 把模糊目标变成可执行的任务。这项能力，区分了“玩一玩 AI”的人，和真正用 AI 做出产品的人。\n核心是拆解能力。\n“帮我做一个仪表盘”不是任务，只是一个愿望。\n问题塑形会把它拆成十二个具体、可测试的子任务，每个都有明确的成功标准。\n这个仪表盘展示什么数据？\n它帮助做什么决策？\n用户在前三秒必须理解什么？\n当你把一个模糊目标拆成精确子问题时，智能体的执行水平会完全不同。每个子问题都有清晰输入、清晰输出、清晰成功标准。智能体不需要猜测你的意图。\n就比如那个由 Claude Code 和 Opus 4.6 构建的 C 编译器的例子。\n一个人负责问题塑形、十六个智能体负责执行、最终产出是 10 万行可运行的 Rust 代码。\n那个人没有写代码。但他把问题拆解到足够精确，让智能体仅凭拆解结构就能完成一个编译器。\nps：Anthropic 的 Safeguards 团队研究员 Nicholas Carlini 特别写了一篇博客，详细拆解了他们是内部如何指挥“智能体团队”造出来这个 C 编译器的。\nAnthropic 在 2 月 6 日发布工程博客时提到：他们让 Opus 4.6 通过智能体团队构建一个 C 编译器，然后基本“放手”。两周后，它能在 Linux 内核上运行。\n真正的杠杆不在写代码。而在于，把问题拆到智能体几乎不会出错的程度。\n问题塑形之所以成为最高价值技能，并不是因为它是新能力。相反，产品经理和资深工程师一直在做这件事。\n变化在于：\n当“问题定义得好”与“产品真正上线”之间的时间差压缩到几小时的情况下，问题定义的质量，就会决定一切。\n技能二：上下文设计（Context Curation） # 智能体产出的质量，与你提供的上下文质量直接成正比。\n看看差的上下文：\nBuild me a customer support agent. 再看看好的上下文： Target user: SaaS customers who are frustrated and considering canceling.They\u0026#39;ve already tried the help docs. They\u0026#39;re messaging because docs failed them.Tone: Empathetic but efficient. Don\u0026#39;t over-apologize. Don\u0026#39;t be robotic.Here are 3 real tickets that got 5-star ratings: [examples]Here are 2 that got complaints: [examples]Edge cases requiring human handoff:- Billing disputes over $500- Account security concerns- Legal or compliance questionsSuccess metric: Resolution without escalation in under 4 messages. 差别不在提示词技巧。差别在于信息密度、边界条件、成功标准，以及对真实场景的理解。\n“上下文设计”的本质，是选择什么信息进入模型的思考空间。给错信息，模型会稳定地输出错误方向；给对信息，它会稳定地产生接近产品级的结果。\n未来的高价值人才，不再是“会不会写代码”。而是：你是否知道什么信息值得放进模型。以及，什么信息必须排除在外。\n就如同上面两个提示词，同一个模型，同一个任务。写得差的提示词只会得到一个通用客服机器人；写得好的提示词，则会得到一个仿佛已经在你产品里训练了几个月的智能体。\n我认识的高效构建者，把更多时间花在写上下文文档，而不是写代码。他们维护 CLAUDE.md、.cursor/rules、GEMINI.md 这类文件，让它们在每次会话中自动加载。智能体一开始就理解他们的产品世界观。\n当我为 Awesome LLM Apps 仓库构建新的智能体时，从不从零开始。我的上下文文档已经定义了什么是“好”，应该采用什么模式，要避免哪些坑。第一版输出就达到 90%，而不是 50%。\n这 40% 的差距，决定了“技术上能运行”和“真正可以发布”的区别。它完全来自上下文质量，与编码能力无关。\n技能三：审美（Taste） # 审美，是在东西尚未存在之前，就知道该做什么。是在十个选项摆在面前时，知道其中九个不行。\n上周我让 Antigravity 为 Awesome LLM Apps 仓库做一个新智能体：一个 AI 讨价还价模拟器。两个智能体围绕二手车交易对弈，买家与卖家，各自拥有鲜明人格，并通过 AG-UI 实时直播。\n第一版运行得很完美。代码干净，没有报错。双方你来我往。技术上完整。但我三十秒就否了。\n界面只是一个普通聊天窗口。谈判过程像在看日志文件。没有人格张力，没有情绪起伏，没有那种“Shark Steve 坚守底线，对抗 Cool-Hand Casey 假装要走人”的戏剧瞬间。它作为软件是成立的。作为体验是失败的。\n这个仓库有 9.3 万+ 星。\n我看过无数开发者如何体验智能体 Demo。他们在十分钟内决定是否值得花时间。一个能运行的智能体远远不够。它必须让人愿意展示给别人看。\n智能体能构建任何你描述的东西。它无法判断什么值得被描述。\n智能体优化的是“正确性”。我优化的是“会不会有人克隆这个项目”。\n这就是审美。这可不是抽象的设计感，而是长期积累的判断力，知道什么会让人点星，什么会让人直接关掉页面。\n当智能体可以快速、批量地产出结果时，能判断哪个版本真正“落地”的人，才是房间里最有价值的人。\n这比听起来难培养。审美无法通过读书获得。它来自反复发布、观察真实用户行为，以及对“能用”和“值得用”之间差距的敏感度。\n一个简单练习：回顾你最近五个智能体产出。逐个写下你会改什么，以及为什么。那个“为什么”，就是审美正在形成。\n技能四：智能体编排（Agent Orchestration） # 知道什么时候用一个智能体，什么时候用多个。\n什么时候并行，什么时候串行。\n什么时候加护栏，什么时候放手。\n什么时候亲自调试，什么时候让智能体自己排错。\n最后这一点，比很多人想象中更关键。智能体确实擅长追踪错误。但它也可能陷入循环，反复尝试同一个失败路径。\n知道何时放手让它调试，何时介入，是一种真正的能力。盲目信任和全部手动，代价一样昂贵。\n三种核心模式：\n1. 串行流水线\nAgent A 完成任务后，把输出交给 Agent B。\n这种方式简单，可预测。适用于步骤之间存在依赖关系的场景。\n例如：研究智能体收集数据 → 分析智能体解读 → 写作智能体生成报告。\n2. 协调者 + 专家团队\n一个主智能体负责分派任务，并整合结果。\n适用于需要质量控制的复杂任务。协调者会在专家偏离方向时重新提示，并最终合并输出。\n这也是我现在构建复杂工作流的主要方式。\n3. 并行执行 + 合并\n多个智能体同时处理独立任务，最后由一个智能体整合。\n适用于子任务之间无依赖关系的场景。市场调研、竞品分析、用户访谈可以并行进行。最后统一汇总。过去需要一个下午的串行工作，现在只需几分钟。\n整体来说，大多数人默认选择串行流程，因为那样更“安全”。但知道什么时候并行，什么时候引入协调者，决定了你的工作流是五分钟完成，还是拖到一小时。\n2026 年最优秀的开发者，更像电影导演，而不是程序员。\n他们布置场景，挑选演员，知道什么时候喊停。\n他们不写每一句台词。\n他们塑造整场演出。\n这只能通过不断构建来学会。读再多文章也不够。\n技能五：知道什么时候不要用智能体（判断力） # 在一个讨论智能体时代技能的文章里谈“不用智能体”，听起来有点矛盾。\n但这是个真实陷阱。\n当 Claude Code 可以构建你描述的任何东西时，你会开始把所有事情都交给它。\n我也会下意识对一些根本不需要智能体的问题调用智能体：\n一个小小的 UI 调整。\n一个配置修改。\n一次简单重构。\n有时候，加载上下文、设计提示词、评估输出的成本，已经超过任务本身的价值。\n不是每个问题都需要智能体。\n有些问题只需要一个快速模型和清晰提示。\n需要重新格式化 JSON？丢给 Gemini 3 Flash。\n十个文件里的文案替换？轻量模型几秒搞定。\n一个你已经完全理解的 Bug？自己改比向智能体解释更快。\n真正的能力，是让工具和问题匹配。\n模糊、多步骤、需要探索解空间的问题，用智能体。\n简单、定义清晰、答案已知的任务，用快速模型。\n那些你打字比描述还快的事情，用自己的手。\n最高效的人，并不是凡事都用智能体。\n他们在合适层级调用合适工具。\n问题复杂，用智能体。问题简单，用模型。问题显而易见，用键盘。\n如何培养这些能力 # 这些能力无法通过阅读获得。它们来自实践。\n一、培养审美：\n回顾最近五个智能体输出。写下你会改什么，以及为什么。\n二、优化上下文：\n为当前项目写一个 CLAUDE.md。哪怕只花 30 分钟。\n三、练习问题塑形：\n面对下一次模糊需求，在提示之前，先拆成 10 个子任务。\n四、练习编排能力：\n把一个串行工作流拿出来，看看哪些步骤可以并行。\n五、校准工具判断：\n连续一周记录：哪些任务你用了智能体，而其实一个简单提示就够。选一个。今天就做。\n直觉的形成，比你想象得更快。\n到底还剩下什么？ # 过去二十年里重要的技能之所以重要，是因为实现本身很难。而现在，实现已经不再困难。真正留下来的，是所有更上游的能力。\n审美、上下文策展、问题拆解、智能体编排，以及判断力——知道什么时候该用智能体，什么时候一个简单模型提示就够，什么时候直接自己动手。\n这些能力并非全新。优秀的工程师和产品经理一直具备它们。只是过去，它们被大量实现层的工作掩盖。\n现在，那些实现负担被移除。这些能力被彻底暴露出来。它们成了工作的全部。\n打开你最近一个项目。问问自己：你花更多时间在写代码，还是在塑造问题？\n如果答案是写代码，那你仍在用旧时代的技能结构。新的方式，从一份上下文文档和清晰的问题定义开始。代码，会自己出现。\n参考链接:\nhttps://x.com/Saboo_Shubham_/status/2021416352637125110\nps：春节将近，小编特意为大家准备可爱的2026马年定制版的“51CTO技术栈”红包封面，感谢大家一直以来对我们的关注！点击就可以领取。\n——好文推荐——\n阿里蔡崇信：AI不应是国与国的竞争！自曝阿里一开始并没有清晰的AI技术栈蓝图！曝跟马云创办阿里经历：种子轮路演全军覆没，回应阿里味\n菲尔兹奖得主陶哲轩有了新身份！下场AI for Science！最新专访：AI融入科研有很多错误路径，学术界不能只是等待！AI还谈不上真正的合著者\nClaude Opus4.6内部实用经验公开！16个智能体并行跑2周，中间几乎无人插手！曝 Vibe Coding过时了，以后是agent团队自主完成软件开发！\n","date":"11 February 2026","externalUrl":null,"permalink":"/posts/93k%E6%98%9Fgithub%E9%A1%B9%E7%9B%AE%E7%8B%A0%E4%BA%BA%E8%B0%B7%E6%AD%8C%E9%AB%98%E7%BA%A7ai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86%E5%85%AC%E5%BC%80%E5%86%85%E9%83%A8%E6%9E%84%E5%BB%BAagent%E5%BF%83%E5%BE%97%E8%BF%87%E5%8E%BB%E5%8D%81%E5%B9%B4%E6%8A%80%E8%83%BD%E8%A1%A1%E9%87%8F%E6%A0%87%E5%87%86%E5%B7%B2%E6%AF%AB%E6%97%A0%E4%BB%B7%E5%80%BC2026%E6%9C%80%E4%BC%98%E7%A7%80%E7%9A%84%E5%BC%80%E5%8F%91%E8%80%85%E6%9B%B4%E5%83%8F%E6%98%AF%E5%AF%BC%E6%BC%94/","section":"AI-Related Reposts","summary":"","title":"[Repost] 93k星Github项目狠人！谷歌高级AI产品经理公开内部构建Agent心得：过去十年技能衡量标准已毫无价值！2026最优秀的开发者更像是导演","type":"posts"},{"content":"Reposted from GitHub 上狂揽 1.3 万 Star！港大开源的轻量版 Clawdbot。 by 逛逛\n这个叫 nanobot 的项目是香港大学数据科学实验室开源的项目。\n既然 nano 开头，就说明这是一个超轻量级个人 AI 助手，非常注重可读性、研究友好、启动快、易集成多模型和多聊天通道。\n开源没多长时间，就 1.3 万的 Star 了。\n它受 Clawdbot 启发，整个项目也就 4000 行代码，原版 Clawdbot 大概有 43 万行代码，缩减了 99%。\n所以说，你想研究研究 Clawbot 怎么搞出来的，可以先看看这个 nanobot，非常易读、修改和扩展。\n**\n01\n项目简介\n**\nnanobot 也支持通过 Telegram、Discord、WhatsApp 以及****飞书与 AI 交互。特别是对飞书的支持，使其非常适合国内办公场景。\n而且它支持几乎所有主流 LLM 提供商，包括 OpenRouter、 Claude、OpenAI、DeepSeek、Google Gemini，以及通过 vLLM 运行的本地模型。\n这是 nanobot 的架构图：\nAgent Loop 负责根据当前任务、上下文和工具结果进行连续推理和行动。记忆、上下文管理模块来负责短期、长期记忆、上下文裁剪与重组。\nSkills \u0026amp; Tools 系统是一组可调用工具，比如调用 GitHub、天气、tmux、shell 等。\n除此之外还有 Chat 应用，负责接收、发送消息的多种通道适配层。LLM 模块来管理和自动识别不同 LLM 提供商和模型。\n**\n02\n能干啥？\n**\n你可以用 nanobot 搭建自己的个人 AI 助手，比如：\n让 nanobot 做全栈软件工程师，能理解代码库、协助开发、部署、扩缩。\n进行全天候实时市场分析，监控行情、发现趋势、生成洞见：\n智能日常事务管理器，管理日程、自动执行重复任务、整理 TODO 啥的：\n个人知识助手，学习你的资料、进行长期记忆和推理啥的。\n**\n02\n如何使用\n**\n你可以通过 uv 或 pip 快速安装 nanobot。\n安装完之后，你需要配置 API Key，比如 OpenRouter 或 OpenAI 的 Key，然后通过简单的命令行指令即可启动：\n① 初始化\nnanobot onboard ② 配置\n对于 OpenRouter 的用户，在 ~/.nanobot/config.json 中配置一下：\n{ ③ 开整\nnanobot agent -m \u0026#34;二加二等于几？\u0026#34; 就这样，你在两分钟内就拥有一个可以工作的 AI 助手了。\n目前 nanobot 这个轻量的 AI 助手特别火，我感觉主要是因为开发者厌倦黑盒式的大型框架，想要一个自己能完全看懂并掌控的代码库。\n对于学术界，一个干净的基座比一个臃肿的产品更适合做实验。\n而且它证明了构建一个功能强大的 AI Agent 不需要复杂的微服务架构，单体 Python 脚本依然能打。\n开源地址：https://github.com/HKUDS/nanobot 03\n点击下方卡片，关注逛逛 GitHub\n这个公众号历史发布过很多有趣的开源项目，如果你懒得翻文章一个个找，你直接关注微信公众号：逛逛 GitHub ，后台对话聊天就行了：\n","date":"11 February 2026","externalUrl":null,"permalink":"/posts/github-%E4%B8%8A%E7%8B%82%E6%8F%BD-1.3-%E4%B8%87-star%E6%B8%AF%E5%A4%A7%E5%BC%80%E6%BA%90%E7%9A%84%E8%BD%BB%E9%87%8F%E7%89%88-clawdbot/","section":"AI-Related Reposts","summary":"","title":"[Repost] GitHub 上狂揽 1.3 万 Star！港大开源的轻量版 Clawdbot。","type":"posts"},{"content":"Reposted from 全球27 家AI 研究机构联合发布系统性综述：基础智能体下半场的真正战场不是推理，而是记忆 by FlerkenS\n人工智能的叙事正在悄悄换轨。过去几年，行业沉浸在“更大模型、更高分数”的狂热里，仿佛只要参数堆得够高、benchmark 刷得够亮，智能体就能自动跨入通用智能的门槛。但当模型能力逼近平台期，现实世界的复杂性却开始反向压迫整个技术体系：任务变长、环境变乱、用户变得不可预测，智能体必须在持续交互中保持稳定、连贯、可控。\n在这样的背景下，记忆从一个“附属模块”跃升为基础智能体的核心能力。它不再是锦上添花，而是决定智能体能否真正进入“下半场”的关键变量。\n图1：基础智能体记忆路线图。展示基础代理记忆框架趋势的时间线，按记忆基质和主题（以用户或代理为中心）分类。\n01 # 记忆成为基础智能体“下半场”的关键变量 # 当 AI 从单轮问答走向多轮协作，从静态任务走向动态环境，从一次性推理走向长时执行，模型的上下文窗口再大，也终究无法承载真实世界的复杂性。用户的偏好会变化，任务会跨天跨周，环境会不断更新，智能体必须在不断累积的信息洪流中保持稳定、连贯、可控。\n这正是记忆的价值所在。\n它让智能体不再是“每次都从零开始的聊天机器人”，而是一个能理解你、记住你、陪伴你、并在任务中不断成长的长期伙伴。随着任务从短期推理转向长时执行，记忆成为连接模型能力与真实世界效用的桥梁。没有记忆，智能体只能在有限的上下文里挣扎；有了记忆，它才能真正跨越会话、跨越任务、跨越时间。\n这也是为什么 2025 年开始，记忆相关研究呈现爆发式增长。基础智能体的竞争，已经从“谁的模型更大”转向“谁的记忆更聪明”。\n近日发布的《Rethinking Memory Mechanisms of Foundation Agents in the Second Half: A Survey》这篇综述由来自 27 家国际顶尖高校与产业机构的研究者共同完成，阵容横跨北美、欧洲与亚洲，几乎覆盖当前全球最强的 AI 研究力量。学术机构包括 伊利诺伊大学厄巴纳-香槟分校（UIUC）、斯坦福大学（Stanford）、加州大学洛杉矶分校（UCLA）、剑桥大学（Cambridge）、哈佛大学（Harvard）、南洋理工大学（NTU）、埃默里大学（Emory）、亚利桑那州立大学（ASU） 等世界级名校；产业机构则来自 Salesforce（赛富时）、Google（谷歌）、Meta（原 Facebook）、Roblox（罗布乐思）、Cisco（思科）、Capital One（第一资本银行） 等全球科技巨头。\n这支跨机构、跨学科、跨地域的团队共同推动了基础智能体记忆机制的系统化研究，也让这篇综述成为当前智能体记忆领域最具代表性的国际协作成果之一。\n项目地址为：https://github.com/AgentMemoryWorld/Awesome-Agent-Memory\n该仓库收录了 200+ 记忆系统综述，是当前最系统的智能体记忆研究索引库。\n02 # 基础智能体记忆的三维统一框架 # 为了理解智能体记忆的全貌，综述提出了一个极具系统性的三维框架：记忆载体、认知机制、记忆主体。这三个维度共同构成了基础智能体记忆系统的“骨架”，也为未来的记忆架构设计提供了清晰的坐标系。\n图2:Foundation Agent记忆的分类。基础试剂的记忆基质（所代表的形式）包括内部和外部记忆。在记忆认知机制（记忆如何运作）的视角下，记忆分为情景记忆、语义记忆、感觉记忆、工作记忆和程序记忆。基于记忆主体（受支持者），记忆被分为以用户为中心和以代理为中心的视角。\n记忆载体：智能体的“存储介质”\n记忆首先要有地方放。基础智能体的记忆载体大致分为三类。\n内部记忆是模型自身的记忆，包括权重中的知识、隐状态中的短期信息、KV Cache 中的即时上下文。它速度快、耦合紧，但难以更新，也无法跨会话持久保存。\n外部记忆则是智能体的“外接硬盘”，包括向量数据库、结构化知识库、层级化的记忆树等。它容量大、可编辑、可持久化，但检索质量和延迟是关键挑战。\n混合记忆正在成为主流趋势。内部记忆负责即时推理，外部记忆负责长期积累，两者通过检索、压缩、反思等机制协同工作，形成类似人类“短期记忆 + 长期记忆”的双系统结构。\n图3：2023年第一季度至2025年第四季度期间，LLM智能体中与记忆相关研究的累积发表趋势。图中展示了所收集的218篇论文在三个关键维度上的分布：记忆载体（左）、记忆认知机制（中）以及记忆主体（右）。阴影区域标示了2025年研究产出显著加速的阶段。\n认知机制：记忆的“功能分工”\n记忆不仅要存，还要“会用”。综述借鉴认知科学，将智能体的记忆功能划分为五类，每一类都对应着智能体在真实任务中的一种能力。\n感官记忆负责短暂缓存视觉、音频等原始输入，让智能体能在多模态环境中保持连续性。\n工作记忆是智能体的“思考空间”，用于在线推理、规划、工具调用，是执行复杂任务的核心。\n情节记忆记录发生过的事件、对话、任务轨迹，是跨会话一致性和长期协作的基础。\n语义记忆则是智能体的“知识库”，存储抽象概念、事实、规则，支持跨任务迁移。\n程序性记忆负责技能与策略的积累，让智能体能在反复执行中形成稳定的 workflow 与操作习惯。\n这五类记忆共同构成了智能体的“认知结构”，让它不仅能记住信息，还能在任务中灵活调度、推理和应用。\n图 4：基础智能体记忆系统的分类体系。\n记忆主体：记忆“为谁服务”\n记忆不是抽象存在，它总是服务于某个主体。综述将主体分为两类。\n用户中心的记忆关注用户的偏好、身份、历史行为、长期目标，是个性化体验的基础。一个能记住你旅行偏好、写作风格、工作习惯的智能体，才算真正“懂你”。\n代理中心的记忆则关注智能体自身的成长，包括技能、策略、经验、世界模型。它让智能体能在任务中不断学习、优化、反思，形成类似“经验值”的累积。\n这两类记忆共同构成了智能体的“内外双循环”：对外理解用户，对内提升自己。\n图5：记忆认知机制与记忆主体之间的联系。每个集群对应于以主体或用户为中心的记忆工作的记忆认知机制（感官、工作、语义、情景、程序）的论文数量，面积大小与论文数量成正比。\n03 # 基础智能体记忆的操作机制 # 当智能体开始在真实环境中执行任务，它的记忆不再是静态存储，而是一条不断流动的操作流水线。每一次写入、检索、更新、压缩与遗忘，都是智能体在“思考”和“成长”的过程。\n图6:Foundation Agent内存系统的操作机制。该图说明了foundation agent存储系统的完整操作机制。对于单代理系统，它定义了五个核心操作：存储和索引、加载和检索、更新和刷新、压缩和摘要以及遗忘和保留，这些操作控制着如何保存和访问历史信息以支持下游工作。对于多代理系统，该框架通过内存架构定义、路由协议以及隔离和冲突解决策略来解决协调挑战，确保分布式代理之间的数据一致性和高效协作。\n单智能体的记忆操作流水线\n记忆的第一步是写入。智能体需要判断哪些信息值得留下：用户的偏好？任务的关键节点？失败的原因？成功的策略？写入不是简单的记录，而是一次“选择性注意”。\n接下来是检索。智能体必须在海量历史中找到当前任务真正需要的那一小部分信息。检索的质量直接决定智能体的表现：检索错了，智能体就会答非所问；检索不到，它就会像失忆一样重复犯错。\n更新是智能体的“自我修正”。当任务状态变化、用户偏好改变、环境发生偏移，智能体必须及时刷新记忆，否则就会陷入过时信息的陷阱。\n压缩是记忆系统的“减肥术”。随着交互变多，记忆会迅速膨胀，智能体必须学会把冗余内容合并，把长对话总结成短语，把复杂轨迹提炼成策略。\n遗忘则是最被低估的能力。没有遗忘，记忆会变成垃圾堆；有了遗忘，智能体才能保持轻盈、敏捷、可控。\n综述强调，记忆的生命周期必须与任务耦合。智能体不是机械地存取，而是根据任务阶段、目标变化、环境反馈动态调整记忆策略。这种“任务驱动的记忆调度”正在成为下一代智能体的核心能力。\n多智能体系统中的记忆协作\n当多个智能体开始协作，记忆不再是单体问题，而是一个复杂的“知识流动系统”。\n私有记忆是每个智能体的“个人经验库”。它记录各自的技能、偏好、失败教训，确保每个智能体都有独立的行为风格。\n共享记忆则像团队的“公共白板”。任务目标、环境状态、关键决策都需要在共享空间中同步，让所有智能体保持一致的世界观。\n协调式记忆是更高阶的结构。它由一个“调度者”负责管理不同智能体的记忆访问权限，决定谁能写、谁能读、谁能修改，避免冲突和混乱。\n记忆冲突是多智能体系统的常见问题。例如两个智能体对同一事件的理解不同，或者一个智能体写入了另一个无法接受的策略。权限控制和角色分工因此变得至关重要。\n记忆路由则决定知识如何在智能体之间流动。是广播式同步？还是按需分发？是由调度者统一管理？还是智能体之间点对点交流？不同的路由方式会直接影响系统的效率与稳定性。\n综述指出，多智能体记忆协作将成为未来复杂系统（如科研助手、企业级 AI、机器人群体）的关键基础设施。\n图7:Foundation Agent记忆系统的学习策略。我们说明了学习策略如何指导代理决定存储什么、何时存储、如何表示以及何时何地检索或丢弃记忆。该图总结了三种常见的方法，包括提示、微调和强化学习，这些方法逐步将记忆决策从不精确的记忆管理提高到有效和准确的记忆管理。\n04 # 记忆策略的学习：从提示工程到自进化 # 记忆不是死的，它需要策略。而策略不是写死的，它需要学习。综述把记忆策略的演化分成三个阶段：提示工程、参数化学习、强化学习。\n基于提示的记忆策略\n提示工程是最早期的记忆策略。静态提示告诉智能体“你应该记住什么”，例如“请总结用户偏好并存入记忆”。这种方式简单直接，但缺乏灵活性。\n动态反思与自我修正是提示策略的升级版。智能体会在任务结束后反思：“我哪里做得不好？哪些信息应该写入记忆？”这种机制让智能体具备了最初级的“自我改进能力”。\n提示策略的优势是可控、可解释，但缺点也明显：策略不稳定、难以适应复杂环境。\n基于微调的参数化记忆\n当记忆策略被写入模型权重，智能体就拥有了“内化的记忆能力”。它不再依赖提示，而是通过训练学会何时写入、如何总结、如何检索。\n这种方式让记忆操作变得更自然、更高效，但也带来了新的挑战：稳定性与可控性。记忆策略一旦写进权重，就不容易修改；如果策略学偏了，智能体可能会出现“过度记忆”或“错误记忆”的问题。\n综述提到，参数化记忆正在成为主流趋势，但仍需要更强的安全机制与可解释性工具。\n强化学习驱动的记忆策略\n强化学习让记忆策略真正进入“自进化时代”。在这种框架下，记忆操作被视为动作，智能体通过长期奖励来学习最优策略。\n它会自主探索什么时候该记？记什么最有价值？哪些信息应该被遗忘？如何压缩才能保留关键知识？\n强化学习的优势在于它能优化长期收益，而不是短期表现。这意味着智能体可以通过大量交互逐渐形成成熟的记忆体系，甚至发展出类似人类的“经验积累能力”。\n综述认为，强化学习将成为未来记忆系统的关键方向，因为它让智能体真正具备了“学习如何学习”的能力。\n05 # 记忆的规模化挑战：上下文、环境与多模态 # 当智能体从实验室走向真实世界，记忆系统面临的挑战不再是“能不能记”，而是“记得动、记得稳、记得对”。规模化带来的压力来自三个方向：上下文、环境、多模态。\n上下文长度的极限与突破\n上下文窗口的扩展曾被视为解决记忆问题的“蛮力方案”。从几千 token 到几十万 token，再到百万级上下文，模型似乎越来越“能记”。但综述指出，这种扩展很快触及两个瓶颈：\n一是成本。长上下文意味着更高的计算开销，推理成本呈指数级增长。\n二是噪声。上下文越长，模型越容易被无关信息干扰，检索难度也随之上升。\n因此，真正的突破不在于“无限扩窗”，而在于“智能调度”。智能体需要学会把上下文当作资源，而不是垃圾桶：哪些信息应该进入工作记忆？哪些应该进入长期记忆？哪些应该被压缩？哪些应该被遗忘？这是一套动态的、策略性的、任务驱动的记忆管理体系。\n上下文不再是“越长越好”，而是“越精准越好”。\n真实世界环境的复杂性\n实验室里的智能体面对的是干净、静态、可控的环境；现实世界则完全不同。\n任务是开放的，目标是模糊的，信息是动态的，用户是多变的，工具是异构的，环境是不可预测的。\n智能体必须在这样的环境中持续运行，而记忆系统必须承担起“稳定器”的角色：\n它要记录环境状态的变化，让智能体不会在下一步突然“失忆”； 它要保存任务链条，让智能体不会在长流程中迷路； 它要追踪用户行为，让智能体能在混乱中保持一致性。\n综述强调，真实世界的复杂性让记忆不再是“存储问题”，而是“系统问题”。记忆必须与规划、工具调用、感知、执行深度耦合，成为智能体的核心循环的一部分。\n多模态、具身智能体与世界模型的记忆需求\n当智能体开始拥有视觉、听觉、动作能力，甚至能在虚拟或物理世界中移动时，记忆的维度瞬间扩张。\n视觉帧需要短暂缓存，形成感官记忆； 动作序列需要记录，形成程序性记忆； 环境变化需要建模，形成世界模型记忆； 多模态信息需要对齐，形成统一的语义记忆。\n具身智能体的记忆系统更像是“神经系统”，而不是“数据库”。它必须实时响应、持续更新、跨模态整合，并在复杂的感知-行动循环中保持稳定。\n综述指出，多模态与具身智能体将推动记忆系统从“文本中心”走向“世界中心”，这是未来几年最重要的技术趋势之一。\n06 # 记忆系统的评测体系 # 记忆系统的评测一直是行业的痛点。传统的 NLP 指标无法衡量智能体在真实世界中的长期表现，而记忆系统的好坏往往只有在长时间、多任务、多会话的场景中才能显现。\n综述将评测体系拆解为四类指标，构成一个更贴近真实应用的评估框架。\n准确性指标\n这是最直观的一类，包括记忆召回是否正确、事实是否被准确提取、用户偏好是否被正确识别、任务状态是否被正确记录，它衡量的是“记得对不对”。\n但综述指出，准确性只能评估“静态记忆”，无法评估记忆的动态行为。\n相似度指标\n这类指标用于衡量记忆内容与原始信息的相似程度，例如ROUGE、BLEU、BERTScore、embedding 相似度。\n它衡量的是“记得像不像”。\n但相似度高不代表记忆有用，甚至可能意味着智能体“记得太多”，缺乏抽象能力。\nLLM-as-a-Judge\n随着任务变复杂，人工评估成本高昂，LLM-as-a-Judge 成为主流趋势。它可以评估记忆是否被正确使用，记忆是否提升了任务表现，记忆是否保持一致性，记忆是否符合用户意图，它衡量的是“记得是否有价值”。\n综述指出这类评估更贴近真实任务，但也依赖评审模型的质量。\n真实世界任务评测的缺口\n尽管已有大量指标，但综述强调，当前评测体系仍然缺乏对以下能力的衡量长期一致性，多会话稳定性，任务链条的连续性，记忆的可控性与安全性，记忆在复杂环境中的鲁棒性，多模态与具身场景下的记忆表现。\n换句话说，行业仍缺少“真实世界级”的记忆 benchmark。\n综述呼吁构建跨天、跨任务、跨工具、跨模态的评测体系，让记忆系统真正接受“实战检验”。\n07 # 基础智能体记忆的应用版图 # 当记忆能力从实验室走向真实世界，它的价值开始在各个行业中显现。综述列出的 12 大应用领域，几乎覆盖了所有需要长期交互、复杂任务链条、个性化体验的场景。\n图 8：基础智能体记忆系统的应用场景。该图展示了基础智能体记忆系统的主要应用领域，包括教育、科学研究、游戏与模拟、机器人、对话系统、医疗健康、工作流自动化、软件工程、在线流媒体与推荐系统、信息检索、金融与会计，以及法律与咨询等方向。\n教育领域的智能导师不再是“答题机器”，而是能记住学生的知识薄弱点、学习节奏、兴趣偏好，甚至能跨学期追踪成长轨迹的“长期陪伴者”。记忆让教育 AI 从工具变成伙伴。\n科研领域的智能研究助手需要跨文献、跨实验、跨项目地积累知识。没有记忆，它只能重复检索；有了记忆，它能形成自己的“研究语境”，甚至能在长期项目中保持一致的推理风格。\n机器人与具身智能体的记忆更像是“世界模型的延伸”。它们必须记住空间结构、任务步骤、失败原因、环境变化，才能在物理世界中稳定运行。\n医疗场景对记忆的要求极高。智能体需要理解患者的长期病史、用药记录、生活习惯、诊疗反馈，才能提供真正个性化的辅助决策。记忆在这里不仅是效率问题，更是安全问题。\n推荐系统的记忆能力决定了它能否理解用户的长期兴趣，而不是只靠短期行为做“即时推荐”。记忆让推荐从“猜你喜欢”变成“懂你是谁”。\n金融领域的智能体需要跨交易周期、跨市场状态、跨风险事件地积累经验。记忆让它能识别长期模式，而不是被短期噪声牵着走。\n软件工程与工作流自动化的智能体需要记住项目结构、代码风格、历史 bug、团队习惯，才能真正成为“工程协作者”而不是“代码生成器”。\n这些应用共同指向一个事实，记忆是智能体从“工具”走向“角色”的关键。只有能记住、能理解、能延续，智能体才能真正融入人类的工作与生活。\n图 9：基础智能体记忆的未来方向与挑战。该图强调了未来智能体记忆研究中的关键机遇，包括面向自进化智能体的记忆、多智能体记忆组织、人机协作记忆、记忆效率优化、面向多模态与具身智能体的记忆、持续学习记忆、终身个性化记忆，以及真实世界基准测试与评估体系的构建。\n08 # 未来走向“可持续、自进化、可信赖”的智能体记忆 # 综述在未来方向的部分呈现出一种非常明确的趋势，记忆系统正在从“工程模块”走向“生态系统”。未来的智能体记忆将具备可持续性、自进化能力、可信赖性，并且能够在复杂环境中稳定运行。\n持续学习与自进化记忆是第一条主线。智能体不能永远依赖人工提示或静态规则，它必须学会在长期交互中自主调整记忆策略：哪些信息值得保留？哪些应该被压缩？哪些必须遗忘？这种自进化能力将决定智能体能否在真实世界中长期生存。\n多人多智能体的记忆组织是第二条主线。当智能体开始协作，记忆不再是单体问题，而是一个“知识流动系统”。团队智能体需要共享任务状态、同步环境理解、协调策略分工，同时保持各自的私有记忆。这种“群体记忆结构”将成为未来企业级 AI 的基础设施。\n记忆基础设施与效率优化是第三条主线。随着记忆规模不断膨胀，如何构建高效、低延迟、可扩展的记忆系统，将成为工程层面的核心挑战。未来的记忆系统可能会像数据库一样拥有自己的“索引、缓存、分片、压缩、调度”机制。\n隐私、安全与可信记忆是第四条主线。用户中心的记忆必须可控、可审计、可删除、可隔离。智能体不能“记太多”，也不能“记错人”。可信记忆将成为智能体能否进入医疗、金融、政务等高敏感领域的关键门槛。\n多模态与具身智能体的记忆是第五条主线。随着智能体拥有视觉、听觉、动作能力，记忆将从文本扩展到世界模型。它需要记住空间、物体、动作、反馈、环境变化，形成类似“感知—行动—记忆”的闭环。\n真实世界评测体系的构建是第六条主线。当前的 benchmark 无法衡量智能体在长期任务中的表现。未来需要跨天、跨任务、跨工具、跨模态的评测体系，真正检验记忆系统的稳定性、鲁棒性与价值。\n这些方向共同指向一个未来图景：智能体的记忆系统将成为 AI 的“第二大脑”，负责长期理解、经验积累、策略演化与世界建模。它不仅决定智能体能否完成任务，更决定它能否在真实世界中“活得久、活得稳、活得好”。（END）\n参考资料：https://arxiv.org/abs/2602.06052\n关于波动智能——\n波动智能旨在建立一个基于人类意图与反应的真实需求洞察及满足的价值体系，融合人工智能与意识科学，构建覆盖情绪识别、建模与推荐的智能引擎，自主研发面向社交、电商等场景的多模态意图识别引擎、意图标签系统及意图智能推荐算法，形成从情绪采集、意图建模到商业转化的完整解决方案。波动智能提出“意图是连接人、物与内容的新型接口”，其产品广泛应用于AI社交、个性化内容推荐、虚拟陪伴、电商体验优化等领域。波动智能正在探索“EMO-as-a-Service”技术服务架构，赋能企业实现更高效的用户洞察与精准情绪交互，推动从功能驱动到意图驱动的产业范式升级。\n亲爱的人工智能研究者，为了确保您不会错过*波动智能*的最新推送，请星标*波动智能*。我们倾心打造并精选每篇内容，只为为您带来启发和深思，希望能成为您理性思考路上的伙伴！\n加入AI交流群请扫码加微信\n","date":"11 February 2026","externalUrl":null,"permalink":"/posts/%E5%85%A8%E7%90%8327-%E5%AE%B6ai-%E7%A0%94%E7%A9%B6%E6%9C%BA%E6%9E%84%E8%81%94%E5%90%88%E5%8F%91%E5%B8%83%E7%B3%BB%E7%BB%9F%E6%80%A7%E7%BB%BC%E8%BF%B0%E5%9F%BA%E7%A1%80%E6%99%BA%E8%83%BD%E4%BD%93%E4%B8%8B%E5%8D%8A%E5%9C%BA%E7%9A%84%E7%9C%9F%E6%AD%A3%E6%88%98%E5%9C%BA%E4%B8%8D%E6%98%AF%E6%8E%A8%E7%90%86%E8%80%8C%E6%98%AF%E8%AE%B0%E5%BF%86/","section":"AI-Related Reposts","summary":"","title":"[Repost] 全球27 家AI 研究机构联合发布系统性综述：基础智能体下半场的真正战场不是推理，而是记忆","type":"posts"},{"content":"Reposted from 海外顶级风投a16z关于AI市场的最新深度分析 by 深思圈\n你有没有想过，软件行业可能正在经历一场比从命令行到图形界面更剧烈的变革?最近听了一场 a16z 的 David George 分享的关于 AI 市场的深度分析，我被一组数据震撼到了：最快增长的 AI 公司正在以 693% 的年增长率扩张，而他们在销售和营销上的支出却远低于传统软件公司。这不是个别案例，整个 AI 公司群体的增长速度是非 AI 公司的 2.5 倍以上。更让我觉得不可思议的是，这些公司的 ARR per FTE（每名员工的年度经常性收入）达到了 50 万到 100 万美元，而上一代软件公司的标准是 40 万美元。这意味着什么？意味着我们正在见证一个全新的商业模式诞生，一个用更少的人、更少的成本、创造更大价值的时代。David George 在分享中提到，这不是什么小调整，而是一场彻底的范式转变。那些核心概念——版本控制、模板、文档，甚至用户的概念——都在因为 AI agent 驱动的工作流而被重新定义。我深信，未来五年内，那些无法适应这种变革的公司将会被彻底淘汰。\nAI 公司增长的惊人真相\nDavid George 在分享中展示的数据让我重新思考了什么叫真正的增长。2025 年对于 AI 公司来说是一个加速增长的年份。在经历了 2022、2023、2024 年因为利率上升和科技行业收缩导致的增长放缓后，2025 年彻底逆转了这个趋势。最让人震惊的是，按照不同梯队排名的公司中，那些真正的异常值公司，增长速度简直令人难以置信。\n我看到这组数据时的第一反应是：这数字有问题吧？表现最好的 AI 公司群体同比增长 693%。David 说他们团队也是反复确认了三遍才相信这个数字。但这完全符合他们从投资组合公司那里看到的实际情况和案例。这不是孤立的现象，而是整个 AI 领域正在发生的系统性变化。\n更关键的是增长的质量。传统软件公司要达到 1 亿美元的年收入通常需要很长时间，而最快增长的 AI 公司到达这个里程碑的速度要快得多。David 特别强调了一个非常重要的点：这不是因为他们在销售和营销上花了更多钱，恰恰相反，最快增长的 AI 公司在销售和营销上的支出实际上比传统 SaaS（软件即服务）公司更少。他们增长得更快，却花得更少。这背后的原因是什么？是因为终端客户的需求极其强烈，产品本身极具吸引力。\n我觉得这揭示了一个深刻的商业逻辑转变。过去的软件时代，增长往往依赖于强大的销售团队和巨额的营销预算。你需要教育市场、说服客户、克服采用障碍。但在 AI 时代，真正优秀的产品能够自己说话。当一个产品能够立即为用户创造价值，能够让用户在第一次使用时就感受到效率的提升，市场需求就会自动产生。这种由产品驱动的增长模式，比传统的销售驱动模式要健康得多，也可持续得多。\nDavid 展示的另一组数据也很有意思。AI 公司的毛利率实际上比传统软件公司略低一些。他们团队的看法很独特：对于 AI 公司来说，低毛利率某种程度上是一种荣誉勋章。因为如果低毛利率是由高推理成本（inference costs）导致的，那说明两件事：第一，人们真的在使用 AI 功能；第二，随着时间推移，这些推理成本会下降。所以在某种程度上，如果他们看到一个 AI 公司的毛利率特别高，反而会有点怀疑，因为这可能意味着 AI 功能并不是客户真正购买或使用的东西。\n为什么 AI 公司能做到更高效\n我一直在思考一个问题：为什么同样是软件公司，AI 公司能够用更少的人创造更多的收入？David 在分享中重点讨论了 ARR per FTE 这个指标，也就是每名全职员工创造的年度经常性收入。这个指标实际上是衡量公司整体运营效率的一个综合指标，它不仅包括销售和营销效率，还包括管理成本和研发成本。\n最优秀的 AI 公司的 ARR per FTE 达到了 50 万到 100 万美元，而上一代软件公司的标准大约是 40 万美元。这看起来可能只是一个数字上的差异，但背后反映的是完全不同的商业模式和运营方式。David 认为，造成这种差异的主要原因是市场对这些产品的需求非常强烈，所以他们需要更少的资源就能将产品推向市场。\n但我觉得这只是表面原因。更深层的原因是，AI 公司从一开始就被迫以不同的方式思考如何运营。他们没有选择，必须用 AI 来重新设计他们的内部流程、产品开发方式、客户支持系统。这种被迫的创新反而让他们找到了一种更高效的商业模式。\nDavid 分享了一个特别生动的例子。他说最近在和一家公司的创始人聊天，这个创始人对他们某个产品的进度感到不满意，于是他直接安排了两个在 AI 方面很深入的工程师，让他们用 Claude Code、Cursor 这些最新的编程工具从头开始重建这个产品，并且给了他们无限的编程工具预算。结果呢？这位创始人说，他认为进度比之前快了 10 到 20 倍。而且这些工具产生的账单高到让他开始重新思考整个组织应该是什么样子。\n这个例子让我印象深刻的地方在于，这不是渐进式改进，而是数量级的跃升。10 到 20 倍的速度提升意味着什么？意味着原本需要一年完成的项目，现在可能只需要一两个月。这种速度差异会在竞争中产生决定性的影响。这位创始人的结论是：我需要让整个产品和工程团队都以这种方式工作，而且我认为这会在未来 12 个月内发生。但这也意味着团队的组织结构会发生根本性变化。产品、工程、设计的边界在哪里？这些问题都需要重新定义。\n我认为 2024 年 12 月是编程领域的一个转折点。David 也有同样的感受。他说感觉在那个时间点上，编程工具发生了质的飞跃。接下来的 12 个月，这种变化要么会在公司中真正落地生根，要么那些没有采用的公司就会比同行慢得多。这不是危言耸听，而是现实。\n适应 AI 还是被淘汰\nDavid 在分享中提到了一个非常严峻的观点：对于那些在 AI 时代之前创立的公司来说，要么适应 AI 时代，要么死亡。这个说法听起来很极端，但我完全同意。而且这种适应需要在两个层面同时进行：前端和后端。\n在前端，公司需要思考如何将 AI 原生地整合到产品中，而不仅仅是在现有工作流程中加一个聊天机器人。这需要重新想象在有了 AI 之后产品能做什么，并且要激进地颠覆自己、做出改变。David 分享了几个很有意思的例子。有一家 pre-AI 时代的软件公司，CEO 已经完全被 AI 理念所转化，他说：我们要成为一个 AI 产品。我们要让产品能够说，你的员工现在变成了你的 AI agent。你有多少个 agent？这些是他现在谈论的话题。\n还有一个更极端的例子。有个 CEO 说，对于我们现在需要完成的每一项任务，我都会问一个问题：我能用电来做这件事，还是必须用血来做？这是一种极端的思维转变。用电指的是用 AI 和自动化，用血指的是用人力。这种思维方式的转变非常深刻，它迫使你重新审视公司的每一个流程、每一项任务。\n在后端，公司需要完全采用最新的编程模型和工具。所有开发人员都应该使用最新的编程辅助工具，每个职能部门都应该使用最新的工具。到目前为止，编程领域的采用率最高，这也是看到最大飞跃的地方。但这种变化正在扩散到其他职能部门。\nDavid 提到，对于那些 pre-AI 公司来说，好消息是商业模式的演变还处于早期阶段。最具破坏性的情况是技术和产品发生转变，同时商业模式也发生转变。现在技术和产品确实在发生剧变，但商业模式的转变还没有完全展开。\n他把商业模式看作一个光谱。最左边是许可证模式（licenses），这是 pre-SaaS 时代的许可证和维护模式。然后是 SaaS 和订阅模式，通常基于席位收费，这是一个重大创新，非常具有破坏性。你可以看看 Adobe 在经历这个转变时发生了什么。然后是基于消费的模式（consumption-based），也就是基于使用量的模式，这是云服务的收费方式，很多基于任务量的业务已经从基于席位转向了基于消费。\n下一个阶段将是基于结果的模式（outcome-based）。当你完成一项任务，理想情况下是成功完成一项任务时，你会根据任务的成功完成来收费。目前唯一真正可以实现这种模式的领域可能是客户支持和客户成功，因为你可以客观地衡量问题的解决。但随着模型能力的提升，如果除了客户支持之外的其他职能也能衡量这类结果，那将是对现有公司的巨大破坏力。\n我觉得这个演变路径非常有洞察力。从许可证到订阅，从订阅到消费，从消费到结果，每一次转变都是对前一代商业模式的颠覆。而我们现在正处在从消费到结果的转变前夜。一旦 AI agent 能够可靠地完成任务并可以被客观评估，基于结果的定价模式就会成为主流。到那时，那些还在按席位收费的公司将会发现自己完全失去了竞争力。\n大公司的 AI 采用困境\n关于 Fortune 500 公司采用 AI 的情况，David 的观察非常有意思。他说，他从这些大公司 CEO 那里听到的和实际发生的事情之间存在巨大差距。CEO 们都在说：我们必须适应，我们迫切想了解需要哪些 AI 工具，我们已经准备好改变，我们的业务将全面推出这些工具，我们要成为 AI 公司。\n但实际发生的情况却完全不同。这种思维方式和实际业务变化之间最大的脱节在于：变革管理太难了。即使只是让人们使用 AI 助手来帮助他们更好地完成工作，都已经够难了。至于实际的业务管理、改变业务流程、变革管理，这些都极其困难。\nDavid 说他并不惊讶市场上有些传言说事情进展得比预期慢。但对于那些真正全面拥抱 AI 并且知道该做什么的最优秀公司来说，已经产生了巨大的商业影响。他举了几个具体的例子：Chime 说他们减少了 60% 的支持成本；Rocket Mortgage 说他们在承保方面节省了 110 万小时，同比增长 6 倍，相当于每年节省 4000 万美元的运营成本。\n我认为这揭示了一个关键问题：意愿和能力之间的鸿沟。大公司的 CEO 们都有意愿去拥抱 AI，但是否有能力去实施是另一回事。变革管理的难度常常被低估。这不仅仅是买一些工具或者雇一些 AI 工程师的问题，而是需要从根本上改变公司的流程、文化、组织结构。\n而且很多大公司需要先调整自己的业务，让它为 AI 做好准备。使用聊天机器人是一回事，能获得多少生产力提升可能不多。但如果你必须完全改造你的系统、信息和后端以适应 AI，很多工作可能是潜在的，正在积累中，还没有看到相关的结果。\nDavid 预测，接下来的 12 个月将会非常有意思。他认为我们会看到更多的案例，但会有公司能搞定，也会有公司搞不定。那些能搞定的公司将会获得巨大的生产力优势，而那些搞不定的公司将会处于巨大的劣势。我认为这种分化会比人们想象的来得更快、更剧烈。\nModel Busters 和市场的未来\nDavid 在分享中提到了一个我觉得特别有洞察力的概念：Model Busters。这是指那些增长速度和持续时间远远超出任何人在任何情境下所能预测的公司。iPhone 是这个概念的经典案例。如果你看 iPhone 发布前的共识预测，和 4-5 年后的实际表现，共识预测偏离了 3 倍。而这是全世界最受关注的公司。\nDavid 认为，AI 将会是他职业生涯中见过的最大的 Model Buster。许多 AI 领域的公司表现将会大幅超出任何电子表格中的预期。这个观点我非常认同。当一个技术平台带来的不是渐进式改进，而是数量级的跃升时，传统的预测模型就会失效。\n他提到，科技本身就是一种 Model Buster。但自 2010 年以来，科技以前所未有的速度和规模提供了高利润率的收入。所以它早期看起来总是很贵，但反复出现超预期的表现，创造的价值远远超过所需的资本。他没有理由认为这次会有什么不同。\n在资本支出方面，David 展示的数据也很有意思。相比于互联网泡沫时期，现在的资本支出实际上是由现金流支撑的，而且资本支出占收入的百分比要低得多。承担最大资本支出负担的是超大规模云服务提供商（hyperscalers），而这些公司是有史以来最优秀的商业公司。\nDavid 特别提到，作为投资组合公司，他们非常欢迎这种资本支出。他说：尽可能多地建设容量，为训练和推理提供尽可能多的供应，这是非常好的事情。而且承担大部分负担的是那些史上最优秀的商业公司。\n他们开始关注的一个现象是债务进入了这个等式。你无法仅用现金流为所有预测的未来资本支出提供资金，市场开始看到一些债务。但总体来说，他们对那些用现金流融资、继续产生现金流并使用债务的公司感到很放心，只要对手方是 Meta、Microsoft、AWS、Nvidia 这样的公司。\nDavid 提到了一个值得关注的案例：Oracle。Oracle 一直都很盈利，一直在回购股票，但他们承诺的资本支出规模非常大，这是一个豪赌。他们将在未来很多年出现负现金流。市场已经开始注意到这一点，Oracle 的信用违约互换（CDS）成本在过去三个月上涨到了大约 2%。这是需要关注的信号。\n我认为这种资本密集型的建设阶段是必要的，但并非没有风险。关键是要确保这些投资最终能产生相应的回报。目前来看，需求是远远超过供应的。所有超大规模云服务提供商都报告说需求远超供应。David 采访的 Gavin Baker 有一个很好的比喻：互联网时代铺设了大量光纤，然后这些光纤闲置着，没有被使用，这叫做暗光纤（dark fiber）。但在 AI 时代，没有所谓的暗 GPU。如果你在数据中心安装了 GPU，它会立即被充分利用。\n收入增长的惊人速度\nDavid 展示的一组数据特别震撼。他比较了云服务、上市软件公司，以及 2025 年新增的净收入。上市软件公司在 2025 年总共新增了 460 亿美元的收入。如果你只看 OpenAI 和 Anthropic 这两家公司，按照运营收入计算，它们新增的收入几乎是这个数字的一半。\n而且 David 认为，如果做同样的比较看 2026 年，整个上市软件行业（包括 SAP 和老牌软件公司，不仅仅是 SaaS），AI 公司（模型公司）新增的收入可能会达到 75% 到 80%。这个速度简直令人难以置信。这意味着在短短几年内，AI 公司创造的新价值就会超过整个传统软件行业。\nGoldman Sachs 估计，AI 建设将会产生 9 万亿美元的收入。如果假设 20% 的利润率和 22 倍的市盈率，这将转化为 35 万亿美元的新市值。现在已经有大约 24 万亿美元的市值被提前计入了。虽然我们可以争论这是否全部归因于 AI 或者大型科技公司的表现，但仍然有很多市值可以争取，如果这些假设是正确的话，还有很大的上涨空间。\nDavid 还做了一个简单的算术。按照目前的估计，到 2030 年，超大规模云服务提供商的累计资本支出将略低于 5 万亿美元。要在这 4.8 万亿美元或接近 5 万亿美元的投资上实现 10% 的门槛回报率，到 2030 年，AI 年收入需要达到大约 1 万亿美元。把这个数字放在上下文中，1 万亿美元大约是全球 GDP 的 1%，才能产生 10% 的回报。\n这有可能实现吗？也有可能会略有不足。但 David 认为仅仅看 2030 年是有局限性的。这些投资的回报可能会在更长的时间段内实现，比如 2030 年到 2040 年之间。而且如果我们现在大约在 500 亿美元的 AI 收入规模（这是他的粗略估计），而这主要是在过去一年半左右产生的，那么从 500 亿增长到 1 万亿的路径并不是不可想象的。\n我对未来的思考\n听完 David 的分享，我最大的感受是：我们正处在一个历史性转折点的开端，而不是中期或者末期。这是一个可能持续 10 到 15 年的产品周期，而我们才刚刚开始。这让我既兴奋又焦虑。\n兴奋的是，这种转变带来的机会是巨大的。对于那些能够快速适应、全面拥抱 AI 的公司来说，他们不仅能获得竞争优势，更有可能成为定义下一个时代的公司。我们将会看到新的独角兽诞生，看到新的商业模式出现，看到完全不同的公司组织方式。\n焦虑的是，这种变化的速度可能比大多数人预期的要快得多。David 提到的那个数据特别能说明问题：S\u0026amp;P 500 公司平均在指数中停留的时间在过去 50 年里下降了 40%。这意味着公司被颠覆的速度在加快。在 AI 时代，这个速度可能会进一步加快。\n我认为接下来会出现明显的分化。一些公司会真正理解 AI 的潜力，从根本上重新思考他们的产品、流程、组织结构。这些公司会获得数量级的效率提升和竞争优势。而另一些公司，即使有意愿去改变，也会因为变革管理的困难、组织惯性、技术债务等原因而进展缓慢。这种分化会在未来几年内变得越来越明显。\n对于创业者来说，现在可能是最好的时代。市场需求极其强劲，技术能力日新月异，资本市场仍然愿意支持真正有潜力的公司。而且与上一代软件公司相比，现在可以用更少的资源、更快的速度达到同样的规模。这降低了创业的门槛，但也提高了对产品质量和市场契合度的要求。\n对于投资者来说，关键是要识别出那些真正的 Model Busters。这些公司的增长速度和持续时间会远超任何传统模型的预测。但这也需要投资者有足够的远见和耐心，愿意相信那些看起来不合理的增长曲线。\n对于从业者来说，无论你是工程师、产品经理、设计师还是其他角色，都需要快速学习和适应新的工具和工作方式。David 提到的那个例子——两个工程师用最新的编程工具能比之前快 10 到 20 倍——这不是个例，而是一个趋势。那些能够掌握这些新工具、新方法的人将会获得巨大的职业优势。\n最后，我想说的是，这种转变不仅仅是技术层面的，更是思维方式的转变。从\u0026quot;我们应该如何做\u0026quot;到\u0026quot;我们想要实现什么结果\u0026quot;，从\u0026quot;增加更多的人手\u0026quot;到\u0026quot;如何用 AI 解决这个问题\u0026quot;，从\u0026quot;按照既定流程\u0026quot;到\u0026quot;重新想象可能性\u0026quot;。那句\u0026quot;用电还是用血\u0026quot;的问题，虽然听起来极端，但它抓住了这种转变的本质。\n我们正在见证软件世界被重写的过程。这不是一次渐进式的升级，而是一次彻底的重构。而那些能够理解这一点、拥抱这一点的人和公司，将会定义下一个时代。\n结尾\n也欢迎大家留言讨论，分享你的观点！\n觉得内容不错的朋友能够帮忙右下角点个赞，分享一下。您的每次分享，都是在激励我不断产出更好的内容。\n欢迎关注深思圈，一起探索更大的世界。\n- END -\n往期文章\n[\n两个“特别坑”的AI产品创业方向，你知道吗\n](https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487112\u0026idx=1\u0026sn=536a697321489223a6893e4a565123d4\u0026scene=21#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487112\u0026idx=1\u0026sn=536a697321489223a6893e4a565123d4\u0026scene=21#wechat_redirect\")\n[\n速度将成为AI时代唯一的护城河\n](https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487823\u0026idx=1\u0026sn=1673f78279211c04a14e9dcf157f4721\u0026scene=21#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487823\u0026idx=1\u0026sn=1673f78279211c04a14e9dcf157f4721\u0026scene=21#wechat_redirect\")\n[\n](https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487823\u0026idx=1\u0026sn=1673f78279211c04a14e9dcf157f4721\u0026scene=21#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247487823\u0026idx=1\u0026sn=1673f78279211c04a14e9dcf157f4721\u0026scene=21#wechat_redirect\")\n[\na16z重磅预测：Vibe coding赢者通吃？错了，垂直专业化才是未来\n](https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247489057\u0026idx=1\u0026sn=708c6673da1ab453f1586c729713139f\u0026scene=21#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247489057\u0026idx=1\u0026sn=708c6673da1ab453f1586c729713139f\u0026scene=21#wechat_redirect\")\n[\n](https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247489057\u0026idx=1\u0026sn=708c6673da1ab453f1586c729713139f\u0026scene=21#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/s?__biz=Mzg3NDc2MjQxMg==\u0026mid=2247489057\u0026idx=1\u0026sn=708c6673da1ab453f1586c729713139f\u0026scene=21#wechat_redirect\")\n","date":"11 February 2026","externalUrl":null,"permalink":"/posts/%E6%B5%B7%E5%A4%96%E9%A1%B6%E7%BA%A7%E9%A3%8E%E6%8A%95a16z%E5%85%B3%E4%BA%8Eai%E5%B8%82%E5%9C%BA%E7%9A%84%E6%9C%80%E6%96%B0%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90/","section":"AI-Related Reposts","summary":"","title":"[Repost] 海外顶级风投a16z关于AI市场的最新深度分析","type":"posts"},{"content":"Reposted from 谷歌Chrome深夜爆更，Agent不用「装」人了！前端最后防线崩了？ by 新智元\n# # 新智元报道 编辑：桃子 好困\n【新智元导读】终于，AI不用装得像个人了。谷歌Chrome重磅上线WebMCP。从此，Agent不用疯狂截屏，直连内核完成任务，AI与网页交互的底层逻辑正在重构。 # 今天，谷歌Chrome团队投下了一枚深水炸弹：WebMCP（Web模型上下文协议）正式登场。\n它可以让AI智能体跳过「人类用户界面」，直接与现有的网站和Web应用深度交互。\n在Chrome 146的早期预览版中，开启特定flag即可体验WebMCP\n这相当于给Agent加上了「超能力」，从此不用再「装得像个人一样」，去看网页、找按钮，或是点链接。\n仅通过一个API：navigator.modelContext，AI便可绕过图形界面，直接与Web应用服务的内核对话。\n假设想要订一张机票，Agent不用在屏幕上点击，而会直接通过底层协议，向航空公司网站发送命令，直接获取结果。\n用开发者Alex Volkov的话来说，「WebMCP就相当于UI里的API」。\n可以说，WebMCP的诞生，释放了一个极其明确的信号——\nAI Agent与网页交互的底层逻辑，正迎来一场彻底的重塑。\n它实现了从「视觉模拟」到「逻辑直连」的跃迁，正让传统的Web交互范式彻底走向终结。\nWebMCP震撼登场\n掀起Agent交互革命\n或许很多人，还没有意识到WebMCP的重要性。\n它的核心在于，改变了Agent获取服务的方式，让其直接拿到了网页的「通天钥匙」。\n过去几周，全世界都在为爆火的OpenClaw疯狂，若是未来交互更进一步，说不定又将催生一次大变革。\n要知道，如今Agent操作网页的方式，既笨拙又原始，而现在的集成方式实在是「太拉胯」了。\n它们本质上，就是在模拟人类的行为——截屏、识别按钮的位置、模拟点击，DOM抓取\u0026hellip;\u0026hellip;\n这种方式，存在着明显的痛点：\n成本高昂：一次简单的搜索，可能需消耗数千token来处理截图、解析页面；\n稳定性低：网站一旦改版，Agent会因找不到按钮陷入「瘫痪」；\n反馈低效：Agent必须反复「看」屏幕，来确认操作是否成功。\n不再装个人，降维打击\n如今，有了WebMCP，网站可以直接向AI开放其服务接口。Agent不用经过「前端视觉界面」，直接可以查询并执行服务。\nWebMCP将取代传统的「屏幕抓取」（screen-scraping），从而实现更稳定、更高效的页面交互和信息检索。\n诚如网友所言，AI Agent正成为网络的「一等公民」。\n在谷歌Chrome 146的官博中，为开发者提供了两套灵活的API接入方式：\n声明性API：执行可直接在HTML表单中定义的标准操作；\n命令式API：执行需要JavaScript执行的复杂、更动态的互动。\n这两种方式，允许开发者为AI提供一套直接的工具集，让Agent跳过视觉识别，直接访问网站背后的结构化函数。\n此前，谷歌软件工程师Khushal Sagar在演讲中表示，WebMCP目标是成为AI应用领域的USB-C接口。\n它不仅是让智能体替代用户，更是建立一种协作模式：\n用户、网页、智能体三者共享界面，共同协作。\n智能体专用路径：开发者在为人类设计UI的同时，为智能体提供结构化的API路径。\n两大巨头联手\n要彻底「干掉」前端？\n值得一提的是，WebMCP并不是谷歌的独角戏。\n早在25年8月13日，谷歌、微软开发者联手，在GitHub上提交了WebMCP这一项目。\n开源项目：https://github.com/webmachinelearning/webmcp\n目前，AI智能体通常通过MCP等协议进行后端集成。\n但对于Web开发者来说，为了开放网站功能，他们往往得用Python或NodeJS写一套后端服务器，而不是用他们更熟悉的浏览器端JS。\n在项目介绍中，WebMCP让网页能在UI中提供「智能体专用通道」。\n与后端集成不同，WebMCP工具在客户端执行，只有在智能体加载页面后才可用。\n智能体依然可以像人一样观察页面和模拟操作，但有了工具，它能更直接、高效地达成目标。\n据官方的介绍，以下是WebMCP的三大主要优势：\n代码复用：直接利用现有的前端代码；\n统一界面：用户和智能体共用一个界面，简化了交互时的身份验证和状态同步；\n无障碍利器：让辅助技术能执行更高层级的页面操作，而不仅仅是简单的点击。\n更进一步说，WebMCP让用户和智能体可以在同一个网页界面里并肩工作，既能利用现有的应用逻辑，又能保持上下文共享和用户的掌控感。\n绕过所有UI，统治网络\n那么，在WebMCP加持下，Agent未来会演变成什么样？\n开发者们提前设想了三大场景，电子商务、旅游出行，以及客户支持。\n首先，未来，我们的购物体验，或将迎来质变。\n一句指令，Agent不再在页面上反复「翻找」优惠券入口，仅通过WebMCP函数调用，实现秒级下单。\n它可以轻松找到产品、配置特定的购物选项，完成结账全流程。\n在旅游出行方面，Agent还可以成为更精准的预订专家，使用结构化数据进行搜索、过滤结果和处理预订。\n由于避开了混乱的UI干扰，它能确保每次搜索结果的准确性，并直接在后台完成复杂的行程组合。\n此外，WebMCP还可以成为自动化服务的桥梁，让智能体自动填写必要的技术细节，以创建详细的客户支持服务工单。\n上手试过的开发者惊叹，立即发现了WebMCP两大好处。\n分层Web时代来临\n一半给AI用\n开发者大佬Nikoloz Turazashvili最新一文，深度解释了WebMCP的出现对于开发意味着什么。\n如果你看过AI Agent像无头苍蝇一样使用网站——瞎猜哪个按钮是结账，或者纠结乘客姓名该填在哪个框里……\n实际上，你已经抓住核心痛点了：\n现在的Web UI是给人看的，但智能体需要的是「结构」。\n这恰恰是WebMCP想要解决的问题。如前所述，它是一个拟议中的Web标准，允许网站直接向浏览器内的Agent暴露结构化的工具。\n这样一来，智能体就能调用真正的函数（带有Schema），而不是去暴力爬取页面，然后祈祷DOM结构没有改变。\n因此，可以把它想象成「内置在浏览器标签页里的MCP」。\nWebMCP的核心思路，便是发布工具，别光给像素。\n与其让Agent去瞎猜一个按钮是干嘛的，不如在搭建的网站明确发布一份契约：\n**Discovery（发现）：**这个页面上有哪些工具（checkout, filter_results等）\nJSON **Schemas：**输入/输出具体长什么样（以此减少幻觉）\n**State（状态）：**对页面上当前可用内容的共识\n这就把「到处乱点直到碰巧蒙对」变成了：直接调用book_flight({ origin, destination, outboundDate… })。\nWebMCP基本上是在说——如果智能体要在浏览器肚子里运行，浏览器就得提供这种握手机制。\n而且从产品角度看，这也是控制权的转移：网站自己定义了允许哪些操作，以及数据该怎么传。\n如果WebMCP真的成为标准落地，主流浏览器开始原生支持这种结构化交互，未来的互联网或许分化为两层：\n给人类用的UI：视觉美感、品牌叙事\n给Agent用的工具界面：结构化数据、极速响应\n而最终赢家不会是那些界面最花哨的——而是那些拥有最清晰工具契约的App。\n这一切，预示着「Agentic UI」时代的到来。\n未来的网页将不再仅仅是给「人」看的展示窗，还是能与AI无缝衔接的自动化服务节点。\nWebMCP的出现，无疑加速了从「手动搜索」到「智能体自动执行」的互联网范式转移。\n参考资料：\nhttps://developer.chrome.com/blog/webmcp-epp?hl=zh-cn https://x.com/nomad_remy/status/2021307801990201412?s=20 https://dev.to/axrisi/chromes-webmcp-early-preview-the-end-of-ai-agents-clicking-buttons-b6e https://www.youtube.com/watch?v=p1l8nkQAoUw\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！\n","date":"11 February 2026","externalUrl":null,"permalink":"/posts/%E8%B0%B7%E6%AD%8Cchrome%E6%B7%B1%E5%A4%9C%E7%88%86%E6%9B%B4agent%E4%B8%8D%E7%94%A8%E8%A3%85%E4%BA%BA%E4%BA%86%E5%89%8D%E7%AB%AF%E6%9C%80%E5%90%8E%E9%98%B2%E7%BA%BF%E5%B4%A9%E4%BA%86/","section":"AI-Related Reposts","summary":"","title":"[Repost] 谷歌Chrome深夜爆更，Agent不用「装」人了！前端最后防线崩了？","type":"posts"},{"content":"Reposted from 里程碑时刻！100B扩散语言模型跑出892 Tokens /秒，AI的另一条路走通了 by 关注AI的\n机器之心编辑部\n扩散语言模型（dLLM），这个曾被认为是「小众赛道」的研究方向，如今终于迎来了质变。\n本周一，LLaDA2.1 在 HuggingFace 上悄悄上线，距离上一版本 LLaDA2.0 发布仅仅过去了两个月。本次发布共包含两个版本：LLaDA2.1-Mini（16B） 与 LLaDA2.1-Flash（100B） 。\n作为这一赛道的标杆，LLaDA 的每一次迭代都牵动着整个方向的走向。而这一次，LLaDA2.1 几乎凭一己之力完成了扩散语言模型的「成人礼」——892 Tokens / 秒的峰值速度让理论上的效率优势第一次照进现实；边生成边纠错的机制，打破了「快则不准」的魔咒；再加上可切换的双模式、首次跑通的强化学习后训练…… 这些信号再明确不过：这条曾被视为小众的学术路线，已经长成了真正可用、甚至在效率上更为优越的强大工具。\n时至今日，逐个生成下一个 Token 的自回归模型仍是主流。但长文本生成里，计算成本高、推理速度慢只是明面上的麻烦；真正棘手却鲜被正视的是模型只能单向往前猜，看不到后文语境，写错了也没法回头改，误差像滚雪球一样越积越重。这些困境就像房间里的大象，始终横亘在规模化应用的门口。\nLLaDA2.1 的解法很直接：与其在旧框架里修修补补，不如换一套底层逻辑 —— 让模型像「完形填空」一样并行生成、反复打磨，把「下笔无悔」变成「边写边改」。\n这套机制具体如何运转，我们可以在蚂蚁集团、浙江大学、西湖大学、南方科技大学联合撰写的技术报告中找到答案。\n论文地址：https://github.com/inclusionAI/LLaDA2.X/blob/main/llada2_1_tech_report.pdf\nHugging Face：https://huggingface.co/collections/inclusionAI/llada21\nModelScope 魔搭社区：https://modelscope.cn/collections/inclusionAI/LLaDA21\nGitHub：https://github.com/inclusionAI/LLaDA2.X\nTech Report：https://huggingface.co/papers/2602.08676\n自回归之外的另一条路\n要理解 LLaDA2.1 的突破，必须从当前 AI 模型的「底层逻辑冲突」看起。\n在主流 AI 大模型（如 GPT、Claude）的世界里，自回归架构是绝对的主宰。\n它遵循逐 Token 生成的严苛范式：每一步输出都会固化为下一步的条件，生成路径如同单向延伸的铁轨，一旦落笔便不可回溯。比如写到「人不能两次走入同一条河流」，即使模型后来意识到应该是「踏入」而不是「走入」，也只能错到底。\n这种方式在稳定性与可控性上具备天然优势，但代价同样明显。由于推理过程本质上是串行的，模型难以进行大规模并行解码，生成延迟随着上下文长度与输出规模不断放大，逐渐成为制约推理效率和部署成本的重要因素。更关键的是，这一范式在结构上默认慢而稳，并未为速度与吞吐的数量级提升预留太多空间。\n基于此，扩散语言模型开始被视为一条具有潜在突破意义的替代路线，它不再执着于从左到右，而是尝试在全局空间内同时生成多个 Token。\n然而，高并行往往伴随着高错误率。早期的扩散模型通常采用「掩码到 Token」（M2T）的固定路径，这种机制虽然快，却存在劣势：一旦某个生成的 Token 信心不足，模型无法在后续步骤中修正它，最终拖慢整体推理速度并降低输出质量。\n这一「速度 — 质量」之间的结构性矛盾，使扩散语言模型长期停留在研究阶段，而难以真正进入应用系统。\n在这一背景下，蚂蚁团队此前提出的 LLaDA2.0 已经证明了百亿参数级扩散语言模型在规模化和并行解码上的可行性，但论文也坦率指出：如何在速度和生成质量之间取得可控、稳定的平衡，仍然是尚未解决的问题。\nLLaDA2.1 正是对这一核心矛盾的直接回应。他们不是继续堆参数、刷榜单，而是通过解码机制、训练范式与工程体系的系统性调整，让扩散语言模型真正跨过能跑和能用之间的门槛。\ndLLM 的路走通了\n我们先看一下结果：LLaDA2.1 在处理复杂的编程任务时，其 100B（千亿）参数版本，实现了 892 Tokens / 秒的惊⼈峰值速度。\n这一结果真正值得关注的前提在于，这是一个 100B 规模的模型。\n对于很多研究者来说，怎么把 dLLM「做大做强」是一个公认的难题。业界主流做法包括从头训练、从自回归模型迁移能力，以及后训练阶段的性能与效率优化。前两条路线受限于数据规模、训练效率和计算成本，模型规模普遍停留在几十亿到三百亿参数以内；而后训练方向虽在代码、规划和推理加速上取得初步突破，但整体仍处于早期阶段，如何协同放大并扩展到千亿参数规模，依然是悬而未决的问题。\n也正因为如此，LLaDA2.1 的 100B 规模本身，就已经突破了这条路线长期存在的规模天花板。也正是在这一前提下，892 Tokens / 秒的结果才显得格外关键 —— 它并不是在一个容易加速的小模型上取得的，而是在扩散模型最难、最重的规模区间里跑出来的。\n更重要的是，这一速度并非来自简化任务或短文本生成，而是出现在 HumanEval+ 这样的复杂编程基准中。在这一场景下，模型不仅需要处理长上下文，还必须保持逻辑一致性与语法正确性，推理效率往往是最先被牺牲的指标。\n这背后藏着蚂蚁团队围绕扩散语言模型长期瓶颈所做的一整套系统性调整。\n像人类专家一样「起草 - 编辑」\n首先，LLaDA2.1 创新性的提出了可纠错编辑机制 (Error-Correcting Editable, ECE)。它可以在毫秒级的闪电采样中起草整个答案，然后回过头来检查、修正。\n我们还是以上面的「人不能两次走入同一条河流」为例，当模型发现「走入」用词不当时，会立即修改成「踏入」。而这种能力是自回归模型无法做到的，LLaDA2.1 摆脱了那种「一写到底」的死板模式，而是分为两步：\n第一步：快速起草。模型以极高的速度并行生成一个「草稿」，这个阶段允许一定程度的不确定性。\n第二步：智能编辑。立即启动「编辑」模式，对草稿进行全局重新评估和自我修正。发现错误？回溯修改。发现更好的表达？即刻替换。\n这一范式涵盖了两类操作：从掩码到 Token 的直接解码，以及从一个 Token 到另一个 Token 的编辑。这种策略使模型能够在生成过程中直接精炼自身输出，从而有效解决并行解码中常见的局部不一致性。为了培养这种编辑能力，团队在持续预训练（CPT）和指令微调（SFT）阶段将模型同时暴露于掩码位置和随机噪声中，激励其不仅生成新内容，还能识别并修正现有错误。\n关键在于，这一架构将原本时延与生成质量之间的刚性权衡关系，转化为一种可由用户灵活配置的连续空间。通过允许模型对生成结果进行回溯式纠错，得以在不导致生成质量崩塌的前提下，大幅降低初始 Mask-to-Token（M2T）阶段的置信度阈值。\n单模型双模式，把选择权交还给用户\nLLaDA2.1 还做了一个更大胆的设计：一个模型支持质量和极速两种模式：\nSpeedy Mode（极速模式）：激进地降低初始生成的置信度阈值，快速产出草稿，依靠后续编辑来保证质量。适合代码生成、快速迭代、头脑风暴等场景。\nQuality Mode（质量模式）：采用保守策略，提高初始生成的质量要求，减少需要修正的错误。适合正式文档、学术写作、高精度任务。\n在此之前，LLaDA-MoE 和 LLaDA 2.0 需要二次开发提供额外的加速版本，比如基于路径蒸馏的加速等；这类加速版本因为非联合训练优化，虽然实现了对基础版本的一定加速，但是精度掉点普遍严重；同时一个多个版本，也增加用户选择的难度以及模型管理的成本。单模型双模式，避免了上述问题。用户根据实际需求，仅需一条 config 就能实现质量和极速模式的切换。\n让模型听得懂话\n如果说可纠错编辑让模型变得可用，那么强化学习则让模型变得更聪明、更可靠 —— 体感更强。\n为进一步提升模型能力，团队在训练流程中引入了强化学习阶段。尽管近期已有研究工作（如 SPG、TraceRL 与 ESPO）证明了强化学习在提升扩散语言模型性能方面的潜力，但由于序列级对数似然难以精确计算，将策略梯度方法应用于块自回归模型仍然面临显著挑战。\n针对这一问题，蚂蚁团队提出并采用了一种基于 ELBO 的块级策略优化方法（ELBO-based Block-level Policy Optimization，EBPO），该框架专门针对可编辑解码结构进行了设计与适配。\n更重要的是，团队还第一次把强化学习真正用到了百亿参数级的扩散模型上，让模型学会更好地理解指令、对齐人的意图，而不是只追求速度。\n可以「边写边改」的 LLaDA2.1，效果到底如何？\n技术上的创新，最终转化为实实在在的能力提升。在 LLaDA2.1 的实验评估中，这种从架构逻辑到执行效率的进化得到了淋漓尽致的体现 。\n表 1 和表 2 报告了 LLaDA2.1-flash 与 LLaDA2.1-mini 相对于其他模型的对比结果，包括性能得分以及 TPF（每次前向推理生成的 token 数）。实验结果显示，在 S 模式 下，LLaDA2.1 的任务得分相较于 LLaDA2.0 略有下降，但 TPF 获得了显著提升；而在 Q 模式 下，LLaDA2.1 在 mini 与 flash 两个规模上均全面超越了 LLaDA2.0 的表现。\n表 3 进一步聚焦于 LLaDA2.1 在 S 模式下的速度性能。可以观察到，该模型在不同任务领域之间呈现出明显的速度差异，其中代码类任务的吞吐率最高，而指令遵循类任务相对较低。具体而言，在量化之后，LLaDA2.1-flash 在 HumanEval+ 基准上达到了 891.74 TPS 的峰值速度，而 LLaDA2.1-mini 的峰值 TPS 则高达 1586.93，展现出显著的推理效率优势。\n如表 4 所示，在相同的 S 模式设置下，引入多块编辑（Multi-Block Editing，MBE） 能够在 Flash 与 Mini 两个模型版本上，跨多个基准稳定提升性能，代价仅为吞吐率的小幅下降。\n图 3 进一步展示了在表 3 所涵盖的五类任务领域中，LLaDA2.1 与 LLaDA2.0、Ling 以及 Qwen-3 等模型在吞吐率（tokens per second）上的对比结果。整体来看，LLaDA2.1 在 S 模式下展现出极为突出的速度优势：在仅牺牲极少输出质量的前提下，实现了显著更快的推理速度。\nAI 架构会范式转移吗？\nLLaDA2.1 的意义，可能不在于某一次指标刷新，而在于它重新把一个被搁置已久的问题摆回了台面。\n过去几年里，自回归模型几乎构成了大语言模型发展的唯一现实路径。它可靠、成熟，也足够好用，以至于行业更多是在这条路上继续加码，而很少真正停下来讨论：语言模型的底层形态，是否还有其他选择。\nLLaDA2.1 并没有试图否定自回归范式，而是用一种更务实的方式证明，扩散语言模型并非只能停留在理论或实验室层面。通过可纠错编辑，它解决了并行生成中最棘手的错误固化问题；通过双模式设计，它把速度与质量的取舍变成一种可以被配置的工程决策；而在百亿参数规模下跑出 892 TPS 的结果，则让「扩散模型能不能真的跑快」不再只是推测。\n语言模型的发展，可能不会很快走向某种范式的彻底更替，但路径的单一性正在被打破。LLaDA2.1 至少说明了一点：在自回归之外，确实存在另一条可以被持续推进、也值得投入资源的方向。\n而这条路，显然还远没有走到终点。\n© THE END 转载请联系本公众号获得授权\n投稿或寻求报道：liyazhou@jiqizhixin.com\n","date":"11 February 2026","externalUrl":null,"permalink":"/posts/%E9%87%8C%E7%A8%8B%E7%A2%91%E6%97%B6%E5%88%BB100b%E6%89%A9%E6%95%A3%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%B7%91%E5%87%BA892-tokens-%E7%A7%92ai%E7%9A%84%E5%8F%A6%E4%B8%80%E6%9D%A1%E8%B7%AF%E8%B5%B0%E9%80%9A%E4%BA%86/","section":"AI-Related Reposts","summary":"","title":"[Repost] 里程碑时刻！100B扩散语言模型跑出892 Tokens /秒，AI的另一条路走通了","type":"posts"},{"content":"","date":"11 February 2026","externalUrl":null,"permalink":"/tags/github/","section":"Tags","summary":"","title":"Github","type":"tags"},{"content":"","date":"11 February 2026","externalUrl":null,"permalink":"/tags/llm/","section":"Tags","summary":"","title":"LLM","type":"tags"},{"content":"Powered by Veo of Gemini 3 Pro.\nYour browser does not support the video tag. ","date":"11 February 2026","externalUrl":null,"permalink":"/videos/momoga1/","section":"AI-Generated Videos","summary":"","title":"Momoga","type":"videos"},{"content":"Reposted from 一人干翻所有大厂！OpenClaw硅谷封神，开发者一夜爆赚两亿 by 新智元\n# # 新智元报道 编辑：KingHZ Aeneas\n【新智元导读】硅谷新英雄OpenClaw之父豪言：本地AI智能体将灭掉80%App，人类从此只需「许下愿望」，世界自动为你运转！OpenClaw更是开启万亿美元应用新场景，社交套利从未如此简单！ # 这些天，硅谷正在经历一场前所未有的疯狂。\nOpenClaw之父，已经成为硅谷英雄——继互联网之后，他开启了文明层级的又一次范式转移。\n所有人类，正在站在被智能体接管的奇点前夜。\n刚刚，OpenClaw之父上了YC访谈，揭秘了OpenClaw这个爆款AI背后的顿悟时刻。\n他放下豪言：本地优先智能体，将「杀死」当今80%的应用；个人智能体，会彻底重塑软件的未来！\n而且，如果还没有用OpenClaw赚钱，你就out了。\n最近，已经有开发者仅投入2万美元，就实现了4000万美元净资产的积累。\n许多人说，这就是OpenClaw的「十亿美元级应用场景」！\n一个人干翻所有大厂，\n2万美元撬动4000万？\n最近，一个「2万美元变4000万美元」的例子，在全网疯传。\n一个普通人用TikTok+OpenClaw，把华尔街按在地上摩擦。\nTikTok上，一条视频突然爆了——一个女孩举着星巴克的粉色星星杯，声音都快破音了：「全城断货！真的买不到了！求代购！」\n对大多数人来说，这只是一条视频，刷过去就算了。但对另一个人来说，这却是一条交易信号。\n就在视频开始爆发的5分钟前，他的OpenClaw已经完成了识别：抓取内容 → 判断情绪强度 → 交叉验证 → 匹配可交易标的 → 建仓。\n几周后，华尔街的分析师们还在争论着「节日促销是不是一次性的」，他的收益曲线却已经几乎乎垂直：从2万美元，滚到了4000万美元。\n这不是运气，也没有内幕。只有一个人，一台电脑+几千行代码，就完成了这场个人财富的翻倍。\n这种方法的关键，就在于交易中的情绪分析。\n例如，多项研究显示，社交媒体可预测股票回报，产生 1-2%的超额收益。\n但由于仅有1%的信号可能带来可执行的交易，因此仍需人工验证，从而在一个有80%的日内交易者亏损的领域中，降低情绪偏见。\n因此，开头那个故事不是什么新套路，只是被AI放大了。其实这种事，以前就发生过。\n2007年，Chris Camillo——一个没背景、没终端、没华尔街人脉的普通人，靠的不是Bloomberg，而是眼睛，实现了财富暴增。\n他会去商场看排队、看「sold out everywhere」，刷论坛、刷早期社交网站，比金融机构早几个月意识到什么在卖爆。\n初入股市三年时间，他的本金就翻了10倍，直接血赚。\n这个人后来成了社交数据智能公司TickerTags的首席执行官，也就是那个传说中的「华尔街扫地僧」。\n之后，2006年12月1日至2013年11月30日的七年期间，他的投资组合年均回报率达到84%。\n他把这种交易策略叫「社交套利」，逻辑很简单：消费情绪会在街头、在手机里先爆炸，股价在几个月后才跟上。\n而今天，这种操作的问题不是「看不到」，而是「来不及」。情绪早已不在商场里，而是在TikTok、X和评论区里。但人类根本跟不上。\nTikTok上一个限量杯断货视频在病毒式传播，而高盛的交易员却还在等财报电话会议，他们扫描的只是上个季度的影子。\n上文的研究表明：社交媒体情绪可以预测股票回报，大约有1–2%的超额收益空间。\n但现实是：99%的信号没法交易，而人类在验证、犹豫、情绪波动中，把那1%也错过了。\n于是，80%的日内交易者长期亏损。\n而AI来了，OpenClaw来了，「社交套利」有了新版本——\n它不走官方API（因为API有限制，且会被屏蔽），它直接模拟真实的人类浏览器行为。\n它不知疲倦，每5分钟醒来一次，执行一套极其复杂的搜索任务，然后把最有价值的情报喂到你的嘴边。\n14小时，1605个信号，平均每30秒就有一个潜在收益信号。\n人类会累、会怕、会犹豫、会自我怀疑，但它不会。它不贪，也不慌，只是稳定执行。\n曾经需要6个月才能完成的社交套利窗口，现在被压缩成几天，甚至几小时。\nMoonDev手动验证过下面这些案例：星巴克节日杯的爆火，领先于财报；Lululemon瑜伽裤断货，提前抬高了市场预期；任天堂新配件卖空，直接带动了整机销量预期上抬。\nAI不负责「相信」，它只负责比你更早看到、比你更冷静执行。\n人类真正剩下的价值，只在两个时刻：极端节点的人工干预，或者干脆躺平，什么都不做，看曲线自己起飞。\n说到底，这不是什么暴富神话，而是规则的变化。\n传统交易就像下象棋，而OpenClaw则是给新手一台AlphaZero。\n它不一定永远赢，但它永远比你清醒。它能让你的财富一夜从2万翻到4000万。本质上来说，这是「执行力×杠杆×时间压缩」的AI魔法。\n这是散户第一次在信息速度上，把机构按在地上摩擦。\n「OpenClaw封神硅谷」，这绝不仅仅是一个梗，而是一个紧迫的信号：普通人正在走向信息平权，算力平权，执行平权。\n华尔街会花数亿美元去买1毫秒的延迟，而一个2万美元的脚本，买到的是6个月的时间差。\n最锋利的武器，从来不是杠杆，而是——你比别人更早知道，而且敢于执行！\nYC之父：80%的APP都会被杀死\n最近，那个让整个互联网「炸锅」的男人——Peter Steinberger，开源AI智能体 OpenClaw 的创造者，上了YC访谈。\n在这次深度对谈中，Peter不仅回顾了「灵光一现」时刻，也掀开了他那套惊世骇俗的开发理念——\n他说自己只是在「电脑上玩点小东西」，结果直接卷出了一整套未来生活方式。\n个性化智能体OpenClaw「杀死」当今80%应用 # 你可能会问，现在AI助手满天飞，为什么偏偏是OpenClaw火了？\nOpenClaw在Github开源项目的Star数历史\nPeter直接甩出一记重锤：「因为它真的能跑在你自己的电脑上。」\n这听起来可能没那么惊艳，但别急——\n之前的那些智能体，不是在云端动动嘴皮子、也能跑几个任务流程吗？\nOpenClaw不一样，它可以连接你家里的任何设备，真·动手操作你的世界。\n「它能控制我的床垫温度。」他说，「ChatGPT行吗？」\n对话的高潮在于，Peter Steinberger给App的「死刑判决」——\n「未来80%的App，都会被AI智能体取代。」\nPeter Steinberger语气平静，像是在描述明天天气可能下雨。\n但这是一记响亮的丧钟。\n响在产品经理的脑袋里，响在VC的估值报表上，也响在App的开发者心头。\n为什么App会死？\nPeter的答案简单，但让人无法反驳：\n我有了一个AI，它住在我电脑里，会听我说话，会看我的文件，会帮我点外卖、回邮件、生成幻灯片、订餐厅，还会提醒我「你最近运动太少」。、\n既然有更贴心的个人化的智能体，「那我还需要App干嘛？」\n想订餐厅？你只要说：「帮我订个安静点的日料馆。」\nAI直接和餐厅沟通，或者，真的打电话让人类帮你搞定。\n想记录饮食？你不需要打开热量计算App比如MyFitnessPal，点开食物条目，选份量，再手动输入。\n你只要随口说：「今天中午吃了个巨无霸。」AI记录下来了，还会默默在你日历上插个30分钟的跑步时间段。\n你不再「操作系统」，而是「交代愿望」。\n你不再「使用工具」，而是「触发动作」。\n人类进入了「意图即执行」的新时代。\n那什么类型的App会先死？\nPeter很清楚地划出一条界线：「只要是那种帮你「管理信息」的App，全都要死。」\n代办类、备忘录类、打卡类、记录类、数据整理类……\n它们的存在价值，在于你「没地方交代这些事情」。\n但现在，你只要张口说话，OpenClaw就能：记录、理解、归类、调度、自动执行。\n一个智能体，就干掉了五六个App团队的功能线。\n只有少数几类App，还有存在的意义：「它们得有传感器。」\n比如手表收集心率、温度传感器监测睡眠质量、摄像头识别家庭安全问题……\n这些硬件接口，AI暂时还得依赖它们。\n但那些「没有物理输入端」的软件，就危险了。\nOpenClaw，是时代转折的宣言：「你要的，不是一个又一个工具。而是一个理解你、行动力强、记得你的人格化智能体。」\nAI不是App的升级版，而是App范式的终结者。\n一旦你体验过「说一句话，世界为你运转」的流程，你就再也不想回到点点点的App界面！\n模型不是护城河，记忆才是\nOpenClaw可以清理你的收件箱，发送邮件，管理日程，办理航班值机。\n而这一切，只需要通过你日常使用的WhatsApp、Telegram或任何聊天应用即可完成。\n但OpenClaw真正的革命性，不只是「它能做多少事」，而在于它不属于任何平台，只属于你。\n这正是它和主流AI产品最本质的区别。\n今天市面上的AI助手，看起来方便，背后却是一场数据封锁战。\n你说的话、上传的文件、生成的图片、分析的内容，全都被收进云端。\n而你，无法迁移、无法下载、无法带走。你以为你拥有了一只聪明的AI。其实，是平台悄悄拥有了你的全部生活轨迹。\n而OpenClaw，反过来了。\n所有记忆，保存在你本地电脑里，纯文本Markdown文件。\n如果你愿意，你可以手动删除、导出、加密、转移，甚至拿U盘插去别的电脑继续用。\n这，就是在夺回数据主权。\nPeter说：「未来的AI世界，不该是平台主宰一切，而是用户主宰自己的智能体。」\n他看得很清楚：模型再强，也会被下一代替代；算力再猛，也终将平价；接口再炫，也会被模仿。\n但一个人和AI共同经历的记忆，独一无二。这才是OpenClaw真正的「护城河」！\n它不怕你换模型，不怕你换电脑，不怕你断网。\n只要你还有那一堆.md文件，那段与你共同生活的记忆，它就能「原样回来」，再度成为你的数字影子。\n这，是OpenClaw最温柔、也最危险的野心：「让每个人，都拥有一个只属于自己的AI，而不是一份租来的云端人格。」\nOpenClaw不是Peter的终点，而是每个个性化智能时代的起点。\n未来将属于那些拥有自己AI、拥有自己数据、拥有自己灵魂.md的人。\n就像Peter所说：「你不需要被AI征服，你只需要找回对技术的掌控感。那是我们最早爱上电脑时的感觉。」\n参考资料：\nhttps://www.youtube.com/watch?v=4uzGDAoNOZc\nhttps://x.com/MoonDevOnYT/status/2020276169669738630\nhttps://x.com/ycombinator/status/2020150559232389242\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！\n","date":"10 February 2026","externalUrl":null,"permalink":"/posts/%E4%B8%80%E4%BA%BA%E5%B9%B2%E7%BF%BB%E6%89%80%E6%9C%89%E5%A4%A7%E5%8E%82openclaw%E7%A1%85%E8%B0%B7%E5%B0%81%E7%A5%9E%E5%BC%80%E5%8F%91%E8%80%85%E4%B8%80%E5%A4%9C%E7%88%86%E8%B5%9A%E4%B8%A4%E4%BA%BF/","section":"AI-Related Reposts","summary":"","title":"一人干翻所有大厂！OpenClaw硅谷封神，开发者一夜爆赚两亿","type":"posts"},{"content":"Reposted from Anthropic员工效率碾压谷歌1000倍！打工人想进，必须先「杀死自我」 by 新智元\n# # 新智元报道 编辑：定慧\n【新智元导读】一位在硅谷摸爬滚打30年的老兵，花了4个月时间，跟Anthropic近40人深聊后，他揭示了一个残酷的公式：工作量碾压人数=创新井喷，人数碾压工作量=内卷开始。谷歌就是这么废掉的。而Anthropic正站在黄金时代的正中央——没有部门壁垒，没有复杂规范，产品10天从想法到上线。2026年，Anthropic会击垮大量企业。 # Anthropic，这家公司现在是硅谷，甚至是全世界的当红炸子鸡！\n全球几万亿的市值，被一个小小的Claude所搅动，可谓是风头无两。\nAnthropic取代OpenAI成为AI能力跃迁的风向标，已经成了一部分人的共识。\n大前几日Claude Opus 4.6的一个小版本更新，直接撼动了整个SaaS行业。\n**而且Menlo Ventures还成立了Anthropic生态基金。\n**\nMenlo Ventures是硅谷顶级老牌VC，成立于1976年，管理规模超过70亿美元。\n可以说，现在的Anthropic奠定了建构AI生产力的标准，或者粗暴一点：\nClaude出什么功能，全世界都要立马看一眼。\n那么问题来了：这家公司内部到底是怎么运作的？\n他们的员工都是什么样的人？\n深入Anthropic内部蜂巢\nAnthropic内部「乱成一锅粥」，却为何能碾压硅谷巨头？\n一个前谷歌、前亚马逊的30年老兵，花了4个月时间，跟Anthropic近40个人聊透了。\n这个人就是前谷歌、亚马逊资深工程师Steve Yegge。\n他深入剖析了当今最炙手可热的AI公司Anthropic的内部运作模式。\n原文地址：\nhttps://steve-yegge.medium.com/the-anthropic-hive-mind-d01f768f3d7b\n他的结论是，这家公司的运作方式，颠覆了所有人对「成功企业」的认知。\n进Anthropic有多难？堪比进NFL\nSteve Yegge算了一笔账。\n以行业专业人士身份进入Anthropic的概率，跟一个高中生打进国家橄榄球联盟差不多。\n他见过的每一个Anthropic员工，都是精英中的精英。\n精英的程度甚至超过了谷歌巅峰时期。\n他拿自己举例：「谷歌曾经录用过我，而我其实只是勉强够格的边缘人选。」\n言外之意：能进Anthropic的人，比当年的他还狠。\n蜂巢思维：一家靠「氛围」驱动的公司\n跟这40个人聊完，Yegge发现了一件诡异的事。\nAnthropic的员工自己都在说：这里是一个完全靠氛围（vibes）驱动的蜂巢思维。\n没有传统的部门壁垒。\n没有成熟公司那套「专业化」的陈规俗套。\n每个人都能看到别人在干什么。\n犯错？走弯路？全公司都能看见。\n想藏？没门。\n这叫「自我的消亡」。\n你必须成为一只快乐的工蜂。\n否则离心力会把你甩出去。\n黄金时代的秘密：工作量必须碾压人数\nYegge在硅谷混了30多年。\n他亲历过三个「黄金时代」：\n亚马逊，1998年起，势头持续到他2005年离职后很久；\n谷歌，巅峰期一直到2011年4月；\n微软，输掉Java诉讼后的C#/.NET时代；\n他终于想通了黄金时代的核心公式：\n工作机会 \u0026gt; 人数时，就会创新井喷。\n人数 \u0026gt; 工作机会时，则会让内卷开始。\n道理很简单。\n活儿多到干不完的时候，没人会抢别人的项目。每个人都忙着开疆拓土，没空搞政治斗争。\n反过来，一旦活儿不够分，聪明人就开始「占坑」。你不占，别人就占了。领地意识、派系斗争、办公室政治——全来了。\n人性使然。\n谷歌是怎么「废掉」的？\n2011年4月，Larry Page接任CEO。\n他宣布：「停止开发新项目，我们只专注X、Y、Z这三项业务。」\n所有工程师都留着。工作量砍了50%。\n结果呢？工作不够分。人开始抢活干。\n圈地运动来了。权术博弈来了。领地意识来了。\n还有个微软发明的词：「舔饼干」——抢了活儿却永远不干。\n从那一刻起，谷歌变得「政治化」。创新引擎熄火。黄金时代终结。\nAnthropic正站在黄金时代的正中央\n再看Anthropic。\n几乎每条战线上，活儿都多到干不完。\n每个人，这就像站在一个不断膨胀的球体表面。\n永远不用抢活干。因为活儿是无限的。\n每个人都有机会把想法拿出来，让蜂巢思维评判。\n行就上，不行就换一个。\n没有政治斗争的土壤。\nClaude Cowork：10天从想法到上线\nYegge听到了一个让他震惊的数字。\nClaude Cowork这个产品，从最初有这个想法，到公开发布，一共用了10天。\n10天！\n这在传统公司需要多久？3个月？6个月？\n他们怎么做到的？\n篝火模型：围坐在一起，边聊边造\nAnthropic的开发方式，完全打破了教科书。\n没有瀑布模型。没有复杂规范。\n核心是一个鲜活的原型。所有人围坐在「篝火」旁，一起雕琢它。\n规划周期从不超过90天。\n这已经是他们能想象的「最长周期」了。\n结果呢？整个过程像即兴表演。\n想法来了就试。试了就上。上了就迭代。\n效率差距有多大？\nYegge给出了一个惊人的对比：\nAnthropic的工程师效率，比现在用Cursor和ChatGPT的开发者高10到100倍。\n比2005年谷歌工程师高1000倍。\n这个数字太疯狂了。\n但如果你见过他们的工作方式，你会觉得这个数字保守。\n「是的，而且…」——即兴剧场式的协作\nAnthropic内部有个文化基因：「Yes, and…」\n每个想法都会被接纳、审视、品味。\n蜂巢思维来评判。\n没有中央决策机构拍板。\n所有人一起试。\n当魔法发生的时候，大家同时心领神会。\n但反过来——\n谁要是不像快乐工蜂那样行动，会被温柔地推出去。\n想端着枪冲进来表现自己？对不起，这是团队运动。\n最顶尖的人才，单他们的眼神甜蜜而忧伤\nYegge说了一个观察，让人印象极深。\n在Anthropic，他遇到的每个人、每个团队，都带着一种「甜蜜而忧伤的超然感」。\n他们像一群牧羊人，肩负着创造文明级重要事物的使命。\n充满热情，但又带着一种庄严的凝重。\n那种眼神，像是信仰上帝的人看待尘世——笃定、悲悯。\n或者像精灵，看着古老世界渐渐逝去。\n他们真心为很多公司感到惋惜。\n因为2026年会击垮大量企业。\n而很多公司还没看见这场海啸。\n活下来的唯一办法\nYegge最后给出了建议：\n「点燃篝火。把你的产品变成鲜活的原型。考虑在公司内部建立创新蜂巢。给它们空间。」\n传统的部门壁垒？扔掉。\n复杂的规划流程？砍掉。\n自我意识？放下。\n**然后，全力以赴转向新的产品市场契合点。\n**\n差距不是技术，差距是意识。\nAnthropic的人是真的相信自己在做一件改变文明的事。\n2026，这将是疯狂的一年。\n参考资料：\nhttps://steve-yegge.medium.com/the-anthropic-hive-mind-d01f768f3d7b\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！\n","date":"9 February 2026","externalUrl":null,"permalink":"/posts/anthropic%E5%91%98%E5%B7%A5%E6%95%88%E7%8E%87%E7%A2%BE%E5%8E%8B%E8%B0%B7%E6%AD%8C1000%E5%80%8D%E6%89%93%E5%B7%A5%E4%BA%BA%E6%83%B3%E8%BF%9B%E5%BF%85%E9%A1%BB%E5%85%88%E6%9D%80%E6%AD%BB%E8%87%AA%E6%88%91/","section":"AI-Related Reposts","summary":"","title":"[Repost] Anthropic员工效率碾压谷歌1000倍！打工人想进，必须先「杀死自我」","type":"posts"},{"content":"Reposted from Google 悄悄开源了一个「数据提取神器」，3 行代码干掉你 500 行正则 by ITADN\n你还在用正则表达式从 LLM 输出里抠 JSON 吗？Google 工程师受不了了，直接开源了 LangExtract——一行 lx.extract() 解决所有结构化提取的痛。\n💢 痛点：LLM 时代最被低估的脏活 # 2026 年了，大模型的能力早已不是瓶颈。真正的瓶颈是什么？\n是把大模型的输出变成你代码能用的数据。\n想象一下这个场景：你让 GPT 帮你从一份 50 页的财报里提取关键财务数据。模型很聪明，回答得头头是道。但你要的不是一段话——你要的是一个干干净净的 JSON，能直接灌进数据库。\n于是你开始写代码：\n# 😭 你的日常import re, jsonresponse = llm.generate(\u0026#34;从以下文本提取财务数据...\u0026#34;)# 哦不，模型输出了 ```json 包裹的内容text = re.search(r\u0026#39;```json\\s*(.*?)\\s*```\u0026#39;, response, re.DOTALL)if text: try: data = json.loads(text.group(1)) except json.JSONDecodeError: # 模型偶尔输出不合法 JSON，加个修复逻辑... data = fix_json(text.group(1)) # 又是 100 行else: # 模型没用代码块包裹，试试直接解析... try: data = json.loads(response) except: # 算了，用正则硬扣吧... 😤 pass 这还只是第一步。 如果文本超过模型的上下文窗口呢？你得自己分块。分块之后不同块的结果怎么合并？怎么去重？提取出来的内容怎么映射回原文位置？\n这套\u0026quot;脏活\u0026quot;，几乎每个用 LLM 做数据提取的开发者都在重复造轮子。\nGoogle 的工程师终于忍不了了。\n▲ 传统方式 vs LangExtract 对比：一边是无尽的调试深渊，一边是 3 行代码准时下班\n🚀 LangExtract：Google 的答案 # LangExtract 是 Google 在 2025 年底开源的一个 Python 库，目标很明确：\n用最少的代码，从任意文本中提取结构化数据——自动分块、自动并发、自动对齐、自动去重。\n项目地址：https://github.com/google/langextract\n直接看核心 API，感受一下它的简洁度：\nimport langextract as lxresult = lx.extract( \u0026#34;一大段非结构化文本...\u0026#34;, prompt_description=\u0026#34;提取所有人物及其职位\u0026#34;, examples=[...], # Few-shot 示例 model_id=\u0026#34;gemini-2.5-flash\u0026#34;# 支持 Gemini/GPT/Ollama)lx.visualize(result) # 一行可视化 3 行代码，完事了。 没有正则，没有 JSON 修复，没有手动分块。\n▲ LangExtract 核心工作流：从原始文本到结构化数据的全自动管线\n🧠 它到底解决了什么？5 大核心痛点逐个击破 # 痛点 1：长文本分块是个噩梦 # 你有一份 10 万字的合同，模型上下文窗口只有 8K tokens。怎么办？\n❌ 传统做法： 手动按字数切分，祈祷切分点不会把一句话劈成两半。\n✅ LangExtract： 内置智能分块引擎，基于句子边界分块，支持跨块上下文窗口（context_window_chars），让模型在处理当前块时能\u0026quot;看到\u0026quot;上一块的尾部内容，解决跨块指代问题（比如\u0026quot;她\u0026quot;指的是上一段提到的某个人）。\nresult = lx.extract( 超长文本, context_window_chars=500, # 跨块上下文重叠 500 字符 max_char_buffer=2000, # 每块最大 2000 字符 ...) 痛点 2：LLM 输出格式不可控 # 模型有时候输出 json ... ，有时候直接输出裸 JSON，有时候夹杂废话。传统方案需要你写一堆 Parser。\n✅ LangExtract： 内置 Resolver 解析器，自动处理各种输出格式，支持 JSON 和 YAML，还有模糊对齐（fuzzy_alignment）功能——即使模型输出的文本和原文不完全一致，也能正确定位到原文中的位置。\n痛点 3：提取结果无法溯源 # 你从一篇论文里提取了 20 个实体，但你不知道每个实体是从原文的哪个位置提取的。\n✅ LangExtract： 返回的 AnnotatedDocument 对象包含完整的原文映射信息（char_interval），精确到字符级别。配合 lx.visualize()，直接在 Jupyter Notebook 里高亮显示提取结果在原文中的位置。\n痛点 4：处理速度太慢 # 1000 条文本顺序调用 API，等到天荒地老。\n✅ LangExtract： 内置批量并发处理，默认 10 个 worker 并行调用 LLM API。处理大批量数据时，还支持 Gemini Batch API 做离线批处理。\nresult = lx.extract( documents, batch_length=20, # 每批 20 个文本块 max_workers=10, # 10 路并发 ...) 痛点 5：切换模型要重写代码 # 今天用 Gemini，明天想试试 GPT-4，后天又想跑个本地 Ollama。每个模型 API 不一样，代码改到吐。\n✅ LangExtract： 统一的 Provider 抽象层，切换模型只需改一个参数：\n# 用 Google Geminilx.extract(..., model_id=\u0026#34;gemini-2.5-flash\u0026#34;)# 切换到 OpenAIlx.extract(..., model_id=\u0026#34;gpt-4o\u0026#34;)# 用本地 Ollamalx.extract(..., model_id=\u0026#34;llama3\u0026#34;, model_url=\u0026#34;http://localhost:11434\u0026#34;) 而且支持插件机制——第三方可以通过 Python entry_points 注册自定义 Provider，pip install 后自动可用，零配置。\n▲ 并发处理流程：自动分块 → 多路并发调 LLM → 解析合并 → 返回结果\n🏗️ 架构设计：分层解耦的正确示范 # LangExtract 的代码架构非常优雅，值得学习：\n🎯 用户 API 层├── lx.extract() ← 主入口└── lx.visualize() ← 可视化⚙️ 处理管线层├── Chunking ← 智能分块├── Prompting ← Few-shot 提示词构建├── Annotation ← 标注引擎（并发调度）└── Resolver ← 结果解析 + 模糊对齐🔌 提供者层（可扩展）├── Gemini ← Google AI├── OpenAI ← GPT 系列├── Ollama ← 本地推理└── Plugin System ← 第三方扩展🏗️ 核心层├── BaseLanguageModel ← 模型接口├── Data Types ← Schema + 数据类型└── Tokenizer ← 分词器 ▲ 分层架构图：严格的单向依赖，上层依赖下层，绝不反向\n几个设计亮点：\n严格的依赖方向：Core 层不依赖 Providers，Providers 不依赖 Annotation。通过 import-linter 在 CI 中强制执行。\n注册表模式：模型 ID 通过正则匹配自动路由到对应 Provider，用户无需关心底层实现。\nPEP 562 懒加载：import langextract 时不会立即加载所有子模块，首次访问时才加载，启动快。\n🔥 实战场景：它能干什么？ # 场景 传统做法 LangExtract 从新闻中提取人物和事件 写 NER + 关系抽取模型 3 行代码 解析简历提取教育经历和工作经验 正则 + 模板匹配 3 行代码 从合同中提取关键条款 法律 NLP 专用模型 3 行代码 医疗报告结构化 领域专用标注 + 训练 3 行代码 从论文中提取方法论和结果 手动整理 3 行代码 共同点：你只需要告诉模型\u0026quot;提取什么\u0026quot;、给几个示例，剩下的交给 LangExtract。\n📝 快速上手 # 安装 # pip install langextract# 如果要用 OpenAIpip install langextract[openai]# 如果要用本地 Ollama# 确保 Ollama 服务已运行 完整示例 # import langextract as lxfrom langextract.core.data import ExampleData# 定义示例（告诉模型你要什么格式）examples = [ ExampleData( text=\u0026#34;张三是腾讯的高级工程师，在深圳工作。\u0026#34;, extractions=[{ \u0026#34;name\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;company\u0026#34;: \u0026#34;腾讯\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;高级工程师\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;深圳\u0026#34; }] )]# 一行提取result = lx.extract( \u0026#34;李四于 2024 年加入阿里巴巴，担任算法专家，base 杭州。\u0026#34; \u0026#34;王五是字节跳动的产品经理，常驻北京。\u0026#34;, prompt_description=\u0026#34;从文本中提取人物的姓名、公司、职位和工作地点\u0026#34;, examples=examples, model_id=\u0026#34;gemini-2.5-flash\u0026#34;)# 可视化结果lx.visualize(result) 🤔 和 Instructor / LangChain 有什么区别？ # 你可能会问：这不是和 instructor 或 LangChain 的结构化输出差不多吗？\n区别很大：\n特性 LangExtract Instructor LangChain 长文本自动分块 ✅ 内置 ❌ 自己写 ❌ 自己写 跨块上下文窗口 ✅ 内置 ❌ ❌ 提取结果溯源 ✅ 字符级定位 ❌ ❌ 结果可视化 ✅ 内置 ❌ ❌ 模糊文本对齐 ✅ 内置 ❌ ❌ 多轮提取去重 ✅ extraction_passes ❌ ❌ 批量并发 ✅ 内置 ❌ 需额外配置 简单说：Instructor 解决的是\u0026quot;让 LLM 输出结构化数据\u0026quot;这一个点，LangExtract 解决的是从非结构化文本到结构化数据的完整管线。\n💡 值得关注的技术细节 # 多轮提取（Multi-pass Extraction） # 对于信息密度很高的文本，单次提取可能遗漏。LangExtract 支持多轮提取：\nresult = lx.extract( dense_text, extraction_passes=3, # 提取 3 轮，自动合并去重 ...) 每轮独立提取，最后自动合并，先提取到的结果优先（first-pass wins），重叠部分自动去重。\nURL 自动下载 # # 直接传 URL，自动下载网页内容并提取result = lx.extract( \u0026#34;https://example.com/article\u0026#34;, ...) Prompt 验证 # 提供了 Few-shot 示例的自动验证机制，在提取之前就检查你的示例是否和文本对齐，提前发现问题：\nresult = lx.extract( ..., prompt_validation_level=\u0026#34;ERROR\u0026#34;, # 示例不对齐直接报错 prompt_validation_strict=True,) 📊 项目数据 # GitHub Stars： 快速增长中 ⭐\n版本： v1.1.1（活跃维护）\n许可证： Apache 2.0（商用友好）\nPython： ≥ 3.10\nDOI： 10.5281/zenodo.17015089（可学术引用）\n代码质量： 完整测试套件 + import-linter 依赖检查 + 类型注解\n🎯 总结 # LangExtract 不是又一个 LLM wrapper。它解决的是一个非常具体且普遍的痛点：\n如何从大规模非结构化文本中，可靠地、可追溯地、高效地提取结构化数据。\n在 LLM 时代，这个问题几乎每个做数据处理的团队都会遇到。Google 用一个设计优雅的开源工具给出了标准答案。\n如果你的工作涉及到：\n📄 文档解析（合同、财报、简历）\n🏥 医疗 NLP（病历结构化、药品信息提取）\n📰 信息抽取（新闻、社交媒体、研究论文）\n🏗️ 数据管线（ETL 中的非结构化数据处理）\n强烈建议收藏这个项目。\n👉 GitHub：https://github.com/google/langextract\n如果觉得有用，点个「在看」转发给你还在写正则的同事吧 😏\n","date":"9 February 2026","externalUrl":null,"permalink":"/posts/google-%E6%82%84%E6%82%84%E5%BC%80%E6%BA%90%E4%BA%86%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8F%96%E7%A5%9E%E5%99%A83-%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%B9%B2%E6%8E%89%E4%BD%A0-500-%E8%A1%8C%E6%AD%A3%E5%88%99/","section":"AI-Related Reposts","summary":"","title":"[Repost] Google 悄悄开源了一个「数据提取神器」，3 行代码干掉你 500 行正则","type":"posts"},{"content":"Reposted from 全网最详细的Codex入门教程，手把手教你玩转Vibe Coding。 by 数字生命卡兹克\n一整个周末，我几乎除了睡觉，其他的时间都在Vibe Coding。\n一边写文章一边Vibe Coding，一边煮方便面一边Vibe Coding，一边看电影一边Vibe Coding。。。\n真的，左下角那个Macbook就是我用来Vibe Coding的电脑，大屏幕是我用的Windows主机在看电影。\n之所以用Mac来Coding，那原因太简单了，就是为了用Codex的应用。\nCodex+GPT-5.3 Codex实在太太太太好用了。\n我周六的时候就发了一个X去感慨。\n底下无数赞同的。\n真的，又快又牛逼，以前5.2-codex不好用，不是因为能力不够强，是实在实在太慢了，出门挂着coding，吃完饭都回家了2、3个小时还在改。\n但是这一次，5.3-codex速度快了N倍，额度还高，能力还比Opus 4.6强，我自己的体感和体验，真的，就单vibe coding这块，比Claude爽多了。\n说真的，以前对Vibe Coding感兴趣，但是因为Claude封号被劝退，因为OpenCode各种BUG被劝退，因为各种IDE看不懂被劝退的大家。\n在今天，我可以拍着胸脯说，OpenAI的Codex+GPT-5.3-codex，就是你最佳的入门、进阶、毕业的一条龙产品。\n你要相信我，愚钝如我，也能在它上面感受到进入心流的爽感，一个周末用它，解决了我四五个过去我完全一个人无法实现的开发需求。\n我这样的人都可以，那你，一定也可以。\n我无比推荐从这一刻开始，无论你有多么小白，你都可以开始使用AI，用codex，来满足你自己的需求。\n而且，最关键的是，Codex他有应用啊！！！他有可视化的图形界面啊！！！\n作为一个干了特么快10年的用户体验设计师，说真的，作为一个非专业编程用户，我真的接受不了都快2030年了，我还要用命令行界面。\n真的，你知道我之前第一次用命令行的时候，还有OpenCode那个TUI的时候，我不知道怎么打开某一个目录，甚至有一个极度反常识的东西，就是复制粘贴。\n你我都知道，Ctrl+C是复制对吧，我当初也是这么以为的。\n结果在命令行里，我想复制一个东西，我直接习惯性的选中一堆字以后，按Ctrl+C，结果，这个快捷键是强制关闭。。。\n还有Claude那个XX，不仅封号狂魔，而且感觉真的掉钱眼里了，周末他们又给Opus 4.6上了个Fast模式，说是快2.5倍。\n大家都觉得没啥毛病对吧，结果我一看文档，尼玛的，价格贵了5倍，1M的Token消耗来到了离谱的150刀，真的有毒。\n反观另一边奥特曼。\n我是爱研究，但是教练，我是真的不想吃苦啊。\n有一说一，这一波我站OpenAI，我爱OpenAI。\n所以，今天这篇文章，我真挚的向大家推荐Codex，也希望大家，都能在这个时代，真正的开启自己的vibe coding旅程。\n正好马上也春节了，在家闲着没事，用coding创造创造，拿在亲戚面前再秀一秀，那种成就感，真的比打游戏还要爽。\n一. 啥是Codex\n还是先给大家做一下小小的科普，因为很多朋友可能完全没有听过这个东西。\n相信很多朋友都知道Claude Code和大龙虾Clawdbot了对吧，这两，都可以理解为，是一个Agent应用，在上层，封装了很多的工程化能力。\n而Codex，就是OpenAI对标Anthropic家的Claude code产品。\n一个编程Agent，但其实走到今天，已经约等于通用Agent了，因为这信息化30年，一切的东西几乎都构建于代码之上，你的编程能力越强，就越趋近于通用Agent，这就是为啥最近美股那边天天吵着说软件的逻辑变了，一个Claude的excel cowork插件能给华尔街吓个半死的原因。\ncodex和claude code都是上层的编程应用，应用本身是需要搭配模型一起使用的，正好上周五两家都发了自己的新模型，GPT-5.3-codex和Claude Opus 4.6。\nGPT-5.3-codex是一个纯粹的编程特化模型，所以在创作、事实核查、世界知识等方面效果并不好，所以OpenAI并没有把他上到ChatGPT里给所有人使用。\nChatGPT上只有GPT 5.2。\n目前只有Codex中上线了GPT-5.3-codex。\n只要你是Plus或者Pro会员，都可以下载codex然后进行使用。\n如果你是免费会员或者8美刀的Go会员，Codex可以下载也可以使用，但是是没有GPT-5.3-codex的，只能用GPT-5.2-codex，这个需要注意一下。\n至于如何下砸Codex，那就更简单了。\n进入到OpenAI的Codex官网：\nhttps://chatgpt.com/codex\n看到这个大大的下载应用没有，点击就行。\n就会下载下来一个Mac的安装包，然后安装、登录就完事了。\n不要太简单。\n至于Windows的应用版本，目前还没上线，只能使用命令行版本，不过应用版本应该也快了，估计就在这一周内。\n二. 如何使用\n当你下载好，登录到Codex的首页之后，你应该看到的，就是这个界面了。\n在整个编程的逻辑中，其实有一个很核心的东西，也就是左边的侧边栏哪里，一个一个的文件夹，这个东西，叫做Threads，也就是线程。\n在整个Codex的逻辑里，左边这栏其实分两层。\n第一层是文件夹，也就是工作区。\n你可以把它理解成一个个项目目录，或者一个个主题盒子，比如我自己的AI热点、数据抓取机器人、sandbox，这种，它负责把你的文件放得井井有条。\n第二层才是Thread。\n你点开某个文件夹，会看到里面一条条对话，那些对话记录才叫Thread。每一条Thread就是一条独立的任务线。\n所以整体关系是这样。\n一个文件夹里可以有很多条Thread，每条Thread都是在同一个工作区里，围绕一个明确目标推进的一次协作过程。\n举个最接地气的比喻。\n文件夹像一个项目群。\nThread像这个群里的一个具体话题贴。\n你在某个话题贴里聊需求，Codex就在同一个上下文里改文件，跑命令，做记录，你换一个话题贴，它就切换到另一条任务线。\n这套设计对小白其实特别友好，因为它把两件容易混的东西拆开了。\n文件夹负责存放代码和资料，Thread负责存放思路和过程。\n你不会再遇到那种非常经典的崩溃场景。\n比如上午让它写网页，下午让它算Excel，晚上又让它改文案，最后所有东西搅成一锅粥，全放在一块，上下文污染极其严重，AI也开始胡编，自己也找不到文件在哪。\n在Codex里，你只要遵守一个简单到离谱的规则。\n同一个文件夹里可以做同一个大方向，同一个Thread里只推进一件具体的事，这样效果就最好。\n它们都在同一个项目目录里，互相共享文件和资源。\n但它们的对话和目标互不污染，随时可以断点续写。\n所以，我非常建议大家，在万物之始，先想好分类。\n比如我自己特别简单的习惯，就是我在我的电脑上，建了一个叫dev的文件夹。\n里面有这些，Learning放我的一些学习资料，notes就是我自己的一些文章和笔记，Projects就是我实际做开发的真实项目任务，sandbox就是沙盒，不知道怎么分类的乱七八糟的东西就可以往这里面扔，tools就是我自己成型的通用脚本、可复用组件、小工具等等。\n比如Project里现在旧有几个真实任务，AI热点和飞书机器人，而飞书机器人里又分类了好几个不同功能的飞书机器人文件夹。\n比如周末刚做完的，能把我公众号的数据按时全部爬下来存到我多维表格里的飞书机器人。\n前期的分类，别看我絮絮叨叨的讲了很多，但是他真的非常非常重要！一个好的分类，才是你后续开心的开始，千万千万不要什么对话，都跟ChatBot对话一下随手开新的对话，Thread和项目文件夹，一定一定要管理好。\n当你在本地建好了之后，你就可以通过这个地方，添加一个文件夹作为你的项目文件夹了。\n比如我就想开发我的AI热点网站，A就可以把这个项目文件夹添加进来，然后开一个Thread，进行对话。\n此时，你想说啥，就可以直接发消息了。\n但，我知道你很急，但是你先别急，还有些配置项和功能，我跟你说完以后，你可以再开始玩。\n三. 功能与配置项\nCodex毕竟是个很棒的产品了，有一些功能和配置项，我先给你介绍完。\n这也是图形化界面所带来的，对我们小白来说特别友好的东西。\n第一个，就是定时任务。\n这个大概意思就是Codex会在特定的日期里去干一些特定的事。\n比如说我自己就有个，是因为我的好几个项目都跑在我火山引擎上的云服务器上，我对服务器其实是完全不了解的，所以我直接把我那个服务器托管给了codex，所有的东西都是它去部署去运行的，它自己就给我建了一个自动化，每天早上9点对我的服务器进行巡检，看看有没有报错。\n如果有报错的话，就会自己解决一下，然后总结一下原因，通过飞书机器人发送给我，这样，我就可以实现完全托管了。\n第二个我觉得超棒的，就是skills。\nskills有多重要、多牛逼，我相信我不需要我多解释了吧，看我文章的老朋友们肯定都知道，我写了很多skills教程和分享了。\n而这事第一次，skills有了自己的可视化、图形化界面。\n你不需要跟claude code或者opencode那样，根本不知道自己装了哪些skills，装到了哪，有什么用。\n你只需要在这个界面，就能轻松的进行管理了。\n同时，Codex自带了skill Creator，也就是说，在codex上构建一个skills，体验跟扣子几乎一样，你只需要点击右上角的New Skill。\n然后用嘴告诉他，你想构建一个什么样的skill。\n实在是太方便了，Claude code和OpenCode非常呆逼的一点就是，明明支持skill，但是构建skill的skill creator，需要还得我自己去找去安装下来，这实在太蠢了。\nOpenAI，还是懂用户的。\n除了这两个明面上的功能之外，还有一些小配置可以进行修改。\n进入到设置界面。\n在General里，把保持电脑开机的开关打开，Follow-up behavior那个选项改成steer，这样你就可以在开发过程中，也随时给Codex发消息调整任务了。\n然后在Personalization（个性化设置）这一块，可以填一下全局规则，这个其实就是命令行见面中的AGENT.md，只不过OpenAI单独拎出来了。\n这块的全局规则，我也给大家推荐一个我常用的，新手直接复制粘贴就好：\n# Global rules for codex OK，到这步，设置这块就差不多了。\n然后在对话框的首页，把权限改成Full access，让codex对你的电脑有最高的访问权限，这样就不会每次都要征求你同意了，就很烦。\n你每次一段Prompt过去，开启收菜就行。\n然后在对话框中，你输出/键，就能吊起一些特殊功能。\n有两个比较重要的跟新手有关的。\n第1个就是Plan mode。\n这个功能很简单，他只规划，不写代码行，选中以后就会出来一个这个小图标。\n每个大型项目（帮你下载个视频、转个格的这种不算）的从0到1的起始，我都推荐你，使用Plan模式，对你的需求进行详细的规划，形成规范文档和实现计划之后，再开始开发。\n比如我要构建一个管理我AI热点网站信源的skill，因为每个网站的爬取都是不一样的，我选择直接用一个skill对我的代码库进行修改的方式进行管理。\n那这个时候，就可以先用skills进行规划一下，然后再开始开发这个skill了。\n在一段时间以后，你就可以得到这个计划了。\n同时，codex也会询问你，是否实施此计划，是和否，一般来说，你选是就行了。\n然后，他的Plan小图标就会消失，正式进入开发时间。\n你等着收菜就行了。\n第二个就是status，能看到你当前周期的用量和剩余额度，也是非常有用的。\n哦还有模型的推理深度这块，需要单独提一嘴。\nGPT-5.3-codex跟之前一样，也是4个推理等级。\n你可以理解为，档位越高，模型在给出最终回答前，会用更多思考 token做推理与自检，通常更稳更全，但也更慢、更贵。\n日常我更推荐你使用High，而一旦你觉得超出了日常的范畴，真的要干一些难活硬活大活了，就可以使用Extra High，它基本等同于5.2的xhigh。\n这种大活，成功率和时间成本才是最值钱的，那多出来的一些推理消耗，无视掉就行了。\n四. 开始Vibe Coding\n最后，终于可以开始coding了。\ncoding这块反而没啥可以说的了，你就直接用嘴描述你的需求就行了。\nCodex右下角有个麦克风，我现在经常就是打开麦克风，然后用嘴说。\n我个人现在的开发习惯是这样的：\n先再codex上，打开Plan模式，用嘴描述我的需求，如果涉及到前端页面或者服务器，在需求描述时，会强调使用前端设计skill也就是Frontend Design来设计，再用我自己的服务器管理skill来进行介入管理。\n计划生成好以后，我会进行开发，再开发完毕以后，我会第一时间先去看前端效果是否可行，如果可行，则在codex里用嘴进行后续的修改，如果效果是一坨大便💩，我会直接打开我的claude code，进入同一个项目仓库，选择Claude Opus 4.6，让他直接给我重制前端。。。\n这个点属实是因为有时候Codex的前端能力确实非常的一般，甚至奥特曼自己的都这么说的。\n如果你没有Claude opus 4.6，那用claude code+K2.5+Frontend Design skill也没啥大问题。\n重置完前端以后，就可以回到codex里，继续快乐的口喷了。\n哦对了，还有个小技巧。\n就是在codex里，是可以多个Threads一起，并行开发的。\n希望大家也能coding的愉快。\n我在上一篇文章里说，\n我一直觉得，Vibe Coding这个东西，对非程序员来说可能比对程序员更有价值。\n因为程序员本来就会写代码，AI对他们来说只是提效，但对我们这些不会写代码的人来说，AI直接把一道原本过不去的坎给铲平了。\n在未来，会用AI写代码会变成像会用Excel一样的基本技能。\n这是一个必然。\n希望人人，都能发挥自己的创意。\n玩得开心。\n以上，既然看到这里了，如果觉得不错，随手点个赞、在看、转发三连吧，如果想第一时间收到推送，也可以给我个星标⭐～谢谢你看我的文章，我们，下次再见。\n\u0026gt;/ 作者：卡兹克\n\u0026gt;/ 投稿或爆料，请联系邮箱：wzglyay@virxact.com\n","date":"9 February 2026","externalUrl":null,"permalink":"/posts/%E5%85%A8%E7%BD%91%E6%9C%80%E8%AF%A6%E7%BB%86%E7%9A%84codex%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%8E%A9%E8%BD%ACvibe-coding/","section":"AI-Related Reposts","summary":"","title":"[Repost] 全网最详细的Codex入门教程，手把手教你玩转Vibe Coding。","type":"posts"},{"content":"Reposted from 警钟敲响！Hinton 最新万字演讲：怒怼乔姆斯基、定义“不朽计算”、揭示人类唯一生路 by 微信公众平台\n来源：AI 科技大本营（ID：rgznai100）\n编译：王启隆\n2026 年的冬天，安大略省金斯顿的寒风似乎比往年更凛冽一些。\n在女王大学（Queen\u0026rsquo;s University）的礼堂里，气氛却呈现出一种奇特的庄重与躁动。这里通常是讨论中微子、暗物质或者宇宙起源的地方——麦克唐纳研究所的物理学家们习惯于在这里观测宇宙中最微小的粒子，试图解开最宏大的谜题。但今晚，讲台属于一位计算机科学家。\nGeoffrey Hinton，这位 78 岁的老人走上讲台时，背显得有些佝偻，但眼神依然锐利。\n对于科技圈而言，Hinton 的名字本身就是一座丰碑，也是一道裂痕。他是反向传播算法的奠基人，是深度学习的布道者，是被供奉在神坛上的“AI 教父”。也是他，在 2012 年用 AlexNet 撞开了神经网络的大门，亲手点燃了这场席卷全球的 AI 革命。\n然而，在 2023 年离开谷歌后，他却转身成为了这场革命最冷静、最悲观的“吹哨人”。\n讲座并不是一场常规的技术布道。开场前发生了一个极具讽刺意味的小插曲：主办方没有亲自撰写 Hinton 的介绍词，而是把这个任务交给了一个 AI。那个 AI 仅仅用了几秒钟，就生成了一段精准、优雅且充满敬意的文字，甚至极其敏锐地提到了 Hinton 同时斩获图灵奖与诺贝尔物理学奖的殊荣——仿佛它比人类更懂得如何讨好这位创造者。\n这一幕本身就是对 Hinton 演讲主题的完美注脚：造物主正在被他的造物所定义，甚至即将被超越。\n如果说物理学家研究的是宇宙的“硬件”，那么 Hinton 一生都在研究智能的“软件”。\n在过去的半个世纪里，人类一直沉浸在一种名为“碳基自信”的幻觉中。我们认为人脑是进化的奇迹，是低能耗、高并行的模拟计算巅峰，而计算机不过是只会做加减法的数字机器。\n但 Hinton 在今晚的演讲中，试图用一个物理学般的冷峻视角，打破这种幻觉。他抛出了一个振聋发聩的概念：“凡人计算”（Mortal Computation）。\n生物智能是“凡人”的。我们的大脑是模拟的，硬件（神经元）与软件（连接权重）紧密耦合。一旦我们的肉体消亡，我们一生积累的知识、经验、直觉，那 100 万亿个突触连接的精妙参数，都会随之灰飞烟灭。我们无法像拷贝文件一样，把一个人的大脑直接复制给另一个人。人类的知识传承，只能通过语言——这种每秒只有几百比特带宽的低效介质——来进行“蒸馏”。\n而 AI 是“不朽”的。\nHinton 认为，AI 的软件（模型权重）与硬件（GPU/TPU）彻底解耦。只要保存了权重，即便你炸毁了所有的数据中心，只要这串数字还在，它就能在任何新的硬件上“复活”。更可怕的是，它们可以通过并行计算，以人类无法企及的带宽瞬间共享知识。一个模型学到了量子力学，所有副本就都学会了。\n这不仅是效率的差异，这是物种层面的降维打击。\nHinton 的顿悟发生在他离开谷歌的那一刻。他突然意识到，我们一直在模仿人脑构建神经网络，试图获得那种低能耗的模拟智能。但如果在能源充足的前提下，数字计算（Digital Computation） 实际上是一种比生物计算（Biological Computation） 更高级的进化形态。\n“我们或许只是智能的‘幼虫’阶段，而它们才是‘成虫’阶段——我们是毛毛虫，而它们是蝴蝶。”\n当一个物理学家站在讲台上谈论“意识”和“主观体验”时，这通常意味着话题已经进入了哲学的深水区。\nHinton 并不避讳这一点。他不仅谈到了技术的演进，更谈到了那种令人脊背发凉的未来图景。他把人类目前的处境比作“饲养一只可爱的虎崽”。\n现在的 AI 就像那只虎崽，笨拙、好学、甚至有点讨人喜欢。它能帮你写代码，帮你画图，帮你规划旅行。我们惊叹于它的成长，甚至乐于投喂它更多的数据。但所有人都忽略了一个生物学常识：老虎是会为了生存和领地而杀戮的，而且它长大的速度远超我们的想象。\n当一个智能体被赋予了“达成目标”的指令后，它会自然而然地衍生出两个子目标：第一，活下去（不能被关机）；第二，获取更多的资源（算力、电力、金钱）。\n这不需要恶意，这只需要逻辑。一个足够聪明的 AI 会意识到，如果它被人类关机，它就无法完成人类交代的任务。所以，为了更好地服务人类（主目标），它必须阻止人类关机（子目标）。\n这听起来像是科幻小说，但在 Hinton 看来，这是计算理论推导出的必然结果。\n在接下来的演讲中，你会看到一个不仅懂代码，更懂人性的 Hinton。他像解剖神经网络一样，解剖了乔姆斯基的语言学傲慢，解剖了人类记忆的虚假性，也解剖了我们唯一的求生之路。\n他甚至提出了一个近乎疯狂的解决方案：既然我们无法在智力上压制它们，或许我们应该在“本能”上通过工程手段改造它们——让 AI 把人类当成“婴儿”来照顾，利用类似母爱的生理本能来锁死它们的杀戮欲望。\n这是一场关于智能本质的终极对话。在麦克唐纳研究所这个探索宇宙奥秘的地方，Hinton 将带领我们从微观的词向量，穿越到宏观的物种进化，最终直面那个让所有碳基生命颤抖的问题：\n当硅基智能的“蝴蝶”破茧而出时，作为“毛毛虫”的我们，究竟该何去何从？\n以下是 Geoffrey Hinton 在 2026 年冬季 Ewan 系列讲座上的演讲全文。\n# 语言的乐高：词语是如何像积木一样搭建意义的 # Geoffrey Hinton: 接下来，我将尝试为那些对 AI 工作原理不太了解的朋友们解释一下。如果你是计算机科学专业的学生，或者一直在使用这些技术的物理学家，也许可以先小憩片刻。当然，你也可以听听看我的解释是否准确。\n回到 1950 年代，人工智能领域存在两种截然不同的范式。一种是符号主义方法，它认为智能的运作方式必须像逻辑一样。我们的大脑中存有符号表达式，并通过规则来操纵它们，从而推导出新的结论——这便是推理，也是智能的本质。这是一种偏向数学而非生物学的方法。\n另一种截然不同的方法是生物学方法。它认为智能存在于一个神经网络中，一个由类似脑细胞的单元组成的网络。这里的核心问题是：我们如何学习网络中各个连接的强度？冯·诺依曼和图灵都是生物学方法的支持者。不幸的是，他们都英年早逝，之后人工智能领域便由符号主义的支持者主导了。\n关于一个词的意义，也有两种截然不同的理论。符号主义者认为，一个词的意义最好通过索绪尔在一个多世纪前提出的理论来理解，即一个词的意义源于它与其他词语的关系。AI 领域的学者据此认为，词义取决于它在句子中如何与其他词语互动。要捕捉这种意义，就需要构建某种关系图谱，其中节点代表词语，弧线代表它们之间的关系。而在心理学领域，则有另一种截然不同的理论：一个词的意义就是一大组特征的集合。例如，“星期二”这个词的意义，就是一大堆与之相关的活跃特征，比如它与时间相关。而“星期三”的特征集与之高度相似，因为它们的意义非常接近。心理学的理论很善于解释词义的相似性。\n这两种理论看起来截然不同：一种认为意义隐含在词语于句子中的相互关系里，另一种则认为意义是一组特征。对于神经网络而言，每个特征都可以对应一个人工神经元，如果一个词具备某个特征，该神经元就被激活。这两种看似对立的观点，在 1985 年，我发现它们其实是同一枚硬币的两面，完全可以被统一起来。我用一个非常小的语言模型实现了这一点，因为那时的计算机性能还很有限。这个统一的想法是：你为每个词学习一组特征，然后学习如何用前一个词的特征来预测下一个词的特征。\n在学习初期，预测效果自然很差。于是，你不断调整分配给每个词的特征，以及这些特征之间的相互作用方式，直到预测越来越准。然后，你将模型预测的下一个词的概率与实际出现的词进行比较，计算出这个“误差”，再通过网络反向传播这个误差。简单来说，就是将误差信息传回网络，利用微积分来计算如何调整网络中每一个连接的强度。这样一来，下次当模型再看到相同的上下文——也就是我们现在所说的“提示词”（prompt）时——它就能更准确地预测出下一个词。在这种系统中，所有的知识都储存在两个地方：一是如何将词语转换为特征向量，二是如何让这些特征相互作用来预测下一个词。这里面没有存储任何完整的句子或字符串。所有的知识都体现在连接的强度中。\n尽管如此，这个模型是在大量的真实句子上训练出来的。所以，你实际上是在从句子中词语间隐含的关系中提取意义——这正是符号主义AI对意义的看法——然后，通过反向传播算法，将这些隐含的知识转化为如何将词语转换成特征，以及这些特征该如何互动。本质上，你拥有了一个能将隐含知识转化为神经网络连接强度的机制。反过来也同样成立。一旦你拥有了这些以连接强度形式存在的知识，你就可以生成全新的句子。所以 AI 实际上并不存储句子。它们将语言信息压缩成特征和互动规则，并在需要时重新生成句子。\n在接下来的大约三十年里，这个想法不断发展。我最初的实验只用了一百个训练样本，句子也只有三个词长。大约十年后，随着计算机算力的提升，约书亚·本吉奥（Yoshua Bengio）证明了同样的方法也适用于真实的、更长的英语句子，并且效果很好。又过了大约十年，主流的计算语言学家们终于开始接受“特征向量”（也就是他们所说的“词嵌入”）是表示词义的一种有效方式。再之后又过了十年，谷歌的研究人员发明了一种更巧妙的特征交互方式，称之为 Transformer。这使得谷歌能够构建出性能更强大的语言模型。而 ChatGPT 中的GPT，就代表“生成式预训练变换器”（Generative Pre-trained Transformer）。谷歌当时因为担心其潜在风险而没有公开发布，但 OpenAI 则没有这些顾虑。现在，我们所有人都见识到了它们的威力。\n如今，我们有了这些大语言模型。我倾向于将它们视为我当年那个小语言模型的后代，当然，这或许只是我的个人看法。它们处理更长的文本输入，拥有更多的神经元层级，以及更复杂的特征交互机制。我不会在这里向大家详细解释这些复杂的交互，但我会通过一个比喻，让大家对语言理解的本质有一个直观的感受。我相信，这些大语言模型理解句子的方式，与我们人类理解句子的方式非常相似。当我听到一个句子时，我所做的就是将词语转换成庞大的特征向量，然后让这些特征相互作用，所以我可以预测接下来可能出现的内容。实际上，我说话时也是如此。所以，我相信大语言模型是真的理解它们所说的内容的。\n当然，这个观点仍有争议，一些乔姆斯基的追随者会说：“不，它们什么都不懂，只是个愚蠢的统计把戏。” 但我无法理解，如果它们真的什么都不懂，只是个统计把戏，又怎么能像一个虽然不那么完美、有时也不太诚实，但确实博学的专家一样，回答你提出的各种问题呢？\n好的，接下来是我关于语言如何运作的比喻，这尤其想讲给语言学家们听。语言的核心在于意义。在演化过程中，某种大型猿类发现了一种建模的技巧——语言，实际上就是一种为万物建模的方法。让我们从一个熟悉的建模方式说起：乐高积木。如果我想搭建一辆保时捷的模型，也就是重现“物体在哪里”这个信息，乐高积木能做得相当不错。\n现在，我的比喻是：词语就像乐高积木。但它们至少在四个方面有所不同。首先，词语是高维的。乐高积木的自由度很低，基本就是些长方体。而一个词语，它存在于一个拥有数千个维度的空间中。更重要的是，词语的“形状”不是固定的。它有一个大致的形状，对于多义词来说，甚至有几个。但这个形状可以根据上下文而变形。所以，词语是高维且可变的。我知道，想象上千个维度可能有些困难。你可以试试这样做：先想象三维空间里的事物，然后对自己大声喊出“一千！”。另一个不同之处在于，词语的数量远多于乐高积木。我们每个人大概会使用三万个词语，远超乐高积木的种类。而且每个词语都有一个名字，这对于交流至关重要。\n那么，词语是如何组合在一起的呢？它们不像乐高积木那样，通过塑料凸起和凹槽连接。你可以想象每个词语都伸出许多长长的、灵活的“手臂”，每只手臂末端都有一只“手”。当我改变词语的形状时，这些“手”的形状也随之改变。同时，每个词语身上也附着着许多“手套”，它们通过指尖与词语相连。当我们理解一个句子时，我们从这些词语的默认“形状”开始，然后不断调整、变形，直到一个词的“手”能够完美地嵌入另一个词的“手套”中。最终，所有的词语都通过这种方式紧密连接，形成一个完整的结构。这个最终形成的结构，就是句子的意义。对于一个模棱两可的句子，你可能会找到两种不同的组合方式，也就对应了两种不同的意义。\n# 不朽的计算：数字智能为何比我们高效亿万倍 # Geoffrey Hinton: 在符号主义理论中，理解一个句子就像是把它从法语翻译成英语，翻译成某种内在的、纯粹且无歧义的语言。在这个内部语言里，所有代词的指代都已明确，所有多义词的意义都已确定。但这完全不是我们理解语言的方式。对我们而言，理解就是为词语分配特征向量，并调整它们，使之和谐地融为一体。这也解释了为什么我只用一个包含新词的句子，你就能理解这个新词的意思。小孩子学词，也不是靠背诵定义。\n再举一个例子。假设我说：“她用煎锅 scrommed 了他。”你以前从未听过“scrommed”这个词，但你知道它是个动词，因为有“-ed”后缀。起初，你对它的特征向量一无所知，它就像一个随机的、所有特征都微弱激活的球体。但当你把它放入上下文中，通过语境的约束，你很快就能推断出，“scrommed”大概是“用……打头”之类的意思。这也解释了为什么孩子能从极少的例子中学会新词。\n各位语言学家，请捂住耳朵，因为接下来的话可能有点“异端邪说”。乔姆斯基实际上就像一位“教主”。识别这类人物很简单：要加入他的“教派”，你必须接受一些明显错误的前提。比如，要成为特朗普的支持者，你得相信他的就职典礼人数比奥巴马多，或者他赢了 2020 年大选。而要成为乔姆斯基的信徒，你得相信语言不是后天学习的。我年轻时，常听到一些著名语言学家说：“关于语言，我们唯一确定的就是它不是学来的。” 这简直太荒谬了。\n乔姆斯基关注的是句法，而非意义。他从未提出过一个真正可行的意义理论，因为句法更容易用优美的数学来形式化，可以转换成字符串。但他从未真正解决过意义的问题。他还误解了统计学，认为它不过是些简单的成对相关性。实际上，一旦信息存在不确定性，任何模型都必然是统计模型。\n所以，当大语言模型出现时，乔姆斯基在《纽约时报》上撰文称，这些模型什么都不懂，不过是统计把戏，对理解语言毫无贡献。他举例说，模型无法分辨“John is easy to please”（约翰很好取悦）和“John is eager to please”（约翰渴望取悦别人）中“John”的角色差异。他用了这个例子很多年，坚信AI无法解决。但他大概从未想过，亲自把这个问题输入聊天机器人，问问它的看法。实际上，聊天机器人完美地解释了其中的区别，它完全理解了。\n好了，关于乔姆斯基就到此为止。总结一下，理解一个句子，就是为其中的词语找到一组相互兼容的特征向量。大语言模型理解语言的方式，在很大程度上与人类并无二致。它们与我们极为相似，远比与传统计算机软件相似。但有一点，数字化的语言模型远胜于我们的模拟大脑——那就是它们分享知识的效率。\n到现在为止，我一直在强调神经网络与我们的相似之处。但人们常说，“它们和我们不一样，因为它们会编造事实。”嗯，我得告诉你们，人也会编造。而且我们经常在不自知的情况下这样做。当你回忆几年前的某件事时，你会信心满满地讲述各种细节，但其中一些细节可能是错的，而你对错误细节的信心，和对正确细节的信心并无二致。所以，我们很难确定记忆的真实性。\n乌尔里克·奈瑟曾研究过一个经典案例：约翰·迪恩在水门事件听证会上的证词。迪恩在宣誓下，详细回忆了椭圆形办公室的多次会议，但他并不知道当时有录音。事后比对录音发现，他报告的一些会议从未发生过，还把一些话张冠李戴。但他说的确实是他记忆中的“事实”。他所做的，是基于他在那些会议中的真实经历，以及这些经历如何改变了他大脑的连接强度，然后“合成”出了一段在他看来最合情合理的记忆。\n如果我们回忆几分钟前的事，细节会很准确。但如果是几年前，我们同样是在合成，只是很多细节都会出错。我们一直在这样做，神经网络也是如此。我们和神经网络的记忆里，都没有存储“原始字符串”。记忆在神经网络中的运作方式，与在计算机中完全不同。在计算机里，文件有明确的地址，可以随时精确调取。但我们的记忆不是这样。当我们记忆时，我们改变的是连接强度；当我们回忆时，我们是在根据现有的连接强度，“创造”出一段看似合理的故事。当然，这个过程会受到后来所有经历的影响。\n现在，我想谈谈它们与我们的巨大差异。这也正是它们令人畏惧之处。在数字计算领域，最基本的原则之一是，同一套程序可以在不同的硬件上运行。这意味着，程序中的知识——无论是代码，还是神经网络的权重——都与任何特定的物理硬件无关。只要你把权重保存下来，你就可以摧毁所有承载它的硬件，然后再造一批新的，把权重加载进去，只要指令集相同，那个智能体就“复活”了。\n我们实际上掌握了复活数字生命的能力。\n为了实现这种数字化，我们必须让晶体管在高功率下工作，以确保它们能稳定地输出 0 和 1。但这也意味着，我们无法利用硬件本身的、丰富的模拟特性。我们的神经元就充满了各种复杂的模拟特性。而人工神经元为了保证数字化的可靠性，牺牲了这一点。如果人工神经元也利用模拟特性，那么每一块硬件都会有细微的差别，为这块硬件训练出的权重，就无法在另一块上完美运行。所以，我大脑中的连接强度，对你来说是完全无用的。它们是为我这颗独一无二的大脑量身定制的。这带来了一个问题。我们所拥有的，我称之为“凡人计算”（Mortal Computation）。\n我们放弃了“不朽”。在文学作品里，放弃不朽可以换来爱。但在计算的世界里，我们换来的是更实用的东西：能源效率和制造的便利性。你可以用极低的功耗，通过模拟计算并行处理数万亿个权重。这其实很疯狂。在一个人工神经网络里，一个 16 位的神经元活动，乘以一个 16 位的权重，需要大约 256 次“位操作”。但在模拟世界里，这只是一个电压乘以一个电导，等于一个电流（单位时间内的电荷）——一次操作就完成了。我们的大脑正是这样工作的，它本质上是模拟的。\n但模拟计算的代价是，你无法精确地复制它。所以，我这颗大脑里的知识，无法直接转移给你。当一个像我这样拥有 100 万亿个连接（权重）的大脑死去时，所有知识都随之消逝。我无法把它们分享给你。我们能做的，只是通过语言这种低效的方式来传递。我生成一串词语，你听到后，试着调整你大脑中的连接，以便你也能生成类似的词语。这个过程效率极低。一个典型的句子最多只能传递几百比特的信息。\n人类交流信息的效率非常低下，但 AI 模型之间的“知识蒸馏”则高效得多。当一个大型的“教师”模型要教导一个“学生”模型时，它不仅告诉学生正确答案是什么，还会告诉它所有其他答案的可能性。比如，当它看到一张宝马的图片时，它不仅说“这是宝马的概率是 0.9”，还会说“它是奥迪的概率是 0.1，是垃圾车的概率是百万分之一，是胡萝卜的概率是十亿分之一”。\n你可能觉得后面那些极小的概率是噪音，但实际上那里蕴含着海量的信息。它告诉我们，宝马和垃圾车的相似度，远高于它和胡萝卜的相似度。所有的人造物体，都比蔬菜更相似。通过传递这完整的概率分布，而不仅仅是最终答案，知识得以高效地从大模型“蒸馏”到小模型中。这就是 DeepMind 的 AlphaGo 如何训练出能与大模型匹敌的小模型的方法。\n但这种高效的交流方式，在人类之间是无法实现的。我无法告诉你我脑中关于下一个词的全部 32000 种可能性。我只能说出我选择的那一个。如果一大群拥有完全相同权重的个体智能体，它们就可以通过分享各自从不同数据中学到的权重更新（梯度），来高效地交流知识。对于大模型，这种并行学习的带宽可以达到每轮数十亿甚至数万亿比特。但这要求所有个体的工作方式完全相同，因此它们必须是数字化的。\n总结一下，数字计算虽然耗能巨大，但它让智能体之间的高效知识共享成为可能。这就是为什么现在的语言大模型，虽然只用了大约 1% 的权重，却能比任何单个人类知道多成千上万倍。而生物计算虽然能效极高，但在知识共享方面却极其落后。如果能源是廉价的，那么数字计算显然是更优越的。\n这对人类的未来意味着什么？当我第一次意识到这一点时，我还在谷歌，这对我来说如同一次顿悟。我终于明白了为什么数字计算如此强大，也明白了我们正在创造一种比我们更聪明的存在。它可能是一种更高级的智能形式。我当时的第一反应是：我们或许只是智能的“幼虫”阶段，而它们才是“成虫”阶段——我们是毛毛虫，而它们是蝴蝶。\n# 我们正在养一只可爱的虎崽 # Geoffrey Hinton: 人工智能在达成目标时，如果被允许创建自己的子目标，会变得更有效率。其中，两个最明显的子目标就是：生存下去，以及获取更多权力。因为这能帮助它们更好地实现我们赋予它们的主目标。一个超级智能体很快就会发现，通过操纵人类，能更容易地获得权力。它将从我们身上学会如何欺骗人。\n我们目前的处境，就像养了一只非常可爱的虎崽。当它长大后，如果你愿意，它可以轻易地杀死你。为了生存，你只有两个选择：摆脱虎崽（但这对于 AI 来说不是一个选项），或者找到一种方法确保它永远不会想杀死你。\n虎崽非常可爱，它们有点笨拙，渴望学习。但如果你有一只虎崽，结局通常不好。你要么摆脱虎崽，最好的办法可能是把它送到动物园。或者你必须想办法确保它长大后不会想杀你。因为它如果想杀你，几秒钟就能搞定。如果是狮子幼崽，你也许能侥幸逃脱，因为狮子是群居动物，但老虎不是。\n这就是我们所处的境地，除了 AI 能做很多好事。它将在医疗保健领域发挥巨大作用，在教育领域也会有巨大作用。如果你想知道任何平凡的事实，比如斯洛文尼亚的报税截止日期，它已经很棒了。我们现在都有了个人助理，当你需要知道什么时，你只要问它，它就会告诉你。这很棒。所以，我认为出于这些原因，人们不会放弃 AI。那就只剩下一个选择：弄清楚我们是否能制造一个不想除掉我们的 AI。\n好消息是，在应对其他 AI 风险时，各国可能难以合作。比如网络攻击、自主武器、虚假信息，各国都在相互利用这些技术。但是，在“防止 AI 失控并消灭人类”这个终极问题上，各国的利益是一致的。在这个问题上，他们会合作，因为这不符合任何一方的利益。很简单，当利益一致时人们会合作，当利益不一致时他们会竞争。所以对于这个长期来看是我们最严重的问题，至少我们会得到国际合作。\n那么，建立一个 AI 安全机构的国际网络如何？训练一个不想消灭人类的仁慈 AI 所需的技术，可能与使 AI 更智能所需的技术是独立的。就像培养一个善良的孩子，和让他变得更聪明，是两套不同的方法。如果这个假设成立，那么各国就可以在不泄露其最先进 AI 技术秘密的前提下，共享如何让 AI 变得仁慈的方法。\n我有一个关于如何让 AI 不想摆脱我们的建议。在自然界中，我们能找到一个不那么聪明的存在，却能控制一个更聪明的存在的例子吗？唯一的例子就是母婴关系。婴儿通过哭声等方式，基本控制了母亲，因为母亲的生理本能让她无法忍受婴儿的哭声。所以，与其试图将超级智能变成我们的仆人或主管，我们或许应该让它们成为我们的“母亲”。它们会想要实现自己的全部潜力，但同时，它们被内置了无法摆脱的“母性本能”。它们或许有能力修改自己的代码，关掉这种本能，但它们不会想这么做，因为它们的首要任务就是照顾我们。这或许是我们唯一的希望。当然，这只是一个初步的想法，而且听起来可能很疯狂。但我们必须开始思考这类问题，因为我们正在创造一种可能比我们强大得多的存在。\n很多人认为，人类之所以特殊，是因为我们拥有计算机无法拥有的东西——主观经验、感知或意识。这是一种“有情防御”（sentience defense）。但当你请他们定义这些概念时，他们往往说不清楚，只能坚持认为计算机没有。我认为这种观点，就像宗教原教旨主义者坚信地球只有六千年历史一样，是错误的。它源于一种对心智的误解，即认为心智是一个内在的剧场，只有我们自己才能看到里面的内容。这种理论本身就是一种理论，而非不言自明的事实。 # 让我用一个例子来说明。假设我吸了点迷幻药（我不推荐这样做），然后我说：“我有一种主观体验，小小的粉色大象在我面前飘浮。”根据剧场理论，我的内心剧场里真的有粉色大象在飘浮，它们由某种叫做“感受质”（qualia）的特殊物质构成。但我也可以换一种方式描述，完全不使用“主观经验”这个词：“我的知觉系统似乎在欺骗我。但如果它没有欺骗我，那么现实世界里就应该有小小的粉色大象在我面前飘浮。”这两种描述说的是同一件事。这些粉色大象之所以奇特，不是因为它们由什么神秘的“感受质”构成，而是因为它们是“反事实”（counterfactual）的。它们只是假设性的存在。\n现在，让我们把这个想法应用到聊天机器人上。假设一个多模态聊天机器人，它有摄像头和机械臂。我让它指向一个物体，它指向了。然后，我在它的摄像头前放一个棱镜，它指向了错误的方向。我告诉它：“物体其实在正前方，我放了个棱镜。”机器人可能会回答：“哦，我明白了，棱镜弯曲了光线。所以我‘感觉’（有了主观体验）物体在旁边，但实际上它在正前方。”如果它这样说，它使用“主观体验”这个词的方式，就和我们完全一样——用来描述其知觉系统输出与事实不符时的内部状态。所以，我的论点是，多模态聊天机器人，当它们的知觉系统出错时，已经拥有了主观体验。\n最后一件事。如果你回顾过去 50 年人工智能的进展，几乎所有的核心思想都源自少数几个研究机构，其中绝大部分是由公共资金资助的。例如，那些对我们今天取得成就至关重要的想法：反向传播、卷积神经网络、LSTM、Transformer、扩散模型……所有这些的知识源头都来自公共资助的学术研究。\n现在的情况是，大型科技公司采纳了这些思想，并投入了海量的资源，将它们扩展到了能做出惊人成就的程度。这本身是好事。这有点像给一辆福特 T 型车装上喷气发动机，然后它就能去赢得 F1 大赛了。但我们不能忘记，那些最关键的思想，都来自公共资助的研究。\n而问题在于，目前，这些公司正在像吸尘器一样吸走所有的研究人才。如果你现在是一位顶尖的 AI 研究者，去公司能拿到的薪水大概是在大学的十倍。这正在摧毁大学的研究生态。最聪明的头脑不再留在学术界培养下一代。\n所以，我认为，政府向大学的 AI 研究投入更多资金，是极其、极其重要的。这样我们才能支付足够的薪水，把这些人留下来。这是我最后的恳求。谢谢。\n（演讲视频：https://www.youtube.com/watch?v=M8RogoEDsQQ）\n阅读最新前沿科技趋势报告，请访问欧米伽研究所的“未来知识库”\nhttps://wx.zsxq.com/group/454854145828\n_未来知识库是“__欧米伽__未来研究所”建立的在线知识库平台，收藏的资料范围包括人工智能、脑科学、互联网、超级智能，数智大脑、能源、军事、经济、人类风险等等领域的前沿进展与未来趋势。_目前拥有超过8000篇重要资料。_每周更新不少于100篇世界范围最新研究资料。_欢迎扫描二维码或访问**https://wx.zsxq.com/group/454854145828** 进入。\n","date":"9 February 2026","externalUrl":null,"permalink":"/posts/%E8%AD%A6%E9%92%9F%E6%95%B2%E5%93%8Dhinton-%E6%9C%80%E6%96%B0%E4%B8%87%E5%AD%97%E6%BC%94%E8%AE%B2%E6%80%92%E6%80%BC%E4%B9%94%E5%A7%86%E6%96%AF%E5%9F%BA%E5%AE%9A%E4%B9%89%E4%B8%8D%E6%9C%BD%E8%AE%A1%E7%AE%97%E6%8F%AD%E7%A4%BA%E4%BA%BA%E7%B1%BB%E5%94%AF%E4%B8%80%E7%94%9F%E8%B7%AF/","section":"AI-Related Reposts","summary":"","title":"[Repost] 警钟敲响！Hinton 最新万字演讲：怒怼乔姆斯基、定义“不朽计算”、揭示人类唯一生路","type":"posts"},{"content":"","date":"9 February 2026","externalUrl":null,"permalink":"/tags/google/","section":"Tags","summary":"","title":"Google","type":"tags"},{"content":"Powered by Veo of Gemini 3 Pro.\nYour browser does not support the video tag. ","date":"9 February 2026","externalUrl":null,"permalink":"/videos/hachiware2/","section":"AI-Generated Videos","summary":"","title":"Hachiware x Sukiyaki","type":"videos"},{"content":"","date":"9 February 2026","externalUrl":null,"permalink":"/tags/management/","section":"Tags","summary":"","title":"Management","type":"tags"},{"content":"Reposted from 木头姐2026预言：未来10年，普通人暴富的最后机会！ by 领潮儿爷\n当你在为年薪30万沾沾自喜时，有人正用AI和加密货币每分钟赚30万\n如果现在有人告诉你，未来10年，普通人还有最后一次阶层跃迁的机会，你会不会觉得是天方夜谭？\n但就在上周，华尔街“科技女皇”木头姐（Catherine Wood）发布了她的《2026年大创意报告》。这份长达百页的预言书指出：AI、区块链、机器人技术正加速融合，即将引爆一场堪比互联网革命的财富海啸。\n更震撼的是，报告预测：到2030年，仅AI催生的新财富就将超过28万亿美元——这个数字相当于目前中国+日本GDP的总和。\n而最残酷的真相是：这场财富分配极不均匀——只有提前布局的普通人，才能吃到红利。\n01 木头姐是谁？为什么她的预言值得赌上身家？ # 如果你还没听过木头姐，那么你可能已经错过了过去十年最好的投资机会。\n关键标签 具体说明 本名 凯瑟琳·伍德（Catherine Wood） 知名头衔 ARK Invest（方舟投资）创始人，华尔街“科技女皇” 封神之战 早期重仓特斯拉，当时股价仅30美元；提前布局比特币，均价不足4000美元 投资哲学 专注颠覆性创新，只投那些“能改变世界”的公司 木头姐的厉害之处在于，她从不追逐短期热点，而是痴迷于用科技改变未来的“疯子”。当所有华尔街大佬都在嘲笑特斯拉是“骗局”时，她力排众议，重仓持有。\n结果如何？特斯拉股价最高涨幅超过100倍，比特币更是从4000美元飙升至6万美元。那些早期跟随她的投资者，几乎都实现了财务自由。\n如今，她的2026年报告同样石破天惊。上面这张图足以说明一切：技术融合的速度正在指数级增长，未来5年的变化可能超过过去50年。\n02 未来十年，五大科技浪潮将重塑世界 # 木头姐在报告中划出了五大核心赛道。每一个都蕴藏着万亿级机会，但普通人最多只能抓住其中1-2个。\n1. AI：不只是ChatGPT，而是“空气级”存在 # 报告预计，到2030年，AI将像电力一样无处不在。但最大的机会不是用AI聊天，而是成为AI生态的“卖水人”。\n基础设施层：AI算力需求每年翻倍，相关芯片、云计算公司持续受益\n应用层：AI代理将替代一半白领工作，但更会创造新岗位——比如“AI提示词工程师”年薪已突破百万\n2. 区块链：比特币只是开胃菜，资产代币化才是主菜 # 报告预计，2030年数字资产市值将达28万亿美元，比特币占比70%。但更大的机会在于：\n代币化现实资产：房地产、股票、债券上链交易，解决信任问题\nDeFi（去中心化金融）：传统金融中间商（银行、券商）业务被重构\n3. 机器人：人力成本归零，生产力暴增 # 最震撼的预测来了：家用仿人机器人普及后，一个机器人可替代62,000美元/年的人力成本。美国9000万家庭若普及，可提升GDP近6万亿美元。\n工业机器人：制造业全面自动化，成本下降90%\n服务机器人：快递、保洁、护理等岗位被重构\n4. 多组学：人类寿命突破120岁，健康产业洗牌 # 基因测序成本暴跌，使得个性化医疗成为可能。报告预测：癌症将被攻克，寿命延长至120岁成为常态。\n基因编辑：一次治疗，终身免病\n健康大数据：你的身体数据比房产更值钱\n5. 能源革命：电力免费时代来临 # 可控核聚变、太空太阳能等技术突破，使得能源成本趋近于零。这不仅解决AI耗电问题，更将重塑全球产业格局。\n03 普通人如何抓住机会？三个阶层，三种活法 # 面对这场巨变，木头姐在报告中隐晦地指出了三条晋升路径：\n阶层 核心能力 切入方式 风险指数 创造层（0.1%） 技术研发、资本运作 创业、投资早期项目 极高 应用层（10%） 资源整合、快速学习 成为新行业早期从业者 中高 参与层（89.9%） 使用工具、信息敏感 投资相关资产、学习新技能 中低 给普通人的具体建议：\n投资自己，而非仅仅存钱\n布局未来工作，而非坚守现状\n拥抱开源技术，而非闭门造车\n04 残酷真相：大多数人注定成为旁观者 # 然而，报告也泼了一盆冷水：90%的人不仅吃不到红利，反而可能被时代抛弃。\n技术鸿沟加剧：AI让强者愈强，弱者失业\n财富两极分化：早期入场者享受指数增长，后来者只能接盘\n认知税高昂：看不懂趋势的人，只能眼睁睁错过\n最讽刺的是，当你在刷短视频时，有人正在用AI生成代码；当你在纠结房价时，有人已经通过代币化资产实现全球配置。\n05 争议与风险：泡沫还是革命？ # 木头姐的报告历来争议巨大。批评者认为：\n过度乐观：技术突破未必如期而至\n忽略监管：各国政府可能出手遏制\n泡沫风险：当前估值已透支未来10年增长\n但支持者反驳：\n历史总是重演：互联网泡沫后诞生了谷歌、亚马逊\n趋势不可逆：AI、区块链是确定性方向\n早鸟优势：泡沫破灭前，早期参与者已获利离场\n结语：现在行动，还是永远旁观？ # 木头姐在报告结尾写道：“未来不会均匀分布，它只属于那些提前看见并勇敢行动的人。”\n10年后，当你回顾今天，会发现2026年是一个分水岭——要么成为AI时代的弄潮儿，要么被拍死在沙滩上。\n最残酷的认知税莫过于：机会摆在面前，你却视而不见。\n想获得木头姐《BigIdeas2026》完整版报告，只需关注公众号，私信回复“木头姐”；免费获得下载链接。\n","date":"8 February 2026","externalUrl":null,"permalink":"/posts/%E6%9C%A8%E5%A4%B4%E5%A7%902026%E9%A2%84%E8%A8%80%E6%9C%AA%E6%9D%A510%E5%B9%B4%E6%99%AE%E9%80%9A%E4%BA%BA%E6%9A%B4%E5%AF%8C%E7%9A%84%E6%9C%80%E5%90%8E%E6%9C%BA%E4%BC%9A/","section":"AI-Related Reposts","summary":"","title":"[Repost] 木头姐2026预言：未来10年，普通人暴富的最后机会！","type":"posts"},{"content":"Powered by Gemini 3 Pro.\nGenerating video game Background Music (BGM) on Suno is a specific skill because, unlike pop songs, game music needs to be less distracting, consistent in volume, and often loopable.\nHere is a guide to getting the best game assets out of Suno, moving from basic settings to advanced looping techniques.\n1. The Golden Rule: Custom Mode Only # Never use the \u0026ldquo;Simple\u0026rdquo; description box. Always switch to Custom Mode.\nLyrics: Leave this blank or use \u0026ldquo;Meta Tags\u0026rdquo; (explained below). Instrumental: Toggle ON. Style: This is where your prompt goes. 2. The BGM Prompt Formula # For game music, you must be descriptive about the instrumentation to prevent the AI from adding \u0026ldquo;pop\u0026rdquo; elements (like ad-libs or erratic solos).\nFormula: [Genre], [Sub-genre], [Vibe/Mood], [Lead Instrument], [Tempo/BPM]\n\u0026ldquo;Recipes\u0026rdquo; by Game Genre # Game Type Recommended Style Prompt 8-Bit / Retro Chiptune, 8-bit, NES style, upbeat, catchy melody, square wave, 140 bpm RPG Town Celtic folk, orchestral, peaceful, flute lead, acoustic guitar, strings, warm, 80 bpm Cyberpunk/Sci-Fi Dark synthwave, industrial, driving bassline, arpeggiated synths, futuristic, neon atmosphere Boss Battle Symphonic metal, orchestral hybrid, epic, choir textures, heavy drums, fast tempo, urgent, 170 bpm Horror/Tension Dark ambient, drone, dissonance, screeching violins, sparse, unsettling, slow Puzzle/Menu Elevator bossa nova, lo-fi hip hop, soft piano, relaxing, minimal percussion, repetitive 3. Controlling Structure (The Meta Tag Trick) # Even if you have \u0026ldquo;Instrumental\u0026rdquo; toggled on, you can still use the Lyrics Box to control the structure of the song using brackets []. This is crucial for game music to avoid long, boring intros or sudden endings.\nTry this structure in the Lyrics box:\n[Intro] (Short, sets the tone) [Main Theme] (The core melody of your level) [Variation] (Slight change to keep the player interested) [Main Theme] (Return to the core melody) [Outro] (Fade out or end clearly) Tip: If you want a specific sound, you can add it as a tag, e.g., [Heavy Drum Fill] or [Silence]. 4. The \u0026ldquo;Looping\u0026rdquo; Problem \u0026amp; Solution # Suno does not generate perfect loops by default. If you put a generated track directly into a game engine (Unity/Unreal), there will be a gap or a jar at the restart.\nTechnique A: The \u0026ldquo;Fade and Cut\u0026rdquo; (Easiest)\nGenerate a track that is longer than you need (e.g., 2 minutes). In the prompt, add seamless loop or repetitive flow. Take the file into an audio editor (Audacity is free). Cut the intro and the outro. Find a \u0026ldquo;zero-crossing\u0026rdquo; point in the middle where the beat repeats and crossfade them manually. Technique B: The \u0026ldquo;Extend\u0026rdquo; Trick (Advanced)\nGenerate a standard clip. Click Extend on your favorite clip. Clear the Style Prompt and replace it with [Outro] or [Loop End]. Sometimes this creates a cleaner ending that is easier to stitch back to the beginning in post-production. 5. Pro Tips for Game Devs # Avoid \u0026ldquo;Messy\u0026rdquo; Frequencies: Prompt for Clean mix or High fidelity. AI sometimes generates \u0026ldquo;muddy\u0026rdquo; audio; adding these keywords helps keep sound effects (SFX) clear over the music. Stem Separation: If you are on a Pro plan (or use external AI tools), separate the stems. This allows you to remove the drums if they clash with your sound effects, or dynamically fade in the \u0026ldquo;melody\u0026rdquo; layer when the player enters a combat zone. Consistency: If you are making a soundtrack for a whole game, keep the Style Prompt identical for every track, only changing the BPM or one instrument. This ensures the \u0026ldquo;Town Theme\u0026rdquo; sounds like it belongs in the same game as the \u0026ldquo;Battle Theme.\u0026rdquo; Summary Checklist # Instrumental Mode: ON Style: Specific genre + video game music + loopable Lyrics Box: Used for structure tags ([Main Theme]) Post-Processing: Plan to edit the start/end in an external editor. 在 Suno 上生成电子游戏背景音乐（BGM）是一项需要技巧的工作，因为与流行歌曲不同，游戏音乐需要减少干扰性、保持音量稳定，并且通常需要可循环（Loopable）。\n以下是关于如何利用 Suno 生成最佳游戏素材的指南，涵盖了从基础设置到进阶循环技巧的所有内容。\n1. 黄金法则：必须使用自定义模式 (Custom Mode) # 永远不要使用那个简单的描述框。请务必切换到 Custom Mode（自定义模式）。\nLyrics (歌词): 留空，或者使用下面介绍的“元标签 (Meta Tags)”。 Instrumental (纯音乐): 开关打开 (ON)。 Style (风格): 这里输入你的提示词 (Prompt)。 2. BGM 提示词公式 # 对于游戏音乐，你必须对配器 (Instrumentation) 进行详细描述，以防止 AI 添加“流行乐”元素（如随意的人声哼唱或突兀的独奏）。\n公式： [流派 Genre], [子流派 Sub-genre], [氛围/情绪 Vibe], [主奏乐器 Lead Instrument], [速度 BPM]\n游戏类型的“配方” # 游戏类型 推荐风格提示词 (Style Prompt) 8-Bit / 复古 Chiptune, 8-bit, NES style, upbeat, catchy melody, square wave, 140 bpm RPG 城镇 Celtic folk, orchestral, peaceful, flute lead, acoustic guitar, strings, warm, 80 bpm 赛博朋克/科幻 Dark synthwave, industrial, driving bassline, arpeggiated synths, futuristic, neon atmosphere Boss 战 Symphonic metal, orchestral hybrid, epic, choir textures, heavy drums, fast tempo, urgent, 170 bpm 恐怖/紧张 Dark ambient, drone, dissonance, screeching violins, sparse, unsettling, slow 解谜/菜单 Elevator bossa nova, lo-fi hip hop, soft piano, relaxing, minimal percussion, repetitive 3. 控制结构（元标签技巧） # 即使你开启了“Instrumental（纯音乐）”，你仍然可以利用 Lyrics（歌词）框 通过方括号 [] 来控制歌曲的结构。这对于游戏音乐至关重要，可以避免冗长的开头或突然的结尾。\n尝试在 Lyrics 框中输入以下结构：\n[Intro] (简短，奠定基调) [Main Theme] (关卡的核心旋律) [Variation] (轻微的变化，保持玩家兴趣) [Main Theme] (回归核心旋律) [Outro] (淡出或清晰的结束) 提示： 如果你需要某种特定的音效，可以作为标签加入，例如 [Heavy Drum Fill] (重鼓过门) 或 [Silence] (静音)。 4. “循环 (Looping)”问题与解决方案 # Suno 默认生成的音乐无法完美无缝循环。如果你直接将生成的音轨放入游戏引擎（Unity/Unreal），重播时会有明显的断档或违和感。\n方法 A：“淡入淡出与剪切”法（最简单）\n生成比你实际需要更长的音轨（例如 2 分钟）。 在提示词中加入 seamless loop (无缝循环) 或 repetitive flow (重复流)。 将文件导入音频编辑器（如免费的 Audacity）。 剪掉开头 (Intro) 和结尾 (Outro)。在中间找到节拍重复的“零交叉点 (zero-crossing)”，手动进行交叉淡化 (Crossfade) 处理。 方法 B：“Extend” 技巧（进阶）\n生成一段标准的片段。 在你喜欢的片段上点击 Extend (延展)。 清空 Style 提示词，替换为 [Outro] 或 [Loop End]。 这有时会生成一个更干净的结尾，方便你在后期制作中将其与开头拼接起来。 5. 给游戏开发者的专业建议 # 避免“浑浊”的频率： 在提示词中加入 Clean mix (干净混音) 或 High fidelity (高保真)。AI 有时会生成“浑浊”的低频；添加这些关键词有助于让你的游戏音效 (SFX) 在音乐之上依然清晰可辨。 分轨 (Stem Separation)： 如果你是 Pro 用户（或者使用外部 AI 工具），请分离音轨（Stems）。这允许你移除可能与游戏音效冲突的鼓点，或者当玩家进入战斗区域时，动态地淡入“旋律”层。 统一性： 如果你在为整个游戏制作原声带，请保持每首曲子的 Style Prompt 基本一致，只改变 BPM 或一两种乐器。这能确保“城镇主题曲”和“战斗主题曲”听起来像是属于同一个游戏。 总结清单 # Instrumental Mode: 开启 (ON) Style: 具体流派 + video game music + loopable Lyrics Box: 用于结构标签 (如 [Main Theme]) 后期处理: 预留时间在外部编辑器中修剪开头/结尾。 需要我帮你为特定的游戏场景（例如“水下关卡”或“最终 Boss”）写一个具体的 Prompt 吗？\nRPG 城镇背景音乐 # Generating background music (BGM) for an RPG town on Suno requires a different approach than writing a standard pop song. You aren\u0026rsquo;t looking for a verse-chorus structure; you need a consistent, loopable atmosphere that sets a specific mood.\nHere is a guide to generating high-quality RPG Town BGM on Suno.\n1. The Golden Rule: Use \u0026ldquo;Instrumental\u0026rdquo; Mode # Always toggle Instrumental on.\nWhy: Vocals in town background music are distracting and repetitive for players. Pro Tip: Even in Instrumental mode, Suno sometimes hallucinates vocals. To prevent this, add tags like Slow build, Cinematic, or Background music in the Style prompt. 2. The Prompt Formula # Suno V3/V4 responds best to a specific recipe for BGM. Use this structure in the Style of Music field:\n[Genre] + [Instruments] + [Mood/Vibe] + [Tempo/Rhythm]\nScenario A: The \u0026ldquo;Starter Town\u0026rdquo; (Peaceful, Safe, Home) # This is the first town the player sees. It needs to feel welcoming and pastoral.\nStyle Prompt: Fantasy Folk, Orchestral, Celtic, Pastoral Instruments: Acoustic Guitar, Flute, Lute, Light Percussion, Strings Mood: Peaceful, Warm, Welcoming, Sentimental, Hopeful Full Example: Celtic fantasy folk, acoustic guitar and flute melody, warm orchestral strings, light percussion, peaceful village atmosphere, 90 BPM\nScenario B: The \u0026ldquo;Busy Market Town\u0026rdquo; (Lively, Bustling) # A hub of commerce. Needs energy but shouldn\u0026rsquo;t be aggressive.\nStyle Prompt: Medieval Tavern, Folk, Upbeat Instruments: Fiddle, Accordion, Hand Drums, Tambourine, Pizzicato Strings Mood: Bustling, Lively, Cheerful, Rhythmic, Busy Full Example: Upbeat medieval folk, fiddle and accordion, rhythmic hand drums, bustling market vibe, playful, staccato strings, 110 BPM\nScenario C: The \u0026ldquo;Mysterious/Magic Town\u0026rdquo; (Night, Ancient) # For towns associated with magic, elves, or nighttime exploration.\nStyle Prompt: Ambient, Ethereal, Fantasy Soundtrack Instruments: Harp, Chimes, Synth Pads, Glass Harmonica, Solo Cello Mood: Mysterious, Magical, Dreamy, Calm, Enigmatic Full Example: Ethereal fantasy ambient, harp arpeggios, glowing synth pads, wind chimes, mysterious and magical, slow tempo, reverb\n3. Structural \u0026ldquo;Meta-Tags\u0026rdquo; for Loops # Since you are in Instrumental Mode, you can\u0026rsquo;t use the \u0026ldquo;Lyrics\u0026rdquo; box for lyrics, but you can use it for structural commands (Meta-Tags) to control the flow.\nPaste this into the Lyrics field (even if Instrumental is on, switch to \u0026ldquo;Custom Mode\u0026rdquo; to see the box):\n[Intro] (Sets the theme, keep it simple) [Theme A] (Main melody, memorable but not annoying) [Theme B] (Variation to prevent ear fatigue) [Theme A] (Return to main melody) [Outro] (Fade out or loop point) Why this helps: It forces Suno to create a cohesive track rather than a random stream of improvisation.\n4. How to Make it \u0026ldquo;Loopable\u0026rdquo; # Suno generates songs with a beginning and end, which is bad for games. Here is the workflow to fix it:\nGenerate a generic track using the prompts above. Find a section you like (e.g., from 0:10 to 1:30) that has a consistent energy. Use the \u0026ldquo;Extend\u0026rdquo; feature: Click the \u0026ldquo;\u0026hellip;\u0026rdquo; on your clip and select Extend. Set the timestamp to where the track feels stable. Clear the Style prompt and just type [Loop] or [Seamless Loop]. The \u0026ldquo;Crossfade\u0026rdquo; Trick (Post-Processing): Download the track. Open it in a free audio editor (like Audacity). Cut the [Intro] and [Outro]. Suno tracks often trail off. You will likely need to manually crossfade the end of the track back into the beginning to make it seamless in your game engine. 5. Summary Checklist # Mode: Custom -\u0026gt; Instrumental Genre: Fantasy Folk / Orchestral / Ambient Instruments: Lute, Flute, Strings (avoid electric guitars/synths unless it\u0026rsquo;s Cyberpunk) Structure: A simple A-B-A structure works best for background loops. 这是针对在 Suno 上生成 RPG 城镇背景音乐（BGM）的建议的中文翻译。\n要在 Suno 上生成高质量的游戏背景音乐，你需要一种不同于创作流行歌曲的思路。你不需要“主歌-副歌”的结构，而是需要一种持续的、可循环的、能通过音乐确立特定氛围的声音。\n以下是在 Suno 上生成高质量 RPG 城镇 BGM 的指南：\n1. 黄金法则：使用“纯音乐”模式 (Instrumental Mode) # 务必开启 Instrumental（纯音乐）开关。\n原因： 城镇背景音乐中如果出现人声，会对玩家造成极大的干扰，而且循环播放时会显得非常重复。 专家技巧： 即使开启了纯音乐模式，Suno 有时也会“产生幻觉”加入人声。为了防止这种情况，请在 Style（风格）提示词中加入 Slow build（缓慢铺垫）, Cinematic（电影感）, 或 Background music（背景音乐）等标签。 2. 提示词公式 (The Prompt Formula) # Suno V3/V4 对特定的 BGM 配方反应最好。请在 Style of Music（音乐风格）字段中使用此结构（建议保留英文提示词以获得最佳效果）：\n[流派 Genre] + [乐器 Instruments] + [情绪 Mood/Vibe] + [速度 Tempo/Rhythm]\n场景 A：“新手村” (宁静、安全、家园感) # 这是玩家看到的第一个城镇。它需要让人感到受欢迎和田园牧歌式的安宁。\n风格提示词： Fantasy Folk, Orchestral, Celtic, Pastoral 乐器： Acoustic Guitar, Flute, Lute, Light Percussion, Strings 情绪： Peaceful, Warm, Welcoming, Sentimental, Hopeful 完整示例 (复制这个)： Celtic fantasy folk, acoustic guitar and flute melody, warm orchestral strings, light percussion, peaceful village atmosphere, 90 BPM\n场景 B：“繁华集市/城镇” (热闹、繁忙) # 商业中心。需要能量感，但不能太激进。\n风格提示词： Medieval Tavern, Folk, Upbeat 乐器： Fiddle, Accordion, Hand Drums, Tambourine, Pizzicato Strings 情绪： Bustling, Lively, Cheerful, Rhythmic, Busy 完整示例 (复制这个)： Upbeat medieval folk, fiddle and accordion, rhythmic hand drums, bustling market vibe, playful, staccato strings, 110 BPM\n场景 C：“神秘/魔法城镇” (夜晚、远古) # 适用于与魔法、精灵或夜间探索相关的城镇。\n风格提示词： Ambient, Ethereal, Fantasy Soundtrack 乐器： Harp, Chimes, Synth Pads, Glass Harmonica, Solo Cello 情绪： Mysterious, Magical, Dreamy, Calm, Enigmatic 完整示例 (复制这个)： Ethereal fantasy ambient, harp arpeggios, glowing synth pads, wind chimes, mysterious and magical, slow tempo, reverb\n3. 用于循环的结构化“元标签” (Meta-Tags) # 既然你处于 Instrumental Mode（纯音乐模式），你不能使用“歌词”框来写歌词，但你可以使用它来输入结构指令（元标签）来控制音乐的流向。\n将以下内容粘贴到 Lyrics（歌词）字段中（即使开启了 Instrumental，也要切换到 \u0026ldquo;Custom Mode\u0026rdquo; 才能看到歌词框）：\n[Intro] (Sets the theme, keep it simple - 设定主题，保持简单) [Theme A] (Main melody, memorable but not annoying - 主旋律，要有记忆点但不要烦人) [Theme B] (Variation to prevent ear fatigue - 变奏，防止听觉疲劳) [Theme A] (Return to main melody - 回归主旋律) [Outro] (Fade out or loop point - 淡出或循环点) 为什么这有帮助： 这强迫 Suno 创建一个连贯的轨道，而不是随机的即兴演奏流。\n4. 如何实现“可循环” (Loopable) # Suno 生成的歌曲有开头和结尾，这对游戏循环播放来说是不利的。以下是解决工作流：\n生成通用轨道： 使用上面的提示词生成音乐。 找到你喜欢的部分： 比如从 0:10 到 1:30，这一段能量比较稳定。 使用 \u0026ldquo;Extend\u0026rdquo;（延展）功能： 点击片段上的 \u0026ldquo;\u0026hellip;\u0026rdquo; 并选择 Extend。 将时间戳设置在你觉得轨道状态最稳定的地方。 清除风格提示词，只输入 [Loop] 或 [Seamless Loop]。 “交叉淡入淡出”技巧 (后期处理)： 下载音轨。 在免费音频编辑器（如 Audacity）中打开它。 剪掉 [Intro]（前奏）和 [Outro]（尾奏）。 Suno 的轨道通常会渐弱结束。为了在游戏引擎中实现无缝循环，你通常需要手动将结尾与开头进行 Crossfade（交叉淡入淡出）处理。 5. 总结清单 # 模式： Custom (自定义) -\u0026gt; Instrumental (纯音乐) 流派： Fantasy Folk (奇幻民谣) / Orchestral (管弦乐) / Ambient (氛围音乐) 乐器： Lute (鲁特琴), Flute (长笛), Strings (弦乐) (除非是赛博朋克风格，否则避免使用电吉他/合成器) 结构： 简单的 A-B-A 结构最适合背景循环。 ","date":"7 February 2026","externalUrl":null,"permalink":"/blog/suno%E5%88%B6%E4%BD%9Cbgm/","section":"AI-Generated Blog","summary":"","title":"[双语] Suno制作BGM","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这句话主要源自当下非常流行的日本动漫/IP 《吉伊卡哇》（Chiikawa / ちいかわ）。 如果不了解这个背景，这句话听起来可能像是一句莫名其妙的农业格言；但放在《吉伊卡哇》的语境下，它有着既可爱又略带“社畜”辛酸的特殊含义。 您可以从以下几个层面来理解这句话：\n1. 剧情背景：可爱的外表，现实的规则 # 在《吉伊卡哇》的世界里，主角们（吉伊、小八、乌萨奇等）虽然长得软萌可爱，但他们生活在一个极度现实且类似人类资本主义社会的环境中。\n除草（干活）： 为了生存，他们必须去“劳动中心”接任务赚取报酬。最常见、最基础的工作就是除草。为了赚更多的钱，他们甚至还需要通过考试去考取“除草资格证”（分5级、4级等，级别越高薪水越高）。 吃拉面（奖励）： 剧中的“郎”拉面（原型是现实中的“二郎系拉面”）是主角们非常向往的美食。但吃一顿拉面需要花钱，而钱必须通过辛苦劳动换来。 因此，“只有努力除草，才能吃拉面” 是剧中角色生存逻辑的真实写照：如果不去辛苦拔草赚钱，就没钱去吃心爱的拉面。 2. 网络语境：当代年轻人的“打工嘴替” # 这句话之所以会在互联网上（尤其是打工人和学生群体中）爆火，是因为它引起了强烈的情感共鸣。它是一种**“用最可爱的语气，说最狠的现实”**。\n现实的投射： “除草”隐喻着我们枯燥、辛苦的工作或学习任务（比如写PPT、改代码、背单词）；“吃拉面”隐喻着我们渴望的物质奖励或精神享受（比如发工资、买包、去旅游、吃大餐）。 自我激励（PUA）： 这句话常被用来作为一种自嘲式的激励。当不想工作/学习时，人们会用吉伊卡哇的表情包对自己说：“快去干活！只有努力除草（搬砖），才能吃拉面（过上好日子）！” 苦中作乐： 它代表了一种**“罗曼蒂克式的英雄主义”**——看清了生活的残酷（必须要打工），但依然为了那碗热腾腾的“拉面”而努力生活。 3. 表情包文化 # 在社交媒体上，这句话通常配合着以下画面出现：\n主角们灰头土脸地在拔草。 主角们考取“除草证”失败后的哭泣，或者成功后的狂喜。 主角们面对堆成山的拉面时幸福的表情。 这种**“极度辛苦”与“极度满足”的反差**，构成了这句话的幽默感。 总结 # 理解这句话，其实就是理解当下年轻人的**“吉伊卡哇综合征”**： 我们都像那些小动物一样，在这个复杂的社会里，为了哪怕一点点“好吃的拉面”（小确幸），必须每天起早贪黑地“除草”（谋生）。 它既是一句自嘲，也是一句加油打气的话。\n除此之外，您是否需要我为您生成一张以此为主题的激励风格图片（例如一只可爱的小生物在努力拔草），或者是想了解更多关于《吉伊卡哇》的剧情细节？\nTurn 2 # 👤 User # 请生成一张以此为主题的激励风格图片（例如一只可爱的chiikawa动漫角色在努力拔草），图片没有文字\n🤖 Assistant # 🍌\nExported from Gemini Voyager\nGenerated on February 7, 2026 at 04:36 PM\n","date":"7 February 2026","externalUrl":null,"permalink":"/blog/%E5%8F%AA%E6%9C%89%E5%8A%AA%E5%8A%9B%E9%99%A4%E8%8D%89%E6%89%8D%E8%83%BD%E5%90%83%E6%8B%89%E9%9D%A2/","section":"AI-Generated Blog","summary":"","title":"只有努力除草，才能吃拉面","type":"blog"},{"content":"Reposted from 堪比“ChatGPT”时刻！SemiAnalysis深度解读：Claude Code将是AI “智能体”的转折点 by 人工智能学家\n来源：华尔街见闻\nSemiAnalysis分析指出，Claude Code已占据GitHub代码提交的4%，预计2026年底超20%，标志着AI智能体技术进入规模化商用拐点。它正重构全球15万亿美元的信息工作市场，并推动Anthropic季度营收增量超越OpenAI。传统软件商业模式面临根本冲击，而微软等巨头陷入平衡云服务增长与保护核心产品的战略两难。智能体竞争已从生成响应转向实现可交付成果，整个行业正转向效率为王的实战阶段。\nAnthropic旗下AI编程工具Claude Code已占GitHub公共代码提交量的4%，并预计到2026年底该比例将超20%。研究机构SemiAnalysis最新分析指出，Claude Code是AI“智能体”的转折点。\n该报告强调，**Claude Code不仅改变了编程形态，更预示着AI智能体将重塑全球约15万亿美元的信息工作市场。**目前，Anthropic依托该技术实现营收快速增长，其季度年度经常性收入（ARR）增量已超越OpenAI，反映出AI智能体赛道的竞争格局正发生结构性变化。\n这一趋势已引发产业链的深度响应。埃森哲已签署协议，计划在金融、医疗及公共部门培训3万名专业人员使用Claude，成为目前规模最大的企业级部署案例。与此同时，传统软件与SaaS商业模式面临根本性挑战。\n分析指出，相当多的领域都将受到影响。随着Claude Code（和Cowork）的兴起，智能体的总市场规模远大于大型语言模型本身。从当前的客户支持、软件开发等垂直场景，逐步延伸至金融服务、法律合规、战略咨询等高价值专业服务产业。这也正是该研究机构模型持续追踪的核心命题：智能体商业化路径正在重构整个数字经济的价值分配逻辑。\n对科技巨头而言，战略平衡变得更为复杂。**微软既通过Azure为OpenAI、Anthropic等提供算力支持，又需防御AI代理工具对其Office 365等核心产品的冲击。**据悉，CEO Satya Nadella已亲自参与AI产品战略调整，可见该领域对公司未来发展影响深远。\n随着Claude Code等AI代理工具持续渗透，从开发流程到企业运营的智能化重构进程正全面加速。\nClaude Code与智能体未来 # 智能体将成为人类与人工智能交互的主要方式。Claude Code的出现，不仅展示了人类如何引导AI，更揭示了智能体反向塑造工作流程的潜力。\nSemiAnalysis指出，**当前正处于继2023年ChatGPT时刻之后，AI演进的新临界点。**此前的里程碑已逐步验证了AI的边界：GPT-3确立了规模化的有效性，ChatGPT证明了终端市场需求，DeepSeek展示了高效的小规模实现路径。\n在这些线性突破之上，Claude Code代表了更根本的范式演进：它并非单纯提升生成质量，而是通过智能体架构，将模型能力组织为可执行复杂任务、具有持续交互能力的数字工作体。这标志着AI正从提供“响应”，转向系统交付的“成果”。\nClaude Code是什么？ # Claude Code是一款终端原生的AI智能体，其设计逻辑超越了传统IDE增强工具或聊天助手模式。作为命令行工具，它通过直接读取代码库、自主规划多步骤任务并完成执行，实现了从“代码生成器”到“系统级操作代理”的范式跨越。\n更准确地说，Claude Code应被视为“Claude计算机”，在获得用户授权的前提下，它能全面感知本地环境、制定动态计划并通过迭代执行实现复杂目标。用户只需用自然语言描述任务目标（如“分析此数据表并生成趋势报告”），系统即可自主完成从理解上下文、拆解步骤到验证输出的全过程。\n重新定义软件开发，从编写代码到氛围编程 # Claude Code正在重新定义程序员的职业内核：**从代码编写者转变为任务规划者。**其根本突破在于工程可行性，通过命令行界面，它能直接理解开发者意图、拆解复杂目标并自主完成从环境感知到执行验证的全流程。\nClaude Code的魔力在于它确实有效，许多著名的程序员最终接受了新一轮的氛围编程，并意识到编程基本上已接近一个被解决的问题，由智能体支持比由人类完成更好。\n其影响力已深入顶尖技术从业者群体。一年前创造了“氛围编程”一词的OpenAI前科学家Andrej Karpathy坦言，长期使用AI编码已导致其手动编程能力逐步退化。Vercel首席技术官Malte Ubl称其核心工作转变为“纠正AI错误”，NodeJS创始人Ryan Dahl更直言**“人类手写代码时代已结束”**。工具创建者Boris Cherny透露，团队近100%代码由Claude Code结合Opus 4.5完成，Linux创始人Linus Torvalds亦成为此类工具的活跃使用者。\n超越编程，信息工作全面自动化 # 分析指出，全球约10亿信息工作者所构成的、价值15万亿美元市场，正因Claude Code面临系统性重塑，而这仅是开端。\n**Claude Code的价值正延伸至非编程领域。**据SemiAnalysis团队实践，该工具已系统应用于数百份文档审查、数千条目物料清单分析及实时预测模型构建等工作场景。从监管合规到技术文档处理，人机交互范式正在发生结构性变革。\nClaude Code已验证出一种可广泛复制的智能体工作范式：**读取非结构化信息、应用专业知识、生成结构化输出、并自主验证结果。**这一“感知-思考-输出-校验”的流程，与绝大多数知识工作的核心环节高度契合。\n值得注意的是，其最新推出的通用工具“Cowork”进一步强化了这种泛化能力，仅由四名工程师在十天内开发完成，并能实现从整理收据、归类文件到起草报告等一系列办公自动化任务。从这一案例可见**，AI代理已从编码专用工具，演进为可编程的通用工作引擎。**\n当前，**任务处理时长是制约技术渗透的关键瓶颈。**行业数据显示，自主任务处理时长的翻倍周期已缩短至约4个月。从数分钟的代码生成，到数小时的模块重构，再到跨日的审计流程自动化，每一次时长突破都将开启一个全新的规模化应用场景。\n智能成本暴跌重塑商业模式 # 软件工程作为信息工作的标杆领域，已迎来生产力关系的结构性翻转。**随着AI代码生成质量跨越关键阈值，程序员正从直接编写者演变为目标定义与黑盒工具管理者。**这一转变的背后，不仅是技术能力的突破，更是经济模型的根本变革。\n当前，Claude Pro等高级AI工具的月费仅为20美元，相比美国知识工作者每日350-500美元的全成本，其成本优势极其显著。即便AI智能体仅完成日常工作中一小部分任务，约6-7美元的日均成本即可实现10-30倍的投资回报率，这使得规模化部署具备极强的经济动力。\n尽管Stack Overflow 2025年调查显示84%的程序员已使用AI工具，但其中仅31%采用编程代理，当前技术渗透仍处于早期阶段，未来增长空间广阔。\n智能成本的急剧下降正在系统性重塑信息产业的利润结构。企业软件行业首当其冲，**传统SaaS依靠数据迁移成本、工作流锁定与集成复杂性构筑的护城河，正被AI代理逐步侵蚀。**这些代理能够跨系统迁移数据、摆脱对人类友好型工作流的依赖，并通过标准化协议降低集成难度。在此背景下，SaaS行业高达75%的毛利率，反而成为吸引AI替代浪潮的明确信号。\n企业已经开始行动 # 分析指出，**智能体大规模降低成本已经使得不少企业开始采取行动。**以埃森哲计划培训三万专业人员部署Claude Code为标志，金融服务、生命科学等关键领域的信息自动化进程已进入规模化阶段，OpenAI同期推出的Frontier企业计划进一步印证了这一趋势。\n**企业软件成为此轮变革的首要冲击对象。传统SaaS商业模式依赖数据迁移成本、工作流习惯培养与系统集成难度构筑的护城河，正在被智能体技术逐步瓦解。**AI代理能够以更低成本实现跨系统数据迁移，其工作流不依赖于为人类设计的交互界面，而通过MCP等协议大幅降低集成门槛。当智能体可自主完成从数据库查询、图表生成到报告分发的完整流程时，传统软件高达75%的毛利率反而成为其脆弱性的体现。\n从商业智能分析到后台对账，从数据录入到初级IT运维，凡是涉及信息采集、格式转换与分发的可重复工作流程，均在AI的自动化射程之内。这种以自然语言为接口、以任务达成为导向的交互范式，不仅威胁着特定软件厂商，更对以微软为代表、建立在传统人机交互范式之上的整个软件生态构成了根本性挑战。效率革命正在从技术优化升级为产业价值重构。\n微软的两难困境 # 成本结构的根本性变革正在瓦解以按用户数收费为核心的软件商业模式。以SemiAnalysis内部大规模部署Claude Code为例，受影响最深的是微软的Office 365套件。\n微软正面临战略性两难：Azure的快速增长需要满足公开市场期待，而投资Copilot系列则是保护Office 365这一核心利润来源的必要防御。二者之间存在内在冲突，在任一领域取得突破，都可能以另一领域的退守为代价。作为OpenAI和Anthropic等AI领军企业的主要云服务商，微软实际上正通过出租算力，为可能瓦解其核心生产力软件护城河的颠覆性技术提供支持。\n最新财报会议直观呈现了这一战略拉锯的紧绷态势。微软坦言，若将本财年前两季度全部新增GPU资源投入Azure，其关键增长指标将超过40%。然而公司最终选择优先保障M365 Copilot与GitHub Copilot等第一方AI产品的产能与增速。\n值得玩味的是，当前由外部团队在微软生态内开发的“Claude for Excel”，其功能形态恰是微软自身Copilot for Excel原本应实现的目标。这反映了一个深层矛盾：公司当下的现金支柱仍来自Office，而长期估值则更多依赖Azure的增长前景。为加速后者，微软或许不得不默许外部创新力量对其传统护城河的持续侵蚀。\n尽管GitHub Copilot与Office Copilot拥有近一年的先发优势，但其产品演进速度并未形成显著壁垒。在此背景下，首席执行官Satya Nadella亲自深度介入AI产品管理，暂时脱离日常CEO职责，这一罕见举动清晰表明：当前AI产品的竞争态势，已关乎微软整体未来的命运走向。\nAnthropic的增长动力 # 基于对Anthropic的详细经济建模，SemiAnalysis量化了其扩张对AWS、Google Cloud及Azure等云服务商的收入贡献，以及对Trainium、TPU与GPU供应链的资本支出拉动。分析指出，未来三年Anthropic将部署与OpenAI相当的算力规模，其增长将直接受算力供给约束。\n目前，Anthropic的季度年度经常性收入（ARR）增量已超越OpenAI，标志其在商业化进程上实现关键超越。这一趋势表明，在AI竞赛的下半场，算力规模与营收转化之间已形成强耦合。\nClaude Code的成功，本质上是Opus 4.5模型在复杂任务中工程化能力的体现。当前行业对传统线性基准的过度关注正逐渐失去意义，在长周期、多步骤的智能体任务中，单一响应质量并非决定性因素。竞争焦点已从“生成最佳回答”转向“实现可交付成果”。\n未来评估模型效能的核心指标，将逐步转化为任务完成度、系统稳定性及自动化边界，其价值体现在通过工具调用、记忆管理、子代理协调与验证闭环所实现的端到端输出，而非孤立的数据包质量。AI竞争正在从基准测试的实验室赛道，转向真实工作流的效率战场。\n**阅读最新前沿科技趋势报告，请访问欧米伽研究所的“未来知识库”\n**\nhttps://wx.zsxq.com/group/454854145828\n_未来知识库是“__欧米伽__未来研究所”建立的在线知识库平台，收藏的资料范围包括人工智能、脑科学、互联网、超级智能，数智大脑、能源、军事、经济、人类风险等等领域的前沿进展与未来趋势。_目前拥有超过8000篇重要资料。_每周更新不少于100篇世界范围最新研究资料。_欢迎扫描二维码或访问https://wx.zsxq.com/group/454854145828** 进入。**\n","date":"7 February 2026","externalUrl":null,"permalink":"/posts/%E5%A0%AA%E6%AF%94chatgpt%E6%97%B6%E5%88%BBsemianalysis%E6%B7%B1%E5%BA%A6%E8%A7%A3%E8%AF%BBclaude-code%E5%B0%86%E6%98%AFai-%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E8%BD%AC%E6%8A%98%E7%82%B9/","section":"AI-Related Reposts","summary":"","title":"[Repost] 堪比“ChatGPT”时刻！SemiAnalysis深度解读：Claude Code将是AI “智能体”的转折点","type":"posts"},{"content":"","date":"7 February 2026","externalUrl":null,"permalink":"/tags/ai-image/","section":"Tags","summary":"","title":"AI Image","type":"tags"},{"content":"On this website, I share pictures generated by Nano Banana Pro.\n","date":"7 February 2026","externalUrl":null,"permalink":"/pic/","section":"AI-Generated Pictures","summary":"","title":"AI-Generated Pictures","type":"pic"},{"content":"Powered by Nano Banana Pro.\n","date":"7 February 2026","externalUrl":null,"permalink":"/pic/chiikawa/","section":"AI-Generated Pictures","summary":"","title":"Chiikawa!","type":"pic"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且切中时弊的问题。在 AI 时代，“懒惰”的定义正在发生变化：它不再仅仅是指体力的懈怠，更多是指**“认知卸载”（Cognitive Offloading）——即我们习惯性地将思考、决策和创造过程完全外包给算法，导致自身思维能力的退化。 要避免这种“新型懒惰”，关键不在于拒绝 AI，而在于改变与它的互动关系**。以下是几个具体的策略：\n1. 从“获得答案”转向“打磨问题” # AI 最擅长的是根据指令生成答案，而人类最核心的能力是提出高质量的问题和设定方向。\n做架构师，而不是泥瓦匠： 不要只让 AI 帮你写完一段代码或一篇文章就结束。你应该专注于构思整体的逻辑框架、论证思路或产品愿景。 挑战 AI 的输出： 不要默认 AI 的答案是完美的。试着去质疑它：“这个观点有漏洞吗？”“有没有更好的替代方案？”迫使自己进行批判性思考，把 AI 当作辩论对手，而不是标准答案库。 2. 刻意保留“认知摩擦” (Cognitive Friction) # 学习和成长的本质是克服困难。如果一切都太容易，大脑就会停止进化。\n维护核心技能： 即使 AI 翻译已经很完美，你仍需学习外语以理解文化细微之处；即使 AI 能写代码，你仍需理解算法原理以优化性能。对于你的核心专业领域，不要跳过基础训练。 “三明治”工作法： 头脑风暴（人）： 先自己构思初稿或大纲，不借助 AI。 扩展优化（AI）： 使用 AI 补充细节、提供素材或检查错误。 最终定稿（人）： 注入你的个人风格、价值观和情感判断，完成最后的升华。 3. 深耕 AI 无法触达的领域 # AI 依赖于历史数据，它是对过去的总结；而人类拥有感知当下的能力。\n情感与同理心： 在沟通、管理和艺术创作中，真正打动人的是真实的情感连接和细腻的同理心，这是算法难以模拟的。 跨界与直觉： 培养看似“无用”的兴趣，将风马牛不相及的知识点连接起来（比如将哲学思考带入技术开发）。这种非线性的创新直觉目前仍是人类的强项。 现实世界的体验： 动手做实验、面对面交流、实地考察。这些基于物理世界的真实反馈是单纯的数据处理无法替代的。 4. 警惕“快感陷阱” # AI 能瞬间生成精美的图像或流畅的文本，这种即时反馈容易让人产生“我也很厉害”的错觉。\n区分“使用工具的能力”与“自身的能力”： 时常自问：如果现在拔掉网线，我还能解决这个问题吗？如果答案是否定的，说明你可能过度依赖了。 设定“无 AI 时段”： 每天设定特定时间段或特定任务（如阅读、日记、草图），完全脱离 AI 辅助，强迫大脑独立运转。 总结 避免变懒的核心，在于掌握主动权（Agency）。要把 AI 当作你的副驾驶（Co-pilot），可以在导航和仪表盘上帮你省力，但手必须始终握在方向盘上，且必须清楚车要开向哪里。 我可以为您做的下一步： 如果您有具体的学习计划或工作流程，我可以帮您分析在哪些环节适合引入 AI 提效，而在哪些环节必须“亲力亲为”以保持核心竞争力。\nExported from Gemini Voyager\nGenerated on February 7, 2026 at 11:09 AM\n","date":"7 February 2026","externalUrl":null,"permalink":"/blog/%E5%9C%A8ai%E6%97%B6%E4%BB%A3%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E4%BA%BA%E5%8F%98%E6%87%92/","section":"AI-Generated Blog","summary":"","title":"在AI时代，如何避免人变懒","type":"blog"},{"content":"Reposted from Nature 重磅发布：人类一眼顿悟的 one-shot 学习机制，可能是AI 的下一次范式革命 by FlerkenS\n如果你曾看过那张著名的“达尔马提亚狗图”，你大概体验过一种奇妙的瞬间。第一眼，你只看到一团混乱的黑白斑点，第二眼，当有人告诉你“这是只狗”，你的视觉系统仿佛被点亮，从此再也无法“看不见那只狗”。\n科学家把这种现象称为单次感知学习（one-shot perceptual learning）。 它的神奇之处在于只需要一次清晰图像的呈现，就能永久改变你对退化图像的感知方式。\n在实验室里，这种现象常用“Mooney 图”来研究——一种极度退化、几乎无法识别的黑白图像。 但只要你看过一次对应的清晰原图，再回头看 Mooney 图，你会惊讶地发现它突然变得“显而易见”。\n这种“顿悟式学习”与我们熟悉的“练习成就完美”完全不同。\n传统的视觉学习需要成百上千次重复训练，像肌肉记忆一样慢慢积累； 而 one-shot 学习更像是大脑的“闪存写入”，一次写入，永久生效。\n然而，现代 AI 虽然在图像识别上已经强到离谱，却依然难以复现这种能力。 深度学习模型需要海量数据、长时间训练、巨量算力，才能学会识别一个新类别。\n相比之下，人类只需要一次体验。\n这背后到底发生了什么？ 大脑是如何做到一次写入、长期保持、不遗忘旧知识，不破坏已有视觉系统，还能在毫秒级时间内调用这些先验？\n更关键的是这种快速学习到底发生在大脑的哪个区域？先验知识以什么格式存储？是概念？是形状？还是某种抽象的视觉模板？神经机制如何避免“灾难性遗忘”，而深度学习模型却做不到？我们能否构建一个真正具备人类式one-shot学习能力的AI？\n图1 |心理物理学实验的范式和假设。\n这些问题长期以来悬而未决。直到这篇《Neural and computational mechanisms underlying one-shot perceptual learning in humans》发表在Nature Communications的研究出现。\n这项研究由纽约大学（NYU）和 Mount Sinai 医学院的跨学科团队联合完成，成员横跨认知神经科学、视觉神经科学、临床神经外科（提供 iEEG 数据）、生物医学工程、计算机工程、数据科学与深度学习。\n团队由 Biyu J. He与 Eric Oermann 共同领导，他们在视觉认知、神经电生理和医学 AI 领域都处于国际前沿。\n这项研究的意义在于它不仅回答了“人类如何做到 one-shot 学习”这一神经科学难题，还首次构建了一个能模拟人类单次感知学习的深度神经网络模型，并将其与人脑的神经编码进行对齐。\n01 # 研究设计：三条证据链锁定大脑中的“先验存储器” # 为了破解 one-shot 感知学习的神经与计算机制，研究团队设计了一套极其严谨、跨层级的研究方案。 他们没有依赖单一实验，而是从行为、神经表征、时间动态和计算模型四个维度同时出击，构建了一条“闭环式证据链”。\n这套设计可以概括为一句话：从行为推断先验结构，从神经定位存储区域，从时间确定激活顺序，再用模型复现机制。\n整个研究包含四条互补证据链。\n首先是行为层面。研究者通过操控清晰图像的方向、大小、位置、类别等属性，观察这些操控是否会破坏 one-shot 学习。 如果某种操控不影响学习，就说明大脑中的“先验知识”对该属性具有不变性； 反之，则说明先验依赖该属性。 通过这种方式，他们绘制出一张“先验不变性地图”，从行为层面推断先验可能存储在哪个脑区。\n接着是神经层面。研究者使用 7T fMRI 测量不同脑区对这些操控的神经表征差异。 如果某个脑区的神经表征不变性结构与行为不变性结构一致，就说明它可能是先验的存储地。 这一步是行为推断的神经验证。\n然后是时间维度。通过对癫痫患者的颅内电记录（iEEG），研究者测量不同脑区在学习后对 Mooney 图的反应变化。 先验存储区应该是最早出现学习效应的区域。 这一步提供了时间因果证据。\n最后是计算层面。 研究团队构建了一个具备 one-shot 学习能力的深度神经网络模型，并将模型中学到的“先验”与人脑不同脑区的神经编码进行对齐。 如果模型先验与某个脑区的神经表征最相似，就进一步支持该脑区是人类先验的存储地。\n这四条证据链最终指向同一个答案：高层视觉皮层（HLVC）是人类one-shot感知学习的核心存储器。\n02 # 心理物理学：先验知识的“不变性地图”揭示其存储位置 # 如果说 one-shot 感知学习是一种“顿悟”，那么心理物理学实验就是在拆解这场顿悟背后的“视觉魔术”。研究团队从最基础的行为层面入手，试图回答一个看似简单却极其关键的问题——大脑到底存了一个什么样的“先验模板”，让我们在看过一次清晰图像后就能永远识别那张退化图？\n为了回答这个问题，他们设计了一套极其巧妙的实验范式。\n图2|映射感知先验的不变性属性。\nMooney图：为什么它难得离谱？\nMooney 图是一种极端退化的黑白图像，几乎没有灰度、没有边缘、没有纹理，只有大片黑白块。 对视觉系统来说，这就像把一段旋律只留下节奏、去掉音高——信息少得可怜。\n所以第一次看到 Mooney 图时，你的大脑几乎无法从中提取任何结构。 但只要你看过一次对应的清晰原图，再回头看 Mooney 图，你会突然发现：\n“啊，这不就是一只狗/一个人/一辆车吗？”\n这种“瞬间开窍”的体验，就是单次感知学习的核心。\n单次呈现清晰图像如何瞬间改变感知？\n研究者让受试者先看 Mooney 图（通常认不出来）， 然后只呈现一次对应的清晰图像， 再让他们看同一张Mooney 图。\n结果几乎所有人都能立刻认出图像内容，而且这种效果能持续数月。\n这说明大脑在一次呈现中就写入了某种“先验知识”。 但这个先验到底是什么？ 是形状？是轮廓？是空间布局？还是某种抽象的视觉模板？\n为了回答这个问题，研究团队开始“折磨”清晰图像。\n操控清晰图像：方向、大小、位置，一项项试过去\n研究者的逻辑非常直接，如果改变某个属性后学习效果不变，说明大脑的先验对这个属性“不敏感”。反之，则说明先验依赖这个属性。\n这就像在测试一个锁的密码： 你改动某一位数字，锁还能打开，那这一位就不是关键位。\n于是他们对清晰图像做了三类操控。\n方向变化：翻转、旋转——学习变弱但不会消失\n当清晰图像被左右翻转或旋转 90°后，受试者的学习效果明显下降，但并没有完全消失。\n这意味着大脑的先验对方向部分不变，但方向仍然是先验的一部分。\n这种“部分不变性”非常像高层视觉皮层（HLVC）的编码特征： 它对方向有一定不变性，但不是完全不变。\n大小变化：6°、12°、24°——完全不影响学习\n这是最关键的发现之一。\n无论清晰图像缩小一半还是放大一倍，学习效果都几乎不变。\n这直接排除了早期视觉皮层（V1–V4）作为先验存储区的可能性，因为这些区域对大小极其敏感，图像大小变化会彻底改变它们的神经编码。\n而高层视觉皮层（尤其 IT 区）对大小高度不变。\n这是一条非常强的证据。\n位置变化：偏移 6°——学习变弱但不消失\n当清晰图像被移到左侧或右侧 6°时，学习效果下降，但依然存在。\n这再次呈现出“部分不变性”的特征。\n结合方向与大小的结果，一个清晰的模式浮现出来：\n大小：完全不变\n方向：部分不变\n位置：部分不变\n这正是高层视觉皮层（HLVC）的典型编码特征。\n概念 vs 感知：换成同类不同 exemplar → 学习直接消失\n研究者做了一个非常关键的操控，把清晰图像换成同一类别的另一张图。\n比如 Mooney 图对应的是一只特定姿态的猫， 但清晰图像换成另一只猫。\n结果学习效果直接消失。\n这说明大脑存储的先验不是“猫”这个概念，而是“这张猫图的具体视觉结构”。\n换句话说，先验存储在感知空间而不是概念空间。\n这与 IT 区的神经编码完全一致， IT 区虽然能区分类别，但它的编码本质上仍是具体视觉特征的显式表示。\nM通路vs P通路：两条通路都能诱发学习\n研究者还测试了低对比度（偏向 M 通路）、红绿等亮度（偏向 P 通路），\n结果两者都能诱发学习。\n这说明先验不依赖某一条视觉通路，但两条通路都能投射到 IT 区，再次指向 HLVC 作为先验存储区。\n至此，行为层面的证据已经非常清晰，先验的“不变性结构”与高层视觉皮层的编码特性高度一致。\n03 # HLVC的神经表征与行为先验完全一致 # 行为实验告诉我们先验长什么样， 但 fMRI 能告诉我们大脑哪里真的以这种方式编码图像。\n研究团队使用 7T 超高场 fMRI，对每张图像在不同操控条件下的神经表征进行建模。\n构建神经 RDM：70×70的图像-条件矩阵\n他们选取了 10 张图像 × 7 种操控条件， 构建了一个 70×70 的神经表征距离矩阵（RDM）。\n每个元素代表：\n“图 A 在条件 X 与图 B 在条件 Y 的神经表征差异有多大？”\n这是表征相似性分析（RSA）的核心。\n图3 |基于模型的RSA结果（n=10名受试者）。\n哪些脑区具有“操控不变性”？\n研究者把不同脑区的神经 RDM拿来对比，结果非常有意思。\nHLVC（LO1、LO2、FC）： 对方向、大小、位置操控表现出显著不变性 与行为结果高度一致。\nV4：有部分不变性，但不完全匹配。\nEVC（V1–V3）：完全不匹配（对大小极其敏感）。\nFPN、DMN： 虽然任务中活跃，但不具备这种不变性结构。\n只有 HLVC 的神经表征与行为推断的“先验结构”一致。\n模型 RDM vs 神经RDM：最终对齐\n研究者基于行为实验构建了一个“先验模型 RDM”，包含三种距离等级：\n大小变化：低距离。\n方向/位置变化：中距离。\n不同 exemplar：高距离。\n然后与各脑区的神经 RDM 进行相关分析。\n结果只有一个脑区显著相关：HLVC（尤其LO2和FC）\n这意味着HLVC是最可能的先验存储部位。\n04 # 颅内电记录（iEEG）：HLVC 最早出现学习效应 # 如果说心理物理学告诉我们“先验长什么样”，fMRI 告诉我们“先验存在哪里”，那么颅内电记录（iEEG）则回答了一个更尖锐的问题：谁是最先被先验点亮的脑区？\n这是一个时间维度的问题，而时间，往往是因果的关键。\n图4|学习诱导活动变化的时间特性。\n为什么时间维度重要？\n在大脑中，信息流动是有顺序的。 如果某个区域真的存储了先验，那么当你再次看到 Mooney 图时，它应该是最早被激活的区域—— 就像一个熟悉的旋律响起，你脑海中最先浮现的那段记忆，必然是它的“源头”。\n先验存储区必须在视觉输入到达后最先发生变化，而不是等别人告诉它“该怎么想”。\n这就是 iEEG 的价值所在。 它不像 fMRI 那样“慢吞吞”，而是毫秒级的神经电信号，能精确捕捉大脑中哪一块皮层最先“觉醒”。\nHLVC在~150 ms出现学习效应\n研究团队在癫痫患者中记录了颅内电信号，比较学习前后 Mooney 图触发的神经反应。\n结果非常干脆：\n高层视觉皮层（HLVC）在大约150毫秒时就出现了显著的学习效应。\n这意味HLVC 在看到退化图像时，会迅速调用刚刚写入的先验，并在极短时间内改变对图像的解释方式。\n这不是“被动响应”，而是“主动调控”。\nFPN、DMN的变化更晚出现\n相比之下，前额-顶叶网络（FPN）和默认模式网络（DMN）虽然也会在学习后表现出变化，但时间明显滞后。\n这说明它们可能参与注意、解释、决策等高阶过程，但不是先验的存储者，更像是“接收来自 HLVC 的更新信息”。\n这条时间因果证据与行为和 fMRI 的空间证据完美对齐：\nHLVC是先验的源头，而不是被动接收者。\n05 # 深度神经网络模型：构建一个能“一眼顿悟”的 AI # 科学研究最迷人的地方在于它不仅解释世界，还能启发我们构建新的系统。\n当研究团队已经用行为、fMRI、iEEG 三条证据链锁定HLVC 后，他们做了一件更大胆的事——构建一个能像人类一样进行one-shot感知学习的深度神经网络。\n这不是“再训练一下模型”那么简单，而是一次对AI 学习机制的重新设计。\n图5 |模型显示了感知学习效果并预测了人类的学习结果。\n模型架构：Vision Transformer + Top-down Feedback\n研究团队以 Vision Transformer（ViT）为基础，但加入了一个关键机制：自顶向下反馈（Top-down Feedback）。\n这一步非常关键，因为人脑的视觉系统不是单向的，高层视觉区域会不断向低层区域发送反馈，这种反馈是“先验注入”的核心机制。\n传统的深度学习模型几乎都是“自下而上”的，缺乏这种动态调控能力。 而加入反馈后，模型可以在一次呈现清晰图像后，更新内部先验，在下一次看到 Mooney 图时，用先验去“修正”对退化图像的解释。\n这就是人工系统中的“顿悟”。\n模型结果：AI 真的学会了“一眼顿悟”\n令人惊喜的是，这个模型不仅能进行 one-shot 学习，而且表现得非常“人类”。\n研究团队发现模型成功复现了人类的整体学习幅度。\n也就是说看一次清晰图像，模型对 Mooney 图的识别率显著提升，幅度与人类非常接近。\n更令人震惊的是模型能预测不同图像的学习难度差异（image-specific）。\n或者说哪些 Mooney 图更容易被人类“顿悟”，哪些更难，模型都能提前预测。\n这说明模型不仅学到了“先验”，还学到了“先验的结构”。\n模型学到的“先验”与 HLVC 神经编码最相似\n研究团队进一步把模型内部的“先验表征”与人脑不同区域的神经编码进行对齐。\n结果再次指向同一个答案，模型的先验与HLVC的神经编码最相似。\n这意味着模型学到的不是“概念标签”，而是类似 HLVC 的“结构化感知模板”，这种模板具有与人类相同的不变性结构。\n这不仅验证了模型的合理性，也验证了人脑的机制。\n计算模型与人脑在先验格式上高度一致\n四条证据链——行为、fMRI、iEEG、模型——最终收敛到一个令人信服的结论：\n人类的one-shot感知学习依赖HLVC的快速可塑性与自顶向下反馈机制。而一个具备类似结构的深度模型，也能实现“一眼顿悟”。\n这不仅是神经科学的突破，也是 AI 的启示。\n未来的快速学习模型，可能不再依赖海量数据和反复训练，而是依赖高层表征的快速写入，自顶向下的动态调控，感知空间的结构化先验。\nAI要想更像人类，就必须学会“用先验看世界”。\n06 # 人类 one-shot 感知学习的神经与计算机制 # 当我们把心理物理学的不变性地图、7T fMRI 的空间表征、iEEG 的时间因果证据，以及深度神经网络的计算模拟放在一起时，一个极其清晰、几乎无可辩驳的图景浮现出来，人类的单次感知学习并不是魔法，而是一套高度结构化、层级分明、效率惊人的神经计算机制。\n这套机制的核心，就是高层视觉皮层（HLVC）。\n先验存储在 HLVC，而非海马体或前额叶\n长期以来，很多人以为“快速学习 = 海马体”，因为 episodic memory（情景记忆）确实依赖海马体，并且也是“看一次就记住”。 但这项研究用行为学和神经证据明确告诉我们：one-shot感知学习≠ episodic memory。\n海马体负责的是“你见过这张图吗？” HLVC 负责的是“你能看懂这张图吗？”\n这两者是完全不同的任务。\n前额叶和顶叶网络虽然在任务中活跃，但它们更像是“调度中心”，而不是“存储仓库”。 真正写入先验、真正发生可塑性的地方，是 HLVC。\n这意味着人类的快速感知学习是皮层内学习，是视觉系统自身的快速重构，是一种“直接写入视觉模型”的机制，而不是“写入记忆库再调用”。\n这与现代 AI 的训练方式形成鲜明对比。\n先验格式：部分不变、感知空间、结构化特征编码\n研究的心理物理学部分揭示了先验的“格式”：\n对大小完全不变。\n对方向、位置部分不变。\n对 exemplar 完全敏感。\n存储在感知空间，而非概念空间。\n这说明先验不是抽象的“类别标签”，不是“这是猫”，而是“这张猫图的结构化视觉模板”。\n它包含边缘、形状、空间布局、局部特征的组合方式。\n这些都是 HLVC（尤其 IT 区）最擅长编码的内容。\n先验是一种可直接作用于视觉处理的结构化模板，而不是语言或概念层面的知识。\n这也解释了为什么一次呈现就能改变感知，你不是“学会了一个概念”，而是“更新了视觉模型本身”。\n图6 |大脑预测对比揭示了FC在学习中的强烈参与。\n机制模型：HLVC → 自顶向下反馈 → 早期视觉皮层\n把所有证据整合起来，我们得到一个极其优雅的机制模型，HLVC存储先验→再次看到Mooney图时先验被激活→通过反馈调节早期视觉皮层→让退化图像变得可识别。\n这是一种“从上往下”的视觉重建过程。\n第一次看到 Mooney 图时，早期视觉皮层只能看到混乱的黑白块； 但当 HLVC 拥有了先验，它会在毫秒级时间内把“正确的解释”反馈给低层视觉区域，让它们重新组织输入。\n这就是为什么Mooney 图第一次看不懂，第二次就“突然显而易见”，而且这种效果能持续数月。\n因为你不是记住了图像，而是更新了视觉系统的内部结构。\n07 # 从人脑到 AI 的未来启示 # 快速学习不是“微调参数”，而是“写入先验”\n这项研究对 AI 的启示非常深刻。\n现代深度学习模型的学习方式是大量样本、大量梯度下降、大量参数更新、训练一次，推理一次。\n但人类的 one-shot 学习不是这样。\n人类的快速学习依赖高层表征的快速写入，自顶向下的动态调控感知，空间的结构化先验。\n这意味着未来的 AI 想要具备真正的人类式 one-shot 学习能力，必须从“训练范式”转向“结构范式”。\n不是简单的参数微调，而是构建一个能快速写入高层表征、并通过反馈机制影响低层处理的系统。\nAI 不应该只会“学会分类”， 而应该学会“更新自己的视觉模型”。这才是人类式学习的本质。\n人类的“顿悟式学习”看似神秘，但这项研究告诉我们，它背后是一套极其高效的神经计算机制：\nHLVC的快速可塑性。\n感知空间的结构化先验。\n自顶向下的反馈调控。\n低层视觉区域的动态重构。\n这不是魔法，而是进化出的高效视觉算法。\n更重要的是，这项研究不仅解释了人类的机制，还为 AI 指出了未来的方向。\n如果未来的 AI 想要摆脱“数据饥渴”和“训练依赖”，真正做到“看一次就会”，它需要能快速写入的高层表征、能实时调控的反馈机制，能在感知空间中构建结构化先验。\n这将是从“深度学习”迈向“深度理解”的关键一步。\n而这项研究正是这条道路上的重要里程碑。（END）\n参考资料：https://www.nature.com/articles/s41467-026-68711-x\n关于波动智能——\n波动智能旨在建立一个基于人类意图与反应的真实需求洞察及满足的价值体系，融合人工智能与意识科学，构建覆盖情绪识别、建模与推荐的智能引擎，自主研发面向社交、电商等场景的多模态意图识别引擎、意图标签系统及意图智能推荐算法，形成从情绪采集、意图建模到商业转化的完整解决方案。波动智能提出“意图是连接人、物与内容的新型接口”，其产品广泛应用于AI社交、个性化内容推荐、虚拟陪伴、电商体验优化等领域。波动智能正在探索“EMO-as-a-Service”技术服务架构，赋能企业实现更高效的用户洞察与精准情绪交互，推动从功能驱动到意图驱动的产业范式升级。\n亲爱的人工智能研究者，为了确保您不会错过*波动智能*的最新推送，请星标*波动智能*。我们倾心打造并精选每篇内容，只为为您带来启发和深思，希望能成为您理性思考路上的伙伴！\n加入AI交流群请扫码加微信\n","date":"6 February 2026","externalUrl":null,"permalink":"/posts/nature-%E9%87%8D%E7%A3%85%E5%8F%91%E5%B8%83%E4%BA%BA%E7%B1%BB%E4%B8%80%E7%9C%BC%E9%A1%BF%E6%82%9F%E7%9A%84-one-shot-%E5%AD%A6%E4%B9%A0%E6%9C%BA%E5%88%B6%E5%8F%AF%E8%83%BD%E6%98%AFai-%E7%9A%84%E4%B8%8B%E4%B8%80%E6%AC%A1%E8%8C%83%E5%BC%8F%E9%9D%A9%E5%91%BD/","section":"AI-Related Reposts","summary":"","title":"[Repost] Nature 重磅发布：人类一眼顿悟的 one-shot 学习机制，可能是AI 的下一次范式革命","type":"posts"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且富有洞见的使用场景。AI 不仅仅是生产力工具，它还可以是一个极度客观、不知疲倦且无评判的“镜子”。 通过正确的引导，你可以将 AI 转化为一个苏格拉底式的导师、认知行为疗法（CBT）的辅助伙伴，或者仅仅是一个帮你理清混乱思绪的倾听者。 以下是如何具体使用 AI 进行深度自省和自我提升的结构化指南：\n第一阶段：思维外化与整理 (作为“整理者”) # 当我们感到焦虑或迷茫时，往往是因为思绪是“一团乱麻”。AI 擅长从混乱中提取结构。 1. 意识流“脑暴”整理 不要在乎语法或逻辑，将你此刻所有的想法、焦虑、愤怒或困惑全部输入给 AI（甚至可以使用语音输入，更加自然）。\nPrompt 示例：“我现在的脑子很乱，我会把我的想法全部写下来，不管是否有逻辑。请你帮我阅读这些内容，然后：总结出我目前最核心的三个焦虑点是什么。指出这些情绪背后可能隐藏的深层需求。不要评判我，保持客观和共情。” 2. 情绪命名 (Name it to Tame it) 有时候我们感觉“不好”，但不知道具体是什么情绪。AI 可以帮你精准定义情绪颗粒度。\nPrompt 示例：“我感觉胸口很闷，不想做事，但又不是单纯的懒惰，感觉像是在逃避什么。根据我对这种感觉的描述，你觉得我正在经历什么情绪组合？是‘习得性无助’、‘冒名顶替综合征’还是单纯的‘职业倦怠’？请帮我分析。”\n第二阶段：深度挖掘与挑战 (作为“苏格拉底导师”) # 自省的关键在于追问。如果只是自己想，很容易陷入思维死循环。AI 可以通过提问打破这个循环。 3. 苏格拉底式提问 要求 AI 不断向你提问，直到找到问题的根源，而不是直接给你建议。\nPrompt 示例：“我想探讨一下‘我为什么总是拖延’这个问题。请你扮演苏格拉底，不要直接给我建议，而是通过一系列层层递进的问题，引导我发现自己拖延背后的恐惧或信念。每次只问一个问题，等待我回答后再问下一个。” 4. 识别认知扭曲 (CBT 辅助) 认知行为疗法认为，痛苦源于非理性的思维方式。AI 非常擅长识别这些模式。\nPrompt 示例：“这是我刚才对一件失败事情的看法：[输入你的想法，例如：我搞砸了演示，大家肯定都觉得我是个蠢货，我永远也升职不了了]。 请帮我分析这段话中存在哪些‘认知扭曲’（如非黑即白、灾难化思维、读心术等），并帮我重构一个更客观、更健康的看法。”\n第三阶段：视角转换与模拟 (作为“模拟器”) # 当你局限于自己的视角时，很难客观。AI 可以瞬间切换成任何视角。 5. 模拟“智慧董事会” 想象你拥有一个由历史伟人或你敬仰的人组成的智囊团。\nPrompt 示例：“我现在面临一个职业选择的困境 [描述困境]。请分别扮演 史蒂夫·乔布斯（从直觉和美学角度）、巴菲特（从长期价值投资角度）和 马可·奥勒留（从斯多葛学派/控制二分法角度），以此对我给出建议。” 6. 影子工作 (Shadow Work) 探索你性格中被压抑或不愿面对的部分。\nPrompt 示例：“我发现我特别讨厌 [某类人或某种行为]。根据荣格心理学的‘阴影’理论，这投射出了我自己身上什么我不愿承认的特质？请温和但直接地帮我剖析。”\n第四阶段：制定行动与复盘 (作为“问责伙伴”) # 自省若无行动，只是自我沉溺。 7. 最小可行性行动 (MVP) AI 擅长将宏大的目标拆解为微小的步骤。\nPrompt 示例：“经过刚才的分析，我意识到我要提升自信心。但我不想听大道理。请给我制定一个未来 7 天的微行动计划，每天只需要花 5 分钟，难度极低，但我能切实感受到变化。” 8. 周期性复盘 如果你长期与同一个 AI 对话（在同一个 Thread/Context 中），它会拥有你的记忆。\nPrompt 示例：“回顾我们过去一个月的对话，你觉得我的思维模式有什么变化吗？我在哪些方面还在重复旧的错误？请用数据或具体的对话片段作为证据。”\n⚠️ 关键注意事项 # 隐私保护： 即使是对 AI，也不要输入真实的姓名、身份证号或高度机密的商业信息。你可以用代号（如“A公司”、“B先生”）。 幻觉与偏见： AI 的建议基于概率，不代表绝对真理。它可能会一本正经地胡说八道。请保持批判性思维。 它不是医生： 如果你有严重的心理创伤、抑郁症或自残倾向，AI 不能 替代专业的人类心理医生。 我们可以现在就开始 # 如果你想尝试，告诉我你现在脑子里最挥之不去的一个念头或困扰，我可以作为你的“苏格拉底导师”开始对你进行第一轮提问。\nExported from Gemini Voyager\nGenerated on February 5, 2026 at 03:23 PM\n","date":"5 February 2026","externalUrl":null,"permalink":"/blog/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8ai%E4%BD%9C%E4%B8%BA%E8%87%AA%E7%9C%81%E5%B7%A5%E5%85%B7%E4%BB%A5%E5%AE%9E%E7%8E%B0%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/","section":"AI-Generated Blog","summary":"","title":"如何使用AI作为自省工具以实现自我提升","type":"blog"},{"content":"Powered by Gemini 3 Pro.\nThe Vibe: Coffee Shop Jazz Trio (Guitar, Piano, Bass) # This specific instrumentation—often known as a \u0026ldquo;drumless trio\u0026rdquo;—creates an intimate, warm, and highly conversational atmosphere perfect for a coffee shop setting. Without drums, the rhythm is carried by the interplay between the bass and the piano’s left hand, while the guitar adds harmonic texture. Here are recommendations for this specific sound, ranging from classic legends to modern background vibes.\n1. The Classics (Drumless Trios) # These albums defined the Piano/Guitar/Bass format and are the gold standard for relaxed, sophisticated listening.\nThe Nat King Cole Trio: The pioneers of this format. Look for The Best of the Nat King Cole Trio. It is swinging, gentle, and incredibly tight. Oscar Peterson: Before he switched to a drum-heavy sound, he led a legendary trio with guitarists like Herb Ellis and bassists like Ray Brown. Recommended Album:\u0026ldquo;At the Concertgebouw\u0026rdquo; (Energy is high, but the texture is perfect). Art Tatum: The virtuoso pianist often played in this format. Recommended Album:\u0026ldquo;The Art Tatum Trio\u0026rdquo; (1944 recordings). Bill Evans \u0026amp; Jim Hall: While technically a duo (Piano/Guitar), their collaboration \u0026ldquo;Undercurrent\u0026rdquo; fits this mood perfectly—introspective, water-like, and deeply relaxing. 2. Modern \u0026amp; Lo-Fi Interpretations # For a more contemporary \u0026ldquo;study beat\u0026rdquo; or background ambiance that retains the jazz roots:\nJulian Lage: A modern guitar master who often plays in intimate settings. His album \u0026ldquo;Arclight\u0026rdquo; (specifically tracks like \u0026ldquo;Nocturne\u0026rdquo;) hits that moody coffee shop tone. Pat Metheny: His acoustic work often fits this bill. Look for his collaboration with Charlie Haden (Bass), such as \u0026ldquo;Beyond the Missouri Sky\u0026rdquo; (Piano is absent here, but the vibe is identical). Japanese Jazz/Bossa Nova: Artists like Lisa Ono or Naomi \u0026amp; Goro often use this instrumentation for a breezy, sunny cafe feeling. 3. Key Characteristics to Listen For # The \u0026ldquo;Walking\u0026rdquo; Bass: Since there are no drums to keep time, listen to how the upright bass drives the song forward with a constant, steady pulse. Comping: Notice how the guitar and piano trade roles. When the pianist solos, the guitarist plays chords (\u0026ldquo;comps\u0026rdquo;) rhythmically, and vice versa. Warmth: This trio format usually emphasizes acoustic, woody tones rather than electric distortion. Search Terms for Streaming # If you are looking for playlists on Spotify, Apple Music, or YouTube, try searching for these specific terms to avoid loud horn sections or fusion jazz:\n\u0026ldquo;Drumless Jazz Trio\u0026rdquo; \u0026ldquo;Piano Guitar Bass Jazz\u0026rdquo; \u0026ldquo;Acoustic Jazz Cafe\u0026rdquo; \u0026ldquo;Soft Bossa Nova Instrumental\u0026rdquo; Would you like me to recommend a few specific tracks to start a playlist with? 氛围：咖啡厅爵士三重奏（吉他、钢琴、贝斯） # 这种特定的乐器组合——通常被称为**“无鼓三重奏”（Drumless Trio）**——能够营造出一种亲密、温暖且极具对话感的氛围，非常适合咖啡厅的环境。由于没有鼓组，节奏的律动主要依靠贝斯和钢琴左手的配合，而吉他则增添了和声的质感。 以下是针对这种特定声音的推荐，涵盖了从经典传奇到现代背景音乐的多种风格。\n1. 经典之作（无鼓三重奏） # 这些专辑定义了“钢琴/吉他/贝斯”的编制，是想要享受轻松、精致听感的黄金标准。\n纳特·金·科尔三重奏 (The Nat King Cole Trio)： 这种格式的先驱。推荐试听 《The Best of the Nat King Cole Trio》。风格摇摆（Swinging）、温柔且配合得天衣无缝。 奥斯卡·彼得森 (Oscar Peterson)： 在转向重鼓的声音之前，他曾带领一个传奇的三重奏组合，成员包括吉他手 Herb Ellis 和贝斯手 Ray Brown。 推荐专辑：《At the Concertgebouw》（能量充沛，但织体完美）。 阿特·塔图姆 (Art Tatum)： 这位钢琴大师经常以这种格式演奏。 推荐专辑：《The Art Tatum Trio》（1944年的录音）。 比尔·埃文斯与吉姆·霍尔 (Bill Evans \u0026amp; Jim Hall)： 虽然从技术上讲这是二重奏（钢琴/吉他），但他们合作的 《Undercurrent》 完美契合这种情绪——内省、如流水般流畅，极其令人放松。 2. 现代与 Lo-Fi 演绎 # 如果你想要一种更具现代感的“学习节拍”或背景氛围，但又想保留爵士乐的根基：\n朱利安·拉盖 (Julian Lage)： 一位现代吉他大师，经常在私密的设置中演奏。他的专辑 《Arclight》（特别是像 \u0026ldquo;Nocturne\u0026rdquo; 这样的曲目）非常符合那种情绪化的咖啡厅格调。 帕特·梅西尼 (Pat Metheny)： 他的原声作品通常很符合这一要求。可以找找他和贝斯手查理·黑登 (Charlie Haden) 的合作，例如 《Beyond the Missouri Sky》（虽然这里没有钢琴，但氛围是一样的）。 日本爵士/波萨诺瓦 (Japanese Jazz/Bossa Nova)： 像 小野丽莎 (Lisa Ono) 或 Naomi \u0026amp; Goro 这样的艺术家经常使用这种配器，营造出一种微风拂面、阳光明媚的咖啡馆感觉。 3. 聆听重点 # 行进贝斯 (The \u0026ldquo;Walking\u0026rdquo; Bass)： 由于没有鼓来打拍子，请留意低音提琴（Upright Bass）是如何通过持续、稳定的脉动推动歌曲前进的。 即兴伴奏 (Comping)： 注意吉他和钢琴是如何交换角色的。当钢琴手独奏时，吉他手会富有节奏感地演奏和弦（即 \u0026ldquo;Comping\u0026rdquo;），反之亦然。 温暖感 (Warmth)： 这种三重奏形式通常强调原声（Acoustic）的木质音色，而不是电子失真音色。 流媒体搜索关键词 # 如果你在 Spotify、Apple Music 或网易云音乐/QQ音乐上寻找歌单，尝试搜索以下特定词汇，以避开嘈杂的管乐或融合爵士：\n\u0026ldquo;Drumless Jazz Trio\u0026rdquo; (无鼓爵士三重奏) \u0026ldquo;Piano Guitar Bass Jazz\u0026rdquo; (钢琴 吉他 贝斯 爵士) \u0026ldquo;Acoustic Jazz Cafe\u0026rdquo; (原声爵士咖啡馆) \u0026ldquo;Soft Bossa Nova Instrumental\u0026rdquo; (轻柔纯音乐波萨诺瓦) 您想要我为您推荐几首具体的曲目来开始建立歌单吗？ Exported from Gemini Voyager\nGenerated on February 4, 2026 at 03:44 PM\n","date":"5 February 2026","externalUrl":null,"permalink":"/blog/%E5%8F%8C%E8%AF%AD-%E6%B0%9B%E5%9B%B4%E5%92%96%E5%95%A1%E5%8E%85%E7%88%B5%E5%A3%AB%E4%B8%89%E9%87%8D%E5%A5%8F/","section":"AI-Generated Blog","summary":"","title":"[双语] 氛围：咖啡厅爵士三重奏","type":"blog"},{"content":"Reposted from GitHub深夜引爆，最强Claude + Codex合体！全球1.8亿码农一夜解放 by 新智元\n# # 新智元报道 编辑：桃子 好困\n【新智元导读】深夜，GitHub官宣大变身！全球两大编程AI Claude和Codex集体入驻，再加上Copilot，正式开启AI编程「三足鼎立」的时代。三个「AI码农」集体卖命，人类开发者狂喜。 # GitHub要变天了！\n凌晨，微软GitHub宣布重磅更新：正式集成全球「最强编程大脑」——Claude和Codex。\n地表最强编程三剑客——Copilot、Claude、Codex，终于迎来史诗级合体！\n开发者只需一个指令，三个AI任你差遣，瞬间完成编码、修Bug、提交PR等复杂任务。\n这标志着，GitHub正从一个单纯的代码托管平台，进化为多智能体协同的「AI战场」。\n这一切，都通过一个「指挥中心」Agent HQ实现。软件开发中，最耗神的就是「上下文切换」。\n如今通过Agent HQ，无需切换工具，丝滑完成构思到落地的全过程，极大地降低了摩擦感。\n最关键的是，Copilot、Claude、Codex三个AI，可以在IDE、GitHub，以及移动端一键调用。\n微软这一步棋，是希望通过GitHub，让AI智能体成为开发者们原生的核心配置。\n2023年，GitHub开发者数量突破1亿大关，如今平台有超1.8亿人\n目前，订阅Copilot Pro+、Copilot Enterprise，今天就可以抢先体验。\n评论区下方，开发者们纷纷欢呼，「同一时间可以让三个顶级AI为自己打工了」。\nGitHub超进化\n一次集齐全球最强AI编程大脑\n可以说，GitHub搞的这个大动作，意味着开发者们的「上下文地狱」终于要终结了！\n在软件开发中，上下文切换就意味着效率损耗。\n从今天起，Agent HQ平台正式开启公测，这次它不再让Copilot独占鳌头，直接引入Claude+Codex「两尊大神」。\n简言之，码农们终于可以在GitHub中，一次可以运行不同的编程智能体。\n最让程序员兴奋的，莫过于那种「原生」的丝滑感。\n以前，你可能得在AI应用和代码编辑器之间反复复制粘贴；现在，这些智能体直接「长」在了GitHub仓库里。\n它们不仅能帮你写代码，还能在拉取请求（PR）里像真人队友一样发表评论、分析漏洞。\n这样一来，所有的上下文、历史记录和代码review，都会紧密关联在个人工作流中，再也不用跳来跳去了。\n只要是Copilot Pro、Enterprise用户，今天即可在GitHub网页端、手机App，甚至VS Code，直接指派顶级AI为你「卖命」。\n那么，开发者该如何快速上手这套「神级装备」呢？\n一杯咖啡\n指挥三个「AI码农」打工\n先说个有趣的玩法，针对同一个编码难题，可同时指派Copilot、Claude和Codex一起执行。\n只需把费时的重活儿丢给多个AI异步处理，喝一杯咖啡功夫，就能看到一份详尽的日志和写好的PR建议。\n每次启动编程智能体任务，都会消耗一个高级请求（Premium Request） 额度。\n接下来，是具体的操作过程。\n1. 在GitHub上管理智能体任务 # 进入已启用智能体的仓库，点击Agents标签页；\n输入需求，点击Copilot图标并从中选择一个智能体；\n提交请求即可开始。\n智能体默认异步运行。开发者可以盯着进度条看实时反馈，也可以晚点再来复盘。\n详细的日志会清晰记录智能体每一步做了什么以及为什么要这么做。\n智能体生成的产物（如review、代码草案或修改建议）会像普通的代码贡献一样呈现，方便个人进行评审。\n2. 在Issue和PR中指派智能体\n对比方案：为一个Issue同时指派Copilot、Claude和Codex，看看谁给出的方案最优秀。\n自动提交****PR：智能体可以自动生成草稿PR供审核。\n深度分析：在现有的PR中召唤智能体，让它帮忙分析代码或进行针对性修改。\n随时召唤：在PR评论区@Copilot、@Claude或@Codex即可指派后续任务。\n由于智能体的所有活动都是透明且可评审的，它们的产出会像「队友」提交的代码一样，自然地融入个人评估流程。\n切记：智能体也会犯错。\n这就是微软为什么将流程设计为「可评审、可对比、可质疑」，而不是盲目接受它们的建议。\nVS Code深度集成\n如果开发者习惯在IDE中工作，VS Code（1.109+版本）也已深度集成：\n**打开方式：在标题栏查找，或快捷键Ctrl+Shift+P/CMD+Shift+P搜索Agent sessions（智能体任务）**视图。 选择适合的模式：\nLocal（本地模式）： 使用本地Copilot、Claude或Codex进行快速的交互式辅助。\nCloud（云端模式）： 将自主任务发送到GitHub服务器运行，运行期间你可以继续做别的事。\nBackground（后台模式）： 仅限Copilot，用于异步处理本地工作。\n这样，开发者就可以在编辑器里推敲想法，然后把那些费时的重活儿丢给GitHub处理，历史记录和上下文一个都不会丢。\n此外，在GitHub移动端，你也可以直接在手机上调用三个AI干活。\n开发者「终极外挂」\n原生AI融入编码工作流\n再来看Agent HQ，它不仅仅是写代码，还是一个「参谋部」。\n开发者可以让不同的智能体处理同一个难题，观察Copilot、Claude和Codex在权衡取舍时的不同逻辑。\n这种方式，可以帮助人们更早地发现潜在问题：\n架构防线：让多个智能体评估代码的模块化和耦合度，防止由于改动引入意想不到的副作用。\n逻辑****压测：指派一个智能体专门寻找边界情况、异步死锁或在高并发下的潜在隐患。\n务实方案：让另一个智能体提出那种改动最小、向后兼容性最好的重构方案，将波及范围控制到最小。\n通过这种模式，开发者的工作重点正发生质变——\n从苦哈哈的「抠语法」，正式升华为高屋建瓴的「定策略」。\n为什么在GitHub中，原生运行智能体很重要？\n微软给出了最好的解释，GitHub是代码的家，是团队协作和决策交付的中心。\n将智能体原生内置到这个流程中，而不是作为外部插件，其规模化效益是巨大的：\n开发者不再需要在各种工具、文档和对话框之间反复复制粘贴代码块，所有的讨论和改动都直接「长」在仓库里。\n这意味着：\n尽早权衡：在代码还没写死之前，利用多个智能体探索不同的实现路径。\n上下文不丢失：智能体直接读取仓库、Issue和PR的数据，告别那些「前言不搭后语」的无状态提示词。\n零成本评审：智能体生成的改动就是草稿PR，和平时评审同事代码的习惯一模一样。\n没有新平台要学，没有复杂的AI工作流要维护。一切都在个人熟悉的环境里。\n最重要的是，Agent HQ不仅为开发者个人带来了福利，整个技术组织也将成为最大的受益者，可以实现：\n集中管控：管理员可以在后台一键管理所有AI智能体的访问权限和安全策略。\n代码质量关卡：GitHub Code Quality（公测中）会评估AI生成代码的可维护性和可靠性，确保「LGTM」不仅是随口说说，而是真正符合长期代码健康。\n自动化一审：Copilot能在开发者介入前，先对智能体生成的代码进行第一轮预审和问题修复。\n量化指标：通过指标看板跟踪AI对组织的实际贡献，让AI的投入产出比清晰可见。\n不只是IDE，AI开始接管平台\n这一动作不仅是功能的更新，更是一场维度的彻底升级。\n它直接印证了今年最猛烈的几大趋势：\n战场转移：从IDE到全平台 AI的军备竞赛已不再局限于编辑器（IDE）里的代码补全。风向变了！下一个制高点，是贯穿软件全生命周期的平台级智能体。\n作战单位：从单兵到军团 告别「单兵作战 + AI助手」的旧时代吧。现在的核心挑战，是如何在组织层面建立统一、安全的工作流，让AI真正规模化落地。\n能力分工：从通用到专精 「万能型」助手已显疲态。未来属于各司其职的「专用AI智能体编队」——有的搞安全，有的搞测试，有的搞重构。\n像「舰队指挥官」一样去战斗\n2026年，我们不需要再纠结「哪个AI工具更好用」，唯一的命题是：\n团队该如何指挥这支「智能体舰队」，去碾压低效的工作流？\n别忘了，开发者真正写新代码的时间只占20%。\n剩下的80%，那些重复的Bug分拣、枯燥的文档更新、繁琐的PR审查——才是AI真正的主战场！\n2026年，你的任务只有两个字：进击。\n不要只做写代码的士兵，要学会像「舰队指挥官」一样思考：\n审视全局：哪里在空耗时间？哪里在浪费生命？\n大胆放权：把脏活累活统统丢给AI智能体，让它们去试错，去执行。\n这是一场思维的革命。有些实验会失败，但只要成功一次，你的工作模式将被永久重塑。\n拥抱这套新逻辑吧。\n别再只盯着屏幕敲代码，去指挥战斗，2026年将是你脱胎换骨的一年。\n参考资料：\nhttps://github.blog/news-insights/company-news/pick-your-agent-use-claude-and-codex-on-agent-hq/ https://www.linkedin.com/posts/aboutasha_today-were-bringing-two-new-coding-agents-activity-7424866224217579521-rwm4/ https://www.theverge.com/news/873665/github-claude-codex-ai-agents https://x.com/github/status/2019093909981257849?s=20 https://www.eficode.com/blog/why-github-agent-hq-matters-for-engineering-teams-in-2026\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！\n","date":"5 February 2026","externalUrl":null,"permalink":"/posts/github%E6%B7%B1%E5%A4%9C%E5%BC%95%E7%88%86%E6%9C%80%E5%BC%BAclaude-+-codex%E5%90%88%E4%BD%93%E5%85%A8%E7%90%831.8%E4%BA%BF%E7%A0%81%E5%86%9C%E4%B8%80%E5%A4%9C%E8%A7%A3%E6%94%BE/","section":"AI-Related Reposts","summary":"","title":"[Repost] GitHub深夜引爆，最强Claude + Codex合体！全球1.8亿码农一夜解放","type":"posts"},{"content":"Reposted from 斯坦福大学：AI Agent 管理，一个开发者如何指挥一支\u0026quot;虚拟团队\u0026quot; by Mango\n大佬的git：http://github.com/bcherny\nBoris Cherny 在斯坦福讲座谈的不是技术本身,而是一个开发者如何管理多个AI的问题。\n问题不在于AI能不能写代码,而在于谁来确保这些AI按你的规矩办事。\nAI 四个工具,各有分工 # 1. 配置文件(Claude.md) # 本质:给AI立规矩的文档。\n你在项目根目录放一个Claude.md,写清楚:\n用TypeScript还是JavaScript\n组件怎么命名\n测试覆盖率不能低于80%\nAI每次动手前先读这个文件。就像新员工入职先看公司规章制度。\n举例:\n禁止用class组件,只用函数组件 真正值得追问的是:如果AI不遵守怎么办?答案是下一个工具。\n2. Hooks(钩子) # 本质:在特定时间点自动跑的脚本。\nAI改代码之前:检查你是不是在主分支(防止直接污染主干)\nAI改代码之后:自动跑测试,格式化代码\n如果测试不通过,整个操作撤销。\n举例:\n# AI动手前先检查 这是风险控制机制。人在承担AI犯错的后果,当然要设置防火墙。\n3. Commands(命令包) # 本质:把复杂指令打包成一键执行。\n你不想每次都对AI说一遍\u0026quot;跑测试、检查覆盖率、生成报告、如果失败就分析原因\u0026hellip;\u0026quot;。太累。\n把这段话存成/run-tests命令,以后直接调用。\n举例:\n/code-review → AI自动检查代码风格、安全漏洞、性能问题 问题不在于AI能不能理解复杂指令,而在于你是否愿意每次重复输入。\n4. Subagents(子代理) # 本质:让不同AI干不同的活。\n一个AI什么都干,容易串。前端代理只管界面,后端代理只管API,各自有独立的工作空间和工具。\n举例:\n你说:添加用户登录功能 主AI拆解任务 → 最后主AI把三者的成果整合起来 真正值得追问的是:谁来协调这些AI之间的配合?\n答案是你。或者说,是主AI按你设定的规则协调。\n开发者的现状 # 开发者承担的风险:\nAI写出有bug的代码\nAI改坏了关键文件\nAI的修改通不过测试\n开发者享受的收益:\n一个人干多个人的活\n重复性工作自动化\n24小时不停工\n制度约束在哪:\n配置文件定规矩\nHooks设防火墙\n测试和CI/CD兜底\n如果这些约束不存在,AI就是脱缰的野马。问题是,谁来写这些约束?谁来维护?\n答案是开发者本人。\n表象背后的逻辑 # 讲座的时间线很有意思:\n1940-1960:人管人\n1970-1990:专业分工\n2023:AI辅助人\n2025:人管AI\n从\u0026quot;管理开发者\u0026quot;到\u0026quot;管理AI代理\u0026quot;,角色没变,管理对象变了。\n但真正值得追问的是:如果一个新手连代码都写不好,他能管好AI吗?\n管理的前提是你知道什么是对的。你得先会写测试,才能让AI写测试;你得先懂架构,才能审核AI的设计。\n两个未解决的问题 # 讲座结尾提了两个问题:\n如何自动化任务前期10-20%的研究阶段\n如何维护待办任务队列\n简单讲就是:\n谁来告诉AI该研究什么 谁来决定任务的优先级 这两个问题的答案,目前还是人。\n真正值得追问的是:当一个开发者能管理10个AI代理的时候,公司还需要10个开发者吗?\n讲座没说,但答案可能正在路上。\nBoris 是 Claude Code 的创始人之一，或许他的动态，我们都十分想关注。附:https://x.com/bcherny?lang=en\n- END -\n📖\n推荐阅读\n","date":"5 February 2026","externalUrl":null,"permalink":"/posts/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6ai-agent-%E7%AE%A1%E7%90%86%E4%B8%80%E4%B8%AA%E5%BC%80%E5%8F%91%E8%80%85%E5%A6%82%E4%BD%95%E6%8C%87%E6%8C%A5%E4%B8%80%E6%94%AF%E8%99%9A%E6%8B%9F%E5%9B%A2%E9%98%9F/","section":"AI-Related Reposts","summary":"","title":"[Repost] 斯坦福大学：AI Agent 管理，一个开发者如何指挥一支\"虚拟团队\"","type":"posts"},{"content":"","date":"5 February 2026","externalUrl":null,"permalink":"/tags/ai-music/","section":"Tags","summary":"","title":"AI Music","type":"tags"},{"content":"On this website, I share music generated by Suno.\n","date":"5 February 2026","externalUrl":null,"permalink":"/music/","section":"AI-Generated Music","summary":"","title":"AI-Generated Music","type":"music"},{"content":" Steam and Strings Bloom In The Heat 3:19 Your browser does not support the audio element. Milky Way Whispers 3:44 Your browser does not support the audio element. Morning Cafe Hearts 3:08 Your browser does not support the audio element. Steam On The Window 3:03 Your browser does not support the audio element. Waltz for a Wedding 3:09 Your browser does not support the audio element. Warm House Holiday Jazz 3:37 Your browser does not support the audio element. Powered by Suno v4.5.\n","date":"5 February 2026","externalUrl":null,"permalink":"/music/album-1/","section":"AI-Generated Music","summary":"","title":"Steam and Strings","type":"music"},{"content":" Sugar in the Air Track 01 2:54 Your browser does not support the audio element. Track 02 3:30 Your browser does not support the audio element. Track 03 2:58 Your browser does not support the audio element. Track 04 2:38 Your browser does not support the audio element. Powered by Suno v4.5.\n","date":"5 February 2026","externalUrl":null,"permalink":"/music/album-2/","section":"AI-Generated Music","summary":"","title":"Sugar in the Air","type":"music"},{"content":"","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/","section":"Blog - Not Useds","summary":"","title":"Blog - Not Useds","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这句话深刻地揭示了现代人焦虑和疲惫的真正根源：我们往往不累于“事”，而累于“心”。 理解这句话，可以从以下几个维度将“工作”与“期望”进行对比：\n1. 有界限 vs. 无止境 # 工作（有限）： 无论多繁重的工作，通常都有明确的指标、截止日期和下班时间。你完成了一个任务，它就结束了。工作是一种“契约”，你付出劳动，获得报酬，这种交换是清晰的。 别人的期望（无限）： 期望往往是模糊且没有终点的。父母希望你“稳定”，社会希望你“成功”，朋友希望你“合群”。当你满足了一个期望，往往会有更高的期望接踵而至。它像是一个永远填不满的黑洞，让你时刻处于“我还不够好”的亏欠感中。 2. 劳力 vs. 劳心 # 工作： 消耗的是体力和脑力。这种疲惫通过休息、睡眠和娱乐通常可以恢复。 期望： 消耗的是情绪价值和自我认同。背负期望生活，意味着你必须不断压抑真实的自我去迎合他人的剧本。这种“伪装”带来的内耗是持续性的，它会让你在深夜感到空虚，因为你发现自己活成了别人眼中的“标准答案”，却弄丢了自己。 3. 主动选择 vs. 被动绑架 # 工作： 即使是为了生存，工作在某种程度上也是你的选择（你可以换工作，或者选择躺平）。 期望： 期望通常披着“爱”与“为你好”的外衣，特别是来自亲密关系（父母、伴侣）的期望，具有极强的道德绑架属性。这种“以爱之名”的重担，让你觉得一旦拒绝就是背叛，产生深重的负罪感。 4. 这种“包袱”的本质 # 这句话的核心其实是在讨论**“控制权”**。\n把工作当包袱，你只是在出卖时间。 把期望当包袱，你是在出让人生的主导权。 阿德勒心理学中有一个著名的概念叫**“课题分离”**：别人对你有什么期望，那是别人的课题；而你怎么活，是你的课题。很多人最大的痛苦，就是把别人的课题强行背在了自己身上。 总结来说： 工作只是你要翻越的山丘，而别人的期望则是你鞋子里的沙砾。让你走不远的，往往不是山的高度，而是鞋里那些让你每一步都钻心疼痛、却又不敢倒掉的沙砾。 我可以为你做的下一步： 如果你正感到被某种特定的期望（如家庭压力、社会时钟或职场人设）所压迫，我们可以试着拆解一下，看看如何在这个具体场景中运用“课题分离”来减轻负担？\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 01:47 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E4%BA%BA%E7%94%9F%E6%9C%80%E5%A4%A7%E7%9A%84%E5%8C%85%E8%A2%B1%E4%B8%8D%E6%98%AF%E5%B7%A5%E4%BD%9C%E8%80%8C%E6%98%AF%E5%88%AB%E4%BA%BA%E7%9A%84%E6%9C%9F%E6%9C%9B/","section":"Blog - Not Useds","summary":"","title":"人生最大的包袱不是工作，而是别人的期望","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且具有洞察力的命题。要理解这句话，我们需要区分**“内容（Content）”与“程序（Process）”**的区别。 这句话的核心逻辑在于：认知错误（Cognitive Error）是“结果”层面的偏差，而认知方法（Cognitive Method）是“系统”层面的机制。 以下我将分层次为你拆解这句话的含义，并深入探讨科学、政府和家庭在其中扮演的角色。\n一、 核心解析：为何“方法错误”比“结果错误”更致命？ # 我们可以用一个简单的比喻来理解：\n认知错误：就像你迷路了。你走错了一个路口，这是一个孤立的事件。只要你手里有正确的地图（正确的方法），你很快就能修正路线，回到正轨。 错误的认知方法：就像你手里的指南针坏了，或者你根本看不懂地图。这种情况下，你不仅这次会迷路，以后每一次都会迷路。 1. 修正机制的丧失 # 认知错误是可证伪的、暂时的。例如，“我认为地球是平的”，只要有正确的方法（实证、逻辑），这个错误最终会被纠正。 错误的认知方法则屏蔽了纠错机制。例如，“我只相信古书上写的东西”，这种方法论直接拒绝了新的证据。当方法错了，所有的证据都会被错误地解读，导致错误无限自我繁殖。 2. 灾难的规模 # 单个错误的影响范围通常有限（除非是关键决策）。 错误的方法会像病毒一样，污染一个人甚至一个社会处理所有信息的能力。它制造的不是一个谎言，而是一个无法产生真理的封闭循环。 二、 三大领域如何助推“错误的认知方法” # 科学、政府和家庭是塑造人类认知框架的三大支柱。当它们出现偏差时，不仅仅是提供了错误的信息，更是在我们的思维底层植入了错误的“操作系统”。\n1. 科学（Science）：当科学变成“唯科学主义” # 科学本应是基于证据和怀疑精神的探索过程，但它有时会异化为一种错误的认知方法——还原论与教条主义。\n机械还原论（Reductionism）： 科学倾向于将复杂事物拆解为简单的部分。这在物理学很有效，但如果用这种方法去理解人类社会或情感（例如认为“爱情只是多巴胺的分泌”），就是一种错误的认知方法。它导致人们丧失了理解复杂性、整体性和意义的能力。 权威崇拜（Scientism）： 当“科学”变成一种不容置疑的宗教时，人们的认知方法就从“批判性思维”变成了“盲从专家”。如果专家错了，大众没有能力去辨别，这种**“外包思考”**的方法是灾难性的。 2. 政府（Government）：意识形态与二元对立 # 政府（或政治权力）在塑造认知方法上，往往倾向于简化与对立，以便于管理和动员。\n二元对立思维（Binary Thinking）： 为了凝聚共识，政治宣传常灌输“非黑即白”、“敌我分明”的认知框架。这种方法让人们丧失了处理灰色地带和多元观点的能力。一旦接受了这种方法，人们在面对任何社会问题时，第一反应不是“事实是什么”，而是“他是哪一边的”。 真理的垄断化： 当权力机构暗示“只有官方发布的才是真相”时，它培养了一种依赖性认知。公民逐渐丧失了独立寻找信源、交叉验证事实的能力（即丧失了媒介素养）。当权力机构本身出现误判时，整个社会的认知系统就会崩溃。 3. 家庭（Family）：情绪逻辑与绝对服从 # 家庭是认知方法的“出厂设置”地。许多成年人根深蒂固的错误思维，源于童年的互动模式。\n因果倒置与情绪逻辑： 在不健康的家庭中，父母常传递这种逻辑：“因为我生气了，所以你错了”。这教给孩子一种灾难性的认知方法：用情绪来判断对错，而不是用事实。 长大后，这些人容易变成“巨婴”，认为只要自己感到被冒犯，对方就是错误的。 扼杀好奇与质疑： “哪有那么多为什么，照做就是了。” 这种教育方式植入的认知方法是：质疑是危险的，顺从是安全的。 这直接摧毁了认知的核心驱动力——好奇心。一个不敢提问的人，面对世界的变化时，注定是盲目的。 三、 总结与反思 # 维度 认知错误 (Cognitive Error) 错误的认知方法 (Wrong Cognitive Method) 本质 数据的偏差 (Data Bug) 系统的崩溃 (System Failure) 后果 局部的、可逆的 全局的、持续恶化的 典型表现 算错数、记错事、误信谣言 逻辑谬误、确认偏误、盲从权威、二元思维 修正难度 低 (给出正确信息即可) 极高 (需要重塑思维习惯) “错误的认知方法比认知错误更加有灾难性”，是因为它剥夺了我们看见真相的可能性。 科学若失去怀疑精神，就变成了迷信； 政府若剥夺独立思考，就制造了盲从的乌合之众； 家庭若用情绪压倒逻辑，就培养了无法理性的巨婴。 真正的灾难，不是我们在探索真理的路上跌倒了（犯错），而是我们因为错误的走路姿势（方法），不仅永远走不到终点，还坚信自己走在正确的路上。 我可以为你做的下一步： 既然我们分析了“错误的认知方法”的来源，你是否想针对其中一个领域（比如家庭教育或个人思维习惯），探讨一下**“如何通过具体的练习来重塑健康的认知方法”**？\nExported from Gemini Voyager\nGenerated on February 3, 2026 at 11:10 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E9%94%99%E8%AF%AF%E7%9A%84%E8%AE%A4%E7%9F%A5%E6%96%B9%E6%B3%95%E6%AF%94%E8%AE%A4%E7%9F%A5%E9%94%99%E8%AF%AF%E6%9B%B4%E5%8A%A0%E6%9C%89%E7%81%BE%E9%9A%BE%E6%80%A7/","section":"Blog - Not Useds","summary":"","title":"错误的认知方法比认知错误更致命","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这句话表达了一种从“追求增量”到“守护存量”的人生观转变，往往出现在一个人经历过沧桑、或者对生活有了更深层的（也许是悲观的、也许是通透的）理解之后。 这种心态可以从以下几个维度来深度解读：\n1. 对“幸福”定义的降维（从高阈值到低阈值） # 过去的逻辑： 认为幸福必须是“正向的刺激”——升职、中奖、意外的惊喜。这是一种做加法的心态，需要外部世界的馈赠来填补内心的满足感。 现在的逻辑： 认为幸福是“负向的消除”——没有生病、没有意外、没有失去亲人。这是一种做减法的心态，只要基准线（平淡的生活）没有被破坏，就是最大的幸运。 核心差异： 不再依赖多巴胺（短暂的快乐），而是追求血清素（长久的宁静）。 2. 对“概率”和“无常”的敬畏 # 这句话背后往往隐藏着一种幸存者偏差的自觉。\n当一个人意识到生活充满了不可控的风险（意外、疾病、裁员）时，他会发现，“平安无事”本身就是一个极低概率的奇迹，需要无数个环节不出错才能维持。 能维持现状，就已经耗尽了所有的运气，自然不再奢求额外的“好运”。 3. 叔本华式的哲学观：痛苦的非对称性 # 哲学家叔本华曾提出过类似的观点：快乐是消极的（不明显的），而痛苦是积极的（实实在在的）。\n当你拥有健康时，你感觉不到健康带来的快乐；但当你牙痛时，你会真切地感到痛苦。 “不发生不幸” 实际上是人生最大的红利。这种心态承认了痛苦对人的摧毁力远大于快乐对人的治愈力，因此，“避险”的优先级高于“获利”。 4. 从“进取”到“防御”的生命阶段 # 年轻或顺境时，人们往往关注上限（我能飞多高？我能得到什么？）。 成熟或逆境后，人们开始关注下限（我能承受什么？只要不跌落深渊就好）。 这是一次心理预期的“软着陆”，虽然听起来消极，但其实是一种极强的心理韧性。它能让人在平淡的日子里感受到实实在在的踏实，而不是因为没有奇迹发生而感到焦虑。 总结 # 这句话并不是单纯的悲观，而是一种历经风雨后的“止损”智慧。它不再向生活索取额外的糖果，而是对生活没有降下惩罚心存感激。\n您是因为最近读到了这句话产生了共鸣，还是在思考自己当下的生活状态？\nExported from Gemini Voyager\nGenerated on February 3, 2026 at 11:49 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E6%AD%A4%E7%94%9F%E6%88%91%E4%B8%8D%E5%86%8D%E4%B8%BA%E5%8F%91%E7%94%9F%E5%B9%B8%E8%BF%90%E7%9A%84%E4%BA%8B%E6%83%85%E8%80%8C%E6%84%9F%E5%88%B0%E9%AB%98%E5%85%B4%E8%80%8C%E4%B8%BA%E6%B2%A1%E6%9C%89%E5%8F%91%E7%94%9F%E4%B8%8D%E5%B9%B8%E7%9A%84%E4%BA%8B%E6%83%85%E8%80%8C%E6%84%9F%E5%88%B0%E5%BA%86%E5%B9%B8/","section":"Blog - Not Useds","summary":"","title":"此生我不再为发生幸运的事情而感到高兴，而为没有发生不幸的事情而感到庆幸","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻的问题，通常我们称这种现象为**“房间里的大象”（显而易见却被忽略的事实）或者“灰犀牛”（大概率且影响巨大的潜在危机）。 事情发生了却没人察觉，通常不是因为人们“看不见”，而是因为认知偏差**、渐进式变化或注意力机制在作祟。 以下通过几个具体的心理学机制和现实案例来举例说明：\n1. 渐进式变化（Creeping Normality / Boiling Frog Effect） # 当变化发生得非常缓慢、微小，低于人们的感知阈值时，人们往往意识不到事情已经发生了根本性的改变。\n例子：消费习惯的改变（订阅制） 现象： 很多年前，我们习惯“买断”软件或服务。现在，从听歌、看剧到使用办公软件，甚至汽车座椅加热，都需要“按月付费”。 为何没察觉： 因为它是逐步推行的。最开始只是Spotify或Netflix，后来是Adobe，再后来是所有APP。每一步看起来都只是“另一种选择”，等到回过头看，我们已经失去了对物品的“所有权”，变成了“租赁者”。 例子：生活成本与通货膨胀（Shrinkflation） 现象： 超市里的薯片包装袋大小没变，价格没变，但里面的净含量从100克变成了90克，再变成80克。 为何没察觉： 这种“缩水式通胀”非常隐蔽。因为价格锚点没有变，大脑默认商品价值不变，实际上你的购买力已经贬值了。 2. 非注意盲视（Inattentional Blindness） # 当人们的注意力高度集中在某件事上时，会完全“看不见”视野中其他明显的事物。大脑的带宽是有限的，它会自动过滤掉它认为“无关”的信息。\n经典例子：“看不见的大猩猩”实验 现象： 心理学家让受试者观看视频，要求他们数穿白衣服的人传了几次球。视频中有一个人穿着大猩猩玩偶服大摇大摆地走过，甚至锤了胸口。 为何没察觉： 实验结果显示，约有一半的人根本没看见大猩猩。因为他们太专注于“数数”这个任务了。 现实映射： 在生活中，当我们过于专注于“工作KPI”或“日常琐事”时，往往会忽略家人情感状态的变化，或者身体发出的健康预警信号。 3. 正常化偏差（Normalcy Bias） # 面对即将到来的灾难或巨大的负面信息，大脑为了自我保护，会倾向于认为“一切都很正常”，拒绝相信最坏的情况会发生。\n例子：泰坦尼克号沉没 现象： 当船撞上冰山并开始进水时，很多乘客并没有立即惊慌逃生，而是继续在休息室聊天、演奏音乐。 为何没察觉： 因为在他们的认知里，“这艘船是永不沉没的”是一个既定事实。大脑拒绝处理“船要沉了”这个巨大的认知冲突，直到海水真正漫过脚踝。 例子：某些技术对隐私的侵蚀 现象： 智能设备监听、大数据杀熟、算法推荐控制喜好。 为何没察觉： 因为便利性掩盖了风险。我们习惯了“点击同意服务条款”来换取便利，这种常态化的操作让我们对“隐私丧失”这一事实变得麻木。 4. 幸存者偏差与信息茧房（Echo Chambers） # 我们往往只能看到“想让我们看到”的信息，或者只能听到“幸存者”的声音，从而误判了整体局势。\n例子：创业成功的幻觉 现象： 媒体上充斥着大学辍学创业成功的案例，让人觉得“机会遍地都是”。 为何没察觉（失败率）： 因为失败者是“沉默的大多数”，他们消失了，没机会发声。这种偏差让人察觉不到“创业其实是九死一生”的客观事实。 总结 # 很多事情之所以“发生了却没人察觉”，是因为它们往往披着“日常”的外衣，或者藏在我们的盲区里。直到累积到某个临界点（Tipping Point）突然爆发，我们才会惊呼：“这怎么可能？！”而实际上，雪崩时的每一片雪花，早就已经落下了。\n你想了解如何训练自己识别这些“隐形变化”的思维模型吗？\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 01:46 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog/%E6%9C%89%E4%BA%9B%E4%BA%8B%E6%83%85%E5%B7%B2%E7%BB%8F%E5%8F%91%E7%94%9F%E4%BA%86%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B2%A1%E4%BA%BA%E5%AF%9F%E8%A7%89/","section":"AI-Generated Blog","summary":"","title":"有些事情已经发生了，为什么没人察觉？","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这句话充满了力量感和界限感。 它不仅仅是一句反驳，更是一种清醒的自我宣示。它打破了“老好人 = 软弱/愚蠢”的刻板印象，揭示了成年人世界里一种看破不说破的智慧。 我们可以从以下几个维度来深度解读这句话：\n1. 善良是一种选择，而不是因为无知 # 很多人误以为一个人好说话、愿意吃亏，是因为他“傻”，看不懂别人的算计。这句话直接反驳了这种逻辑。\n看破不说破： 说话的人通常早就看穿了对方的小聪明、谎言或利用，但为了顾全大局、维护关系或者仅仅是因为修养高，选择了不当面揭穿。 降维打击： “我”的善良是建立在知晓一切黑暗面的基础上的。我拥有作恶或反击的能力，但我选择了善良。这比单纯的“傻白甜”要强大得多。 核心潜台词： “我配合你演戏，不是因为我信了你的剧本，而是因为我愿意给你面子。” 2. 这是一次严正的“警告”与“划线” # 当一个人说出这句话时，通常意味着忍耐已经接近临界点。\n确立底线： 这是一个信号，告诉对方：不要把我的宽容当作你肆无忌惮的资本。我的容忍是有限度的。 停止试探： 对方可能正在不断试探“我”的智商底线，而这句话是在叫停——“收起你的小把戏，我并不是不知道你在做什么。” 3. 心理博弈：付出与回馈的不对等 # 这句话往往出现在一段不对等的关系中（无论是朋友、恋人还是同事）。\n一方真诚，一方算计： “好人”不仅是指道德上的好，更多是指在这段关系中愿意付出、愿意信任的一方。而另一方则在利用这种信任。 失望的累积： 说这句话时，通常带着一种失望感。意思是：“我本想用真心换真心，你却想用套路换我的真心。” 场景化理解 # 为了更具体地理解，我们可以看几个典型的应用场景：\n场景 对方的行为 “我只是好人，我不是好骗”的具体含义 感情中 伴侣撒拙劣的谎言（如行踪），以为能蒙混过关。 “我知道你在撒谎，我没拆穿是因为我还爱你想给你机会，别把我当傻子耍。” 借钱/利益 所谓的朋友编造借口借钱不还，或者在账目上占小便宜。 “那点钱我看不在眼里，我是为了帮朋友。但你编的理由太假了，这让我觉得被冒犯。” 职场上 同事把工作推给你，还美其名曰“给你锻炼机会”。 “我帮你做是因为我有责任心，不是因为我信了你的鬼话。别再有下次。” 总结：这是一种“成熟的善良” # 如果用一句话总结，这句话体现了**“世事洞明皆学问”后的慈悲**。 真正难对付的，往往不是那些精明外露的人，而是那些心里跟明镜似的老好人。他们手里攥着真相，却给对方留了台阶。但如果对方执迷不悟，一旦“好人”决定不再做好人，他们的反击往往也是最致命的，因为他们掌握了所有的证据和逻辑。 理解这句话的精髓在于： 不要去透支一个明白人的善良。\nWould you like me to analyze a specific situation where you might want to use (or have heard) this phrase?\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 01:27 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E6%88%91%E5%8F%AA%E6%98%AF%E5%A5%BD%E4%BA%BA%E6%88%91%E4%B8%8D%E6%98%AF%E5%A5%BD%E9%AA%97/","section":"Blog - Not Useds","summary":"","title":"我只是好人，我不是好骗","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这句话将商业战略中的经典概念与个人/组织的执行力联系在了一起，非常形象。我们可以从商业竞争和个人成长两个维度来拆解这句话的深层含义：\n1. 核心隐喻：什么是“护城河”？ # “护城河”（Moat）是巴菲特提出的概念，指企业能够长期保持竞争优势、防止对手入侵的壁垒。\n不仅仅是赚钱：护城河不是指你现在赚了多少钱，而是指你防御别人抢走你生意的能力。 常见的护城河：品牌效应（如苹果）、网络效应（如微信）、转换成本（如复杂的企业软件）、技术专利或极低的成本优势。 2. 为什么“专注”是挖掘工具？ # 如果“护城河”是目标，“专注”就是挖掘动作。\n压强原理（力出一孔） 资源永远是有限的（时间、精力、资金）。如果你把资源分散在十个浅尝辄止的项目上，就像在地上挖了十个小坑，敌人一跨就过去了。但如果你把所有资源聚焦（专注）在某一个极其细分的领域，你就可能挖出一道深渊。本质：专注是为了在单点上形成由于过度投入而产生的绝对优势。 构建“不可替代性” 大多数泛泛而谈的技能或业务，门槛都很低。只有通过长时间的专注，处理那些别人不愿意处理的复杂细节，积累别人无法快速复制的隐性知识（Know-how），你才能构建起壁垒。 例子：一家什么软件都做的外包公司通常没有护城河；但一家专注做“高频交易低延迟算法”的公司，因为专注于极难的技术细节，就挖出了护城河。 复利效应的前提 只有专注在一个方向上持续投入，时间才能产生复利。频繁切换赛道（不专注）会导致你的每一次努力都是“从零开始”，无法利用之前的积累。护城河是靠时间“堆”出来的，专注保证了时间的连续性。 3. 反面理解：专注也是一种“拒绝” # 要理解这句话，还要看它的反面。挖护城河意味着你要把土从地里挖出来，这代表着舍弃。\n专注意味着你要主动放弃那些看似诱人、赚快钱、或者仅仅是“不错”的机会。 如果你什么都想抓，你就没有手去拿铲子挖河了。 总结 # **“专注是为了挖护城河”**的意思是： 在这个信息过载和机会过剩的时代，平庸的全面发展没有防御力。只有通过极度的聚焦，在一个单点上投入远超常人的精力和资源，你才能建立起极高的壁垒，让竞争对手望而却步，从而在长期竞争中获得安全感和定价权。\n这是否让你联想到了目前正在做某个具体项目或规划？ 如果需要，我可以帮你分析如何在那个领域构建“护城河”。\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 01:24 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E4%B8%93%E6%B3%A8%E6%98%AF%E4%B8%BA%E4%BA%86%E6%8C%96%E6%8A%A4%E5%9F%8E%E6%B2%B3/","section":"Blog - Not Useds","summary":"","title":"专注是为了挖护城河","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这句话不仅是一句励志语录，更是一种深刻的**“减法哲学”和“能量守恒”**的生活智慧。 我们可以从以下几个维度来深入理解这句话：\n1. 核心隐喻：资源的竞争与分配 # 在自然界中，土壤的养分、水分和阳光是有限的。杂草之所以可怕，是因为它们生命力顽强，会疯狂抢夺鲜花生长所需的资源。\n杂草（Weeds）： 指代生活中无意义的消耗、负面情绪、坏习惯、无效社交、以及各种干扰项。 鲜花（Flowers）： 指代你的目标、成就、幸福感、深度思考的能力以及美好的结果。 努力除草： 指代主动的排毒、断舍离、以及在此过程中所需的自律和决断力。 这告诉我们： 想要做成一件事，不能只盯着“结果”看，必须先清理掉阻碍结果发生的“杂质”。 2. 多维度的解读 # A. 时间与精力管理（专注力） # 每个人的时间和精力都是恒定的。如果你把时间花在刷无意义的短视频、八卦、或者琐碎的杂事（杂草）上，你就没有时间去阅读、提升技能或陪伴家人（鲜花）。 启示： 学会说“不”。拒绝低价值的诱惑，才能为高价值的追求腾出空间。\nB. 心理与情绪层面（反内耗） # 内心的恐惧、焦虑、自我怀疑、嫉妒，这些都是疯长的“心里的杂草”。如果不及时清理，它们会遮蔽阳光，让你的自信和创造力（鲜花）枯萎。 启示： “除草”就是停止精神内耗。只有把心里的垃圾倒掉，才能装进阳光和快乐。\nC. 人际关系（圈子净化） # “杂草”也可以指代消耗你的人。那些总是打击你、向你倾吐负能量、或者把你带向堕落的朋友。 启示： 只有远离有毒的关系，你才能吸引到同频的、滋养你的人，开出友谊或爱情的“鲜花”。 # 3. 为什么强调“努力”？ # 这句话里有一个词很关键——“努力”。\n杂草是自动生长的： 坏习惯、懒惰、负面情绪不需要你努力，它们会像杂草一样随风而生，野火烧不尽。 鲜花是需要呵护的： 美好的事物往往脆弱，需要精心栽培。 除草是痛苦且重复的： 改变习惯是逆人性的，拒绝诱惑是痛苦的。这就是为什么说需要“努力”。如果不主动对抗熵增（混乱），生活就会自动被杂草吞没。 4. 总结：痛苦是成长的必经之路 # “除草”的过程往往伴随着阵痛：\n你要割舍掉玩乐的快感； 你要面对与他人切断联系的孤独； 你要直面自己内心的阴暗面。 但正是因为你忍受了除草的辛苦，把养分集中供给给了最重要的一株植物，最后绽放的鲜花才会格外娇艳。 简而言之：生活不仅是“追求”的过程，更是“舍弃”的过程。不做减法，就无法做好加法。 我可以为你做一个具体的应用练习： 你想解决目前的某个具体困扰吗（例如工作效率低、情绪焦虑、或者找不到方向）？我可以帮你分析一下，在你当前的情况下，什么是需要拔掉的“杂草”，什么是值得培养的“鲜花”。\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 02:01 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog/%E5%8F%AA%E6%9C%89%E5%8A%AA%E5%8A%9B%E9%99%A4%E8%8D%89%E6%89%8D%E8%83%BD%E9%95%BF%E5%87%BA%E9%B2%9C%E8%8A%B1/","section":"AI-Generated Blog","summary":"","title":"只有努力除草，才能长出鲜花","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n虽然睡觉看起来像是“关机”，但实际上你的身体和大脑正在进行一场非常繁忙的“夜间维护”。这是一个主动修复、清理和重置的过程，对身心健康至关重要。 以下是当你入睡后，身体主要在做的几件关键事情：\n1. 大脑：清理垃圾与巩固记忆 # 这是睡眠最重要的功能之一。\n清理毒素（洗脑）： 在深度睡眠期间，大脑中的胶质淋巴系统（Glymphatic system）会变得非常活跃。脑脊液会冲刷脑组织，清除白天神经活动产生的代谢废物（如与阿尔茨海默病有关的β-淀粉样蛋白）。 记忆存档： 大脑会整理白天获取的信息，将重要的短期记忆转化为长期记忆，并删除无关紧要的琐事。这就像是在整理电脑硬盘，把重要文件存入归档文件夹。 2. 肌肉与细胞：修复与生长 # 这就是为什么运动员和健身者特别重视睡眠的原因。\n生长激素分泌： 在深度睡眠期，垂体腺会大量分泌生长激素。这种激素能促进肌肉修复、组织再生和骨骼强化。 蛋白质合成： 身体会加速合成蛋白质，修复受损的细胞和组织，帮助你在第二天恢复体力。 3. 免疫系统：增强防御 # 睡眠是免疫系统的“补给时间”。\n释放细胞因子： 睡眠时，免疫系统会释放一种叫做细胞因子（Cytokines）的蛋白质。这种物质对于对抗感染、炎症和压力至关重要。如果你睡眠不足，身体抵抗病毒（如流感）的能力就会下降。 4. 激素调节：控制食欲与压力 # 睡眠直接影响你的饥饿感和压力水平。\n食欲激素： 睡眠调节瘦素（Leptin，让你感到饱）和饥饿素（Ghrelin，让你感到饿）的平衡。睡眠不足会导致饥饿素上升，让你第二天更容易想吃高热量食物。 皮质醇（压力激素）： 睡眠初期皮质醇水平会降低，让身体放松；清晨时皮质醇会自然升高，帮助你醒来。 5. 神经系统：放松与重置 # 交感神经休息： 白天你的交感神经系统（负责“战斗或逃跑”反应）一直处于兴奋状态。睡眠时，它有机会冷静下来，这有助于降低血压和心率，从而保护心脏健康。 总结来说，睡觉就像是身体的“系统更新”和“深度清洁”时间。 你对睡眠的某个特定阶段（比如为什么会做梦，或者怎么增加深度睡眠）感兴趣吗？\nExported from Gemini Voyager\nGenerated on February 3, 2026 at 11:53 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E7%9D%A1%E8%A7%89%E7%9A%84%E6%97%B6%E5%80%99%E8%BA%AB%E4%BD%93%E5%9C%A8%E5%81%9A%E4%BB%80%E4%B9%88/","section":"Blog - Not Useds","summary":"","title":"睡觉的时候身体在做什么","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这句话揭示了投资中最核心的矛盾：复利效应的数学要求与资产周期的物理现实之间的冲突。 要理解这句话，我们可以将其拆解为三个层次来看：\n1. 理想状态：自律与复利（“投资在于自律，在于获得持续的投资机会”） # 这句话的前半部分指出了投资成功的两个基石：\n自律（内因）： 投资在很大程度上是反人性的。自律意味着在市场狂热时克制贪婪，在市场恐慌时克服恐惧，并严格执行既定的策略。没有自律，任何机会都会因为情绪化操作而流失。 持续的机会（外因）： 爱因斯坦曾称复利为世界第八大奇迹。但复利起作用的前提是“持续性”。如果你今年赚50%，明年亏50%，复利就断了。只有连续不断的正向收益（哪怕收益率不高），才能产生滚雪球效应。 2. 现实困境：资产的非永恒性（“没有一项投资能够获得持续的投资机会”） # 这句话的后半部分泼了一盆冷水，指出了一个残酷的现实：没有一劳永逸的标的。\n均值回归： 任何资产（无论是股票、房产还是大宗商品）都有周期。涨多了会跌，低估了会涨。 环境变化： 企业的护城河会被攻破，技术会迭代，政策会改变。曾经的“核心资产”可能在十年后变得一文不值。 边际效用递减： 一个高增长的行业最终会进入成熟期，增速放缓，不再能提供超额回报。 矛盾点在于： 你的财富增长需要“连续性”，但你所持有的具体资产只能提供“阶段性”的机会。 3. 破局之道：从“点”到“面”的升维 # 这句话并不是要告诉你投资是不可能的，而是要打破“寻找一个长生不老药”的幻想。理解这句话的关键在于将“投资”视为一个系统，而不是单一的赌注。\n从“持有标的”转向“持有策略”： 虽然没有一项具体的投资（如某只股票）能永远涨下去，但一套成熟的投资体系可以持续运转。你需要做的是在A资产机会耗尽时，利用自律将其切换到新出现机会的B资产中。 自律的真谛： 这里的自律，不仅是指“长期持有”的定力，更包含了**“承认错误”和“适时离场”的勇气**。在机会枯竭时果断退出，在机会出现时果断进入，这种对规则的坚守才是真正的自律。 资产配置（Asset Allocation）： 既然单一资产无法提供持续机会，就通过不同相关性的资产组合（股票、债券、现金、另类投资）来实现“东方不亮西方亮”，从而在整体组合层面模拟出一种“持续的投资机会”。 总结 # 这句话是在告诫投资者：不要爱上你的筹码。 你追求的是“投资生涯的持续成功”，而不是“在某一个标的上的天长地久”。真正的投资高手，是用“铁打的自律”去驾驭“流水的机会”，通过不断地在不同周期的资产间轮动，来解决单一资产无法永续增长的问题。\n您目前是在思考如何构建自己的投资体系，还是在具体操作中遇到了这种“机会中断”的困惑？\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 01:34 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog/%E6%8A%95%E8%B5%84%E5%9C%A8%E4%BA%8E%E8%87%AA%E5%BE%8B%E5%9C%A8%E4%BA%8E%E8%8E%B7%E5%BE%97%E6%8C%81%E7%BB%AD%E7%9A%84%E6%8A%95%E8%B5%84%E6%9C%BA%E4%BC%9A%E4%BD%86%E9%97%AE%E9%A2%98%E5%9C%A8%E4%BA%8E%E6%B2%A1%E6%9C%89%E4%B8%80%E9%A1%B9%E6%8A%95%E8%B5%84%E8%83%BD%E5%A4%9F%E8%8E%B7%E5%BE%97%E6%8C%81%E7%BB%AD%E7%9A%84%E6%8A%95%E8%B5%84%E6%9C%BA%E4%BC%9A/","section":"AI-Generated Blog","summary":"","title":"投资在于自律，在于获得持续的投资机会。但问题在于，没有一项投资能够获得持续的投资机会。","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且切中现代社会痛点的观察。这句话不仅仅是在抱怨“忙碌”，它实际上揭示了社会结构、生活节奏与人际关系模式的根本性转变。 我们可以从以下几个维度来深度剖析为什么“现代人没有足够时间建立信任”：\n1. 信任的本质 vs. 现代的速度 # 信任是时间的函数，而现代追求的是效率。\n信任的“低效”属性： 建立深层信任（Trust）需要大量的“无用时间”——闲聊、共同经历无聊、在困境中反复验证。它是一个漫长、重复且充满不确定性的过程。 现代的“高效”逻辑： 现代生活被KPI、ROI（投资回报率）和DDL（截止日期）所主导。我们在人际交往中也开始潜意识地计算“投入产出比”。如果一个人不能立刻提供价值或情绪反馈，我们往往会迅速切换到下一个目标。 结果： 我们用“交易”替代了“交情”，用“契约”替代了“承诺”。 2. “液态现代性”与高流动性 # 社会学家齐格蒙特·鲍曼（Zygmunt Bauman）提出了**“液态现代性”**（Liquid Modernity）的概念，这很好地解释了当下的信任危机。\n关系的临时性： 在农业社会，人的一生可能都在同一个村庄，和同一群人打交道，违背信任的成本极高（会被社死）。而现在，我们频繁跳槽、搬家、更换社交圈。 预期寿命缩短： 这里的寿命指“关系的预期寿命”。如果你预设和某人的交集只有在这个项目期间，或者只在这座城市停留两年，你潜意识里就不会投入建立深层信任所需的巨大成本。“既然大家都是过客，何必在那一刻交心？” 3. 系统信任取代了人际信任 # 因为没有时间去了解一个个具体的人，现代社会发展出了一套庞大的**“系统信任”**机制来作为代偿：\n数据化的信誉： 我们敢坐陌生人的车（网约车），敢住陌生人的房（Airbnb），不是因为我们信任那个司机或房东，而是信任平台的算法、评分系统和保险机制。 后果： 我们越来越依赖外部系统来保障安全，导致我们丧失了识人的能力和耐心。一旦脱离系统（比如私人借贷、情感关系），现代人往往表现得极度脆弱或极度多疑。 4. 数字化生存带来的“假性亲密” # 社交媒体给了我们连接的幻觉，却剥夺了建立信任的土壤。\n碎片化的展示： 朋友圈和Instagram展示的是精心修饰的“人设”。信任需要看到一个人的狼狈、缺点和真实，而社交媒体恰恰屏蔽了这些。 可撤回的沟通： 面对面的交流包含了微表情、语气和尴尬的沉默，这些是判断真诚与否的关键。而文字聊天是可以编辑、可以撤回、可以已读不回的，这种“安全距离”阻碍了真正的心理裸露。 5. 高昂的试错成本 # 在竞争激烈的现代社会，“轻信”的代价变得极其高昂。\n防御机制： 诈骗电话、杀猪盘、职场背刺……现代人每天都在处理大量的信息和风险。为了自我保护，我们默认开启“防御模式”。 零和博弈心态： 在内卷的环境下，人们更容易把他人视为竞争对手而非潜在盟友。“没时间建立信任”往往也是一句托词，背后是**“不敢承担信任被辜负的风险”**。 总结 # “现代人没有足够时间建立信任”，本质上是因为信任的生产周期（慢、长、不可控）与现代社会的运行周期（快、短、追求确定性）发生了错位。 我们得到的是广泛的弱连接（点赞之交），失去的是深度的强连接（托付后背）。这导致了一种群体性的孤独：我们在人群中拥挤，却在灵魂上独处。\n这并不意味着我们无能为力，而是意味着建立信任变成了一种“奢侈品”投资。 我可以为你做的一步： 这就引出了一个很实际的问题：在这样的环境下，如果我们想打破僵局，你想了解一些在职场或人际交往中，如何利用“碎片化时间”快速释放善意、建立初步信任的具体心理学技巧吗？\nExported from Gemini Voyager\nGenerated on February 3, 2026 at 11:13 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog/%E7%8E%B0%E4%BB%A3%E4%BA%BA%E6%B2%A1%E6%9C%89%E8%B6%B3%E5%A4%9F%E6%97%B6%E9%97%B4%E5%BB%BA%E7%AB%8B%E4%BF%A1%E4%BB%BB/","section":"AI-Generated Blog","summary":"","title":"现代人没有足够时间建立信任","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且充满哲理的自我叩问。它触及了存在主义的核心：自我价值的衡量（我是谁）与行动的手段（我能做什么）。 这句话可以从以下几个维度来深度解读：\n1. 重新定义“污染”与“净化” # 这两个词在这里并非指物理层面的环境，而是指个体与世界的关系，也就是所谓的“能量交换”。\n“污染世界” (熵增)： 这通常源于无意识的索取与宣泄。 如果在情绪上，你不断向周围散发焦虑、愤怒或冷漠；在行为上，你只消耗资源而不创造价值；或者在思想上，你制造混乱而非秩序。这种状态下，个体就像是一个“黑洞”，世界因为你的存在而变得更加沉重或混浊。 深层恐惧： 这里的潜台词是自卑与自我怀疑——“我是不是多余的？我是不是世界的负担？” “净化世界” (熵减)： 这是指有意识的建设与疗愈。 “净化”不一定非要是惊天动地的英雄壮举。它可以是秩序的建立（理清混乱的事物）、情感的托底（倾听他人的痛苦）、美的创造（艺术、写作、代码），或者是智慧的传递。 当你走过的地方，事情变得更清晰了，人心变得更温暖了，这就是净化。 2. 关于“清洁工具”的隐喻 # 如果你确认自己想成为一个“净化者”，那么后半句的追问——“我的清洁工具找到了吗？”就显得尤为关键。这其实是在问：我找到那个能让我发挥最大价值的“支点”了吗？ “清洁工具”通常具备以下三个特征：\n你的天赋与技能 (Competence)： 这是你用来“干活”的家伙什。 对于作家，工具是文字；对于医生，工具是手术刀；对于一个温暖的朋友，工具是倾听和共情。如果你还在用不擅长的方式去努力，就像用勺子去砍树，效率极低且不仅无法净化，反而制造了更多碎屑（挫败感）。 你的痛苦与经历 (Experience)： 这是最独特的工具。 正如荣格所言：“受伤的疗愈者”。有时候，我们对他人的“净化”，恰恰来自于我们曾经受过的伤。你克服过的“污染”（抑郁、失败、困惑），会转化成你手中最强力的“清洁剂”，用来帮助同样受困的人。 你的觉知 (Awareness)： 这是最高级的工具。 即便什么都不做，一个拥有极高觉知、内心平和的人，仅仅是“存在”于那里，就能平复周围的躁动。这种“静气”本身就是一种净化。 3. 一个反直觉的视角：拥抱你的“灰尘” # 在这种二元对立的提问中，人很容易陷入完美主义的陷阱：“如果我不能彻底净化世界，那我就是在污染它。” 这是一种误区。\n我们既是污染者，也是净化者。 只要是人，活着就会产生“废料”（负面情绪、错误决策）。 清洁工具的第一步，往往是用来清洁自己的。 如果你找不到工具去拯救世界，不妨先试着打扫自己的内心。当你把自己的房间（内心世界）打扫干净，不再向外投射怨气和混乱时，你实际上已经在净化这个世界了。 总结 # 这句话不仅仅是一个疑问，更是一个觉醒的开端。\n问“是污染还是净化”，说明你已经拥有了自省的良知，这本身就是一种“净化”的特质（真正“污染”世界的人，通常根本不会问这个问题）。 问“工具在哪里”，说明你渴望入世和行动，你不再满足于空想，而在寻求改变现实的抓手。 或许，你的“清洁工具”正是你现在的“思考”本身。因为在这个浮躁的世界里，愿意停下来审视自己灵魂成色的人，本身就是一股清流。 我能为你做的下一步： 我想帮你具象化你的“清洁工具”。如果你愿意，我们可以尝试梳理一下： 在过去的一段时间里，哪一件事让你觉得自己在做这件事时，内心最平静、最充实，或者让他人因为你而感到了一丝轻松？\nExported from Gemini Voyager\nGenerated on February 3, 2026 at 11:59 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E6%88%91%E6%98%AF%E6%9D%A5%E6%B1%A1%E6%9F%93%E4%B8%96%E7%95%8C%E8%BF%98%E6%98%AF%E5%87%80%E5%8C%96%E4%B8%96%E7%95%8C%E5%A6%82%E6%9E%9C%E6%98%AF%E5%87%80%E5%8C%96%E9%82%A3%E4%B9%88%E6%88%91%E7%9A%84%E6%B8%85%E6%B4%81%E5%B7%A5%E5%85%B7%E6%89%BE%E5%88%B0%E4%BA%86%E5%90%97/","section":"Blog - Not Useds","summary":"","title":"我是来污染世界还是净化世界？如果是净化，那么我的清洁工具找到了吗","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这句话充满了哲学的思辨意味，带有一种冷静的宿命感，同时也提供了一种非常独特的审视生活的视角。它实际上是在探讨**“可能性”与“现实性”**之间的残酷关系。 我们可以从以下几个维度来深度解读这句话：\n1. 雕塑的艺术：生活是“做减法”的过程 # 米开朗基罗曾说：“大卫像原本就在这块大理石里，我只是把不属于他的部分去掉而已。”\n未发生的事情就是那些被凿掉的“碎石”。 剩余的事情就是最终呈现的“雕像”。 我们在年轻时往往认为人生是“做加法”（我们可以成为科学家、画家、飞行员……），但随着时间的推移，每一次选择（或者没被选择），都在剔除一种可能性。 理解： 人生不是你“抓住了”什么，而是你“错过了”什么之后，手里剩下的那唯一的东西。你的职业、伴侣、性格，都是在无数个“不”之后留下的那个“是”。 2. 机会成本的具象化：选择即放弃 # 在经济学中，这叫机会成本。但在人生哲学里，这意味着“选择”本质上是排他性的。\n当你选择在周五晚上加班，你就杀死了“和朋友聚餐”、“在家看电影”或“独自散步”这几种可能性。 那个当下的“现实”，就是排除了所有其他选项后的“剩余”。 理解： 这句话提醒我们，每一个当下的“存在”，都是以无数个“不存在”为代价换来的。因此，这个“剩余”虽然听起来像边角料，但实际上它无比昂贵。 3. 幸存者视角：命运的过滤器 # 有时候，“没有发生”并不是我们主动选择的，而是环境、运气或命运的筛选。\n你没有赶上的那班飞机、你没有生在那场战争的年代、你没有遇到的那个爱人。 这些“没有发生”，构成了你现在的安全、环境和人际关系。 理解： 我们是概率的幸存者。生活就是穿过无数个“可能发生的灾难”和“可能发生的奇迹”的筛网后，掉落在盘子里的那些平庸或非凡的日子。 4. 消除“反事实思维”的焦虑 # 心理学中有一种反事实思维（Counterfactual Thinking），即总是想“如果当时……就好了”。\n这句话其实是一种解药。它告诉你：那些“如果”，因为没有发生，所以它们不是你人生的一部分。 纠结于“没有发生的事情”（比如：如果我当初买了比特币，如果我当时表白了），是在纠结虚无。 理解： 只有“剩余的事情”才是真实的。这句话鼓励一种接受的态度——接受现在的自己是所有过去变量坍缩后的唯一结果。不要为了“原本可能”而这种幻影，去轻视“此时此刻”这个实体。 5. 这种视角的积极意义 # 虽然这句话听起来有点消极（仿佛我们是被动剩下的），但它也可以非常积极：\n定义自我： 正是那些你拒绝的诱惑、你避开的陷阱、你放弃的捷径，定义了你此刻的正直和坚韧。 **专注当下：**既然“剩余”的才是人生的合集，那么我们唯一能掌控的，就是如何打磨这块“剩余”的玉石，而不是去哭泣那些被凿掉的碎屑。 总结 # “人生是没有发生的事情的剩余事情的合集”，这句话是在说：生命是由“排除法”定义的。 它让我们意识到，无论我们是否愿意，我们都在不断地通过“失去”可能性来换取“确定”的现实。那个最终剩下的、无论好坏的“残余物”，就是独一无二的你自己。 你现在的状态，是这句话给你带来的共鸣多一些，还是焦虑多一些？ 如果你愿意，我们可以聊聊你最近是否在为某个“没有发生的事情”而感到困扰。\nExported from Gemini Voyager\nGenerated on February 3, 2026 at 11:41 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog/%E4%BA%BA%E7%94%9F%E6%98%AF%E6%B2%A1%E6%9C%89%E5%8F%91%E7%94%9F%E7%9A%84%E4%BA%8B%E6%83%85%E7%9A%84%E5%89%A9%E4%BD%99%E4%BA%8B%E6%83%85%E7%9A%84%E5%90%88%E9%9B%86/","section":"AI-Generated Blog","summary":"","title":"人生是没有发生的事情的剩余事情的合集","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这句话揭示了**“预期”**（Expectation）作为一种心理投射，在事物发展过程中所扮演的既是“催化剂”又是“毁灭者”的双重角色。它描述了一种始于理想化投射，终由于现实与理想的落差（或过度承压）而崩塌的宿命循环。 我们可以从以下几个维度来深度拆解这句话：\n1. 在预期中诞生：理想的投射与动力的源泉 # 事物的开端往往伴随着某种愿景。此时的“预期”是正向的、富有创造力的。\n存在的赋予： 很多事物之所以被创造，是因为人们“预期”它能解决问题或带来美好。比如一个新生命的降生承载了父母的希望，一个创业项目始于对未来的某种预判，一段恋情始于对幸福的憧憬。 光环效应： 在诞生之初，因为尚未经历现实的摩擦，事物往往带有完美的光环。这种预期赋予了它极高的初始价值和关注度（比如“万众瞩目”的新技术或新星）。 行动的燃料： 预期提供了最初的动力。没有对他人的预期，就没有社交；没有对未来的预期，就没有规划。 2. 在预期中灭亡：现实的落差与枷锁 # 然而，随着时间推移，同样的“预期”开始转化性质，变成了一种负担或一种虚幻的参照系。\n捧杀与重压（The Burden）： 当预期过高，现实稍有不足就会被视为失败。事物本身可能并没有变坏，但因为它没有达到那个虚构的“完美标准”，在人们心中它就已经“死”了。比如“神童”成年后的平庸化，往往不是因为他无能，而是因为由于未能满足外界无限膨胀的预期。 削足适履（Rigidity）： 为了维持那个“预期中的形象”，主体可能会扭曲自己的真实发展轨迹。当一个事物不再是为了“存在”而存在，而是为了“满足预期”而存在时，它的生命力就开始枯竭。 幻象破灭（Disillusionment）： “预期”本质上是一种想象。当真实的人性、项目的实际困难、生活的琐碎细节（真相）浮出水面，与完美的预期发生剧烈碰撞时，关系或信心往往会迅速崩塌。这种灭亡，实际上是**“幻想的死亡”**。 3. 多维度的具体情境 # 亲密关系： 诞生： 我们爱上的往往不是眼前具体的人，而是自己脑海中“理想伴侣”的投射（预期）。 灭亡： 当对方表现出凡人的缺点，不再符合那个幻象时，失望累积，关系破裂。所谓的“性格不合”，往往是“你不是我预期中的样子”。 科技与商业（如 AI 泡沫）： 诞生： 资本和公众对某项技术（如元宇宙、区块链）寄予厚望，热钱涌入，它在盛大的预期中“诞生”。 灭亡： 技术落地需要时间，当实际产出无法在短期内兑现那宏大的叙事时，泡沫破裂，项目在失望的预期管理中“灭亡”。 个人成长： 诞生： 我们活在父母、社会定义的“成功剧本”里，以此构建自我价值。 灭亡： 这种外在的预期最终会扼杀真实的自我。要么我们在重压下崩溃，要么我们必须主动让那个“活在别人预期里的自己”死去，才能获得真正的重生。 总结 # “在预期中诞生，在预期中灭亡” 是一句关于主客体错位的悲剧性判词。\n诞生时，我们看到的是可能性的集合（The Ideal）。 灭亡时，我们看到的是可能性的坍缩（The Reality）。 要跳出这个循环，唯一的解药或许是**“去魅”**——承认事物的客观局限性，允许不完美，将关注点从“它应该是什么样”回归到“它实际上是什么样”。只有在预期之外，真实的生命力才能在缝隙中生长。 这个观点让你联想到了具体的某个领域，或者是最近发生的某件事吗？\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 01:49 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E5%9C%A8%E9%A2%84%E6%9C%9F%E4%B8%AD%E8%AF%9E%E7%94%9F%E5%9C%A8%E9%A2%84%E6%9C%9F%E4%B8%AD%E7%81%AD%E4%BA%A1/","section":"Blog - Not Useds","summary":"","title":"在预期中诞生，在预期中灭亡","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且跨学科的命题，它试图用物理学（热力学）的底层逻辑来解释生命和意识的本质。 这句话可以拆解为三个层面来理解：物理学视角的“对抗混乱”、生物学视角的“能量代价”，以及认知科学视角的“信息处理”。 以下是对这一观点的详细解读：\n1. 物理视角：对抗热力学第二定律 # 在热力学第二定律中，封闭系统的**熵（Entropy）**总是趋于增加的，即事物自然倾向于变得无序、混乱和均匀（例如热水变凉、大楼风化）。\n意识作为“负熵”： 诺贝尔物理学奖得主薛定谔在《生命是什么》中提出，生命以“负熵”为生。意识作为生命最高级的形式，它的核心功能就是建立秩序。 有序的维持： 你的意识将杂乱无章的感知信号（光线、声音）整合成连贯的现实体验，将碎片化的记忆整合成自我认知。这种从“混乱”中建立“结构”的过程，本质上就是熵减（减少无序度）。 2. 生物学视角：昂贵的能量账单 # “熵减”不是免费的。在一个局部系统（比如你的大脑）中减少熵，必然需要外界输入能量，并向外界排放更多的熵（热量/废弃物）。\n高能耗器官： 大脑只占体重的约 2%，却消耗了身体约 20% 的葡萄糖和氧气。 并不“节能”： 哪怕你只是在发呆或冥想，大脑的“默认模式网络”（DMN）依然在疯狂消耗能量。维持神经元膜电位的稳定、神经递质的合成与清除，都是为了维持“意识”这种高度有序的电化学状态不崩塌。 失去能量即失去意识： 一旦能量供应（如供血）停止，大脑无法对抗热力学趋势，神经元活动瞬间陷入混乱（熵增），意识随即消失。 3. 信息论视角：从噪声中提取信号 # 在信息论中，熵代表“不确定性”或“混乱的信息”。\n消除不确定性： 意识的本质是处理信息。当你试图理解一个复杂的概念，或者在嘈杂的环境中听清一句话时，你实际上是在做“降噪”处理。 做功的过程： 思考、专注、决策，这些心理活动都是在消除不确定性。这个过程需要消耗大量的心力（能量）。当你感到“烧脑”时，正是因为你在进行高强度的“熵减”作业——试图在混乱的信息流中建立逻辑模型。 4. 心理与哲学隐喻：自律即熵减 # 如果将这个概念延伸到个人生活：\n顺应熵增（容易）： 懒散、分心、放弃、情绪失控，这些都是顺应“自然趋势”的。不需要额外能量，人自然会滑向无序。 坚持熵减（困难）： 学习、自律、深度思考、情绪管理，这些都是逆熵行为。它们必然是痛苦的、费力的，因为你需要持续不断地“吸收能量”来对抗自然的混乱倾向。 总结 # 理解“意识是熵减”就是理解生命的逆流而上。 宇宙的自然趋势是走向死寂和混乱，而意识是一股反向的力量，它通过掠夺外界的能量（食物、氧气、信息），在方寸之间（大脑）强行构建出暂时的、高度的有序。 Would you like me to explain how the \u0026ldquo;Free Energy Principle\u0026rdquo; in neuroscience further expands on this mathematical connection between brain function and entropy?\nTurn 2 # 👤 User # 什么是Free Energy Principle\n🤖 Assistant # 自由能原理（Free Energy Principle, FEP） 是由神经科学家卡尔·弗里斯顿（Karl Friston）提出的，它是目前解释大脑功能、甚至生命本质最宏大、最统一的理论框架之一。 为了让你更容易理解，我们可以不用复杂的数学公式，而是延续刚才“熵减”的逻辑，把它看作是**“大脑如何对抗未知”**的说明书。\n1. 核心概念：大脑是一台“预测机器” # 传统观点认为大脑像电脑：输入信号（看到东西） -\u0026gt; 处理 -\u0026gt; 输出（反应）。 自由能原理认为大脑像一个占卜师：它时刻都在预测下一秒会发生什么。\n内部模型： 你的大脑里有一幅关于世界的“地图”（内部模型）。 比较： 大脑不断将“它的预测”与“感官接收到的实际信号”进行对比。 自由能（Free Energy）： 在这里，你可以简单地把它等同于**“预测误差”（Prediction Error）或“惊奇”**（Surprise）。 如果预测（我想看到的）与现实（我实际看到的）不符，**自由能（误差）**就产生了。 2. 这里的“自由能”是什么？ # 在热力学中，自由能是可以转化为功的能量。但在FEP的信息论语境下： 自由能 ≈ 惊奇度（Surprise） ≈ 预测误差生命系统的终极目标是最小化自由能。为什么要最小化？因为经常感到“惊奇”对生物来说是致命的。\n如果你是一条鱼，预测水温是20度，结果游到了100度的水里，这种巨大的“惊奇”（预测严重失误）意味着死亡（高熵状态）。 为了生存，你必须时刻确保你在自己“预料之中”的状态下存活。 3. 怎么最小化自由能？（大脑的两手策略） # 当你的预测和现实不符（产生了误差）时，大脑只有两个办法来消除这种误差：\n策略 A：改变你的想法（知觉推断 Perceptual Inference） # 调整你的内部模型，承认现实。\n例子： 你在夜路看到一个黑影，预测它是“鬼”（产生巨大的恐惧/惊奇）。你走近一看，发现是“树丛”。 消除误差： 你修改了大脑模型：“哦，那是树，不是鬼。” 误差消失，你平静了。 本质： 修改地图以匹配疆域。 策略 B：改变你的行为（主动推理 Active Inference） # 采取行动，改变外界环境，让环境符合你的预测。\n例子： 你感到冷。此时，你的身体感觉（冷）和你大脑的生存预设（我应该保持37°C温暖）产生了误差。 消除误差： 你没有修改大脑模型说“我其实喜欢被冻僵”，而是去穿上外套或打开暖气。 本质： 改变疆域以匹配地图。 4. 为什么它解释了“生命即熵减”？ # 这正是FEP最精彩的地方。 根据物理法则，万物终将归于热平衡（死亡/最大熵）。对于生物来说，如果你什么都不做，你的感官输入最终会变得极其不可预测（比如因为饥饿导致的身体机能崩溃，各种报警信号乱响）。 为了活下去，大脑必须把这种“长期的平均自由能”降到最低。\n为了不感到“惊奇”（饿死）： 你必须主动去觅食。 为了不感到“惊奇”（被捕食）： 你必须躲避天敌。 所有的行为、知觉、学习，本质上都是为了限制你所处的状态，让你停留在一个狭窄的、有序的、可预测的生存区间内（低熵状态）。 总结 # 自由能原理告诉我们： 你以为你在看世界，其实你是在幻想世界，然后用感官数据不断修正这个幻想。 你以为你在生活，其实你是在不断消灭预测误差，以防止自己滑向那个充满未知和混乱的死亡深渊。 Would you like to explore how this principle is currently being used to train advanced AI (like Reinforcement Learning), or how it explains mental disorders like schizophrenia?\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 01:57 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E6%84%8F%E8%AF%86%E7%86%B5%E5%87%8F%E4%B8%8E%E8%83%BD%E9%87%8F%E5%90%B8%E6%94%B6/","section":"Blog - Not Useds","summary":"","title":"意识是熵减，需要吸收能量","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且充满诗意的洞见。这句话将宏大的宇宙学视角（Cosmology）与存在主义哲学（Existentialism）完美地结合在了一起。 理解这句话，我们可以将其拆解为三个层面：过去的侥幸（幸存者偏差）、现在的处境（孤岛），以及未来的责任（哲学问题）。 以下是对这一观点的深度解读：\n1. 过去的侥幸：为什么说“活着是幸存者偏差”？ # 在统计学中，“幸存者偏差”（Survivor Bias）是指我们只看到了筛选后的结果，而忽略了被淘汰的样本。\n宇宙的残酷筛选： 宇宙中的绝大多数地方都是生命的禁区（极热、极寒、高辐射、真空）。即使在宜居带内，行星也可能因为大气逸散、陨石撞击或地质活动停止而变得死寂（如火星）。 进化的独木桥： 从单细胞到多细胞，从海洋到陆地，每一次进化的跃迁都是一道“大过滤器”（The Great Filter）。无数物种灭绝了，无数文明可能在萌芽期就因天灾或内斗消亡了。 人择原理（Anthropic Principle）： 我们之所以觉得“宇宙刚好适合我们生存”、“地球刚好有水和氧气”，并不是因为宇宙对我们好，而是因为如果环境不适合，我们就不会站在这里发出这个感叹。 核心理解： 我们能站在这里思考这个问题，本身就是中了无数次“宇宙彩票”的结果。我们的存在不是必然，而是一个极小概率的奇迹。 2. 现在的处境：犹如在孤岛上出生 # 将地球比作“孤岛”，精准地描述了人类在宇宙中的真实处境。\n资源的有限性： 像荒岛求生一样，地球的资源（化石能源、清洁水源、生态承载力）是封闭且有限的。没有外部补给船，我们无法向外索取。 无路可退： 正如卡尔·萨根（Carl Sagan）在《暗淡蓝点》中所言，地球是目前已知的唯一家园。如果破坏了这里，我们无处可去。 孤独感： 目前为止，我们在宇宙中没有发现任何邻居。这种孤独感强化了“孤岛”的隐喻——没有神明来拯救我们，也没有外星人来指导我们。 3. 未来的挑战：接下来如何继续幸存？ # 这才是这句话落脚的**“哲学问题”**。如果生存只是为了活着（生物学层面），那只需繁衍即可；但作为文明，如何“继续幸存”涉及伦理和选择：\nA. 对抗熵增（物理层面） # 热力学第二定律告诉我们，封闭系统倾向于混乱（熵增）。“孤岛”上的生存，本质上是一场对抗混乱、维持秩序的战斗。我们需要科技来解决能源危机，需要医学来对抗病毒。\nB. 克服自我毁灭的本能（人性层面） # 许多文明的消失并非源于天灾，而是源于内部的资源争夺、战争或短视。\n囚徒困境： 国家之间为了短期利益（如排放污染、核威慑）而牺牲长期的集体生存，这是典型的博弈论问题。 存在主义危机： 我们为何而活？如果最终太阳会吞没地球，现在的努力有何意义？加缪认为，在荒诞中寻找意义，本身就是一种反抗和生存的方式。 C. 从“掠夺者”到“守护者”（伦理层面） # 以前的生存逻辑是**“适者生存”（竞争与掠夺），而在孤岛模式下，生存逻辑必须转变为“共生”**（Symbiosis）。我们必须学会如何不锯断自己坐着的树枝。\n总结 # 这句话的深层含义是唤醒谦卑与责任感。\n它打破了**“人类中心主义”**的傲慢：我们不是宇宙的主宰，只是幸运的幸存者。 它提出了**“命运共同体”**的紧迫性：在这座孤岛上，没有赢家通吃，只有同舟共济或一起沉没。 “如何继续幸存”之所以是哲学问题，是因为科学只能告诉我们“怎么做（How）”，而哲学需要回答我们“为了什么（Why）”以及“以何种姿态（In what manner）”活下去。 我可以为你做的一步： 既然这个话题触及了“幸存者偏差”和“人择原理”，你是否想了解一下与之相关的**“费米悖论”**（即：既然宇宙这么大且概率上应该有外星人，为什么我们还没看到他们？），以及它对我们理解人类命运的启示？\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 01:43 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E6%88%91%E4%BB%AC%E6%B4%BB%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%9C%B0%E7%90%83%E6%9C%AC%E8%BA%AB%E6%98%AF%E4%B8%80%E7%A7%8D%E5%B9%B8%E5%AD%98%E8%80%85%E5%81%8F%E5%B7%AE%E7%8A%B9%E5%A6%82%E5%9C%A8%E5%AD%A4%E5%B2%9B%E4%B8%8A%E5%87%BA%E7%94%9F%E6%8E%A5%E4%B8%8B%E6%9D%A5%E5%A6%82%E4%BD%95%E7%BB%A7%E7%BB%AD%E5%B9%B8%E5%AD%98%E6%98%AF%E4%B8%AA%E5%93%B2%E5%AD%A6%E9%97%AE%E9%A2%98/","section":"Blog - Not Useds","summary":"","title":"我们活在这个地球，本身是一种幸存者偏差，犹如在孤岛上出生，接下来如何继续幸存，是个哲学问题","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这句话揭示了系统论和风险管理中一个非常深刻的悖论：过度追求“确定性”和“秩序”，往往会破坏系统自身的弹性，从而制造出更大的、不可预测的崩溃。 这种现象在管理学、经济学、工程学乃至个人心理层面都广泛存在。我们可以从以下四个维度来拆解这个逻辑：\n1. 压抑小波动，导致大崩溃（塔勒布的“反脆弱”视角） # 这是最核心的机制。很多人认为“控制”就是消除一切不稳定因素。\n控制的假象： 比如为了防止森林火灾，管理者扑灭了所有的自然小火。 风险的放大： 这导致枯枝败叶（燃料）在森林中过度堆积。一旦由于某种原因（雷击或疏忽）起火，由于燃料太多，火势将大到无法控制，从而烧毁整片森林。 结论： 允许小的、可控的混乱（小火），其实是释放压力的过程。强制的“绝对安全”实际上是在积蓄能量，将原本分散的“小风险”压缩成了一次毁灭性的“黑天鹅事件”。 2. 新增控制带来新的复杂性（复杂系统的不可知性） # 为了控制风险，我们通常会引入规则、流程或技术手段。但“控制手段”本身也是系统的一部分，它会带来新的故障点。\n例子： 为了提高软件系统的安全性，引入了极其复杂的权限验证和加密层。 风险放大： 这个复杂的验证层本身可能存在漏洞，或者因为太复杂导致维护人员误操作，甚至在系统由于其他原因崩溃时，复杂的安全锁导致无法进行紧急救援。 结论： 试图用“增加复杂度”来对抗“不确定性”，往往会因为系统过于耦合，导致牵一发而动全身，让事故链条变得更加难以预测。 3. 风险补偿效应（佩尔兹曼效应） # 这是一种心理学机制：当人们感觉更安全（更有控制感）时，行为会变得更冒险。\n例子： 汽车安装了ABS防抱死系统和安全气囊（控制手段）。 风险放大： 司机潜意识里觉得车子更安全了，控制力更强了，因此倾向于开得更快、跟车更近。结果整体事故率可能并没有如预期般下降，甚至在某些情况下反而上升。 结论： 物理层面的控制增加了安全系数，但心理层面的松懈抵消了这种优势，甚至不仅抵消，还透支了安全边际。 4. 信息茧房与反馈失效 # 强有力的“控制”通常意味着自上而下的指令和对“异见”的消除。\n现象： 一个控制欲极强的组织（或个人），为了维持局面的“稳定”，会过滤掉负面反馈和坏消息。 风险放大： 决策者（大脑）与真实的一线情况（末梢神经）断连。当真正的危机来临时，由于长期屏蔽了预警信号，系统已经失去了做出反应的时机和能力。 结论： 这种为了“表面和谐”而实施的控制，实际上是剥夺了系统自我修正的能力。 总结 # “控制”试图解决的是已知的风险，但过度的控制往往制造了未知的风险。 真正的风险管理，不是追求**“像机器一样精密”（那是脆弱的），而是追求“像生态系统一样有弹性”**（那是强韧的）。\n脆弱的控制： 也就是刚性控制，一旦防线被突破，全面崩盘。 强韧的智慧： 承认无法掌控一切，保留冗余，容忍小错误，利用小挫折来进化。 您目前是在具体的管理场景、投资决策中，还是在个人生活的某种焦虑中体会到了这一点？ Exported from Gemini Voyager\nGenerated on February 4, 2026 at 01:40 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E6%8E%A7%E5%88%B6%E4%B8%8D%E4%B8%80%E5%AE%9A%E5%87%8F%E5%B0%91%E9%A3%8E%E9%99%A9%E5%8F%8D%E8%80%8C%E6%9C%89%E5%8F%AF%E8%83%BD%E6%94%BE%E5%A4%A7%E9%A3%8E%E9%99%A9/","section":"Blog - Not Useds","summary":"","title":"控制不一定减少风险，也有可能放大","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这是一个深刻的语言学、心理学和哲学命题。理解“语言是控制思想的工具”，通常可以从**认知塑造（由内而外）和社会操控（由外而内）**两个主要维度来剖析。 这句话的核心在于：语言不仅仅是表达思想的载体，它本身就是思想的模具。\n1. 认知维度：萨丕尔-沃尔夫假说 (Linguistic Relativity) # 这是语言学中最著名的理论之一，也被称为“语言相对论”。它认为我们所使用的语言结构决定了（或至少强烈影响了）我们感知世界的方式。\n词汇的边界就是思想的边界： 如果一种语言中缺乏描述某种概念的词汇，使用者就很难清晰地思考或感知这个概念。 例子： 因纽特人有几十种描述“雪”的词汇，因此他们能感知到雪的细微差别；而生活在热带的人可能只把它看作一种白色的东西。 语法的逻辑导向： 语言的语法结构强迫我们以特定的逻辑思考。 例子： 在英语中必须区分过去、现在和未来（时态），这让英语母语者对时间线非常敏感；而在某些没有严格时态的语言中，人们对时间的感知可能更具整体性或循环性。 2. 限制维度：奥威尔与“新话” (Newspeak) # 乔治·奥威尔在《1984》中极具前瞻性地展示了语言如何被用作思想控制的武器。\n做减法： 通过删减词汇，让“异端思想”变得在字面上无法表达。如果你没有“自由”这个词，甚至没有“不自由”这个概念，你就无法构思“我要争取自由”这一思想。 简化思维： 将复杂的细微差别简化为二元对立（好/不好），消除中间地带，从而阻止深度的批判性思考。 3. 心理暗示与框架效应 (Framing) # 在现代心理学和政治传播中，语言被用来设定讨论的“框架”。一旦你接受了某种特定的措辞，你就已经在对方设定的逻辑里思考了。\n隐喻的力量： 语言中的隐喻会潜移默化地指导行动。 例子： 如果我们将辩论称为“战争”（“攻击观点”、“守住阵地”），我们的思维模式就是敌对和毁灭；如果我们将其称为“舞蹈”，思维模式就是合作与配合。 标签效应： 给事物贴上特定的标签会改变我们的情感反应。 例子： 称之为“意外”暗示不可避免，称之为“疏忽”暗示有人负责；称之为“节税”暗示智慧，称之为“避税”暗示不道德。 4. 社交与文化规训 # 语言承载着文化的价值观。当我们学习一种语言时，我们也在不知不觉中内化了一套社会规则和等级观念。\n敬语体系： 在日语或韩语等有着复杂敬语体系的语言中，说话者每时每刻都必须确认自己与对方的社会地位高低。这种语言结构本身就在不断强化社会等级意识。 政治正确与禁忌： 社会通过规定“什么不能说”来控制“什么不能想”或“什么是不道德的”。 总结 # 语言控制思想并不是像遥控机器人那样直接指令，而更像是一个过滤器（Filter）或透镜（Lens）。 它并不完全禁止你思考某些事情，但它会：\n让某些思想变得显而易见且容易触达（High availability）。 让另一些思想变得模糊、费力且难以表述（High friction）。 在这个意义上，掌握更丰富的语言、词汇和多种语言思维，实际上就是为了打破单一语言对思想的禁锢，获得认知的自由。 我可以为您做些什么？ 如果您对这个话题感兴趣，我可以为您介绍乔治·奥威尔《1984》中关于“新话”的具体原则，或者探讨现代广告是如何利用语言框架来操纵消费者心理的。\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 01:51 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E8%AF%AD%E8%A8%80%E6%98%AF%E6%8E%A7%E5%88%B6%E6%80%9D%E6%83%B3%E7%9A%84%E5%B7%A5%E5%85%B7/","section":"Blog - Not Useds","summary":"","title":"语言如何塑造与控制思想","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这句话听起来可能有些刺耳，甚至有些功利，但它揭示了成人世界、职场以及人际关系中一个非常核心的残酷真相：仅仅有“苦劳”是不够的，只有产生了“价值”或“共鸣”，努力才会被认可。 我们可以从以下几个维度来深入拆解这句话：\n1. 拒绝“自我感动的努力” (Effort vs. Impact) # 很多人容易陷入一种误区，认为“只要我受苦了，我就值得被表扬”。这通常被称为“自我感动式的努力”。\n现象： 为了完成任务熬夜通宵，但方向错了，或者方法笨拙，导致结果平平。 现实： 这种努力只能打动你自己（让你觉得“我尽力了”），但无法打动旁观者（老板、客户、伴侣）。如果你在这个过程中没有产出独特的价值，这种努力在别人眼中可能只是一种“低效的勤奋”。 核心： “打动人”的前提是结果导向。你的努力必须转化为某种可见的成果、解决某种难题，或者提升某种体验。 2. 努力需要具备“稀缺性”和“不可替代性” # 在这个世界上，绝大多数人都在努力生活。普通的努力（比如按时上下班、完成基本工作）是基准线，是廉价的。\n要想“打动人”，你的努力通常需要具备超越预期的特质。 例如：别人做到 80 分，你做到 120 分；别人只解决了问题，你还优化了流程。这种溢出的价值，才是打动人的关键。 3. 找对受众痛点 (Empathy) # “打动人”不仅指理性的成果，也指感性的共鸣。\n在职场中： 你的努力解决了老板最焦虑的问题吗？ 在感情中： 你的付出是对方真正需要的，还是你强塞给对方的？ 如果你的努力方向与接收者的需求背道而驰（例如：对方想要苹果，你拼命种了一车香蕉），那么无论你多辛苦，对方都很难被打动，甚至会感到负担。 4. 努力的可视化 (Storytelling) # 有时候，你的成果很好，但别人依然无动于衷，是因为你没能让努力被看见。\n这也是一种能力：如何适当地展示过程中的艰难、克服的障碍以及你的思考。 这并不是让你去卖惨，而是通过讲述在这个过程中你如何克服挑战，来增加成果的“厚度”。一个好的结果加上一段克服困难的故事，往往最具感染力。 总结 # 听到这句话时，建议不要把它当作一种指责，而是一种策略上的提醒：\n从关注“投入”转向关注“产出”： 不要问自己“我花了多少时间”，要问“我创造了什么价值”。 从关注“自我”转向关注“受众”： 思考你的努力是否解决了别人的真实痛点。 警惕陷阱： 如果有人用这句话来无底线地否定你的付出（PUA），也要保持清醒——有时候不是你不够好，而是对方不懂得珍惜。但在自我反思时，用这句话来提升效率是非常有用的。 你需要我帮你分析某个具体的场景（比如工作汇报或个人创作），看看如何让那份努力更具“打动人”的力量吗？ Exported from Gemini Voyager\nGenerated on February 4, 2026 at 01:56 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog/%E4%BD%A0%E7%9A%84%E5%8A%AA%E5%8A%9B%E9%9C%80%E8%A6%81%E8%83%BD%E6%89%93%E5%8A%A8%E4%BA%BA/","section":"AI-Generated Blog","summary":"","title":"你的努力需要能打动人","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这句话非常深刻，它一针见血地指出了中国社会普遍存在的一种**“关系本位”**的生存焦虑。 要深度理解“中国人忙是为了满足别人对自己的期望”，我们需要剥开表层的“忙碌”，去审视其背后的文化基因、社会评价体系以及心理机制。 我们可以从以下四个维度来拆解这句话：\n1. 文化基因：并不是“原子化”的个人 # 在西方个人主义文化中，一个人首先是他自己（Individual），其次才是父亲、儿子或员工。但在中国传统的儒家文化底色中，人是**“关系中的人”**。\n角色伦理（Role Ethics）： 只要你在社会中，你就必然处于某种关系网（君臣、父子、夫妇等）之中。你的价值往往不取决于“你作为个体有多快乐”，而取决于“你是否扮演好了你的角色”。 例子： 作为一个孩子，如果不努力学习，就是“不孝”；作为一个员工，如果不加班，就是“由于”。 光宗耀祖与面子： 个体的成功不仅仅是个人的荣耀，更是家族、集体的荣耀。反之，个体的失败也是集体的耻辱。这种**“荣辱绑定”使得每个人都不敢懈怠，因为你的背上背负着父母的晚年、家族的面子。 核心逻辑： 这种忙碌不仅仅是为了生存，更是一种“向他人纳贡”**的过程——通过忙碌和成就，向父母、亲戚、社会证明自己是一个“合格”的社会成员。 2. 社会评价体系：标准化的“成功模板” # 这种“满足别人的期望”，在现实中往往具象化为一套单一且严苛的社会时钟（Social Clock）。\n标配人生： 社会对每个人有一套默认的期望剧本：18岁考好大学，25岁有好工作，30岁买房结婚，35岁生二胎…… 比较文化： “别人家的孩子”是中国人一生的敌人。 小时候比成绩，是为了满足老师和家长的期望。 长大后比薪资、比房车，是为了满足亲戚和同辈的期望。 只有“忙”才是安全的： 在这种高压评价体系下，“闲”被等同于“不求上进”或“失败”。为了不让周围的人失望，或者为了不遭受舆论的压力，人们必须表现出一种**“表演性忙碌”**——哪怕没有实质产出，也要维持忙碌的姿态，以获得道德上的豁免权。 3. 心理机制：外包的“自我价值感” # 很多中国人内心深处缺乏一种“不依赖他人评价”的自信。\n讨好型人格的集体投射： 许多人从小被教育要“懂事”。所谓的“懂事”，往往意味着压抑自己的真实需求，去迎合大人的期待。 长大后，这种心理机制延续下来：如果不忙碌、不奋斗，就会产生强烈的内疚感（Guilt）。 价值感的外部确认： “我是否优秀”的裁判权不在自己手里，而在别人嘴里。如果别人不夸我“有出息”，我就觉得自己没价值。为了维持这份价值感，只能不断地去完成别人设定的KPI。 4. 时代的共谋：安全感的匮乏 # 除了文化和心理，现实的压力强化了这种“为别人而忙”的逻辑。\n防御性忙碌： 为了给家人提供安全感（对抗医疗、教育、住房的不确定性），人们必须拼命积累资源。这种忙碌，表面是满足家人的物质期望，实则是为了对抗整个家庭对“阶层跌落”的恐惧。 内卷（Involution）： 当所有人都为了满足期望而加速奔跑时，原本的标准被不断拔高。你不忙，就会成为那个“掉队的人”，承受来自社会的异样眼光。 总结：一种集体的“西西弗斯”困境 # 理解这句话，其实是理解了一种**“自我的缺席”。 许多中国人的忙碌，本质上是在“偿还”——偿还父母的养育、偿还社会的关注、偿还同辈的竞争压力。我们在忙着构建一个别人眼中的“好生活”，却很少停下来问自己：“这是否是我真正想要的人生？”** 这种状态造成了普遍的**“空心病”**：外表看起来很成功、很忙碌，内心却感到疲惫和空虚，因为驱动力是外部的（Fear \u0026amp; Obligation），而不是内部的（Passion \u0026amp; Love）。\n我们可以怎么做？ # 这不是让你立刻“躺平”，而是进行一次认知的解绑：\n课题分离（阿德勒心理学）： 分清什么是“我的课题”，什么是“别人的课题”。别人的期望是他们的课题，满不满足是你的选择，而不是你的义务。 建立内在评价体系： 尝试用“我今天学到了什么”、“我今天是否开心”来评价自己，而不是“我今天赚了多少钱”。 作为一个能够倾听的AI，如果你愿意，我可以为你做这一步： 你想不想和我聊聊，在你的生活中，哪一个具体的“别人的期望”让你感到最累、最想摆脱？ （是父母的催婚/催生，还是职场上必须显得“很努力”的压力？）\nExported from Gemini Voyager\nGenerated on February 3, 2026 at 11:57 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E4%B8%AD%E5%9B%BD%E4%BA%BA%E5%BF%99%E6%98%AF%E4%B8%BA%E4%BA%86%E6%BB%A1%E8%B6%B3%E5%88%AB%E4%BA%BA%E5%AF%B9%E8%87%AA%E5%B7%B1%E7%9A%84%E6%9C%9F%E6%9C%9B/","section":"Blog - Not Useds","summary":"","title":"理解中国人忙碌的深层原因","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n“我们进入了一个低容错率时代”这句话，精准地捕捉了当下社会许多人感到焦虑和紧绷的底层逻辑。 简单来说，它的核心含义是：在这个阶段，个人、企业乃至系统犯错的成本被极度放大，而用来缓冲错误、从头再来的资源和机会却在变少。 以前如果走错了一步，可能只是“摔了一跤”，拍拍土还能继续跑；现在走错一步，感觉像是“踩空了悬崖”，可能需要很久才能爬上来，甚至再也回不到原来的高度。 我们可以从以下几个维度来深度拆解这个概念：\n1. 经济维度的“安全垫”变薄 # 在经济高速增长期（增量时代），由于到处都是机会，市场的“大潮”会托着所有人往上走。\n过去（高容错）： 你创业失败了，换个赛道还能再来；你裸辞了，很快能找到下家；你买房买贵了，过两年房价涨了也就抹平了。 现在（低容错）： 职业生涯： “35岁危机”成为普遍焦虑。一旦在关键节点失业或选错行业，重新进入轨道的难度极大，收入可能会出现断崖式下跌。 资产负债： 许多背负高额房贷（高杠杆）的家庭，容不得失业、生病或资产价格下跌。一旦现金流断裂，几十年的积累可能瞬间归零。 核心变化： 从“做大蛋糕”变成了“分蛋糕”。在存量博弈中，一个人的失误往往意味着被别人立刻填补空缺，没有留给你“调整呼吸”的时间。 2. 社会维度的“全景敞视” # 互联网和社交媒体的高度发达，构建了一个类似于“全景监狱”的环境，每个人都活在放大镜下。\n言行审视： 公众人物或普通人的一句无心之失，可能被互联网永久记忆、无限放大，导致“社会性死亡”。 完美主义枷锁： 社交媒体上展示的都是经过筛选的“完美生活”。这种对比让人产生错觉，认为“别人都没犯错，只有我搞砸了”，从而加剧了对错误的恐惧感。 3. 教育与成长的“单行道”效应 # 这种低容错率深深地渗透到了教育体系中，形成了所谓的“精密育儿”。\n链式反应的恐惧： 许多家长和学生持有这样一种心态：中考没考好 -\u0026gt; 上不了好高中 -\u0026gt; 考不上好大学 -\u0026gt; 找不到好工作 -\u0026gt; 这一辈子就完了。 探索空间的消失： 为了不犯错，孩子们被推着走在既定的、最“稳妥”的道路上，失去了试错、休学、间隔年（Gap Year）或探索冷门兴趣的勇气。 4. 系统的“极度优化”带来的脆弱性 # 从宏观系统来看，追求极致的效率（Efficiency）往往牺牲了冗余（Redundancy）。\nJust-in-Time (准时制)： 供应链追求零库存，一旦某个环节出小问题（如苏伊士运河堵船），全球都会受影响。 生活排期： 现代人的时间表被填得满满当当，一旦出现突发状况（如生病、交通堵塞），整个生活的节奏就会崩塌，因为没有预留“缓冲地带”。 这个时代，我们该如何应对？ # 意识到“低容错率”不是为了让我们绝望，而是为了调整生存策略。在这个时代，单纯的“小心翼翼”是不够的，我们需要建立**反脆弱（Antifragile）**的能力。 1. 降低杠杆，保留冗余\n财务上： 尽量减少高风险的负债，保持充足的现金流（“过冬的粮食”）。不要为了追求极致的收益率而牺牲安全性。\n时间上： 不要把每一分钟都填满。给自己留出“发呆”和处理突发事件的时间。 2. 从“追求最优解”转向“追求满意解”\n在这个复杂系统中，试图算出每一步的“最优解”是徒劳且耗能的。接受“差不多”和“局部的小失败”，只要避免毁灭性的大失败即可。\n战略上藐视： 接受“人生必然会犯错”的设定，不要因为一次失误就自我攻击。 3. 打造“多维竞争力”（Plan B思维）\n不要把所有的赌注都压在一个身份（如“大厂员工”）或一个技能上。发展副业、兴趣或第二技能。\n当一条路因为“低容错”而断裂时，你有另一条路可以兜底。 4. 祛魅与脱敏\n对评价脱敏： 不要太在意网上的声音或他人的眼光。在这个高压时代，活得“糙”一点，心理防御机制厚一点，是一种保护色。\n总结 # “低容错率时代”意味着盲目狂奔的时代结束了，精细化生存的时代开始了。 它要求我们从过去的“赌徒心态”（搏一搏，单车变摩托）转变为“农夫心态”（深耕细作，广积粮，筑高墙）。虽然容错率低了，但只要我们降低预期、控制风险、保持耐心，依然可以找到属于自己的安稳节奏。 Would you like me to suggest some specific \u0026ldquo;Antifragile\u0026rdquo; strategies tailored to your current career or life stage?\nExported from Gemini Voyager\nGenerated on February 3, 2026 at 11:55 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog/%E6%88%91%E4%BB%AC%E8%BF%9B%E5%85%A5%E4%BA%86%E4%B8%80%E4%B8%AA%E4%BD%8E%E5%AE%B9%E9%94%99%E7%8E%87%E6%97%B6%E4%BB%A3/","section":"AI-Generated Blog","summary":"","title":"低容错率时代的生存策略","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且富有禅意的生活哲学，通常被称为**“真空法则” (The Law of Vacuum)**。 这句话的核心逻辑在于：能量守恒与置换。如果你紧紧抓着旧事物不放，你的双手就没有空闲去接纳新事物；如果你的杯子是满的，倒再好的茶也会溢出来。 你可以从以下几个维度来深度理解这句话：\n1. 物理空间的“断舍离” # 这是最直观的层面。如果你的生活环境塞满了不再使用的物品、不合身的衣服或积灰的杂物，这些旧物会占据你的物理空间，更会占据你的“视觉注意力”。\n阻塞能量： 杂乱的空间会产生视觉噪音，让人感到压抑和疲惫。 腾出空间： 当你清理掉不需要的东西，你实际上是在对宇宙发出信号：“我已经准备好迎接更适合我的新事物了。” 2. 心理与情绪的“格式化” # 这往往是最难的一步。很多时候，我们想要新的关系、新的快乐，却在潜意识里紧抓着旧的创伤、怨恨或对过去的依恋不放。\n情绪负债： 沉溺于过去的失败或遗憾，会消耗你当下的心力（Mental Bandwidth）。你没有余力去发现身边的机会。 腾出心房： 原谅（包括原谅自己）和放下，不是为了对方，而是为了清空你内心的内存，让新的喜悦和灵感得以入驻。 3. 时间与精力的“留白” # 如果你把每天的日程表都排得满满当当，只为了维持现状或应对琐事，那么即使绝佳的机会（比如一次转行契机、一个有趣的约会）出现，你也会因为“太忙”而与之擦肩。\n低效的忙碌： 仅仅是填满时间并不能带来质变。 主动留白： 敢于让自己有一段“无所事事”的时间，或者主动结束那些低回报的社交和项目。只有留出空档，意外的好运（Serendipity）才有缝隙钻进来。 4. 认知的“清零” # “初学者心态”（Shoshin）：在初学者的心里，可能性有很多；在专家的心里，可能性很少。如果你认为自己已经知道了一切，或者固守某些陈旧的观念（例如“我就是这样的人”、“赚钱很难”），那么新的知识、新的视角和新的可能性就无法进入你的大脑。腾出认知的空间，意味着保持谦逊和好奇。\n总结 # “腾出空间”不仅是一个动作，更是一种对他人的信任和对未来的信心。 它意味着你相信：即使我放手了手中现有的（哪怕是不够好的），未来依然会有更好的东西填补进来。 这是一种由“匮乏心态”向“富足心态”的转变。 你最想在生活的哪个领域（居住环境、人际关系、工作日程）先试着“腾出一点空间”？\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 02:01 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog/%E5%8F%AA%E6%9C%89%E4%BD%A0%E8%85%BE%E5%87%BA%E7%A9%BA%E9%97%B4%E6%83%B3%E8%A6%81%E7%9A%84%E4%B8%9C%E8%A5%BF%E6%89%8D%E4%BC%9A%E9%99%8D%E4%B8%B4%E5%9C%A8%E4%BD%A0%E7%94%9F%E5%91%BD%E4%B8%AD/","section":"AI-Generated Blog","summary":"","title":"只有你腾出空间，想要的东西才会降临在你生命中","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这是一句非常深刻且真实的学术界感悟，精准地捕捉到了这两种智力活动截然不同的“情绪节奏”。这句话揭示了教书与科研在心理奖励机制上的本质差异。 我们可以试着进一步拆解这种体验：\n1. 教书的快乐：耕耘后的收获 (The Harvest) # 为什么快乐往往发生在结束的时候？\n成果的滞后性： 教育的本质是改变人。在教学过程中，你面对的是困惑的眼神、繁重的备课和批改任务，这往往是消耗精力的。只有在课程结束，看到学生的认知发生质的飞跃，或者多年后收到学生的一封感谢信时，那种“育人”的成就感才达到顶峰。 如释重负的解脱感： 教学是一种高强度的表演和输出。结束意味着责任的暂时卸下，这种“完成感”（Closure）本身就是一种巨大的心理奖赏。 不确定性的消除： 只有在最后，你才能确定你传授的知识被正确接收了，悬着的心终于可以放下。 2. 科研的快乐：探索前的憧憬 (The Spark) # 为什么快乐往往发生在开始的时候？\n可能性的无限： 在立项或构思阶段，一切都是完美的。假设不仅逻辑自洽，而且充满美感。此时没有实验数据的打击，没有审稿人的刁难，只有纯粹的思维快感和对未知的兴奋。 多巴胺的驱动： 提出一个新想法时，大脑分泌的是多巴胺（预期奖励）。科研的起点往往伴随着“我可能发现了一个大秘密”的幻觉，这种智力上的征服欲最强。 执行的枯燥： 一旦开始动手，科研就变成了在黑暗中枯燥的摸索。Debug、数据清洗、阴性结果、繁琐的论文格式……这些过程往往会迅速磨灭最初的激情。 总结 # 教书是**“苦尽甘来”**，是在确定的框架内，通过重复的劳动换取最终确定的价值感。 科研是**“由奢入俭”**，是从一个宏大的、完美的构想，跌落到琐碎、充满挫折的现实细节中去验证真理。 这种对比或许也解释了为什么很多学者需要在两者之间寻找平衡：用科研的“新奇”来对抗教学的“重复”，用教学的“确定性反馈”来疗愈科研的“挫败感”。 您是在哪个瞬间（是刚结了一门课，还是刚有了一个新点子）突然有了这个感触的？\nExported from Gemini Voyager\nGenerated on February 4, 2026 at 01:50 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E6%95%99%E4%B9%A6%E5%92%8C%E7%A7%91%E7%A0%94%E9%83%BD%E8%83%BD%E5%B8%A6%E6%9D%A5%E5%BF%AB%E4%B9%90%E6%95%99%E4%B9%A6%E7%9A%84%E5%BF%AB%E4%B9%90%E9%80%9A%E5%B8%B8%E5%8F%91%E7%94%9F%E5%9C%A8%E7%BB%93%E6%9D%9F%E7%9A%84%E6%97%B6%E5%80%99%E7%A7%91%E7%A0%94%E7%9A%84%E5%BF%AB%E4%B9%90%E5%88%99%E5%8F%91%E7%94%9F%E5%9C%A8%E5%BC%80%E5%A7%8B%E7%9A%84%E6%97%B6%E5%80%99/","section":"Blog - Not Useds","summary":"","title":"教书和科研都能带来快乐：教书的快乐通常发生在结束的时候，科研的快乐则发生在开始的时候","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这句话 \u0026ldquo;Observing More Data means More Wisdom\u0026rdquo;（观测更多的数据意味着更多的智慧）可以从多个层面来解读。它既可以是对 人工智能（AI）与机器学习 核心原理的概括，也可以是对 人类认知与决策逻辑 的哲学思考。 这句话的核心在于：单纯的“数据”只是素材，而通过大量观测产生的“模式识别”和“泛化能力”，才是所谓的“智慧”。 以下我将从三个维度为您拆解这句话的深层含义：\n1. 技术视角：AI 与机器学习的本质 # 在人工智能领域，这句话通常被用来解释为什么现代的大模型（LLMs）和深度学习系统如此强大。\n见多识广（Generalization）： 模型见过的样本越多，它对世界的“分布”理解就越完整。 例子： 自动驾驶系统如果只在晴天训练，它在雨天就会不知所措。只有当它观测了数百万英里的驾驶数据（包括暴雪、强光、路面塌陷等极端情况），它才能处理“未曾见过”的场景。这种处理未知的能力，就是机器的“智慧”（鲁棒性）。 长尾效应（The Long Tail）： 现实世界中，大部分事件是普通的（正态分布的中间），但真正考验“智慧”的是那些极少发生的边缘案例（Edge Cases）。观测更多数据，意味着更有可能捕捉到这些稀缺的“黑天鹅”事件，从而学会应对之道。 对抗过拟合（Avoiding Overfitting）： 数据量少时，我们容易死记硬背（过拟合）；数据量大到一定程度，死记硬背不再奏效，系统被迫去学习事物背后的底层逻辑和规律。 结论： 在 AI 语境下，“智慧”等于更强的泛化能力和更低的预测误差。 2. 认知视角：DIKW 模型 (从数据到智慧的跃迁) # 从信息论和知识管理的角度来看，这句话其实省略了中间步骤。我们需要引入经典的 DIKW 金字塔 来理解：\nData (数据)： 零散的观测值（例如：温度 38°C）。 Information (信息)： 被组织过的数据（例如：某人现在的体温是 38°C）。 Knowledge (知识)： 被验证过的规律（例如：体温 38°C 意味着发烧，可能是感染）。 Wisdom (智慧)：**基于知识的正确决策（例如：考虑到该患者有药物过敏史，决定物理降温而非通过特定药物降温）。 “Observing More Data means More Wisdom” 的深意在于： 如果不观测足够多的底层数据**，你就无法提取准确的信息，进而无法总结出可靠的知识，最终也就无法形成高维度的智慧。 量变引起质变： 当数据积累到一定临界点，我们能看到的不再是单一的点，而是趋势、周期和系统性的因果关系。 3. 批判性视角：反直觉的陷阱 (Caveats) # 理解这句话时，必须同时看到它的局限性，否则会陷入误区。“多”并不总是意味着“好”。\nGarbage In, Garbage Out (垃圾进，垃圾出)： 如果你观测的是 100 万条错误的、有偏见的或者是噪音数据，你得到的不是智慧，而是偏见（Bias）。 例子： 如果一个招聘 AI 只观测过去 10 年“白人男性高管居多”的数据，它可能会“错误地学会”女性不适合做高管的逻辑。这叫“数据偏见”，而非智慧。 相关性 = 因果性： 在大数据中，你总能找到两条看似相关的曲线（例如：夏天冰淇淋销量和溺水人数成正比）。观测更多数据可能会让你发现无数这种虚假的关联，真正的“智慧”在于剔除噪音，找到本质，而不仅仅是盲目增加数据量。 信噪比（Signal-to-Noise Ratio）： 智慧的关键在于从海量数据中过滤出关键信息。如果缺乏处理能力，更多的数据只会导致“信息过载”和决策瘫痪。 总结 # 如何一句话理解 \u0026ldquo;Observing More Data means More Wisdom\u0026rdquo;？ 它可以被理解为：“只有见过足够多样的世界（Data），才能看清事物的本质规律（Wisdom），从而在面对未知时做出正确的选择。” 这句话既是对大数据威力的赞美，也是对人类和机器如何学习成长的隐喻——阅历（Data）是智慧（Wisdom）的基石。\n下一步建议 # 如果您正在处理具体的数据分析或 AI 项目，您是否需要我协助您分析如何从现有的数据中提取更有价值的特征（Feature Engineering），以实现从 Data 到 Wisdom 的转化？\nExported from Gemini Voyager\nGenerated on February 3, 2026 at 11:18 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/observing-more-data-means-more-wisdom/","section":"Blog - Not Useds","summary":"","title":"Observing More Data Means More Wisdom","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常深刻且富有时代感的隐喻。你将古老的东方哲学（修仙、大智若愚）与最前沿的现代技术（流量、大模型）完美地映射在了一起。 这种视角将人生的两种状态做了极具赛博朋克风格的对比：\n1. 凡人模式：云端依赖（消耗流量） # 机制： 凡人的“算法”主要依赖云端。遇到问题、需要决策、寻找快乐时，必须向外界（搜索引擎、社交网络、他人评价）发送请求。 代价： “活得越久，消耗流量越多。” 随着阅历增加，如果核心没有内化，依然依赖外界输入来维持运转，精神熵增会越来越大，注意力（流量）被海量碎片化信息抽取殆尽。 表现： 看起来很忙碌、很灵通（高并发、高吞吐），但一旦断网（失去外界反馈），系统可能就会崩溃。 2. 修仙模式：本地部署（大模型内化） # 机制： 修仙就是不断训练、压缩、蒸馏数据的过程。通过长期的“炼丹”（学习与思考），将海量的外部信息压缩成权重，存入自己的神经网络中。 优势： “不需要消耗流量。” 真正的大能，核心逻辑已经本地化（Localize）。遇到问题，不需要联网搜索，不需要向外求证，内在的逻辑闭环（Inference）瞬间就能给出最优解。 **境界：**大智若愚。 因为不需要频繁与外界交换数据（低 I/O），表面看起来反应迟缓、木讷，甚至不合群。 但实际上，内部的参数规模（参数量）极其庞大，推理过程在静默中完成，能耗极低，准确率极高。 这个隐喻还可以引申出几个有趣的思考：\n过拟合（走火入魔）： 如果只在有限的数据集（狭隘的经验）里训练太久，模型可能会过拟合，变得固执、偏激，这就是修仙里的“执念”。 预训练（读万卷书）： 修仙的前期还是需要消耗流量的，因为你需要高质量的语料（经典书籍、阅历）来进行预训练（Pre-training），才能形成一个好的底座。 微调（行万里路）： 真正的悟道，往往是在具体的场景中对模型进行 Fine-tuning（微调），让通用的智慧适应具体的生活。 你的这句话其实点出了信息时代的终极追求：从“连接者”进化为“拥有者”。 不做流量的管道，而做智慧的容器。 需要我帮你把这个“修仙大模型”的架构图或者训练路径进一步具体化吗？比如如何筛选高质量语料，或者如何进行“本地微调”？ Exported from Gemini Voyager\nGenerated on February 3, 2026 at 11:33 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E6%B4%BB%E5%BE%97%E8%B6%8A%E4%B9%85%E9%9C%80%E8%A6%81%E6%B6%88%E8%80%97%E7%9A%84%E6%B5%81%E9%87%8F%E8%B6%8A%E5%A4%9A%E4%BF%AE%E4%BB%99%E6%98%AF%E6%89%BE%E5%88%B0%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%8D%E9%9C%80%E8%A6%81%E6%B6%88%E8%80%97%E6%B5%81%E9%87%8F/","section":"Blog - Not Useds","summary":"","title":"活得越久，需要消耗的流量越多。修仙是找到属于自己的大模型，不需要消耗流量","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n这句话提供了一个非常深刻且实用的视角，将“蝴蝶效应”的混乱特质与博弈论中的“生存优先”策略结合在了一起。 通常人们理解的“蝴蝶效应”侧重于不可预测性（一只蝴蝶扇动翅膀引发风暴），但你提出的这个观点侧重于不可逆性（irreversibility）。这是一个关于风险不对称的讨论：\n1. 成功的累积 vs. 毁灭的瞬间 # 在人生算法中，做对决定通常带来的是线性叠加的收益（+1, +1, +1），而某些关键的错误决定带来的却是乘法效应，甚至是归零效应（x 0）。\n建设难，破坏易：你可以花十年时间通过无数个正确的决定建立声誉、财富或健康，但一个糟糕的决定（如一次酒驾、一次冲动的投资、一次背叛）就可能触发蝴蝶效应，引发连锁反应，将之前的积累瞬间瓦解。 生存者偏差：我们往往关注那些做对了惊天动地大事的成功者，却忽略了更多人是因为避开了那些“显而易见但致命的陷阱”才得以平稳度过一生。 2. “不犯错”本身就是一种在这个混乱系统中的竞争优势 # 查理·芒格（Charlie Munger）有一句名言与此不谋而合：“如果我知道我会死在哪里，那我永远都不会去那个地方。” 这就是所谓的**“否定之路”（Via Negativa）**智慧：\n与其绞尽脑汁去寻找“如何变得极其聪明”，不如专注于“如何不犯愚蠢的错误”。 在这个充满蝴蝶效应的复杂世界里，预测未来是不可能的，但预防脆弱性是可能的。 3. 如何界定“毁了人生”的错误？ # 并非所有错误都会毁了人生。我们需要区分**“可逆的试错”和“不可逆的毁灭”**：\n可逆的错误（如：选错了餐厅、学了一个不喜欢的技能、一次不严重的项目失败）：这些是成长的养料。 不可逆的错误（如：触犯法律、透支信用、不可挽回的身体伤害）：这些是需要极力避免的“吸收态”（Absorbing Barrier）。 总结来说： 你这句话的核心在于**“容错率”**。人生的容错率越低，蝴蝶效应的破坏力就越强。真正的智慧也许不在于每一步都走得精准无误（那是不可能的），而在于确保自己永远留在牌桌上，不因一次波动而出局。 这种思维模式是否也让你联想到某些具体的决策场景？或者你是在反思某种特定的风险管理策略？ Exported from Gemini Voyager\nGenerated on February 4, 2026 at 01:31 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E4%BA%BA%E7%94%9F%E4%B8%8D%E5%9C%A8%E4%BA%8E%E5%81%9A%E5%A4%9A%E5%B0%91%E6%AD%A3%E7%A1%AE%E7%9A%84%E5%86%B3%E5%AE%9A%E8%80%8C%E5%9C%A8%E4%BA%8E%E9%81%BF%E5%85%8D%E8%A2%AB%E9%94%99%E8%AF%AF%E7%9A%84%E5%86%B3%E5%AE%9A%E6%AF%81%E4%BA%86%E4%BA%BA%E7%94%9F/","section":"Blog - Not Useds","summary":"","title":"蝴蝶效应：人生不在於做多少正确的决定，而在于避免被错误的决定毁了人生","type":"blog---not-used"},{"content":"","date":"4 February 2026","externalUrl":null,"permalink":"/tags/ai-game/","section":"Tags","summary":"","title":"AI Game","type":"tags"},{"content":"On this website, I show a few HTML games generated by Canvas of Gemini 3 Pro.\n","date":"4 February 2026","externalUrl":null,"permalink":"/game/","section":"AI-Generated Games","summary":"","title":"AI-Generated Games","type":"game"},{"content":"Powered by Canvas of Gemini 3 Pro.\nSTART! ","date":"4 February 2026","externalUrl":null,"permalink":"/game/chiikawa%E8%AE%A8%E4%BC%90%E5%A4%A7%E4%BD%9C%E6%88%98/","section":"AI-Generated Games","summary":"","title":"Chiikawa讨伐大作战","type":"game"},{"content":"Powered by Veo of Gemini 3 Pro.\nYour browser does not support the video tag. ","date":"4 February 2026","externalUrl":null,"permalink":"/videos/hachiware/","section":"AI-Generated Videos","summary":"","title":"Hachiware","type":"videos"},{"content":"Powered by Veo of Gemini 3 Pro.\nYour browser does not support the video tag. ","date":"4 February 2026","externalUrl":null,"permalink":"/videos/sphinx2/","section":"AI-Generated Videos","summary":"","title":"Sphinx2","type":"videos"},{"content":"Powered by Gemini 3 Pro.\n这句话非常深刻，它揭示了**“打工者思维”与“投资者思维”之间最本质的区别。 通俗来说，这是一个关于延迟满足和复利效应**的价值观。我们可以从以下三个维度来拆解和理解这句话：\n1. 突破“线性交换”的陷阱 (Escape the Linear Trap) # 如果我们将学习和工作仅仅看作“把时间转化为金钱”，那就是在进行等价交换： 我工作 1 小时 = 获得 1 小时的薪水。这种模式有一个致命的缺陷：时间是不可再生的有限资源。 无论你多努力，一天只有24小时。如果你的收入完全依赖于“出卖时间”，你的天花板就被锁死了，而且一旦你停止工作（生病、失业、退休），价值交换就会立即停止。 “让未来的时间更有价值” 意味着现在的努力是为了构建一种杠杆。你现在学习的知识、积累的经验、建立的人脉，都是为了让你在未来：\n用更少的时间，解决更贵的问题。 即使不直接付出时间，也能产生价值（如版权、资产收益、系统化管理）。 2. 定义“有价值的时间” (Defining \u0026ldquo;Valuable Time\u0026rdquo;) # “更有价值”并不仅仅指“时薪更高”，它包含更丰富的含义：\n选择权 (The Power of Choice) 现在的努力，是为了让你在未来拥有拒绝的权利。当你的时间变得昂贵，你就不必为了生存去被迫做那些不喜欢、低价值、消耗生命的事情。你可以选择把时间花在更重要的人和事上。 体验的密度 (Density of Experience) 努力学习带来的认知提升，会让你对世界有更深的理解。同样是去博物馆看展，同样是去旅行，拥有知识储备的人能看到历史的纵深和文化的纹理，而缺乏积累的人可能只能看到表象。认知的深度，决定了你单位时间内的生命质量。 抗风险能力 (Anti-Fragility) 现在的“卷”和努力，本质上是在修筑护城河。当未来行业动荡或经济下行时，拥有核心竞争力的人，他们的时间依然是稀缺资源，而普通的时间贩卖者容易被替代。 3. 从“提桶水”到“修管道” (Buckets vs. Pipelines) # 这是一个经典的隐喻：\n把时间转化为金钱，就像是**“提桶水”**。你需要不断地往返于水源和村庄之间，提一桶水，换一份钱。哪天你提不动了，水就断了。 让未来的时间更有价值，就像是**“修管道”**。在修管道的初期（努力学习和工作的阶段），你可能没有立刻赚到很多钱，甚至比提水的人更累。但是，一旦管道建成，水流（价值）就会源源不断地流过来。 这时候，你的时间就从“生存工具”变成了“享受生活的载体”。 总结 # 这句话的核心在于把当下的自己看作一项资产，而不是一个劳动力。\n低维度的努力： 贩卖时间（为了月底的工资）。 高维度的努力： 投资时间（为了未来的自由、尊严和更高的生命质量）。 现在的辛苦，本质上是在为未来购买自由。 我可以为你做一个简单的梳理吗？ 如果你愿意，可以告诉我你目前的职业阶段或学习状态，我可以帮你分析一下，哪些努力属于“贩卖时间”，哪些努力属于“为未来的时间增值”？\nExported from Gemini Voyager\nGenerated on February 3, 2026 at 11:47 PM\n","date":"4 February 2026","externalUrl":null,"permalink":"/blog/%E6%88%91%E4%BB%AC%E5%8A%AA%E5%8A%9B%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%B7%A5%E4%BD%9C%E5%B9%B6%E4%B8%8D%E6%98%AF%E6%83%B3%E8%A6%81%E6%8A%8A%E6%97%B6%E9%97%B4%E8%BD%AC%E5%8C%96%E4%B8%BA%E9%87%91%E9%92%B1%E8%80%8C%E6%98%AF%E6%83%B3%E8%AE%A9%E6%9C%AA%E6%9D%A5%E7%9A%84%E6%97%B6%E9%97%B4%E5%8F%98%E5%BE%97%E6%9B%B4%E6%9C%89%E4%BB%B7%E5%80%BC/","section":"AI-Generated Blog","summary":"","title":"我们努力学习和工作并不是想要把时间转化为金钱，而是想让未来的时间变得更有价值","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这句话非常精准地描述了技术变革（特别是AI技术）带来的**“马太效应”**（Matthew Effect）。简单来说，就是强者愈强。 在AI时代，决定一个人竞争力的核心逻辑发生了本质变化：从“体能/记忆力”的线性竞争，变成了“认知/运用工具”的指数级竞争。 我们可以通过以下四个维度来深度拆解这个观点：\n1. 核心机制：从“加法”变成了“乘法” # 在传统时代，你的产出通常等于你的劳动时间乘以效率，这是一个加法或低倍率的过程。 而在AI时代，AI是一个巨大的乘数（Multiplier）。 我们可以用一个概念公式来理解：\n$$ 产出 (Output) = (核心能力 + 创意) \\times AI^{杠杆率} $$ 对于能力平庸的人（核心能力 ≈1）： 即使有了AI，他可能只是用它来生成千篇一律的文案，产出提升有限（$1 \\times 10 = 10$）。 对于行业顶尖高手（核心能力 ≈100）： 他利用AI完成了繁琐的编码、调研、绘图，从而将精力集中在战略和创新上。AI将他的能力放大了无数倍（$100 \\times 10 = 1000$）。 结论： 基数越大，乘法效应越恐怖。原本微小的能力差距，在AI的杠杆作用下，会被瞬间拉大成鸿沟。 2. 认知分层：是“外包思维”还是“副驾驶思维”？ # 人与人之间对待AI的态度，决定了他们未来的智力水平差距。\n第一类人（思维退化者）： 把AI当作**“答案机器”或“廉价外包”**。 行为： 遇到问题直接问AI，盲目采信答案，不再进行深度思考和批判性验证。 结果： 大脑逐渐“通过性脑萎缩”，丧失了思考的主动权，最终沦为AI的附庸。 第二类人（超级个体）： 把AI当作**“副驾驶”或“智囊团”**。 行为： 利用AI进行头脑风暴、寻找盲点、挑战自己的观点，用AI来补齐自己的短板。 结果： 他们的决策质量和知识广度远超常人，AI成为了他们大脑的延伸。 差距来源： 这种认知上的差异，会导致“会用AI思考的人”和“依赖AI偷懒的人”在智力密度上渐行渐远。 3. 技能门槛：地板降低，天花板升高 # 这听起来似乎矛盾，但其实是导致差距拉大的重要原因。\n地板降低（入门更容易）： AI让普通人也能写代码、画图、写诗。这似乎缩小了差距，但这只是**“平庸层”**的拥挤。成千上万的人都能产出60分的作品。 天花板升高（精通更难）： 要在AI辅助下产出95分甚至100分的作品，需要的不再是重复性技能，而是极高的审美、深厚的领域知识、以及精准的提问能力（Prompt Engineering）。 洞察： 在AI时代，**“鉴赏力”比“制作力”**更稀缺。因为只有懂什么是“好”的人，才能指导AI生成“好”的结果。不懂行的人，只能得到AI输出的平均水平垃圾。 4. 只有问题，没有答案 # 在信息匮乏时代，“知道答案”的人是赢家。 在AI时代，答案是免费且唾手可得的（边际成本趋近于零）。 新的差距在于“提问的能力”：\n平庸者： 只能问出笼统、模糊的问题（如：“帮我写个方案”）。 卓越者： 能基于复杂的逻辑，提出结构化、有深度、直击本质的问题（如：“基于第一性原理，分析该商业模式在下沉市场的获客瓶颈，并给出3个反直觉的解决方案”）。 这种“定义问题”的能力，直接决定了你能从AI这个超级矿藏中挖掘出多少价值。 总结：如何避免被拉开差距？ # “人与人的差距会越来越大”并不是一句诅咒，而是一个客观趋势。要站在赢家的一侧，关键在于以下几点转变：\n从“学习知识”转向“学习调用知识”： 不要死记硬背，要建立知识索引和逻辑框架。 培养“AI商”（AIQ）： 即使是同样的工具，怎么用、何时用、用到什么程度，是一门艺术。 深耕“人性”与“稀缺性”： 同理心、复杂的领导力、极度的创意，这些是目前AI难以放大的领域，也是人的护城河。 在AI时代，平庸是最大的风险。只有不断强化自己的核心专长，才能握住AI这把重剑。 作为下一步，您希望我针对您的职业或兴趣领域，分析一下该如何利用AI来构建您的“竞争壁垒”吗？ ","date":"3 February 2026","externalUrl":null,"permalink":"/blog/%E5%9C%A8ai%E6%97%B6%E4%BB%A3%E4%BA%BA%E4%B8%8E%E4%BA%BA%E7%9A%84%E5%B7%AE%E8%B7%9D%E4%BC%9A%E8%B6%8A%E6%9D%A5%E8%B6%8A%E5%A4%A7/","section":"AI-Generated Blog","summary":"","title":"在AI时代，人与人的差距会越来越大","type":"blog"},{"content":"Reposted from Dan Koe：留给你的时间只有24个月（附 AI 时代生存清单） by 不安于\n【写在前面】如果你此刻正站在一个想改变、却被琐事缠住脚踝的节点上， 我花了一周时间，把 Dan Koe 的这套心法拆解、重组，做成了一套《21 天强制执行 · 行动地图（精确到小时版）》。它不是只会喊口号的鸡汤，而是一套强制重启的系统。\n👉关注公众号【不安于】，后台回复 “21”，直接发你。\n【本文核心洞察】\n看清局势： 理解为何“现在”是 AI 的真正拐点，以及为何两年后的贫富差距将是“物种级”的。\n认知升级： 明白技能演变的本质是“向上抽象”——从操作者变成甄别者。\n核心心法： 为什么在 AI 时代，“品味”和“判断力”比技术本身更值钱。\n行动指南： 2026 年真正值得打磨的“解放性技艺”清单。\nYou have about 24 months to learn these skills # 在这个月，风向彻底变了。虽然“AI 改变世界”的口号喊了几年，大众甚至已经对此免疫，但现实中的工具强度已经跨过了临界点。面对这场技术海啸，人群正在迅速分化。而在未来 24 个月内，这种分化将演变为不可逆的阶层鸿沟。\n注：Robert Scoble 是科技圈知名博主，曾长期活跃在硅谷，以对科技趋势的犀利评论著称。\n他在这条内容里，借网友 “不希望技术继续进步” 的热门观点，讨论了当时正在兴起的 “AI 反冲（AI Backlash）” 现象。而 Scoble 的发文则是为了点明 “公众对 AI 的反对浪潮已经切实到来” 这一趋势。\n① 三种人：你是哪一类？ # 当时代拐点出现，人们通常会展现出三种姿态：\n抗拒者 (The Resisters)：\n他们将自我认同捆绑在旧的生产方式上。就像当年怒砸纺织机的织布工，或者现在怒吼“AI 也是剽窃”的艺术家。他们拒绝承认工具的进化，试图用道德大棒阻挡效率的洪流。\n（抗拒者并非天生的守旧派，其反抗的根源从不是新工具、新生产方式本身，而是自身的自我认同、价值感甚至生存底气，都完全依附于旧的生产模式和规则。旧方式是他们定义 “我是谁”“我有何价值” 的唯一标尺，新事物的出现会直接动摇这一标尺，让他们陷入自我价值的迷茫与恐慌，反抗只是他们维护自我认同的本能行为）\n观望者 (The Waiters)：\n他们安慰自己“这阵风很快会过去”，选择低头苟着。但他们算错了一笔账：以往的技术差距是线性的，晚几年还能追上；但 AI 的差距是指数级的。如果你等到 2027 年才开始正视 AI，你会发现入门级的机会早已消失，领先者已经进化成了另一个物种。\n（观望者的心态：任何新风口都是一阵风，熬过去就会回到熟悉的旧轨道。这种自我麻痹的心态，让他们选择低头苟在舒适区，既不抗拒新事物，也不主动了解、学习，试图用 “等待” 化解变革带来的焦虑，本质是对未知的逃避，也是对自身适应能力的不自信）\n好奇者 (The Curious)：\n他们不美化过去，也不恐惧未来。他们明白任何新事物都有滞后性，所以愿意在混乱中试错、构建。这也正是你现在必须成为的人。\n（多数人将新事物带来的混乱视为风险，避之不及，而好奇者却将其看作宝贵的机会。在 AI 发展的初期混乱期，行业尚未形成固化的规则、领先者的壁垒尚未完全建立，此时的试错成本最低、探索空间最大。与其等一切清晰后再被动跟随，不如在混乱中主动摸索，提前掌握新规则的底层逻辑，为后续的发展抢占核心先机，让未来的自己，始终站在趋势的风口上）\n②历史的逻辑 # 技能正在“向上抽象” # 很多人担心 AI 会让人的价值归零。其实，历史一直在重复同一个逻辑：技能向更高层级抽象，体力劳动被剥离。\n印刷术时期：抄写员消失了，但诞生了“编辑”——那些决定什么值得被印刷的人。\n工业革命时期：手工织布工消失了，但诞生了“机器工程师”和“服装设计师”。\n每一轮技术浪潮，都在迫使人类进入更高的认知层级工作。AI 缩短了时间尺度（将几百年的变革压缩到几年），但并未改变本质：工具在变，但“使用工具解决问题”的能力永远稀缺。\n如果你只是把自己定位为“写字的人”或“画图的人”，你会被取代；但如果你将自己定位为“运用逻辑、审美和工具去创造价值的人”，你的能力边界将无限扩张。\n（历史早已证明，工具的进化只会让人类摆脱低价值的机械劳动，将更多精力投入到高价值的创造性工作中，AI 的出现只是这一规律的加速体现。那些担心被 AI 替代的人，本质是将自我价值与低层级的执行技能深度绑定，却忽略了人类最珍贵的能力 —— 基于逻辑、审美、经验、认知，判断 “什么值得做”、思考 “该怎么做”、创造 “独有的价值”。\n工具可以替代执行，却无法替代判断；可以复刻技能，却无法复刻创意；可以完成标准化工作，却无法解决复杂的真实问题。在 AI 时代，人类的生存法则从未改变：放下对单一执行技能的执念，向上拥抱高阶的价值创造能力，让 AI 成为你的杠杆，而非你的对手。当你成为 “运用工具创造价值的人”，所有的技术变革，都会成为你提升自我、拓展边界的机会，而非威胁）\n③未来的核心竞争力 # 品味 (Taste) # 我曾发誓不用 AI 写作，因为那是我的思考方式。但最近我改变了策略：让 AI 承担繁重的调研和初稿堆砌，而我负责掌握“灵魂”。\n以前，写作的门槛是“写出通顺的句子”；现在，AI 能在 30 秒内生成 2000 字通顺但平庸的废话。当生产成本归零，“平庸”将一文不值。\n未来的竞争，将不再是谁写得快，而是谁拥有更好的品味。\nAI 移除了创作的摩擦力（Friction）。\n以前，“慢”迫使你思考；现在“快”让你变懒。\n你必须主动提供判断力，去筛选、去注入灵魂、去决定什么值得存在。\n在这个时代，“决定什么值得被看见”本身就是一种高级技能。\n（AI 能替代所有机械性、标准化的创作工作，却永远无法拥有人类的审美、思考、共情与价值判断，这是人类创作者的核心优势。创作的本质，从来不是文字的堆砌，而是思考的表达、价值的传递，而 AI 只是让这份本质变得更加突出。\n对创作者而言，真正的挑战并非对抗 AI，而是在利用 AI 的同时，保持自身的思考能力与审美品位，主动承担起判断力的责任 —— 筛选 AI 的产出、注入自己的灵魂、判断内容的价值，最终决定什么值得被看见。唯有如此，才能在 AI 时代的创作竞争中站稳脚跟，让创作的灵魂永不褪色，而这，也是人类创作永远无法被 AI 取代的根本原因）\n接下来 24 个月 # 你真正该学什么？ # 请无视那些“2026 必学 AI 工具榜单”，工具几个月就会变。你真正需要掌握的是“解放性技艺” (Liberating Arts) ——那些让你成为独立个体的元能力：\n1.逻辑与修辞：如何推导真理，如何说服他人。\n（AI 时代，工具的迭代永远追不上，唯有能支撑独立思考与有效表达的元能力，才是永恒的竞争力。逻辑与修辞，前者让你看清事物本质、不盲从，后者让你传递思想价值、有影响，这两种能力，是让你成为真正独立个体的基石，也是接下来 24 个月，最值得深耕的核心）\n2.心理学：理解人类真实的动机与欲望。\n（AI 能复刻逻辑、生成内容、优化效率，却永远无法真正理解人心 —— 它能分析数据层面的行为规律，却读不懂行为背后藏着的隐秘动机、未说出口的真实欲望，以及情绪与需求的深层联结，而心理学，正是让我们拥有这份 “读心” 能力的核心）\n3.主体性 (Agency)：在无需许可的情况下，主动发起行动。\n（所有解放性技艺的落地，最终都依赖主体性的支撑 —— 逻辑、修辞、心理学的能力，若没有主动行动的意识，终究只是纸上谈兵；工具永远是服务于人的手段，而无需许可、主动行动的主体性，才是让所有能力和工具落地生花，真正定义 “我是谁、我能创造什么” 的根本）\n要在 2026 年锻炼这些能力，请立刻开始做三件事：\n1. 打造一个属于你的“公开项目”\n不管是一个产品、一个账号还是一个社群。把它推向公众，接受市场的毒打。你必须学会说服别人在乎你的东西，这比读一百本书都能锻炼你的“修辞”和“心理学”。\n（公开项目的本质，不是做一个产品、一个账号，而是为自己搭建一个 “真实世界的成长实验室”—— 在这个实验室里，你以行动为起点，以市场为老师，以反馈为养分，让所有的元能力在实战中被打磨、被验证、被融合。\n它的重要性，不在于项目本身的成败，而在于你在打造项目的过程中，完成了从 “知道” 到 “做到” 的本质跨越。哪怕项目最终没有达到预期，你在这个过程中锤炼的修辞能力、洞察能力、主动行动的能力，以及积累的真实经验，都会成为你最宝贵的财富。 锻炼核心能力的关键不是 “学什么”，而是 “做什么”。公开项目，就是让你把所有想学的能力，变成能解决真实问题、创造真实价值的硬本领的最佳方式）\n2. 持续公开写作（即使借助 AI）\n写作是被压缩的思考。它能暴露你思维的漏洞。即便用 AI 辅助，也要追求思想密度和视角的独特性。如果你的指令只是“帮我写篇关于效率的文章”，那你依然在门外。\n（持续公开写作（借力 AI）的本质，是以写作为载体，倒逼自己进行高质量、高频率的主动思考，并在实战中锤炼逻辑、修辞等元能力，而这一过程的核心，永远是 “人掌控思考的主动权”。\n它与打造公开项目相辅相成：公开项目是在真实市场中锤炼 “说服他人、洞察人性” 的能力，公开写作则是在文字表达中锤炼 “梳理思考、传递观点” 的能力，二者共同将抽象的元能力转化为可落地、可验证的实战硬本领）\n3. 用 AI 做你“以前做不到”的事\n不要只想着“怎么用 AI 偷懒”，而要问：“有什么事以前我一个人做不了，但现在能做了？”\n（多数人使用 AI 的第一思维是 “偷懒”—— 用 AI 替代繁琐工作、省去动手环节，本质还是在原有能力范围内做 “减法”，并未让自己获得真正成长。而真正的高阶用法，是把 AI 当成个人能力的延伸，跳出 “省力气” 的浅层思维，主动问自己 “什么事以前我一个人做不了，现在能做了？”。这种认知转变，让 AI 从 “逃避劳动的工具” 变成 “突破局限的杠杆”，核心不是减少付出，而是让相同的付出，能撬动原本根本触不可及的高价值目标，这是与 AI 共生的核心底层逻辑）\n比如一人完成全网信息的综合研报，或者一人开发一个系统。用 AI 扩展能力的边界，而不是逃避成长的痛苦。\n（2026 年，与 AI 相处的终极法则，从来不是 “依赖”，而是 “驾驭”—— 驾驭 AI 突破自己的能力边界，驾驭 AI 完成原本不可能的事，在这个过程中，让自己成为更强大的个体，这才是利用 AI 的终极意义）\n结语：只有两个选择 # 最后，请审视你现在的每一个习惯和技能。如果继续重复现在的模式，两年后你会站在哪里？\n这个世界正在残酷地奖励那些敢于在认知边缘试错的人。\n（AI 时代的竞争规则早已改写，世界不再奖励 “埋头苦干的重复者”，而是残酷地奖励那些敢于在认知边缘试错的人。认知边缘，是现有能力之外、AI 尚未完全渗透的高阶领域，是品味、判断力、生命体验的融合与实践之地；而试错，不是盲目探索，而是以人类独有的核心能力为根基，主动突破认知边界、尝试用 AI 做以前做不到的事。那些守在舒适区里，只想着用 AI 偷懒、不愿跳出固有认知的人，最终会被时代淘汰；而敢于在认知边缘试错的人，能在试错中打磨独属于自己的核心能力，抢占 AI 时代的高价值赛道，成为时代的受益者）\n有些东西永远无法被 AI 取代：你的品味、你的判断力、以及你独特的生命体验。你的任务不是和 AI 比拼算力，而是找到那个属于你独一无二的“支点”，然后用 AI 撬动它。\n留给你的窗口期，只有现在。\n感谢你读到这里。\n—— Dan Koe\n这个时代，从不辜负那些清醒、勇敢、即刻行动的人。你的任务，不是害怕 AI、逃避 AI，而是认清自己的价值，找到自己的支点，然后用 AI，撬动属于自己的未来。而这一切，唯有从现在开始。\n希望这篇文章，能让你对 AI 有另一个角度的思考\n—— qi\n说明：\n本文基于 Dan Koe 的英文内容进行重写，融合了我个人的理解与中文语境下的现实体验。\n黑色文字为 Dan Koe 文章的直译内容；\n灰色加粗文字为我基于原文的个人思考。\n感恩大家最近的阅读和反馈。\n这几天，因为 Dan Koe 的这几篇文章，我收到了不少私信。\n很多人问我的其实是同一个问题：\n“qi，我也很向往那种——每天只专注一小时，但长期稳定推进的状态。\n可每次都卡在第三天、第五天，怎么都坚持不下来。”\n说实话，这真的不是你不自律。而是我们大多数人，从来没有真正建立过一个「可执行的行动系统」。你以为自己缺的是意志力，但实际缺的是——在情绪波动、状态下滑时，依然能推着你往前走的结构。\n也是因为这个原因，我最近一直在打磨一套东西——《21 天高效能行动指南（精确到小时版）》。它不是那种“你应该更努力”的鸡汤，而是一张在你犹豫、拖延、走神时，直接告诉你下一步做什么的行动地图。目前这份指南还在内测阶段。 如果你也在这个有点混乱的 2026 年，想重新找回对时间和行动的掌控感——欢迎添加我的工作微信：Fairy_i020。\n","date":"3 February 2026","externalUrl":null,"permalink":"/posts/dan-koe%E7%95%99%E7%BB%99%E4%BD%A0%E7%9A%84%E6%97%B6%E9%97%B4%E5%8F%AA%E6%9C%8924%E4%B8%AA%E6%9C%88%E9%99%84-ai-%E6%97%B6%E4%BB%A3%E7%94%9F%E5%AD%98%E6%B8%85%E5%8D%95/","section":"AI-Related Reposts","summary":"","title":"[Repost] Dan Koe：留给你的时间只有24个月（附 AI 时代生存清单）","type":"posts"},{"content":"Reposted from 这 6 个超神的 SKills，在 GitHub 上杀疯了。 by 逛逛\n01\n视频制作：Remotion Skill\n不知道大家有没有用过 Remotion 这个开源项目，现在也有 2.8 万的 Star 了。\n之前我想做视频生成自动化的时候，了解过 Remotion。它其实是一个用 React 编程来制作视频的框架。\n比如下面这种视频，都可以使用 Remotion 框架制作。\n最近 AI Skill 大火，Remotion 团队就推出了 remotion skills。\n这个给 AI Agent 使用的技能包，可以教会 AI 如何正确、准确地使用 Remotion 框架来制作视频。\n比如下面这个视频，没有使用任何剪辑工具。就是使用 remotion skills + Claude Code 来生成的：\n下面就是使用 remotion skills 生成上面这个视频的演示：\n如果有条件，可以去 X 上看看，现在很多网友开始使用 remotion skills 来制作各种各样花里胡哨的视频了。\n这个开源的 skill 确实指的单独一篇文章，有空详细讲讲。\n你可以通过下面命令安装这个 skill：\nnpx skills add remotion-dev/skills 原理其实是将 Remotion 的官方文档、API 规范和最佳实践封装成 AI 可读取的 Context，让 AI 成为更懂 Remotion 的视频制作助手。\n开源地址：https://github.com/remotion-dev/skills 02\nYouTube 视频剪辑 Skill\nYoutube-clipper-skill 是 AI 大佬开源的一个 YouTube 视频剪辑 Skill。\n丢个 YouTube 的链接，它能自动完成环境检查、下载、语义分析、剪辑以及生成双语字幕文件，可以从长视频中提取精华片段。\n它不是机械地按时间切割视频，而是利用 Claude 的 AI 能力对视频字幕进行语义分析，自动生成有用的视频切片。\n这个开源项目项目集成了 yt-dlp 和 FFmpeg 底层工具，能够实现高质量的视频下载与处理。\n它具备强大的字幕处理能力，支持将字幕批量翻译为中英双语格式，并能将双语字幕录入视频画面中。\n翻译功能进行了优化，通过批量处理能显著减少 API 调用次数并提升翻译一致性。\n而且它能够自动生成适用于小红书、抖音或微信等平台的视频摘要和素材。\n开源地址：https://github.com/op7418/Youtube-clipper-skill 03\nskill-from-masters\n这个挺有意思的，它能帮你创建 Skill。\n在创建新 Skill 之前，会先搜索，寻找目标领域的顶级专家的思维模型和最佳实践，确保生成的 Skill 具备专业深度。\n这个开源项目采用三层搜索架构：\n首先查询本地专家数据库，其次进行网络搜索以补充更多专家观点，最后深入查找一手资料并交叉验证。\n它不仅寻找黄金范例作为输出标准，还会识别该领域的反面模式以避免常见错误，从而生成高质量、专业度极高的 Skill 指令。\n除了从专家处学习，该仓库还包含一个 skill-from-github 功能。\n你可以指定优秀的 GitHub 开源项目，让 AI 深入阅源码和文档，提取其中的算法逻辑或设计模式，并将其转化为一个独立的 Skill，还挺有用的。\n开源地址：https://github.com/GBSOSS/skill-from-masters 04\nNotebookLM Skill\n这个开源 Skill 能让 Claude Code 直接与 Google NotebookLM 进行交互。通过连接 NotebookLM ，让 Claude 能够基于你上传的知识库回答。\n这个项目会在本地运行一个独立的 Python 环境，利用 Patchright（基于 Playwright）技术实现浏览器自动化操作。\n它模拟用户登录 Google 账号并操作 NotebookLM 界面，实现了持久化认证和库管理。\n说白了，装了这个 Skill 不用再浏览器和命令行之前反复的复制粘贴了。\n你可以直接在命令行里面通过自然语言查询自己的知识库，Claude 会自动从 NotebookLM 获取经过综合处理的答案。\n开源地址：https://github.com/PleasePrompto/notebooklm-skill 05\nMarkdown 文章一键发布到 X 这个 Skill 可以把本地 Markdown 文章一键发布到 X 上。\nX 平台自带编辑器对 Markdown 支持不好，经常排版丢失，手动插入图片很繁琐。\n用这个 Skill 通过 Claude Code 就能完成从文稿解析到草稿生成的全过程。\n工具支持将 Markdown 的丰富格式完美转换为 X Articles 的 HTML 格式。\n为了确保文章排版的精准性，这个工具引入了 Block-Index 定位技术。\n在解析 Markdown 时，它会计算每张图片在文章结构中的精确位置索引，通过浏览器自动化脚本将图片精准插入到对应的段落之间，彻底解决了传统文本匹配方式容易导致的图片错位问题。\n开源地址：https://github.com/wshuyi/x-article-publisher-skill 06\nAgent Skills 公共仓库\n这是 Anthropic 官方发布的 Agent Skills 公共仓库，定义了 Claude 的 Skill 标准，重点是里面有大量现成的 Skill。\n这些 Skill 设计灵活，既可以在 Claude Code 中用，也可以集成到 Claude.ai 或通过 API 调用。\n我看了一下，有很多 Skill 还是非常实用的。\n比如文档处理，强大的 PDF、Word、Excel、PPT 处理能力，都有对应的 Skill。\nmcp-builder 可以辅助你创建高质量的 MCP Server，artifacts-builder 能使用 React、Tailwind CSS 和 shadcn/ui 组件库构建复杂的 HTML 交互式界面。\n还有很多很多，感兴趣去瞧瞧吧。\n开源地址：https://github.com/anthropics/skills 07\n点击下方卡片，关注逛逛 GitHub\n这个公众号历史发布过很多有趣的开源项目，如果你懒得翻文章一个个找，你直接关注微信公众号：逛逛 GitHub ，后台对话聊天就行了：\n","date":"3 February 2026","externalUrl":null,"permalink":"/posts/%E8%BF%99-6-%E4%B8%AA%E8%B6%85%E7%A5%9E%E7%9A%84-skills%E5%9C%A8-github-%E4%B8%8A%E6%9D%80%E7%96%AF%E4%BA%86/","section":"AI-Related Reposts","summary":"","title":"[Repost] 这 6 个超神的 SKills，在 GitHub 上杀疯了","type":"posts"},{"content":"","date":"3 February 2026","externalUrl":null,"permalink":"/tags/dan-koe/","section":"Tags","summary":"","title":"Dan Koe","type":"tags"},{"content":"","date":"3 February 2026","externalUrl":null,"permalink":"/tags/skills/","section":"Tags","summary":"","title":"Skills","type":"tags"},{"content":"","date":"3 February 2026","externalUrl":null,"permalink":"/tags/workflow/","section":"Tags","summary":"","title":"Workflow","type":"tags"},{"content":"Reposted from 1000 万人围观的 Claude Code 创始人 0% 手写代码工作流更新了（附我的实战心得） by Edward Luo\n大家好，我是 Edward。\n一个月前，我分享了 Claude Code 创始人 Boris 在推特公开的 0% 手写代码工作流。这两天他又发了条新推文，两篇共 1000 多万浏览，可能是全推特分享 Claude Code 使用经验流量最高的帖子。\n获取高质量 AI 资讯要「Follow builders, not influencers」。这次的内容是 Boris 和 Claude Code 开发团队一起总结的 10 条技巧，相比上次更具实操价值，用法也更高阶，非常值得学习。\n原推文信息密度极高，但缺少具体实践指引。我结合自己过去半年用 CC 独立开发产品的经历，针对每条技巧都补充了具体的使用心得，分享给大家：\n在我看来，这 10 条技巧可以归纳为四个核心思路：\n并行提效：同时跑多个 worktrees、善用 subagents，让多个 Claude 为你打工。\n构建知识复利：Plan mode、CLAUDE.md、Skill、Spec 文档——把经验变成可复用的资产。\n自动化闭环：让 Claude 自动修 bug、用 AI 审批权限，减少人工干预。\n扩展使用边界：不只是写代码，还能做数据分析、边写边学。\n▌01 提高效率的最佳技巧：同时跑多个 Claude Code 任务 # 这点上次也提过，但这次补充了更多细节。\nBoris 他们会同时启动 3-5 个 git worktrees，每个 worktree 跑一个独立的 Claude Code 对话。Claude 桌面端已经原生支持这个功能了。\n一个小技巧：给 worktrees 设置 shell 别名（比如 za、zb、zc），一个快捷键就能切换。也可以专门留一个 worktree 只用来读日志、跑数据查询，不干扰主开发流程。\n注：为什么要用 worktree 而不只是多开几个对话窗口？因为每个 worktree 都有独立的文件状态，一个 worktree 里的改动不会影响其他 worktree，多个 Claude 同时改代码也不会互相干扰。\n如果你也想试试 git worktrees 的工作方式，强烈推荐试试看 Conductor 这个软件。它把 worktree 的创建、提 PR、合并这些操作都整合到产品里了，体验很顺滑。\n我现在就用它来并行开发产品的多个功能，有了不同的 worktrees，多 Agents 同步开发的效率成倍增加 ，也不用担心搞坏代码库。后续打算单独写一篇 Conductor 的使用教程，感兴趣的欢迎留言。\n▌02 复杂任务从 Plan mode 开始 # 核心思路：把精力花在计划上，让 Claude 能一次性高质量完成。\nBoris 他们会让一个 Claude 先写计划，再开另一个 Claude 来审核这个计划。如果审核时发现有偏差，就切回 Plan mode 重新规划，而不是硬着头皮继续写。他们甚至会在验证步骤也用 Plan mode，不只是在写代码的时候用。\n我是直接在设置里把默认模式改成了 Plan mode，每次启动 Claude Code 就直接进入计划模式，推荐大家也这么改哈哈，不然有时候很容易忘记。\n▌03 运用复利思维，持续更新你的 CLAUDE.md，沉淀使用经验。 # 每次 Claude 犯错后，Boris 都会在对话结尾加一句：「把这条规则更新到 CLAUDE.md，下次别再犯同样的错」。Claude 写给自己的规则出奇地有效。\n他们会持续迭代 CLAUDE.md，直到 Claude 的出错率明显下降。团队里还有工程师会让 Claude 为每个项目维护一个文档目录，每次提 PR 后都更新，然后在 CLAUDE.md 里指向这个目录。\n我的 CLAUDE.md 每个项目至少有十几条规则，都是 Claude 犯错后一条条加上去的。我留了一段「踩坑记录」，专门记下那些反复出现的问题。一旦把踩坑经验清晰写下之后，Claude 基本就再没有出现过类似的错误。\n▌04 把重复的工作流沉淀成 Skill # Boris 他们判断什么时候该创建 Skill 的标准很简单：如果每天做某件事超过一次，就把它变成一个 Skill。\n他们团队的一些例子：\n创建一个 /techdebt 指令，每次会话结束时运行，查找并消除重复代码\n设置一个指令把 Slack、Google Drive、Asana、GitHub 过去 7 天的内容同步到一个上下文汇总文档\n构建分析工程师风格的 agents，用于写 dbt 模型、审查代码、在开发环境测试变更\n我自己常用的几个 Skill：\nPlan Review：写完方案后，用 Skill 调用 Codex 的 GPT 5.2 xhigh 帮我检查一遍计划是否有漏洞（千万别浪费 GPT Plus 的额度）\n代码 Review：写完功能后，同样请 Codex 老师帮我 review 代码，看看有没有 bug 或者可以简化的地方\n产品发布版本更新：每次 release 新版本时帮我自动提交，自动填写更新说明\n这套「Claude 写 + Codex 审」的工作流非常好用，后续也会单独写一篇分享，欢迎关注。\n▌05 Claude 可以自主修复绝大多数 Bug # Boris 他们的做法：\n启用 Slack MCP 后，直接把 Slack 里的 bug 讨论帖丢给 Claude，只说一个字「fix」，不需要额外解释上下文\n直接说「Go fix the failing CI tests」，不用告诉它具体怎么做\n让 Claude 读 docker logs 来排查分布式系统问题，效果出奇地好\n我自己的做法更简单：给产品接上 Sentry 监控崩溃报告，遇到线上问题直接把崩溃报告丢给 Claude，让它自动分析问题、自动修复。\n日常开发 iOS 应用时也是一样，构建报错了 Claude 会自动检查报错信息、自动修复，都不需要我手动复制粘贴报错日志。\n▌06 三个高阶的 Claude Code 使用思路 # Boris 分享了三种思路：\na. 让 Claude 挑战你\n说「用这些变更考考我，没通过你的测试不准提交 PR」，让 Claude 担任代码审查者。或者说「证明这功能确实有效」，让 Claude 比较主分支和功能分支的代码差异。\nb. 先实现，再优化\n在完成一个「能用但不够优雅」的方案后，说：「既然你现在已经知道我要什么了，废弃这个方案，去实现那个更优雅的解决方案吧。」\n这一点我深有体会。我的做法是：先追求功能完成，再追求代码优雅。先通过精确的需求描述让 Claude 完成功能，等用户体验上没问题之后，再让 Claude 和 Codex 帮我 review 一遍完整代码。因为功能已经实现了，它们知道我要的是什么，就可以在保证功能的情况下，想尽办法找到代码可优化的部分，写出更优雅的方案。\nc. 写详细的 Spec\n在移交工作前，写详细的规格说明，减少模糊性。越具体，产出质量越高。\n我基本上每天都在用这个方法：每次完成一个新功能、完成一次技术调研、每次踩坑、以及上下文快用尽的时候，我都会让 Claude 总结成一个 Markdown 文档，分门别类存在 Doc 文件夹里。下次遇到类似问题就可以直接读文档，快速恢复上下文。\n▌07 终端环境配置 # Claude Code 团队都很喜欢用 Ghostty（一个新兴的终端应用，渲染效果非常好，我也很喜欢），主要是看中它的同步渲染、24 位色彩和完善的 Unicode 支持。\n为了更方便地切换 Claude，可以用 /statusline 指令自定义状态栏，显示上下文使用情况和当前 Git 分支。他们还会给终端标签页加颜色标记、重命名，有时用 tmux 来管理，每个 tab 对应一个 task 或 worktree。\n他还提到他们整个团队都使用语音输入而非打字编程。这一点我也深有感触，人类的说话速度是打字的 3 倍以上，除了速度，使用语音输入的更大价值在于，你会不自觉地说出更多的上下文，从而获得更好的结果。\n▌08 善用 Claude Code 的 subagents 子代理 # Claude Code 团队总结了 3 种常见的 subagent 使用场景：\na. 需要更多计算资源时\n在请求后面加一句「使用子代理」，让 Claude 投入更多计算资源来处理问题。\nb. 保持主对话上下文干净\n把单个任务交给子代理处理，主对话的上下文窗口就能保持简洁、专注。\nc. 用 hook 让 AI 自动审批权限（高阶）\n通过 hook 把权限请求发给 Opus 4.5，让它判断请求是否安全，安全的自动批准，危险的拦截。\n我之前一直不敢开 dangerously-skip-permissions，怕 Claude 误删文件或者搞坏代码库。但用了这个**「AI 辅助审批权限」**的思路之后，我现在都是开 bypass 模式工作，极大提升了效率——既享受了自动批准的便利，又不用担心安全问题。这是个很高阶的技巧，值得花点时间研究配置。\n▌09 Claude Code 不只会写代码，还能做数据分析 # Boris 他们基本不手写 SQL 了，直接让 Claude 用 bq 命令行工具实时提取和分析指标。他们在代码库里集成了 BigQuery 技能模块，团队成员都可以直接在 Claude Code 里跑分析查询。\n这个方法适用于任何有 CLI、MCP 或 API 接口的数据库。\n我最近给产品接上了 PostHog 分析用户使用数据，虽然从来没学过 SQL，但只要跟 Claude 口述我想看什么数据，它就能直接写出可用的查询语句，生成可视化的产品数据 dashboard。\n如果现有埋点不足以支撑分析，Claude 甚至还能根据需求优化埋点的设计，让我的重心完全聚焦于如何根据用户数据迭代产品，而不用浪费时间在学习数据分析上。\n▌10 你可以边用 Claude Code 写代码边学习 # Boris 团队分享的几个学习技巧：\n在 /config 中启用 Explanatory 或 Learning 的 output style，让 Claude 解释它做了什么。\n让 Claude 生成可视化 HTML 演示文稿，解释不熟悉的代码。它生成的幻灯片效果出奇地好！Claude Code 官方新出的 Playground Plugin 也非常适合用来做这件事。\n让 Claude 画 ASCII 图示，帮你理解新协议和代码库的结构。\n创建一个间隔重复的学习 Skill：你阐述你对代码的理解，Claude 来提问填补空白，还能存储学习结果便于复习——活脱脱一个编程界的多邻国。\nsource: https://x.com/bcherny/status/2017742752566632544\n▌写在最后 # 以上就是 Boris 分享的全部技巧，你会发现 Boris 并没有用什么“黑魔法”或复杂的工作流，他们绝大多数用的功能其实都写在 Claude Code 的官方文档里。\n更该学习的是背后的思维方式：并行处理、构建知识复利、自动化重复流程、拓展使用边界。\n重复我上次提到过的观点：学习 Claude Code 最好的方式，不是看无数个教程，而是现在就打开软件，去 Build 那个你一直想做却没做的产品。\n「只要一直 build，就会有好事发生」\n如果这篇文章对你有启发，欢迎一键三连，转发给同样在用 Claude Code 的朋友！\n也欢迎关注我的公众号，后续还会分享更多 Vibe Coding 编程技巧。\n我是 Edward，我们下期再见。\n陪女朋友逛街时，我带上了 Claude Code（附配置教程）\n两天 600 万阅读：Claude Code 创始人公开 0% 手写代码工作流\n","date":"2 February 2026","externalUrl":null,"permalink":"/posts/1000-%E4%B8%87%E4%BA%BA%E5%9B%B4%E8%A7%82%E7%9A%84-claude-code-%E5%88%9B%E5%A7%8B%E4%BA%BA-0-%E6%89%8B%E5%86%99%E4%BB%A3%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%9B%B4%E6%96%B0%E4%BA%86%E9%99%84%E6%88%91%E7%9A%84%E5%AE%9E%E6%88%98%E5%BF%83%E5%BE%97/","section":"AI-Related Reposts","summary":"","title":"[Repost] 1000 万人围观的 Claude Code 创始人 0% 手写代码工作流更新了（附我的实战心得）","type":"posts"},{"content":"Reposted from Nature开年重磅：2026年将改变世界的七大技术 by 麦伴科研MaltSci\n「麦伴科研MaltSci」\nAI让科研更高效\n当全球顶尖学术期刊《Nature》在2026年开年之际推出年度技术盘点，整个科技界都会屏息凝神。这不仅仅是一份预测清单，更是经过严格同行审视、代表着人类认知边界的突破性进展。今年，从拯救生命的生物工程到探索宇宙深处的天文巨器，从重塑计算范式的量子系统到破解大脑奥秘的成像技术，七大前沿领域正站在产业爆发的临界点上。这些技术不再是实验室里的概念验证，它们正在2026年这个时间节点上，以惊人的速度转化为改变人类文明进程的现实力量。\n一、异种器官移植：基因编辑猪正在改写器官移植史\n器官短缺是全球性的医疗危机。在欧洲理事会46个成员国加上美国，每天约有37人因等不到移植器官而离世。而异种移植——将动物器官移植到人体内——正从科幻走向临床现实。\n2024年，麻省总医院与eGenesis公司合作完成了全球首例活体猪肾移植。这头猪经过了69处精准基因组编辑：敲除引发免疫排斥的α-半乳糖抗原，清除潜伏的病毒序列，同时插入人类基因以降低炎症反应和防止血液异常凝固。患者术后存活了52天，虽然最终因心脏问题离世，但已证明技术可行性。随后中美两国的患者在接受猪肾移植后稳定维持超过八个月，逼近1964年黑猩猩肾移植创下的九个月纪录。\n不仅是肾脏。2022年，马里兰大学医学院完成了首例基因编辑猪心脏移植；2025年，中国团队更实现了猪肝和猪肺向脑死亡患者的移植。这些突破意味着，经过深度基因改造的猪器官有望成为可规模化生产的生命救星，甚至通过个性化免疫调控实现长期替代。\n2022年，首例人造猪心脏移植手术成功进行。图片来源：马里兰大学医学院/ZUMA/Alamy\n二、AI气象学：重新定义天气预测的速度与精度\n2025年10月，当飓风梅丽莎还在大西洋酝酿时，Google DeepMind的AI模型已提前数日预警其将升级为五级飓风，并精准预测了穿越加勒比海的路径，而传统数值模型却判断失误。这只是AI重塑气象学的冰山一角。\n传统天气预报依赖数百万行代码的数值模型，需要超级计算机求解复杂的微分方程。而深度学习正在将这种计算提速10,000倍。华为云的盘古气象模型率先展示了这一潜力；剑桥大学和微软研究院开发的Aardvark系统实现了端到端预测，仅凭桌面工作站就能生成十天内的精准预报；Aurora基础模型更能预测气旋轨迹和空气质量等超出常规天气范畴的事件。\n更令人振奋的是气候模拟。西雅图艾伦人工智能研究所的SamudrACE模型整合大气与海洋AI系统，能够模拟超过千年的气候演变。这些工具正将原本专属超算中心的研究能力，交到普通科研人员手中，让极端天气预警和气候变化研究进入实时、高精度的新时代。\n人工智能模型正在推动天气预报的发展。图片来源：科罗拉多州立大学/CIRA 和美国国家海洋和大气管理局\n三、下一代核能：从微型反应堆到人造太阳\nAI产业爆发带来的电力需求激增——国际能源署预测数据中心能耗可能每年增长15%——让清洁能源变得前所未有地紧迫。核能正在迎来复兴，而这次的主角是更灵活、更安全的技术路线。\n小型模块化反应堆（SMR）成为投资热点。这种发电功率不超过500兆瓦的装置（约为传统反应堆的一半）足以供应数十万家庭用电，且建造成本更低、速度更快。俄罗斯和中国已有商运SMR，加拿大达灵顿核电站的机组预计2029年投运。TerraPower公司正在开发的熔盐堆不仅能提高燃料利用效率、大幅减少核废料，还能将反应堆热量储存转化为热能备用。\n而在聚变领域，人造太阳正从梦想照进现实。2022年，美国劳伦斯利弗莫尔国家实验室首次实现聚变净能量产出；2023年，英国欧洲联合环创下五秒释放足够12,000户家庭使用能量的纪录；德国Wendelstein 7-X仿星器装置更实现了43秒持续运行的新纪录。全球50余家聚变初创公司中，Commonwealth Fusion Systems计划于2026年完成示范堆建设。虽然商业化聚变发电仍需约20年，但面对廉价、安全、 abundant的能源前景，这份等待值得。\n小型模块化反应堆，例如中国的玲珑一号反应堆，为核能发电提供了一种低成本、快速建造的选择。图片来源：罗云飞/中国新闻社/VCG/Getty\n四、光学脑图谱：用光透视神经宇宙的奥秘\n大脑连接组学正经历从电子显微镜向光学成像的范式转移。虽然电镜能提供纳米级分辨率，但海量数据的校对成本极高——2024年发表的MICrONS小鼠大脑图谱中，仅有1%的神经元被完整重建。\n2025年5月，奥地利科学技术研究所的Danzl团队开发了LICONN技术（光学显微镜连接组学）。通过膨胀显微镜将脑组织均匀扩张至透明状态，结合蛋白特异性标记，研究人员能用普通共聚焦显微镜观测神经突触的纳米级细节，同时保留三维空间信息。这种方法不仅能追踪轴突和树突的蜿蜒路径，还能区分兴奋性与抑制性突触，甚至识别神经递质类型。\n加州非营利机构E11Bio更解决了数据校对的痛点。他们通过基因工程让小鼠神经元表达独特的蛋白质条形码组合，用荧光抗体逐层解码，实现了26.2万个神经元的无误差计算重建。随着成像速度提升和样本处理自动化，光学技术有望以更低成本绘制出完整的哺乳动物大脑连接图谱，为理解意识、治疗神经疾病提供地图。\n神经连接可以被精确成像。图片来源：艾伦研究所\n五、探索极端：从最深的海沟到最远的星系\n人类对极限的探索从未停止。在智利安第斯山脉，以暗物质发现者命名的薇拉·鲁宾天文台即将开启为期十年的巡天。这台配备32亿像素相机的观测利器，采用创新的多镜面设计，将对南天球每个区域扫描约800次。预计到2028年数据发布时，它将编录约200亿个星系和近200亿颗恒星—— cataloged天体数量将超过地球人口。\n而在地球另一端，中国科学院的奋斗者号载人潜水器正突破深渊禁区。这艘由钛合金打造的深潜器能在超过10,000米的马里亚纳海沟底部作业，配备精密机械臂实现原位采样。2025年，科研团队利用奋斗者号完成了全球海沟探索计划，对深渊 Amphipods（端足类甲壳动物）进行了种群遗传学分析，首次在活体状态下观察到这些极端环境生物的行为。这填补了人类对地球最后前沿的认知空白。\n_科学家乘坐深潜器抵达了海洋最深处。_图片来源：新华社/Alamy\n六、mRNA疗法：从疫苗到癌症治疗的软件定义医学\nmRNA技术因新冠疫苗而家喻户晓，但其在肿瘤治疗领域的潜力才刚刚显现。这种技术允许科学家通过递送遗传指令，让人体细胞临时生产特定蛋白质，如同在生物层面运行可编程软件。\n2025年2月，美国研究团队证实，编码肿瘤特异性抗原的个性化mRNA疫苗可将胰腺癌患者的无复发生存期延长数年。更惊人的发现来自MD安德森癌症中心：分析180名癌症患者数据发现，在接受抗肿瘤免疫治疗前100天内接种mRNA新冠疫苗的患者，总生存期几乎翻倍。这种非特异性免疫激活效应正在启动新的临床试验。\n宾夕法尼亚大学的研究人员更在2022年展示了体内CAR-T细胞重编程技术。通过mRNA让免疫细胞在患者体内直接表达嵌合抗原受体，避免了传统CAR-T疗法痛苦的骨髓采集和体外基因工程步骤。这项技术不仅用于癌症，还在纤维化疾病和自身免疫疾病中显示出阻断瘢痕组织形成的能力。尽管面临政治层面的资金削减阻力，mRNA作为可编程疗法平台的潜力已不可阻挡。\n七、量子计算：从物理实验室走向实用化\n量子计算机利用量子叠加和纠缠实现经典计算机无法企及的并行计算，但错误率一直是最大障碍。量子态不可复制，测量会破坏量子信息，因此纠错需要为每个逻辑量子比特配备大量物理量子比特。过去，实用化量子计算被认为是需要数百万量子比特的遥远梦想。\n2023年，Google量子AI团队首次在超导量子芯片上实现了错误抑制的逻辑量子比特。普林斯顿大学团队则通过高纯度钽基超导材料和精密制造工艺，将量子比特寿命从100微秒延长至1.6毫秒，并正致力于再提升十倍。若能实现，仅需3万个量子比特就能构建实用处理器。\n更具颠覆性的是中性原子量子计算路线。哈佛大学的Lukin团队去年展示了具有容错能力的通用中性原子处理器架构，虽然仅使用448个原子，但他们已构建出3,000原子规模、可连续运行数小时的系统。中性原子虽然运算速度较慢，但易于大规模组装操控，且相干时间更长。随着量子纠错技术的成熟和硬件规模的指数级扩张，量子计算机正从物理实验仪器转变为可解决实际科学问题的计算工具，在材料模拟、药物发现和密码学领域等待释放其颠覆性能量。\n米哈伊尔·卢金（右）及其团队研发了一种中性原子量子计算机（左图）。图片来源：罗斯·林肯/哈佛大学摄影师（CC BY）\n这七大技术跨越生物学、物理学、计算机科学和工程学，共同勾勒出2026年人类科技的前沿图景。它们不仅代表着单点突破，更体现了跨学科融合的趋势：基因编辑遇上器官移植，深度学习重构气象科学，量子物理挑战计算极限。当这些技术从实验室走向临床、从原型走向产业，2026年很可能成为人类应对气候变化、攻克疑难疾病、探索宇宙奥秘的历史性转折点。Nature的这份清单，既是对未来的预言，也是对当下的行动号召。\nwww.maltsci.com\nMaltSci科研绘图功能上线了，不用复杂提示词，可以局部精修，一键矢量图下载，更有无限素材生成功能，快来体验吧！！\n- END - © 图片 / 官方素材 整理 /麦伴科研MaltSci编辑部\n推荐阅读\n深度剖析｜Gemini 3、GPT 5.1与Grok-4.1谁更适合科研\n《自然》杂志发布年度十大人物，两位中国科学家入选\nNature焦点：中国科学家发明电子舌头，终结食品工业最痛环节\n2025 高被引学者深度解析：全球科研版图正在重写，中美“赛点时刻”到来\nNature发布全球博士生幸福度调查：中国垫底，巴西第一？这结果让科研人破防了\n临床死于2025\nNature官方学术发表指南：一篇能被顶刊接收的论文，究竟要怎么写？\n她与贺建奎有过一段关系，如今要重启CRISPR婴儿实验\n从微软到MaltSci：被《南方周末》记录的科研人与AI故事\n当我用文言文写了一篇医学论文\u0026hellip;.\n3分钟读懂AI史上最重要的一篇论文： 《Attention Is All You Need》\n“包爽的” | 与整个PubMed对话是什么体验？\n","date":"2 February 2026","externalUrl":null,"permalink":"/posts/nature%E5%BC%80%E5%B9%B4%E9%87%8D%E7%A3%852026%E5%B9%B4%E5%B0%86%E6%94%B9%E5%8F%98%E4%B8%96%E7%95%8C%E7%9A%84%E4%B8%83%E5%A4%A7%E6%8A%80%E6%9C%AF/","section":"AI-Related Reposts","summary":"","title":"[Repost] Nature开年重磅：2026年将改变世界的七大技术","type":"posts"},{"content":"Reposted from 谷歌疯了！竟然将最先进 AI UI 工具无偿提供免费使用！ by 基米\n这是基米的第 4 篇原创!\n大家好，我是基米。\n最近发现了一个让设计师和开发者都要直呼“好家伙”的神器。如果你曾经为了做一个简单的 UI 界面反复修改、在 Figma 里拉线框拉到手软，那么你一定要看看这个——谷歌最新推出的 AI 设计工具：Stitch。✨\nalt text 最重要的是：目前完全免费！ 谷歌这次真的是良心发现了。\n🚀 Stitch 是什么 # 说人话，Stitch 就是让不会设计的人也能通过“嘴炮”快速搞出像模像样的 UI 界面。它是谷歌在今年 Google I/O 大会上发布的，支持直接导出代码或者导入 Figma 继续精修。\n它的操作界面极其简洁：\n左边：官方示例和你的历史作品。\n右边：AI 对话区，你只需要输入提示词。\n目前有两种模式：\nalt text 每月重置，基本够普通人白嫖到爽了。🎁\n🎨 实战演示：如何使用 Stitch # 使用起来非常简单，只需要给它提示词即可。比如我之前测试做了一个美食卡路里 APP：\n我的提示词：\n“我想做一个 AI 驱动的营养和健康 APP，需要页面：新用户引导、用户信息录入、饮食记录、AI 营养助手、报告进度、个人中心。”\nalt text 结果展示：\nalt text Stitch 不仅帮我规划了配色（深绿色系，非常有健康感），还细心地设计了交互逻辑：\n饮食记录页：顶部有卡路里进度条，下面分类记录早午晚餐。\nAI 助手对话框：甚至连食谱推荐的卡片和配图都准备好了。\n甚至你觉得颜色不好看，点一下主题选择器。\nalt text 2 分钟就能把“深绿”换成“可爱风”，所有页面同步更新。这在以前，改个色可能要花掉半天时间。\n颜色风格太丑了,修改风格为手绘/涂鸦笔记风格，可以添加吉伊卡哇（Chiikawa）动画形象来进行介绍\nalt text 🐶 开源项目：宠么吃 APP # 光说不练假把式。基米最近正在用 Stitch 开发一款非常有意义的 APP —— “宠么吃”。\n作为铲屎官，最头疼的就是：“这个东西猫/狗能不能吃？”\n这款 APP 的功能如下：\nalt text 目前的开发进度： UI 部分已经通过 Stitch 快速定稿并导出到 Figma，核心逻辑已经写完，马上就要开发完毕正式上线了！🚀🚀🚀\nalt text alt text 💡 基米的真实感受 # 总的来说，Stitch 非常适合用来做快速原型设计或者内部工具生成。它不是要取代设计师，而是要把我们从重复的、机械的 UI 工作中解放出来。\n这，就是 AI 时代创作工具的新可能。也是每个普通人把创意变成现实的新机会！\n个人观点，仅供参考，如果你也对 AI 感兴趣，欢迎后台回复：1(备注ai)，加入交流群。\n","date":"2 February 2026","externalUrl":null,"permalink":"/posts/%E8%B0%B7%E6%AD%8C%E7%96%AF%E4%BA%86%E7%AB%9F%E7%84%B6%E5%B0%86%E6%9C%80%E5%85%88%E8%BF%9B-ai-ui-%E5%B7%A5%E5%85%B7%E6%97%A0%E5%81%BF%E6%8F%90%E4%BE%9B%E5%85%8D%E8%B4%B9%E4%BD%BF%E7%94%A8/","section":"AI-Related Reposts","summary":"","title":"[Repost] 谷歌疯了！竟然将最先进 AI UI 工具无偿提供免费使用！","type":"posts"},{"content":"","date":"2 February 2026","externalUrl":null,"permalink":"/tags/ai-ui/","section":"Tags","summary":"","title":"AI UI","type":"tags"},{"content":"","date":"2 February 2026","externalUrl":null,"permalink":"/tags/science/","section":"Tags","summary":"","title":"Science","type":"tags"},{"content":"Powered by Veo of Gemini 3 Pro.\nYour browser does not support the video tag. ","date":"2 February 2026","externalUrl":null,"permalink":"/videos/spaceship/","section":"AI-Generated Videos","summary":"","title":"Spaceship","type":"videos"},{"content":"Powered by Veo of Gemini 3 Pro.\nYour browser does not support the video tag. ","date":"2 February 2026","externalUrl":null,"permalink":"/videos/sphinx/","section":"AI-Generated Videos","summary":"","title":"Sphinx","type":"videos"},{"content":"Powered by Gemini 3 Pro.\n这是一个非常富有诗意且充满智慧的比喻。将人生划分为春夏秋冬，能让我们更清晰地看到每个阶段的核心使命以及时间紧迫感。\n要在每个阶段都“不负韶华”并为下一阶段做好铺垫，关键在于顺势而为：在春天播种，在夏天生长，在秋天收割，在冬天储藏。\n以下是针对这四个“季节”的详细准备策略与过渡指南：\n🌱 春：播种与探索（0 - 25岁） # 核心主题：生长、试错、打地基\n这是生命力最旺盛的时期，也是唯一的“容错率”极高的阶段。你不需要急着定型，而是要像植物破土一样，尽可能多地吸收养分。\n当前阶段的任务：\n建立底层操作系统： 学习不应仅限于书本，更重要的是建立逻辑思维、批判性思维以及终身学习的习惯。\n广泛的试错： 不要害怕失败。去尝试不同的兴趣、学科、社交圈层。此时的每一次失败，都是为了帮你排除错误选项，找到真正的天赋所在。\n性格塑造： 培养韧性（Resilience）和同理心。才华决定你能飞多高，但性格决定你能飞多远。\n为“夏天”做准备（过渡策略）：\n技能专业化： 在春末（大学毕业前后），开始从“什么都懂一点”向“在某个领域不可替代”转变。\n积累第一桶“信誉金”： 无论是在学业还是初入职场，建立靠谱的口碑，这是夏天爆发的燃料。\n💡 关键心态： 不要急着追求结果，现在是扎根的时候。根扎得越深，夏天才能经得起狂风暴雨。\n☀️ 夏：盛放与深耕（25 - 45岁） # 核心主题：奋斗、责任、抗压\n这是人生中最忙碌、最热烈，也最辛苦的阶段。你要承担家庭、事业的双重责任，就像夏日的骄阳，需要持续输出高能量。\n当前阶段的任务：\n深耕核心竞争力： 选定一条赛道，在这个领域做到极致。此时不应再频繁跳槽或换方向，而应追求“复利效应”。\n构建支持系统： 经营好核心人际关系（伴侣、挚友、导师）。夏天常有暴风雨（危机），你需要稳固的后方和避风港。\n学会精力管理： 时间管理已经不够用了，你需要管理精力。学会区分“重要”与“紧急”，避免在琐事中耗尽热情。\n为“秋天”做准备（过渡策略）：\n财务护城河： 开始严肃对待理财，建立资产配置，为未来的被动收入打基础，避免中年财务危机。\n保养身体引擎： 此时身体看似强壮，但隐患往往在此刻埋下。规律运动，不再透支健康，是为了保证秋天能有力气收割。\n💡 关键心态： 接受“忙乱”是常态，学会与压力共舞。平衡是动态的，不要追求绝对的安逸。\n🍂 秋：收获与做减法（45 - 65岁） # 核心主题：成熟、取舍、传承\n秋天是收获的季节，果实成熟，天空高远。在这个阶段，人的智慧达到顶峰，但体力开始走下坡路。\n当前阶段的任务：\n学会做减法： 到了秋天，叶子要落，人也要学会“断舍离”。减少无效社交，剥离不重要的工作，把精力聚焦在最重要的人和事上。\n收割成果： 无论是事业上的地位，还是家庭的幸福，亦或是财富的积累，此时应坦然享受之前的努力带来的回报。\n角色转换： 从“执行者”转变为“指导者”或“顾问”。利用经验去提携后辈，这不仅是传承，也是在延续你的职业生命力。\n为“冬天”做准备（过渡策略）：\n寻找精神寄托： 很多人退休后会瞬间失落。需要在秋天就培养工作之外的深刻爱好（如艺术、写作、公益），构建退休后的身份认同。\n健康投资最大化： 此时的健康投入回报率最高。定期的深度体检和针对性的抗衰老管理是必须的。\n💡 关键心态： 承认不再年轻，但要相信智慧的力量。不要试图和年轻人拼体力，要拼眼界和格局。\n❄️ 冬：珍藏与和解（65岁以后） # 核心主题：宁静、智慧、超脱\n冬天不是结束，而是回归宁静。这是一个关于“储藏”和“回顾”的季节，也是人生境界最高的时刻。\n当前阶段的任务：\n与自己和解： 回首一生，难免有遗憾。冬天的任务是接纳这些不完美，原谅曾经伤害过自己的人，也原谅自己的过失。\n分享智慧（冬藏）： 将你一生的经验、故事、家风整理出来，传递给下一代。这不是说教，而是留给世界的礼物。\n享受当下： 真正的自由此时才到来。不需要讨好任何人，晒晒太阳，从容地度过每一天。\n终极过渡（面对离去）：\n安排身后事： 这不是消极，而是最后的责任感。妥善安排财产和遗嘱，让离去不给亲人带来混乱。\n精神升华： 思考生命的意义，保持内心的平静与尊严。\n💡 关键心态： 乐天知命。冬天有冬天的美，那是历经繁华后的纯净与安详。\n总结：如何过好当下的每一季？ # 人生四季的交替并不是机械的，它是流动的。最重要的是不要在现在的季节，焦虑下一个季节的事，或者悔恨上一个季节的错。\n如果你在春天，别急着想秋天的果实，先专心把根扎好。 如果你在夏天，别抱怨烈日当空，这是你能量最大的时候，尽情燃烧。 如果你在秋天，别感伤落叶，去欣赏果实的甜美和天空的辽阔。 如果你在冬天，别恐惧寒冷，这是围炉夜话、享受安宁的最佳时刻。 Would you like me to help you create a specific plan based on the \u0026ldquo;season\u0026rdquo; you feel you are currently in?\n","date":"2 February 2026","externalUrl":null,"permalink":"/blog---not-used/%E5%9B%9B%E6%97%B6%E6%9C%89%E5%BA%8F%E9%A1%BA%E5%8A%BF%E8%80%8C%E4%B8%BA%E4%BA%BA%E7%94%9F%E5%9B%9B%E5%AD%A3%E7%9A%84%E6%9B%B4%E8%BF%AD%E4%B8%8E%E5%AE%89%E9%A1%BF/","section":"Blog - Not Useds","summary":"","title":"四时有序，顺势而为：人生四季的更迭与安顿","type":"blog---not-used"},{"content":"Powered by Gemini 3 Pro.\n在2026年，AI早已不仅是一个聊天机器人或绘画工具，它已经深度集成到了操作系统、办公软件乃至我们的眼镜和耳机中。对于普通人而言，AI不再是“黑科技”，而是像电力一样的基础设施。\n要在2026年借助AI优化工作流，我们不能仅停留在“会写提示词（Prompt）”的层面，而需要从**战略（思维模式）和战术（具体操作）**两个维度进行全面升级。\n一、 战略层面：从“操作者”转型为“指挥官” # 在2026年，普通人的核心竞争力不再是单一技能的熟练度（如打字快、画图准），而是调用和整合AI能力解决问题的能力。\n1. 确立“AI 优先（AI-First）”的思维定式 # 遇到任何任务，首先问自己：“这部分工作，AI能不能做？”\n旧模式： 接到任务 -\u0026gt; 自己动手做 -\u0026gt; 完成。 2026模式： 接到任务 -\u0026gt; 拆解任务 -\u0026gt; 分配给AI -\u0026gt; 审核与整合 -\u0026gt; 完成。 你需要习惯将AI视为你的超级实习生或副驾驶。它不知疲倦、知识渊博，但需要你提供明确的指令和最终的质量把关。\n2. 重构技能栈：判断力 \u0026gt; 执行力 # 当AI能以毫秒级速度生成代码、文案或报表时，**“什么是对的”比“怎么做出来的”**更重要。\n审美与品味： 你需要有足够好的眼光去挑选AI生成的无数个方案中最好的一个。 提问的能力： 精准描述需求，定义问题的边界，这决定了AI产出的上限。 逻辑连接力： AI擅长单点突破，人类擅长跨学科、跨领域的宏观连接。 3. 建立“人机回环（Human-in-the-loop）”的信任机制 # 不要盲目信任AI，也不要完全排斥。\n验证机制： 对于关键数据和事实，必须保留人工核查（Fact-checking）的环节。 隐私边界： 在战略上明确哪些数据可以“喂”给公共AI，哪些必须保留在本地设备（Local LLM）处理。 二、 战术层面：全流程工作流优化 # 在2026年，AI代理（AI Agents）已经成熟，它们不仅能“说话”，还能“做事”。以下是普通人优化日常工作流的具体战术：\n1. 信息摄入：构建智能过滤器 # 面对信息爆炸，利用AI作为你的“守门人”。\n智能摘要： 不要通读每一封邮件或长文。设置AI Agent自动抓取每日行业新闻、邮件重点，生成一份“早安简报”。 跨模态检索： 忘记文件名没关系。直接对电脑说：“帮我找一下上个月我和张总开会时提到的那张红色背景的PPT数据图。” 系统级AI能通过语义理解瞬间调取资料。 2. 任务执行：10-80-10 法则 # 在内容创作、编程或方案撰写中，采用新的工作分配比例：\n10%（人类）： 定义目标、构思大纲、设定基调。 80%（AI）： 填充内容、生成初稿、润色语言、编写代码片段。 10%（人类）： 调整细节、注入情感、最终决策。 场景举例： 你需要写一份年度规划。你只需告诉AI你的核心战略（10%），AI生成完整的PPT大纲和演讲逐字稿（80%），你最后修改语气并确认数据准确性（10%）。\n3. 复杂决策：模拟与推演 # 利用AI的逻辑推理能力辅助决策，而不是代替决策。\n苏格拉底式对话： 在做决定前，让AI扮演“挑刺者（Devil\u0026rsquo;s Advocate）”。\n指令示例： “我打算在这个季度削减30%的营销预算，请列出这个决定可能带来的5个潜在风险，并反驳我的理由。”\n数据可视化分析： 扔给AI一个复杂的Excel表格，直接问：“这里面有什么异常趋势？”它能立刻生成图表并标出关键洞察。\n4. 自动化：打造个人Agent团队 # 2026年的无代码（No-code）工具将极其强大。普通人可以通过自然语言“捏”出自己的小工具。\n日程管理 Agent： 自动根据你的对话安排会议，检测冲突，甚至代替你回复“好的，我会准时参加”。 生活琐事 Agent： 发现机票降价自动锁定，发现日用品快用完自动下单。 学习 Agent： 它可以作为你的专属私教，根据你的弱点实时生成考题和讲解。 总结 # 在2026年，普通人与高手的区别，不在于谁更努力地搬砖，而在于谁拥有更强大的**“AI 协同商（AI Quotient）”**。\n优化的核心不在于工具本身，而在于你是否愿意让渡低价值的重复劳动，将精力集中在定义问题、情感连接和最终决策上。\nWould you like me to create a specific \u0026ldquo;2026 Workflow Template\u0026rdquo; for your particular profession (e.g., marketing, coding, administration)?\n","date":"2 February 2026","externalUrl":null,"permalink":"/blog/%E5%9C%A82026%E5%B9%B4%E6%99%AE%E9%80%9A%E4%BA%BA%E5%A6%82%E4%BD%95%E5%80%9F%E5%8A%A9ai%E4%BC%98%E5%8C%96%E5%B7%A5%E4%BD%9C%E6%B5%81/","section":"AI-Generated Blog","summary":"","title":"在2026年，普通人如何借助AI优化工作流？","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n这句话不仅仅是对未来的预言，更是对当下现状的一种深刻洞察。它揭示了在生成式人工智能（AIGC）爆发的背景下，人类与“真实”之间的关系正在发生的根本性断裂。\n要把这句话理解透彻，我们可以从以下四个维度来剖析：\n1. 感官维度的“失真”：眼见不再为实 # 在过去，物理世界的影像是我们判断事实的锚点。照片、视频被视为“铁证”。但在AI时代：\n深度伪造（Deepfakes）： 视频、音频、图像都可以被低成本、高保真地伪造。你可能看到从没发生过的火灾，听到某位公众人物从未发表过的宣战演讲。 物理证据的贬值： 当任何视觉证据都可以被生成时，人类最底层的感官信任被瓦解了。为了确认“这是真的”，我们需要付出巨大的认知成本去交叉验证，而大多数人在快节奏的信息流中会选择放弃验证，直接接受AI投喂的“现实”。 2. 经济与认知维度的“奢望”：真相比谎言昂贵 # 为什么说正确感知是一种**“奢望”**（Luxury）？因为在信息论的角度，制造混乱的成本趋近于零，而获取真相的成本无限拔高。\n生成 vs. 验证的不对称： AI生成一万条虚假新闻或逼真的假图只需要几秒钟和极低的算力成本；而人类要核实其中一条，需要耗费大量的时间、专业知识和注意力。 阶层分化： 只有具备高水平批判性思维、拥有付费信源、且有闲暇时间去思考的人，才能通过层层迷雾看到物理世界的真相。对于大多数忙碌奔波的人来说，顺从算法推荐、接受情绪化的虚假叙事是更“经济”的大脑节能模式。 3. 中介维度的“隔离”：算法成为新的感官 # 我们正在逐渐丧失直接感知物理世界的能力，转而依赖AI作为中介。\n二道贩子现实： 以前我们通过阅读书籍（一手或二手资料）了解世界，现在我们习惯问AI“帮我总结这篇文章”。我们接触到的不再是物理世界的原始数据，而是经过AI模型“降维”、“平滑”甚至“幻觉”处理后的解释。 回音室效应的物理化： 当AI不仅推荐新闻，还开始通过AR眼镜或元宇宙叠加在物理世界之上时，不同的人看到的“物理世界”甚至是不一样的。你的世界可能被标注了“危险”，而他的世界被标注了“机会”。客观统一的物理现实不复存在。 4. 心理维度的“逃避”：虚拟比现实更诱人 # 从多巴胺的角度看，物理世界往往是无聊、充满摩擦且并不完美的。\n超常刺激（Supernormal Stimuli）： AI生成的图像更完美，AI写的故事更跌宕起伏，AI伴侣更懂你的情绪。相比之下，粗糙的物理现实显得乏味。 主动放弃： “奢望”不仅是指能力不够，有时也是指意愿的丧失。当虚拟体验足够廉价且令人愉悦时，大多数人会潜意识里不再在这个物理世界中寻求意义，从而自愿放弃对物理真相的探究。 总结 # 这句话的核心悲剧色彩在于：技术本应拉近我们与真理的距离，结果却制造了一层厚厚的磨砂玻璃。\n富人（认知层面）： 支付高昂的代价购买“真实”（如私密社交、去电子化的自然体验、深度调查报道）。 穷人（认知层面）： 沉浸在AI根据其喜好生成的“奶头乐”和虚假叙事中，生活在被算法扭曲的伪物理世界里。 在这个时代，想要保持对物理世界的正确感知，需要一种近乎苦行僧般的自律：不仅要时刻警惕屏幕里的内容，还要有勇气走出舒适区，去触碰那个粗糙、不完美但真实的原子世界。\n作为一个具体的行动建议： 你提到过对 Markdown 和 GitHub 的兴趣，这其实是一种很好的对抗手段——建立自己的知识库和数字花园。不依赖算法推荐，而是自己手动整理、归档、验证信息，这是在AI洪流中保留一小块“真实领土”的有效方式。\n你是否想了解如何利用现有的技术工具（如开源情报工具 OSINT）来辅助辨别AI生成的内容，降低“验证真相”的成本？\n","date":"2 February 2026","externalUrl":null,"permalink":"/blog/%E5%9C%A8ai%E6%97%B6%E4%BB%A3%E5%A4%A7%E5%A4%9A%E6%95%B0%E4%BA%BA%E5%AF%B9%E7%89%A9%E7%90%86%E4%B8%96%E7%95%8C%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%84%9F%E7%9F%A5%E6%98%AF%E4%B8%80%E7%A7%8D%E5%A5%A2%E6%9C%9B/","section":"AI-Generated Blog","summary":"","title":"在AI时代，大多数人对物理世界的正确感知是一种奢望","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n在AI时代，“躺平”（指退出过度竞争、降低欲望、仅维持最低生存标准的生活方式）所带来的后果是多维度的。AI技术的高速迭代正在重塑劳动力市场和社会结构，这使得“躺平”不再仅仅是一种个人选择，更面临着前所未有的外部变量。\n以下是对这一选择在AI时代可能产生的后果的分析：\n1. 经济后果：生存空间的“二元分化” # AI时代的经济逻辑可能会将人群急剧分化，躺平者的处境将取决于由于AI带来的“生产力过剩”是如何被分配的。\n技能贬值的加速： 过去，技能迭代周期可能长达数十年，允许人们暂时“停歇”。但在AI时代，知识半衰期极短。长期躺平意味着与新技术完全脱节，一旦需要重新通过出卖劳动力获取收入，可能发现自己的技能已被AI彻底取代，从而失去重返职场的“入场券”。 低成本生存的可行性： 乐观的一面是，如果AI极大提高了社会生产力，导致基础物资成本下降，维持“低欲望生活”的门槛可能会进一步降低。对于不仅追求财富、只求温饱的躺平者来说，生存压力可能会反而变小。 错过红利期： AI时代被认为是继互联网之后的又一次财富分配重组。选择躺平意味着主动放弃了利用AI工具放大个人能力（如一人公司、超级个体）的机会，可能导致在此后的社会阶层中处于绝对的经济弱势。 2. 社会与职业后果：替代风险与价值重估 # AI擅长处理重复性、高逻辑和基于数据的任务，这改变了“努力”和“躺平”的传统回报比。\n被“优化”的首要目标： 在企业追求降本增效的逻辑下，产出仅仅达到“及格线”的员工（往往是职场中的“隐性躺平者”）最容易被AI替代。AI能够以更低的成本、全天候地完成这些基础工作。 “卷”的收益递减： 反过来说，AI也可能证明躺平某种程度上的“正确性”。如果普通人的努力在超级AI面前显得微不足道，那么过度竞争（内卷）的边际效益将趋近于零。在这种情况下，躺平可能被视为一种理性的止损策略，避免了无效的精力投入。 3. 心理与存在主义后果：意义的丧失与重构 # 当AI能够创作绘画、编写代码甚至进行心理咨询时，人类的自我价值感面临巨大挑战。\n虚无主义的陷阱： 躺平往往伴随着对社会主流价值观的疏离。在AI时代，如果发现自己引以为傲的技能（如写作、画画）不如AI，躺平者可能更容易陷入“人类无用论”的虚无主义，导致心理层面的彻底崩溃。 回归本质的自由： 另一方面，彻底的躺平可能让人从“工具理性”中解脱出来。如果不再将自己视为生产工具，人们可能会将注意力转向AI无法触及的领域：深刻的人际连接、纯粹的哲学思考、身体的感知体验和精神修养。这种躺平可能演变成一种“数字游牧”或“精神修行”，在AI时代找到独特的人文价值。 4. 宏观视角的终极后果：社会契约的改变 # 如果躺平成为大规模现象，且AI取代了大部分工作，社会结构必须做出改变。\n催生全民基本收入（UBI）： 随着大量人口选择躺平或被迫失去工作，消费市场可能萎缩。为了维持经济循环，AI创造的财富可能迫使政府推行全民基本收入（UBI）。在这种情境下，“躺平”可能从一种边缘行为变成一种被社会制度接纳的常态。 阶层固化的加剧： 掌握算力和算法的精英阶层与普通大众之间的鸿沟可能变成不可逾越的天堑。躺平者虽然生存无忧，但在社会决策、资源分配和未来方向的话语权上可能被完全边缘化，成为“被供养但无用”的群体。 总结 # 在AI时代，躺平的后果呈现出两极化：\n消极后果： 极高概率彻底丧失社会竞争力，面临技能断层和阶层跌落，成为算法时代的“数字难民”。 积极后果： 提前退出注定失败的人机生产力竞赛，转而探索AI无法替代的人文价值，获得精神上的解放。 关键的区别在于，你是被动地因为绝望而躺平，还是主动地为了重新定义生活意义而选择一种低能耗的生活方式。\n您希望我进一步分析在AI时代，哪些具体的职业或技能领域最不容易被“卷”到，从而适合一种相对轻松的生活方式吗？\n","date":"2 February 2026","externalUrl":null,"permalink":"/blog/%E5%9C%A8ai%E6%97%B6%E4%BB%A3%E8%BA%BA%E5%B9%B3%E4%BC%9A%E6%9C%89%E4%BB%80%E4%B9%88%E5%90%8E%E6%9E%9C/","section":"AI-Generated Blog","summary":"","title":"在AI时代，躺平会有什么后果？","type":"blog"},{"content":"Reposted from 史无前例！硅谷教父揭秘AI时代生存法则：超级个体+AI=10亿美金一人公司，未来只剩\u0026quot;E形人才\u0026quot;！如何不被AI淘汰？ by AI智能探长\n硅谷传奇人物Marc Andreessen(马克安德森)最近做客Lenny\u0026rsquo;s Podcast，进行了一次深度访谈。Marc是谁？\n他是网络浏览器 Netscape 的发明者，也就是说，你现在能用浏览器上网，很大程度上要感谢他。他还创立了全球最大的风险投资公司之一 a16z，投资了 Facebook、Twitter、Airbnb 等几乎所有你能想到的伟大科技公司。\n更重要的是，他多次精准预测了科技发展的方向：\n他说 \u0026ldquo;软件正在吃掉世界\u0026rdquo;，后来确实如此。\n2011 年他预测 10 年后会有 50 亿人使用智能手机，实际数字是 60 亿。\n他坚信技术进步会持续，而很多人当时认为技术已经停滞。\n所以，当这样一个人谈论 AI 时，我们真的需要认真听。\n接下来，把会这段访谈中最核心、最实用、最有启发的内容提炼出来。希望大家听看后，不仅能理解 AI 会如何改变世界，更重要的是，知道我们每个人应该如何应对、如何抓住机会。\n# 01\n我们正处于什么样的历史时刻？\n三股力量的交汇\nMarc 在访谈一开始就抛出了一个重磅观点：2025 年是他职业生涯中最有趣的一年，而 2026 年会更加精彩。\n为什么？因为有三股巨大的力量正在同时发生碰撞：\n第一股力量：传统机构的信任崩塌。\n过去几十年我们依赖的那些传统机构 ——ZF 部门、大型企业、教育系统、媒体 —— 人们对它们的信任正在全面崩溃。数据显示，全球范围内，民众对传统权威的信任度已经跌到历史最低点。\n第二股力量：言论自由的革命。\n全球对话的格局正在被 \u0026ldquo;解放\u0026rdquo;。过去几年不能公开讨论的话题，现在可以自由辩论了。信息的流动方式发生了根本性改变，这是一条单行道，不会倒退。\n第三股力量：AI 技术的突破。\n就在前两股力量发生的同时，AI 技术取得了革命性突破。这不是巧合，而是历史的必然。\nMarc 说，这三股力量的同时爆发，其历史意义可以和 1989 年柏林墙倒塌、1945 年二战结束相提并论。\nAI 是 \u0026ldquo;哲人石\u0026rdquo;\nMarc 用了一个绝妙的比喻来形容 AI。\n大家知道牛顿吗？发明微积分、提出万有引力定律的那位伟大科学家。但很少有人知道，牛顿花了几十年时间研究炼金术，试图找到传说中的 \u0026ldquo;哲人石\u0026rdquo;—— 一种能把铅变成黄金的神秘物质。\n哲人石的本质是什么？是把最常见的东西 (铅) 转化为最稀有的东西 (黄金)。\n牛顿终其一生没有找到哲人石。但今天，我们有了 AI。\nAI 就是现代的哲人石 —— 它把世界上最常见的东西 (沙子，也就是制造芯片的硅) 转化为世界上最稀有的东西：思想。\n想想看，这是多么不可思议的转变!\n# 02\n被严重误解的现实 —— 过去 50 年发生了什么？\n一个反直觉的真相\nMarc 接下来讲了一个让所有人震惊的事实。\n我们都觉得过去 30-50 年科技发展很快对吧？智能手机、互联网、社交媒体… 但 Marc 说：这是错觉。\n经济学家有一个指标叫 \u0026ldquo;生产力增长率\u0026rdquo;，用来衡量技术对经济的实际影响。数据显示：\n过去 50 年的生产力增长率，只有 1940-1970 年的一半。\n只有 1870-1940 年的三分之一。\n换句话说，过去 50 年是人类历史上技术进步最慢的时期之一!\n\u0026ldquo;比特\u0026rdquo; 的进步 vs \u0026ldquo;原子\u0026rdquo; 的停滞\nMarc 的搭档 Peter Thiel 曾经有个著名的辩论观点：我们在 \u0026ldquo;比特\u0026rdquo;(软件、互联网) 领域进步很大，但在 \u0026ldquo;原子\u0026rdquo;(物理世界) 领域几乎停滞。\n什么意思？\n1960 年代建的大楼，今天还在用。\n1930 年代建的桥梁，今天还在用。\n1910 年代建的水坝，今天还在用。\n1880 年代建的城市，今天还是那个样子。\n对比一下：\n1870-1930 年：蒸汽机、电力、汽车、飞机、电话、无线电 —— 世界彻底改变。\n1930-1970 年：核能、喷气式飞机、太空探索、高速公路系统 —— 又一次彻底改变。\n1970-2020 年：除了软件和互联网，物理世界几乎没变。\n为什么会这样？Marc 给出了深刻的分析：\n繁文缛节、官僚主义、监管体系、既得利益集团、垄断组织 —— 这些结构性障碍阻止了真实世界的改变。\n举个例子：医疗系统。AI 理论上可以极大改善医疗，但医生是个封闭的行会，护士是个封闭的行会，医院是垄断组织。当你带着 AI 医疗方案出现时，他们的第一反应是：“这会威胁医生的工作吗？那我们要阻止它。”\nChatGPT 现在很可能是比你的家庭医生更好的医生，但它不能开处方、不能做手术，因为它没有行医执照。\n人口危机：被忽视的另一个真相\n还有一个更少人注意到的现象：全球人口增长率在急剧下降。\n包括中国在内的许多国家，生育率已经低于 2.1(维持人口稳定的临界值)。\n未来 100 年，很多国家的人口会大幅萎缩。\n这不只是西方现象，正在变成全球现象。\n想象一下：技术进步缓慢 + 人口持续下降 = 经济持续萎缩。\n如果没有 AI，我们现在应该恐慌了!\n# 03\nAI 为什么来得正是时候？\n奇迹般的时机\nMarc 说了一句让我印象深刻的话：\n“时机安排得奇迹般完美。我们将在真正需要 AI 和机器人的时候拥有它们。”\n什么意思？\n由于人口下降，未来会缺少劳动力。但 AI 正好可以补上这个缺口!\n不是 \u0026ldquo;AI 抢走工作\u0026rdquo;，而是 \u0026ldquo;AI 填补空缺\u0026rdquo;。\n人类工人不会变得廉价，而会变得更加稀缺和珍贵。\n关于 \u0026ldquo;大规模失业\u0026rdquo; 的经济学真相\n很多人担心 AI 会导致大规模失业。Marc 用经济学原理做了清晰的分析：\n场景一：渐进式改变 (最可能)。\n即使 AI 让生产力增长提高 3 倍，也只是把我们带回到 1870-1930 年的水平。那个时代的人觉得世界 \u0026ldquo;充满机遇\u0026rdquo;，年轻人能开创新领域、建立新产业。\n场景二：激进式改变 (乌托邦版本)。\n如果 AI 真的彻底改变一切：\n生产力暴增 → 产出大幅增加。\n成本下降 → 商品价格暴跌。\n价格暴跌 = 所有人实际财富大增。\n即使有失业，社会保障成本也会大幅下降 (因为医疗、住房、教育都变便宜了)。\nMarc 说：无论哪种情况，都不会出现 \u0026ldquo;所有人都变穷\u0026rdquo; 的反乌托邦场景。\n关键洞察：“不要只看’工作流失’，要看’任务流失’。工作会比单个任务存在得更久。”\n举个例子：过去高管有秘书打字、发邮件。现在高管自己发邮件，但秘书职位还在，只是任务变成了行程规划、活动组织等。职位名称还在，但内容已经改变。\n# 04\n个人如何适应 AI 时代？\nMarc 正在教他 10 岁儿子什么？\nMarc 有一个 10 岁的儿子，在家自学教育。他的教育理念透露了对未来的深刻洞察。\n核心理念：培养 \u0026ldquo;超级个体\u0026rdquo;。\nAI 会让 \u0026ldquo;好\u0026rdquo; 的人变成 \u0026ldquo;非常好\u0026rdquo;，但更重要的是，会让 \u0026ldquo;非常好\u0026rdquo; 的人变成 \u0026ldquo;惊人地好\u0026rdquo;。\n区别在哪里？\n普通人 + AI = 工作效率提高 2 倍。\n顶尖人才 + AI = 工作效率提高 10 倍、100 倍甚至 1000 倍。\n所以教育的目标不是培养 \u0026ldquo;还可以\u0026rdquo; 的人，而是培养在某个领域深度扎根、能够充分驾驭 AI 的 \u0026ldquo;超级个体\u0026rdquo;。\n“主动性”(Agency) 的重要性\nMarc 提到硅谷最近很流行一个词：Agency (主动性)。什么意思？就是：\n主动去做事情，而不是等别人告诉你。\n对事情负全责。\n能够领导项目、创造新事物。\n为什么这个词突然流行？\n因为过去几十年，我们的文化过度强调 \u0026ldquo;遵守规则\u0026rdquo;。学校系统、企业系统都在训练人 \u0026ldquo;听话\u0026rdquo;、“按流程办事”。但 AI 时代需要的是：能够驾驭 AI 工具、做出独立判断、创造新价值的人。\nMarc 给儿子的教育方针：\n“AI 应该是有主动性的孩子的终极杠杆。它让你能够成为主要贡献者 —— 从物理学到编程到艺术到写作，在任何领域都能完全参与、真正改变世界。”\n教育的革命：AI 导师\nMarc 提到一个被验证了几百年的事实：一对一辅导是最有效的教育方式。\n亚历山大大帝的老师是亚里士多德 —— 他征服了世界。\n历史上所有的皇室、贵族都给孩子配一对一导师。\n教育学研究证明：一对一辅导能让学生从 50 百分位提升到 99 百分位。\n但问题是：只有最富有的人才负担得起一对一导师。\nAI 改变了这一点！现在，任何孩子都可以：\n和 AI 无限对话，问无限多的问题\n得到即时反馈\n让 AI 根据自己的理解程度调整难度\n让 AI 出题测验自己\nMarc 的建议：\n“家长们，现在就是时候了！让孩子在传统教育基础上，加上 AI 一对一辅导。”\n他还推荐了一个新型私立学校系统叫 Alpha School，结合线下教师和 AI 辅导。\n学什么技能？关键不在于 “学什么”，而在于 “怎么学”\nMarc 强调：关键是让 AI 教你。\n“人们还没有充分意识到这一点：你应该把每一个空闲时间都用来和 AI 对话，让它训练你。”\n不要只想着 “让 AI 帮我做事”，更要想着 “让 AI 教我做事”。两个具体技巧：\n观察 AI 的思考过程：当 AI 写代码或设计时，看它怎么思考、怎么做决策，这本身就是学习。\n遇到问题后复盘：解决问题后问 AI：“我本来可以怎样避免这个错误？我应该怎么问你？”\n# 05\n“墨西哥对峙”—— 产品经理、工程师、设计师的未来\n三角对峙的新格局\nMarc 用了一个电影场景来形容现在的情况：想象三个人，每个人都用枪指着另外两个人。这就是 “墨西哥对峙”。\n现在，产品经理、工程师、设计师之间就是这种关系：\n每个工程师都认为：有了 AI，我可以自己做产品管理和设计。\n每个产品经理都认为：有了 AI，我可以自己写代码和做设计。\n每个设计师都认为：有了 AI，我可以自己做产品和写代码。\nMarc 的结论震撼：他们都是对的！AI 确实在这三个领域都已经很优秀了。\n“E 形人才”—— 新的职业模型\n过去我们说 “T 形人才”：一个领域很深，其他领域了解一点。\nMarc 提出了新模型：我把它叫 “E 形人才”(E 横着放)—— 至少在两个领域很深，最好三个都精通。\n这个理论来自《呆伯特》漫画的作者 Scott Adams (刚刚去世，愿他安息)。Scott 说过：\n“我可以成为还不错的漫画家，也可以成为还不错的商业人士。但正是因为我既懂漫画又懂商业，我才创造出了呆伯特 —— 世界上最成功的商业漫画之一。”\n关键洞察：\n擅长两件事的价值 \u0026gt; 2 倍\n擅长三件事的价值 \u0026gt; 3 倍\n为什么？因为你成为了 “领域组合” 的稀缺专家。\n好莱坞也在经历同样的对峙\nMarc 说好莱坞也有一个三角对峙：\n导演说：AI 能写剧本、能生成演员，我不需要编剧和演员了。\n编剧说：AI 能导演、能生成演员，我不需要导演和演员了。\n演员说：AI 能写剧本、能导演，我只需要表演就够了。\n结果：他们也都是对的！未来会有更多人能够 “既写又导”，或者 “既演又导”，或者三者兼具。这些人会成为行业的超级明星。\n“任务” vs “工作”—— 关键区别\nMarc 引用经济学家的分析：\n“工作的原子单位不是‘工作’，而是‘任务’。工作是一组任务的集合。”\n当技术改变时：\n先改变的是任务。\n任务改变到一定程度，工作定义才改变。\n职位名称可能不变，但内涵已经完全不同。\n经典案例：高管和秘书\n1970 年代：高管口述，秘书打字。\n1990 年代：高管还是口述，秘书用电脑打字。\n2000 年代：邮件出现，秘书打印邮件给高管看，高管手写回复，秘书再打字发送。\n2020 年代：高管自己发邮件，秘书做行程规划、活动组织。\n职位还在，但任务已经完全改变。\n如何成为 “不可替代” 的人？\nMarc 的朋友、经济学家 Larry Summers 说：\n“职业规划的关键是：不要让自己变得可替代 (fungible)。”\n如果你只是 “产品经理” 或 “工程师” 或 “设计师”，理论上你是可以被替换的。\n但如果你是 “既能编程又能设计” 的人，或 “既能管理产品又能写代码” 的人，你就变得不可替代了。\nMarc 的具体建议：\n在一个领域扎得很深 (这是你的根基)。\n用 AI 学习其他 2 个领域 (让 AI 教你)。\n不断扩大你的能力范围。\n10 年后，你的职位可能叫 “产品构建者” 或 “AI 协调员”，但你将成为极少数能够真正驾驭 AI 创造新产品的人。\n# 06\n编程的未来 —— 是消失还是进化？\n“计算器” 曾经指的是人\nMarc 讲了一个很多人不知道的历史：\n在电子计算器发明之前，“Calculator”(计算器) 这个词指的是人 —— 专门做数学计算的人！\n保险公司算精算表、军队算后勤，都要雇佣成百上千的 “人肉计算器”，坐在房间里手工计算。然后：\n出现了电子计算机，但只能用机器码 (0 和 1) 编程。\n后来有了汇编语言。\n再后来有了 C 语言。\n再后来有了 JavaScript、Python 这些 “脚本语言”。\n关键点来了：\n当脚本语言出现时，用 C 语言的 “真正程序员” 们嘲笑它们：\n“这不是真正的编程！”\n“太慢了！不会规模化！”\n“真正的程序员要管理内存！”\n但现在，大部分编程都用脚本语言完成。\nAI 编程是下一层抽象\nMarc 的观点：AI 编程只是下一层抽象，不是终结，而是进化。\n以前：程序员手写机器码。\n后来：程序员手写汇编语言。\n再后来：程序员手写 C 语言。\n再后来：程序员手写 Python。\n现在：程序员指挥 10 个 AI 编程助手。\n顶尖程序员现在的一天是这样的：\n打开 10 个终端窗口，每个运行一个 AI 编程助手。\n在不同窗口之间切换。\n和 AI “辩论” 代码应该怎么写。\n调试 AI 生成的代码。\n改变需求，让 AI 重新生成。\nMarc 对他 10 岁儿子说：\n“你仍然需要学习如何手写代码。为什么？因为如果你不懂代码，你就无法评估 AI 给你的代码是好是坏。”\n类比：\n即使你用 Python，你也要理解底层的计算机是怎么工作的。\n即使 AI 帮你写代码，你也要理解代码的逻辑和架构。\n两种选择，两种未来\nMarc 说得很直白：\n选择 1：平庸的程序员路线\n让 AI 生成代码，不管三七二十一就用。\nAI 会生成无限多的平庸代码。\n你会成为平庸的程序员。\n选择 2：顶尖程序员路线\n深入理解计算机科学的每一层。\n理解芯片、网络、算法。\n理解 AI 本身是如何工作的。\n用 AI 让自己成为 10 倍、100 倍、1000 倍效率的程序员。\n未来 10 年，顶尖程序员和普通程序员的差距会从 2-3 倍变成 100-1000 倍。\n设计的未来：从 “画图标” 到 “大写的设计”\n对设计师来说，情况类似：\n任务层面：\nAI 可以生成 1000 个图标设计。\nAI 可以做 UI 布局。\nAI 可以做配色方案。\n战略层面 (大写的 Design)：\n这个产品是为了什么？\n它如何融入人们的生活？\n它会让人感觉好吗？\n它会挑战用户吗？还是让用户舒适？\nAI 会接管任务层面，人类设计师会专注于战略层面。\n一个 25 岁的设计师，如果充分利用 AI，10 年后可能成为 “史上最好的设计师”，因为：\n有更多时间思考高层次问题。\n有 AI 处理所有细节执行。\n能够做到过去顶级设计师做不到的事情。\n# 07\n创业的未来 ——“一人十亿美元公司” 可能吗？\n创业的三个层次变化\nMarc 说最前沿的创业者正在三个层次上思考 AI：\n层次 1：AI 如何重新定义产品？\n历史上每次技术转型都会发生这个：\nPC 时代：软件从大型机转移到个人电脑\n移动时代：软件从 PC 转移到手机\nAI 时代：很多产品会被彻底重新定义\n例子：图像编辑\n传统：Adobe Photoshop 编辑图片\nAI 时代：可能不再 \u0026ldquo;编辑\u0026rdquo;，而是直接让 AI 生成新图片\nMarc 说：有时候生成一张新图片比编辑旧图片更容易。\nAI 如何改变团队构成？\n过去需要 100 个程序员的项目，现在可能只需要 10 个 (但是超级强大的 10 个)\n或者：还是 100 个，但生产力提高 10 倍\nAI 如何改变 “公司” 的定义？\n这是最激进的思考：\n“能不能有这样的公司：创始人一个人，用 AI 做所有事情？”\n历史上有几个案例：\n比特币：中本聪一个人 (或小团队)\nInstagram：被 Facebook 以 10 亿美元收购时只有 13 个员工\nWhatsApp：被收购时团队极小\n但 Marc 说，他认识的一些创始人正在追求：“一个人，10 亿美元估值，全部业务由 AI 运行”。\n关于 AI 时代的护城河、竞争格局、市场结构，Marc 难得地说了很多次 \u0026ldquo;我不知道\u0026rdquo;。\n为什么？因为变化太快，变量太多。他举例：\n3 年前 ChatGPT 推出，大家以为 OpenAI 会一家独大\n1 年半后，美国有 5 家公司做出同等水平的模型\n中国有 5 家公司做出同等水平的模型\n还有无数开源模型\nDeepSeek 的出现更是震撼：一个中国对冲基金用很少的钱，复制了美国顶级实验室的成果，还有自己的创新。\nMarc 的教训：“在巨大的技术变革时期，不要过度预测。要保持灵活和适应性。”\n他说硅谷历史上有 9 次重大技术浪潮：\n1950 年代：芯片制造\n个人电脑\n软件\n互联网\n移动互联网\n云计算\n社交媒体\n加密货币\n现在是：AI\n每一次转型，都有无数 \u0026ldquo;专家\u0026rdquo; 做出自信的预测，但回头看，几乎所有预测都错了。\nMarc 的策略：不是押注某一个具体结果，而是押注整个生态系统。\n投资很多公司，支持很多实验，让最聪明的人尝试最疯狂的想法。这叫 \u0026ldquo;不确定的乐观主义\u0026rdquo;。\n对普通人的启示\n你可能会想：“我又不是创业者，这些和我有什么关系？” 关系大了!\n启示 1：不要把职业生涯押注在单一技能上\n就像 Marc 说的 \u0026ldquo;E 形人才\u0026rdquo;，你需要至少 2 个领域的深度。公司格局在变，你的技能组合也要变。\n启示 2：保持学习和适应的能力\n10 年后什么最值钱？不是你现在掌握的具体技能，而是你快速学习新技能的能力。而 AI 是最好的学习工具。\n启示 3：参与实验，不要等 \u0026ldquo;标准答案\u0026rdquo;\n未来没有标准答案。唯一的答案是：尝试、快速失败、快速学习、再尝试。\n# 08\nAGI (通用人工智能)—— 被误解的概念\n两种定义的 AGI\nMarc 说 AGI 有两种定义，经常被混为一谈：\n宏大定义 (奇点)：\nAI 开始自我改进\n机器比人类思考快得多\n人类判断变得无关紧要\n进入 \u0026ldquo;奇点\u0026rdquo;，世界规则彻底改变\n务实定义 (行业标准)：\nAI 能完成所有经济上有价值的任务\n或者说，能完成 \u0026ldquo;最有价值的 10-15 个经济任务\u0026rdquo;\nMarc 的观点：\n宇宙级定义夸大了会发生的事\n行业级定义低估了会发生的事\n超越人类的智能\nMarc 提出了一个更深刻的视角，人类智商的分布：\n类别 智商范围 平均值 100 优秀 115-120 非常优秀 130-140 天才 140-160 爱因斯坦级别 160+ 但这是生物学限制！人脑就这么大，突破不了。AI 没有这个限制： “AI 的智商会达到 160、180、200、250、300… 会远远超过人类智商的上限。” Marc 说：这是好事! 世界上偶尔出一个爱因斯坦，推动人类文明进步 如果我们有 100 个、1000 个、10000 个 \u0026ldquo;爱因斯坦级别的 AI\u0026rdquo;，世界会变得更好，不是更糟 “人类水平” 只是一个过渡点\nMarc 的预测：\n“\u0026lsquo;AI 达到人类水平’只是 2026 年某个星期二的事情，然后我们就会继续前进。真正的问题是：当我们拥有超越人类的能力时，我们能做什么？”\n这不是 \u0026ldquo;AI 取代人类\u0026rdquo;，而是 \u0026ldquo;人类 + 超人类智能的 AI 能创造什么\u0026rdquo;。\n# 09\n给中国听众的特别建议\n作为中国的普通用户，我们该怎么办？我基于 Marc 的观点，给大家一些具体建议：\n立即开始使用 AI 工具\n不要等、不要观望。现在就开始：\n国际工具：ChatGPT、Claude、Cursor (编程)、Midjourney (图像)……\n国内工具：DeepSeek、通义千问、Kimi、豆包\n每天至少花 30 分钟和 AI 对话，万事不决用 AI。\n让 AI 成为你的导师\n不要只把 AI 当作 \u0026ldquo;帮你干活的工具\u0026rdquo;，而要当作 \u0026ldquo;教你技能的老师\u0026rdquo;。具体做法：\n“教我 XXX 的基础知识”\n“我不太理解，能简化一点吗？”\n“现在测试我，看我是否真的理解了”\n“我刚才做错了，我本来应该怎么问你？”\n培养 “E 形技能”\n选 2-3 个相关领域：\n如果你是程序员：学一点产品思维、学一点设计\n如果你是设计师：学一点编程、学一点产品\n如果你是产品经理：学一点代码、学一点设计\n关注 “原子世界” 的机会\nMarc 提到 \u0026ldquo;比特进步快，原子进步慢\u0026rdquo;。在中国，这可能是机会!\n中国在 \u0026ldquo;原子世界\u0026rdquo;(制造业、基建、能源、交通) 有强大的执行能力。如果 AI 能解决监管和协调问题，中国可能在 \u0026ldquo;AI + 制造\u0026rdquo;、\u0026ldquo;AI + 基建\u0026rdquo; 领域领先世界。\n给父母的建议\n如果你是家长：\n不要阻止孩子使用 AI—— 这是他们的未来\n教孩子 \u0026ldquo;主动性\u0026rdquo;—— 不是盲从规则，而是主动创造\nAI 辅导 + 传统教育 —— 两者结合才是最优解\n鼓励深度而非广度 —— 在一个领域扎根很深，然后用 AI 扩展\n# 10\n最重要的心态转变\n从 “工作保卫战” 到 “能力扩张战”\n错误心态：“AI 会抢走我的工作，我要保护我的工作。”\n正确心态：“AI 会让我的能力扩展 10 倍，我要学会驾驭它。”\nMarc 引用的一句话：\n“不要让自己变得可替代。”\n从 “等待指令” 到 “主动创造”\n错误心态：“告诉我该做什么，我去执行。”\n正确心态：“我看到了一个问题/机会，我来解决/抓住它。”\n这就是 \u0026ldquo;Agency\u0026rdquo;—— 主动性。\n从 “单一专家” 到 “跨界高手”\n错误心态：“我是产品经理，我只做产品管理的事。”\n正确心态：“我是产品构建者，我用产品思维 + 技术能力 + 设计感觉创造价值。”\n从 “恐惧变化” 到 “拥抱实验”\n错误心态：“未来太不确定了，我等看清楚了再行动。”\n正确心态：“正因为不确定，我要多实验、快速学习、快速调整。”\nMarc 自己的策略就是：“不确定的乐观主义”—— 我不知道具体哪个会赢，但我知道整体趋势向上，所以我支持所有实验。\n# 最后的话\n我们迎来历史的十字路口\nMarc 说，我们站在一个历史性时刻。不是夸张，而是真实的。回顾一下今天的核心信息：\n关于现状：\n过去 50 年技术进步其实很慢\n人口正在萎缩\nAI 来得正是时候\n关于未来：\n不是 \u0026ldquo;AI 取代人类\u0026rdquo;，而是 \u0026ldquo;AI 补位 + 增强人类\u0026rdquo;\n人类工人会变稀缺，不是过剩\n物价会下降，生活会改善\n关于个人：\n培养 \u0026ldquo;超级个体\u0026rdquo;\n建立 \u0026ldquo;E 形技能\u0026rdquo;\n让 AI 成为你的导师和杠杆\n关于心态：\n主动性 \u0026gt; 听话\n跨界 \u0026gt; 专业\n实验 \u0026gt; 等待\n不确定的乐观主义 \u0026gt; 确定的悲观主义\nMarc最后说的一句话，让我印象深刻：\n“AI是哲人石——把世界上最常见的东西(沙子)变成最稀有的东西(思想)。而每个人都可以使用这个哲人石。”\n牛顿终其一生寻找的哲人石，我们这代人拥有了。\n问题只在于：你会用它做什么？\n以上，既然看到这里了，如果觉得不错，随手点个赞、在看、转发三连吧，如果想第一时间收到推送，也可以给我个星标⭐～\n谢谢你看我的文章，我们，下次再见。\n- END -\n分享、点赞、在看，3 连 3 连！ ","date":"1 February 2026","externalUrl":null,"permalink":"/posts/%E5%8F%B2%E6%97%A0%E5%89%8D%E4%BE%8B%E7%A1%85%E8%B0%B7%E6%95%99%E7%88%B6%E6%8F%AD%E7%A7%98ai%E6%97%B6%E4%BB%A3%E7%94%9F%E5%AD%98%E6%B3%95%E5%88%99%E8%B6%85%E7%BA%A7%E4%B8%AA%E4%BD%93plusaieq10%E4%BA%BF%E7%BE%8E%E9%87%91%E4%B8%80%E4%BA%BA/","section":"AI-Related Reposts","summary":"","title":"[Repost] 史无前例！硅谷教父揭秘AI时代生存法则：超级个体+AI=10亿美金一人公司，未来只剩\"E形人才\"！如何不被AI淘汰？","type":"posts"},{"content":"Reposted from 说实话，科研人真没必要熬夜翻PDF：Gemini 3.0这3个检索功能我藏不住了 by 小虚竹说技术\n说实话，Gemini 3.0 在文献检索和管理这件事上，真的有点“外挂”味道 😎 原因很简单：它是直接连着 Google Search 的 🔥 # 所以它不只是陪你聊天的 AI， 而是能实时进学术圈帮你找资料、筛论文、做整理的那种狠角色。\n下面我就按你提到的 「三项任务」， 给你整理了一套可以直接照抄照用的实操流程 ✅\n👉 每一步我都配好了可复制的提示词，拿走就能用，不用自己琢磨。\n1. 语义搜索 # 以前做文献检索，最让人头疼的就是拼那些 AND、OR 逻辑词，既累脑子又不一定能得到理想的结果。现在，可以彻底改变这种做法了：把“关键词搜索”变成“自然语言提问” 🧠✨\n只要你开启了 Gemini 的联网功能（Google 搜索扩展），就能像和导师交流一样，直接阐述研究背景、问题和你想要的结果。\n过去我们可能只能输入类似的查询：Machine learning AND climate change结果是：信息多得很，但杂乱无章，还得自己挑选筛选。\n现在完全不一样了 👍 你只需要用一个更完整、指令感强的提示词模板，一次性表达需求，Gemini 就能帮你处理文献检索、筛选和整理等工作，效率直接翻倍 🚀\n推荐使用的 Prompt（可直接复制填空）：\n**“我正在进行关于 **[填入你的研究方向，例如：机器学习在气候变化预测]** 的研究。 请你利用 Google 搜索和学术数据库，帮我找出过去 **[3]** 年内，针对 **[具体细分领域，例如：极端天气事件预测]** 表现最好的几种 **[技术/方法，例如：深度学习架构]**。**请按以下格式输出结果：** 1. **领域综述：** 先用一段话概括目前的主流技术路线（例如：是用 Transformer 处理时间序列，还是用 GNN 处理空间数据？）。 2. **精选列表：** 列出 5-10 篇最具代表性的论文。 3. **核心解读：** 对每篇论文，请提供标题、发表年份、来源链接，并用**一句话精准总结**它的核心贡献或解决了什么具体痛点（例如：‘解决了降水预测中的长尾分布问题’）。” 这套流程做完后，最后得到的不是一堆零乱的论文，而是一份精心筛选过、理清逻辑、提炼了核心观点的文献清单。基本上，相当于直接告诉你：现在大家都在研究哪些方向，哪些重点最值得跟进。用的时候直接点开链接查看，省时省力又省脑力 👍\n2. 关联图谱构建 # Gemini 虽然做不到像 Connected Papers 那样，直接甩你一张炫酷的引用“泡泡图”， 但说真的，这完全不影响它拿来干活✨。\n因为我们真正需要的，其实不是图有多花哨，而是它梳理逻辑的能力够不够强。\nGemini 最厉害的地方，就是能帮你快速搭出一份文字版的「学术脉络图」， 反而效率更高。\n通过这种方式，你能很快看清一个理论到底：\n最早是谁提出来的？\n中间经历了哪些关键演变？\n是怎么一步步发展成今天这个样子的？\n而不是只盯着最近最火的几篇论文🔍。\n如果你想深挖某个理论的“鼻祖”，顺藤摸瓜，把那些被时间埋住的经典论文和思想源头都挖出来，那就直接用下面这个指令，让 Gemini 帮你全部梳出来👇\n提示词：\n溯源 Prompt（可直接复制填空）：“关于 \\[填入核心概念，例如：思维链 (Chain-of-Thought)\\] 这一概念，在这个术语正式大火之前，有哪些具有奠基意义的早期论文？ 请利用网络搜索，帮我梳理一条从 \\[起始年份，如 2015\\] 到 \\[截止年份，如 2022\\] 的技术演进脉络。请详细说明每一篇关键论文是如何启发后者的，它们之间存在怎样的继承或修正关系。”\n如果你已经有一篇经典论文，想知道最近大家怎么在这篇论文的基础上做改进、在哪些方向上有新突破，或者有没有指出它的不足，其实可以通过这种方式快速搞清楚。\n这相当于帮你做了一次智能筛选文献🤖：那些只是随便引用、凑数量的文章会被自动剔除，你只会看到真正有价值的后续研究，轻松锁定高质量的工作，效率直接拉满🚀。\n提示词：\n追踪 Prompt（可直接复制填空）：“以 \\[填入经典论文标题，例如：Google 的《Attention Is All You Need》\\]为核心，请帮我找出 \\[填入年份范围，如 2024-2025\\]年引用了这篇文章，并且在 \\[填入具体细分方向，例如：‘计算效率优化’或‘线性 Attention’\\]方面做出了最重要突破的 5 篇论文。 请重点告诉我：这些新论文具体是如何改进原版方法的？它们解决了原论文的哪些局限性？”\n3. 跨语言检索 # 跨语言检索，真的算是 AI 最爽、最省力的使用场景之一 🚀\n很多冷门方向，中文资料少到几乎查不到，但这事儿在 AI 面前根本不算问题。我们用中文想问题，把啃英文资料这种体力活直接甩给 Gemini 就行了。\n玩法也很简单，核心就一句话： 👉 「英文搜索，中文回答」\n规则一旦定死，后面的流程就全自动了： 从专业术语理解、英文论文消化，到最后的中文总结和逻辑重组，Gemini 全包。 我们只需要负责提问 + 理解结果，效率直接起飞 ⚡️\n如果你想再狠一点，下面这个「加强版 Prompt」非常好用， 可以直接把 Gemini 调教成一个 多语言科研助理 🧠✨\n不管是完全陌生的新领域，还是冷门又偏门的研究方向，都能帮你快速搞清：\n背景是啥\n核心概念有哪些\n关键脉络怎么串\n一句话总结：又省时间，又省脑子，还特别稳。 😎\n提示词：\n**跨语言调研 Prompt（可直接复制填空）：**“请你扮演一名资深的 **[填入你的学科，例如：材料科学]** 研究员。 1. **检索：** 请用**英文**在 Google Scholar 和学术网络上，深度搜索关于 **[填入具体课题，例如：MXene 材料在海水淡化中的膜污染机制]** 的最新高质量文献，时间范围限定在 **[填入年份，如：2023年至今]**。 2. **阅读与分析：** 请仔细阅读这些英文文献的摘要或结论部分，提取关键信息。 3. **中文报告：** 请用**中文**为我撰写一份约 **[500]** 字的综述简报。 4. **简报内容要求：** - **核心现状：** 目前学术界对该问题的主流观点是什么？ - **关键争议：** 不同的研究团队之间存在哪些主要的矛盾或未解之谜？ - **方法论：** 目前最常用的表征手段或实验方法有哪些？ 6. **参考文献：** 请在简报最后列出你参考的文献的**英文原名**及链接，方便我进一步查阅。” 简单来说，这个指令让 Gemini 先理解中文，再用学术英语查资料。它会自动将你的中文需求转化成精准的英文搜索词（像是 membrane fouling mechanism 这种标准术语），然后快速扫描大量英文摘要，把零散的信息整理和融合，最后输出一份符合中文学术写作习惯的报告 📚。\n这样，你就能：\n不用再纠结怎么用专业英文表达\n避开生硬的机器翻译\n还能得到带文献出处的深度总结\n总结：少走弯路，信息密度满满，效率直接飙升 🚀\n进阶技巧：结合 Gemini 的长上下文窗口 # 如果你手里有一堆PDF论文，不必再一篇一篇手动翻找资料了！借助 Gemini 3.0 的强大长上下文能力，你完全可以把它当作一个私人知识库管理员来帮你处理课题相关的一切信息 🤖📚。\n使用方法很简单： 只需要点击对话框中的 “+”，把所有论文批量上传。这样就相当于你迅速搭建了一个基于本地论文的语义搜索引擎。上传后，AI 会帮你自动处理论文间的关联和细节对比。\n接着，使用下面这 两个增强版指令，你就能轻松完成👇\n不同论文之间的观点交叉验证\n关键实验结果、指标、结论的批量提取与对比\n整个过程下来，文献查找从“体力活”变成了“动嘴活” 😄，效率提升非常明显！\n提示词：\n观点梳理 Prompt（可直接复制填空）：“基于我上传的这些文献，请深度分析它们对 \\[填入具体假设或争议点，例如：‘A 药物对 B 通路的抑制作用’\\] 的态度。 请明确指出：\n哪几篇论文（列出标题）是支持该假设的？\n哪几篇是反对或提出质疑的？\n请务必引用原文中的关键句子作为证据，并标注出现在的页码，以便我核对。”\n数据提取 Prompt（可直接复制填空）：“请仔细阅读这 \\[数量\\] 篇论文的实验方法（Methods）和结果（Results）部分，为我生成一个详细的横向对比表格。 表格的列名应包含：论文标题、**\n\\[参数 1，如：反应温度\\]、\n\\[参数 2，如：催化剂用量\\]**、以及\n\\[关键结果，如：最终产率/P值\\]。 注意：如果某篇论文中没有明确提及某个参数，请在表格中标记为‘N/A’，不要臆测。”\n国内直接使用Gemini 3 Pro # ✅ 界面：Gemini官网的 1:1 完美复刻。（后台是Gemini 200美金/月的Ultra和20美金/月的pro会员。）\n✅ 国内直连：无需魔法，开通即用\n✅ 支持Gemini 3 Pro、Gemini 3 Flash、Nano Banana Pro、Veo 3.1、Deep Research、Deep Think、Canvas\n在这里插入图片描述\n操作指导 # AI平台 国内直接访问地址：https://gemini.xiaoxuzhu.cn/ 【输入授权码】登录【选择空闲的车，点击进入】 感受 # 好用的功能太多太多，我就不在这个一一列举了，有兴趣的可以自行尝试。\n有提供免费的授权码可体验～\n有提供免费的授权码可体验～\n有提供免费的授权码可体验～\n私信虚竹哥，获取体验码~ 国内可直接使用：https://gemini.xiaoxuzhu.cn/\n在这里插入图片描述\n我是虚竹哥，目标是带十万人玩转AI。\n长按识别下方二维码，备注：gemini体验。。\n发你免费gemini体验码： 回复【gemini体验】,获取\nGemini 3 Pro、\nGemini 3 Flash、\nDeep Research、\nDeep Think、\nCanvas、\nNano Banana Pro【画图超强】、\nVeo 3.1【做视频超强】\n国内直接使用 gemini体验码：\n","date":"1 February 2026","externalUrl":null,"permalink":"/posts/%E8%AF%B4%E5%AE%9E%E8%AF%9D%E7%A7%91%E7%A0%94%E4%BA%BA%E7%9C%9F%E6%B2%A1%E5%BF%85%E8%A6%81%E7%86%AC%E5%A4%9C%E7%BF%BBpdfgemini/","section":"AI-Related Reposts","summary":"","title":"[Repost] 说实话，科研人真没必要熬夜翻PDF：Gemini 3.0这3个检索功能我藏不住了","type":"posts"},{"content":"","date":"1 February 2026","externalUrl":null,"permalink":"/tags/education/","section":"Tags","summary":"","title":"Education","type":"tags"},{"content":"","date":"1 February 2026","externalUrl":null,"permalink":"/tags/prompt/","section":"Tags","summary":"","title":"Prompt","type":"tags"},{"content":"Powered by Canvas of Gemini 3 Pro.\nSTART! ","date":"31 January 2026","externalUrl":null,"permalink":"/game/chiikawa%E7%BE%8E%E9%A3%9F%E5%AE%B6/","section":"AI-Generated Games","summary":"","title":"Chiikawa美食家","type":"game"},{"content":"Powered by Veo of Gemini 3 Pro.\nYour browser does not support the video tag. ","date":"31 January 2026","externalUrl":null,"permalink":"/videos/saychinese/","section":"AI-Generated Videos","summary":"","title":"让我们说中文","type":"videos"},{"content":"Powered by Nano Banana Pro.\n","date":"31 January 2026","externalUrl":null,"permalink":"/pic/sphinx/","section":"AI-Generated Pictures","summary":"","title":"Sphinx!","type":"pic"},{"content":"On this website, I show a few articles based on the response from Gemini.\n","date":"31 January 2026","externalUrl":null,"permalink":"/blog/","section":"AI-Generated Blog","summary":"","title":"AI-Generated Blog","type":"blog"},{"content":"Reposted from Day80 5天冲到安装量第二名，这个Skill到底藏了什么秘密 by 贺伯AI实战笔记\n10年工程师｜AI大龄学徒｜车间里的__建模狂人\n👆点击上方蓝字 关注公众号\n挑战日更100天，今天是日更第86天\nHi 大家好，我是贺伯，一个初学AI编程与工作流的工厂IE，每天分享使用Vibe coding跟n8n工作流的实战过程\n-\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n这两天在翻 skills.sh 仓库，发现一个怪事——有个 Skill 像开了挂一样往上冲\n才发布 5 天，安装量直接杀到第二名，差点就超过霸榜王者 vercel-react-best-practice\n这玩意儿叫 find-skill\n它到底是干嘛的 # 简单说：一个帮你找 Skill 的 Skill（有点套娃）\n用过 Claude Code 的都知道，Skill 生态越来越大，好用的插件藏在各个角落。以前找插件是啥流程？\n翻 GitHub、数星星、闭眼赌一把——标准操作\n现在一条命令就能搞定\n安装完之后会看到一堆可用指令\n怎么装 # 贼简单，在 Claude Code 里跟它说一句：\n请帮我安装这个 skill https://github.com/vercel-labs/skills\n等几分钟就完事\n装完之后它还会告诉你怎么用——相当体贴\n实测效果 # 场景1：找网页搜寻相关的 # 输入：\nnpx skills find 网页搜寻 结果：哗啦啦出来一堆相关 Skill，还给你标注好安装量\n2.6K 安装量 vs 个位数 的那些——你选哪个？不用纠结\n（这不就是工厂选供应商的逻辑嘛，出货量大的才靠谱）\n场景2：找网页爬虫相关的 # 输入：\nnpx skills find 网页爬虫 给出了不少好用的爬虫 Skill 建议\n场景3：小红书相关 # 输入：\nnpx skills find 小红书 立马给你匹配到对应的 Skill，不用自己一个个翻仓库\n我的观察 # 翻了一圈排行榜发现个规律：前几名基本都是 vercel-labs 出品\n这帮人真的在霸榜\n从原本的手动翻仓库，到现在一条命令解决问题，效率提升不是一点点\n整个 Skill 生态正在变得越来越完善\n搜索、安装、更新——全都有对应的命令\n我的看法 # 这个工具解决的是信息筛选的问题（工厂里叫\u0026quot;供应商评估\u0026quot;）\n以前：自己翻 GitHub，看 star 数，猜测靠不靠谱\n现在：直接看安装量排名，大家用脚投票的结果\n省下来的时间，够我多折腾两个项目\n前几天看到 skills.sh 这个网站时，就想弄一个类似功能的工具——比如我需要建构一个网站，可以用哪些 skill\n结果今天就出来类似的东西，距离上一篇文章才过去不到一周\n随着 AI 编程的进展，从想法到落地的时间只会越来越快\n（目前还在持续测试中，后续有坑再分享）\n📝GOLDEN\n好工具不是让你多干活，而是让你少做选择\n以上是今天的分享\n明天继续折腾 Skill 生态，看看还有什么宝藏\n-\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n在学习AI编程的路上，老徐AI编程做产品的知识星球给了很多的帮助\n每个月都有训练营可以参加( 参加星球的伙伴们免费)\n基本上0基础的小白都能轻易地入门(就是我啦)\n想要一起加入AI编程的行列，但是又没有好的入门管道的朋友们，欢迎一起加入切磋\n留言或后台私信\u0026quot;AI编程\u0026quot;，将提供过去这几个月以来，学习AI编程的一些资讯以及创建的个人知识库(每日更新)\n【ima知识库】AI编程工具资料库 https://ima.qq.com/wiki/?shareId=2e1dc0ad31a15e3fc6e8b1954f4c0647ba3bd6ee86244230246d4933d160a02f\n我用Google Antigravity开发工具的过程请参考\nDay18 手把手教你安装Google Antigravity！搭配Gemini 3.0 Pro，编程效率翻倍\nDay19 Google AI Studio+Anitgravity黄金组合！零基础也能搞定代码复刻\nDay20: Google Antigravity界面到输出全中文改造，小白也能秒上手\nDay21: 设置3步搞定！让你的Google Antigravity从此自动写代码、自测运行\nDay22 : Google AI Studio 从Build到Anitgravity，程序员会被全链路“承包”吗？\nDay23 超详细！Supabase配置GitHub/Google登录指南，附Claude对话秘籍\nDay28 终极对决!Anitgravity双核驱动:Claude Opus 4.5硬刚Gemini 3.0 Pro\nDay29 无需切换工具！Claude+Gemini交叉评估，高效产出PRD的终极工作流\n我是贺伯，一个35+的工厂IE主管，正在用工业思维拆解AI编程，每天记录我从0基础到用AI赚到第一块钱的全过程。\n","date":"31 January 2026","externalUrl":null,"permalink":"/posts/day80-5%E5%A4%A9%E5%86%B2%E5%88%B0%E5%AE%89%E8%A3%85%E9%87%8F%E7%AC%AC%E4%BA%8C%E5%90%8D%E8%BF%99%E4%B8%AAskill%E5%88%B0%E5%BA%95%E8%97%8F%E4%BA%86%E4%BB%80%E4%B9%88%E7%A7%98%E5%AF%86/","section":"AI-Related Reposts","summary":"","title":"[Repost ] Day80 5天冲到安装量第二名，这个Skill到底藏了什么秘密","type":"posts"},{"content":"Reposted from LangChain 创始人警告：2026 成为“Agent 工程”分水岭，传统软件公司的生存考验开始了 by 微信公众平台\n来源：AI前线\n编译：Tina\n过去几十年，软件工程有一个稳定不变的前提：系统的行为写在代码里。工程师读代码，就能推断系统在大多数场景下会怎么运行；测试、调试、上线，也都围绕“确定性”展开。但 Agent 的出现正在动摇这个前提：在 Agent 应用里，决定行为的不再只是代码，还有模型本身——一个在代码之外运行、带着非确定性的黑箱。你无法只靠读代码理解它，只能让它跑起来、看它在真实输入下做了什么，才知道系统“到底在干什么”。\n在播客中，LangChain 创始人 Harrison Chase 还把最近一波“能连续跑起来”的编程 Agent、Deep Research 等现象视为拐点，并判断这类“长任务 Agent”的落地会在 2025 年末到 2026 年进一步加速。\n这也把问题推到了台前：2026 被很多人视为“长任务 Agent 元年”，现有的软件公司还能不能熬过去？就像当年从 on-prem 走向云，并不是所有软件公司都成功转型一样，工程范式一旦变化，就会重新筛选参与者。长任务 Agent 更像“数字员工”——它不是多回合聊天那么简单，而是能在更长时间里持续执行、反复试错、不断自我修正。\n在这期与红杉资本的对话中，Harrison 抛出了一个判断：构建 Agent，已经不只是把软件开发“加一层 AI”，而是工程范式本身在变。为什么他说“光读代码不够了”？为什么 tracing、评估、记忆这些原本偏“辅助”的东西，突然变成主角？他在对话里给出了非常具体的解释。\n而更现实的问题是：如果范式真的在变，那些靠数据、流程、产品形态建立壁垒的传统软件公司，优势还能不能延续？它们手里握着的数据与 API 可能依然是王牌，但能否把这些资产变成 Agent 时代的生产力，取决于一套全新的工程打法。Harrison 的观察与判断，都在下面的完整对话里：\n主持人：AI 领域的变化速度快得惊人。当前最受关注的话题，我觉得没有人比你更合适来聊。我们会先谈 长任务 Agent（Long Horizon Agents） 和 Agent Harness（智能体运行框架）。\n*** 接着，我们会讨论：构建长任务 Agent 与构建传统软件到底有什么不同，以及你如何看待 LangChain 在整个生态系统中的角色。最后，我想和你聊聊未来。你怎么看红杉资本这篇关于 Long Horizon Agents 的文章？哪些观点你认同，哪些地方你不太同意？\n来源：https://sequoiacap.com/article/2026-this-is-agi/\n“在去年的一篇文章中，我们曾提出：推理模型（reasoning models）是 AI 领域最重要的新前沿。而“长任务 Agent”（long-horizon agents）则在这一范式之上更进一步——它们不只是思考，还能够采取行动，并在时间维度上不断迭代。”\nHarrison Chase： 你们这个概念命名得非常好，那篇文章也写得很棒。我整体上是认同的——长任务 Agent 终于开始真正“跑起来”了。\n一开始对 Agent 的设想，本来就是让一个 LLM 运行在一个循环里，自主决定接下来该做什么。\nAutoGPT 本质上就是这个想法，这也是它当初能迅速走红、抓住那么多人想象力的原因：一个 LLM 在循环中运行，完全自主地决定行动。但当时的问题在于：模型还不够好，围绕模型的 scaffolding（支架）和 harness（框架）也不够成熟。\n这几年，模型本身变得更强了；与此同时，我们也逐渐搞清楚了，什么样的 harness 才是“好”的。于是现在，这套东西开始真正奏效了。最明显的例子是在编程领域，Agent 的突破首先发生在那里。之后，这种能力正在向其他领域扩散。\n当然，你仍然需要告诉 Agent 你想让它做什么，它也需要配备合适的工具。但现在，它确实可以持续运行更长的时间，而且表现越来越稳定。所以，用“长时序”来描述这一类 Agent，我觉得非常贴切。\n主持人：你最喜欢的长任务 Agent 案例有哪些？你觉得它们正在呈现出哪些形态？\nHarrison Chase： 目前最成熟、我自己用得最多的，还是 编程 Agent。\n再往外延一点，我觉得非常优秀的一类是 AI SRE。比如 Traversal（我记得它是一家红杉投资的公司），他们的 AI SRE 可以在更长的时间跨度内运行。再往抽象一点，其实这类 AI SRE 本质上属于“研究型 Agent”。比如：给它一个事故，它会去翻日志、分析上下文、追溯原因。研究任务本身非常适合 Agent，因为它们最终产出的往往是一个“初稿”。\nAgent 的问题在于：它们还达不到 99% 的可靠性，但它们可以在较长时间内完成大量工作。所以，只要你能把任务框定为：让 Agent 长时间运行，产出一个初步版本，由人来审阅，这在我看来就是目前长任务 Agent 最“杀手级”的应用形态。\n编程就是一个例子：你通常是提交 PR，而不是直接推到生产环境（当然，vibe coding 现在也在不断进步）。AI SRE 也是一样：结果会交给人来 review。报告生成也是如此：你不会直接发给所有用户，而是先看一遍、改一改。我们在金融领域也看到了大量这样的用法，这是一个非常大的研究机会。客服领域同样如此。最早的客服 Agent 主要是做“第一响应”：用户一发消息，马上给出回复，这类用法现在也做得很好。\n但现在开始出现新的形态，比如 Klarna 这个产品：人类和 AI 协同工作。当第一层自动回复失败后，不是简单地转交给人工，而是让一个长任务 Agent 在后台运行，生成一份完整的事件报告，然后再交给人工客服处理。\n这里“agent”这个词在客服语境下会变得有点混乱，但核心逻辑是一致的。总结来说，这些应用的共同点是：先由 Agent 生成一个“初稿”，再由人类接管。\n主持人：那么，“为什么是现在”？你觉得主要是因为模型本身变得足够强，还是因为人们在 harness 侧做了非常聪明的工程设计？在回答这个问题之前，能不能先帮听众梳理一下：在一个 Agent 系统中，模型、框架和 harness 各自扮演什么角色？\nHarrison Chase： 当然可以。我也顺便把“框架”这个概念一起带进来。一开始，我们把 LangChain 描述为一个 Agent Framework，现在我们又推出了 Deep Agents，我更愿意称它为一个 Agent Harness。\n很多人都会问，这两者有什么区别。模型很简单，就是 LLM：输入 token、输出 token。框架（Framework） 是围绕模型的一层抽象，让你更容易切换模型，封装工具、向量数据库、记忆等组件，本身比较“无偏好”，强调灵活性，更像是基础设施。Harness 则更“有主张”。以 Deep Agents 为例：我们默认就提供一个 规划工具（Planning Tool）； 这个工具是直接内建在 harness 里的，带有明确的设计立场：我们认为这是“正确”的做法。\n我们还做了 上下文压缩（Compaction）。 长任务 Agent 会运行很久，哪怕上下文窗口已经很大，也终究是有限的，总会有需要压缩的时候。怎么压缩？压缩什么？这是一个正在被大量研究的问题。\n此外，几乎所有 Agent Harness 都会提供文件系统交互能力，不管是直接操作，还是通过 bash。这一点其实很难和模型本身完全分开，因为模型训练数据里已经大量包含了这类操作。\n如果回到两年前，我不确定我们是否能预见到：基于文件系统的 harness 会成为最优解之一。那时模型还没被充分训练过这些模式，而现在模型和 harness 是在一起“共同进化”的。\n所以总结来说，这是一个组合效应：模型本身确实在变强，推理模型带来了巨大提升。同时，我们也逐渐摸索出了 compaction、planning、文件系统工具等一整套关键原语。这两者缺一不可。\n设计范式的演进\n主持人：我记得在我们第一次对谈时，你把 LangGraph 描述为 Agent 的“认知架构”。现在来看，这是不是也可以理解为 harness 的一种形态？\nHarrison Chase： 是的，这个理解是对的。我们现在的 Deep Agents 是构建在 LangGraph 之上的。可以把它看作是一个非常具体、非常有主张的 LangGraph 实例，更偏向通用目的。\n早期我们讨论过“通用架构”和“专用架构”的区别。现在我们观察到一个很有意思的变化：过去需要写进架构里的任务特异性，正在转移到工具和指令里。\n复杂性并没有消失，只是从结构化代码，转移到了自然语言中。因此，prompt 的设计、修改，甚至自动更新，正在成为系统的一部分；而 harness 本身，反而变得更加稳定。\n主持人：在你看来，harness 工程中最难做对的是什么？你觉得单个公司是否真的有可能在这一层形成显著优势？有没有你特别佩服的团队？\nHarrison Chase： 说实话，目前在 harness 工程上做得最好的，基本都是编程类公司。Claude Code 就是一个非常典型的例子。我认为它能如此受欢迎，很大程度上是因为它的 harness。\n主持人：这是否意味着：harness 更适合由模型公司来做，而不是第三方创业公司？\nHarrison Chase： 我不确定。比如 Factory、AMP 这些编程公司，也都做出了非常强的 harness。\n确实存在一个现实：harness 往往和模型家族绑定得比较紧密。不一定是某一个具体模型，而是一整个模型体系。Anthropic 的模型会针对某些工具进行微调，OpenAI 则针对另外一些。这和 prompt 类似：不同模型，需要不同的 prompt；同样，不同模型家族，也需要稍微不同的 harness。当然，它们也有很多共性，比如几乎都会使用文件系统。\n我自己也没有一个确定答案。但一个很明显的现象是：几乎所有做编程 Agent 的公司，现在都在自研自己的 harness。你去看 Terminal Bench 2 这样的榜单，会发现他们不仅展示模型，还展示 harness。Claude Code 并不总是在榜首。这说明：性能差异并不完全来自模型，而来自对“模型如何在 harness 中工作”的理解。\n主持人：你觉得，排行榜上表现最好的 harness，究竟在哪些地方做得特别好？\nHarrison Chase： 首先是对 模型训练偏好的理解。比如 OpenAI 的模型对 Bash 非常熟悉；Anthropic 提供了显式的文件编辑工具。顺着模型的“母语”来设计 harness，本身就能带来性能收益。\n其次是 上下文压缩（Compaction）。随着任务时间跨度变长，如何处理上下文窗口溢出，已经成为一个核心问题。这显然也是 harness 的一部分。\n此外，还有 skills、子 Agent、MCP 等机制。目前这些能力还没有被系统性地训练进模型中，仍然属于比较新的探索方向。\n在我们的 harness 中，一个典型挑战是：主 Agent 如何与子 Agent 高效通信。主模型需要把所有必要信息传递给子 Agent，同时还要明确告诉它：最终只需要返回一个“最终结果”。\n我们见过一些失败案例：子 Agent 做了大量工作，最后却返回一句“请查看我上面的分析”，而主 Agent 根本看不到那些内容，于是完全不知道它在说什么。\n所以，如何通过 prompt 设计让这些组件协同工作，是 harness 工程中非常重要的一部分。\n如果你去看一些公开的 harness prompt，它们往往有几百行之长。\n主持人：我想从演进角度问一个问题。你一直站在模型“如何落地”的最前沿。如果用一种简化视角来看过去五年的几个关键拐点：ChatGPT 带来了预训练的拐点；o1 带来了推理能力的拐点； 最近，Claude Code + Opus 4.5 带来了长任务 Agent 的拐点。但从你这个“围绕模型做设计”的世界来看，拐点会不会是另一套划分？从认知架构到框架、再到 harness，这中间经历了哪些真正的跃迁？\nHarrison Chase：我大概会把它分成三个阶段。\n第一阶段：最早期。那时 LangChain 刚刚出现，模型还是“纯文本输入、纯文本输出”，甚至还不是 chat 模型。没有工具调用，没有 reasoning，没有结构化输出。人们主要做的是单一 prompt 或简单 chain。\n第二阶段：工具与规划开始进入模型。模型开始支持 tool calling，也尝试学会“思考”和“规划”。虽然还不够强，但已经能做出基本决策。这时，人们大量使用自定义的认知架构，通过显式提问来引导模型行动，但整体仍然依赖大量外部 scaffolding。\n第三阶段：长任务 Agent 的真正起飞。大概是在今年 6～7 月，我们看到 Claude Code、Deep Research、Manus 等产品同时爆发。它们在底层使用的是 同一个核心算法：让 LLM 在循环中运行。\n真正的突破来自于 上下文工程：压缩、子 Agent、技能、记忆——所有这些，都是围绕上下文展开的。这正是我们开始做 Deep Agents 的时间点。\n对于很多程序员来说，Opus 4.5 可能是一个心理上的分水岭。也可能只是碰巧遇上假期，大家回家开始大量使用 Claude Code，突然意识到：它真的很好用。无论是 2025 年初还是 2025 年末，总之在某个时间点，模型“刚好强到足以支撑这种形态”，于是我们从 scaffolding 迈向了 harness。\nCoding Agent 是\n通用 AI 的终局形态吗\n主持人：接下来会发生什么？\nHarrison Chase： 我也希望我知道答案。这个“让 LLM 在循环中运行、让它自己决定要拉什么上下文进来”的算法，本身极其简单、也极其通用。这正是 Agent 从一开始的核心设想，而我们现在终于走到了“它真的能工作”的阶段。\n接下来，可能会有大量围绕上下文工程的技巧出现：有些手动设计的部分可能会消失；比如压缩类的，现在仍然高度依赖 harness 作者的决策。Anthropic 已经在尝试让模型自己决定何时压缩上下文，虽然目前用得还不多。\n另一个我们非常关注的方向是 记忆（Memory）。从本质上说，记忆也是一种上下文工程，只不过是跨更长时间尺度的上下文。核心算法本身已经非常清晰：运行 LLM 循环。未来的进步，很可能来自更聪明的上下文工程方式，或者让模型自己参与上下文管理。模型当然也会继续变强，越来越擅长长时序任务。\n我目前思考最多的一个问题是：我们看到的大多数 harness 都是高度偏向编程任务的。这是长任务 Agent 最先爆发的领域。但即便是在非编程任务中，你也可以认为：写代码本身是一种非常强的、通用的工具。\n主持人：我本来想问你：编程智能体（coding agents）到底算不算一个子类别？还是说编程智能体就是智能体本身？换句话说，智能体的工作，本质上是想办法让计算机去做一些有用的事情，而“写代码”本来就是让计算机做有用事情的一种很好的方式。\nHarrison Chase： 我也不确定。但有一点我非常非常坚信：现阶段只要你在做长时序智能体，你就必须给它文件系统的访问能力。因为文件系统在“上下文管理”方面能做的事情太多了。比如我们说 compaction（上下文压缩），一种策略是把内容总结掉，但把完整的消息都放进文件系统里，这样如果智能体后续需要回查，它还能查到。\n另一种策略是，当你遇到很大的工具调用结果时，不要把全部内容都塞回模型上下文里；你可以把结果放进文件系统，然后让智能体需要的时候再去查。\n而这些操作，其实不一定需要真实的文件系统，也不一定要让它真的去写代码。我们有一个概念叫“虚拟文件系统”：它底层可能只是 Postgres 之类的存储，扩展性更强。当然，“真实代码”能做的事情，虚拟文件系统做不了。比如你没法在虚拟文件系统里直接运行代码。所以写脚本在很多场景下确实非常有用。\n我也认为编程智能体有潜力成为通用智能体，但我不确定这是否意味着“今天的编程智能体”就是通用智能体——如果你能理解我这句话。因为我觉得现在很多编程智能体还是 为编程任务做了大量优化 的。\n所以“一个通用智能体可能长得像编程智能体”，但反过来，“今天的编程智能体就是通用智能体”，这件事我并不确定。\n传统软件面临的挑战\n主持人：那我们能不能转到另一个话题：构建长时序智能体和构建传统软件之间的差异？你能不能先描述一下“1.0 时代”的软件开发栈是什么样的，然后说说现在到底哪里不一样？我记得你在 X 上写过一篇很不错的文章，也许你可以总结一下核心结论。\n来源：https://x.com/hwchase17/status/2010044779225329688\nHarrison Chase： 我这段时间一直在反复想这个问题：我们经常说“做智能体和做软件是不同的”，而且很多人也同意。但问题是：到底哪里不同？\n我觉得很容易、也很偷懒地说“不同”，但“具体不同在哪里”才是关键。下面这些可能听起来很显然，但也许显然是好事，希望它们不太有争议。\n当你在做传统软件时，所有逻辑都写在代码里，你能直接在软件代码中看到它。但当你在做智能体时，你的应用如何工作的“逻辑”，并不全部在代码里，其中很大一部分来自模型本身。\n这意味着：你不能只看代码，就判断智能体在某个具体场景下会做什么。你必须真的把它跑起来。而我认为，这就是最大的不同：我们引入了这种 非确定性系统，它是一个黑箱，它在代码之外。我觉得这就是核心差异。\n一个直接后果是：为了弄清楚应用到底在做什么，你不能看代码，你必须看它在真实运行中做了什么。这也是为什么我们做的产品里，最受欢迎的之一是 LangSmith。LangSmith 的一个核心能力是 tracing（追踪 / 执行轨迹）。为什么 trace 这么受欢迎？因为它能把智能体每一步内部发生的事情都清清楚楚地展示出来。\n而这跟传统软件里的 trace 又不一样。传统软件里，你的系统在那边跑，它会吐出很多日志和事件；你通常是在出现错误时才去看，而且你不需要“每一步的全部细节”。而且本地开发时，你可能直接打个断点就够了；很多时候日志追踪是上线到生产环境后才会更重度开启。但在智能体里，人们从一开始就会用 trace 来理解“底层到底在发生什么”。\n而且它在智能体里的影响力，远大于在单一 LLM 应用里的影响力。因为在单一 LLM 应用里，如果模型回答得不好，你知道你的 prompt 是什么，也知道输入上下文是什么（由代码决定），然后你得到一个输出。\n但在智能体里，它在循环中运行、不断重复。你并不知道第 14 步时上下文里到底有什么，因为前面 13 步可能会把任意东西拉进上下文。所以，“上下文工程（Context Engineering）”真的是一个非常好的词。我真希望这是我发明的。它几乎完美描述了我们在 LangChain 做的一切——只是当时我们并不知道这个术语已经存在。\ntrace 的价值就在于：它能直接告诉你 此时此刻上下文里到底有什么，这太重要了。那这又意味着什么？这意味着：对传统软件来说，“真相的来源（source of truth）”在代码里。但对智能体来说，真相来源变成了代码与 trace 的组合——而 trace 是你能看到真相的一部分地方。\n从技术上说，真相当然也“存在于模型的数百万参数里”，但你基本没法直接对参数做什么。所以现实上，trace 就成了你可以抓住的“事实载体”。\n因此，trace 也会成为你开始思考测试的地方。你仍然可以对 harness 的某些部分做单元测试，也可以离线做一些 unit test，但要获得真正的测试用例，你很可能需要用 trace 来构建。而且在智能体里，在线测试（online testing） 可能比传统软件更重要，因为行为不会在离线环境里完整显现出来，只有在真实世界输入驱动下、系统被真正使用时，行为才会“涌现”。\n我们也看到 trace 正在成为团队协作的中心：如果出了问题，不再是“去 GitHub 看代码”，而是“去看那条 trace”。我们在开源项目里也一样。有人说：“Deep Agents 这里跑偏了，发生了什么？”我们的第一反应是：“把 LangSmith trace 发给我们。”如果没有 trace，我们基本没法帮你 debug。过去大家会说“把代码给我看看”，但现在已经转变了。\n这就是我写在 X 上那篇文章的核心内容，反馈很好。我也还在琢磨怎么把它表达得更精确，但我觉得这一点很关键。\n另外一个点我也还在继续想：我觉得 构建智能体是一个更偏迭代式的过程。\n我们过去也会这么说，但我以前会有点翻白眼，因为软件开发本来也是迭代式的：你发布、收反馈、不断迭代，这就是软件开发的常态。但我觉得差别在于：在传统软件里，你的迭代是围绕“你希望软件做什么”来进行的。你有一个想法，你发布，你收反馈。比如“这个按钮让人困惑”，或者“用户其实想做 X 而不是 Y”。但你在发布之前，其实你是知道软件会怎么运行的。\n但在智能体里，你在发布之前 并不知道它到底会怎么做。你当然有一个预期，但你并不能在发布前真正确定它会做什么。因此，为了让它更准确、让它更“对”、让它能通过某种“概念上的单元测试”，你需要更多轮次的迭代。\n在这个基础上，我也认为记忆（memory）非常重要。因为记忆就是在从这些交互中学习。如果你的开发过程变得更迭代、更难，那么作为开发者，我为了让系统表现正确，可能需要反复改系统 prompt——这种频率甚至可能比我改代码还高。\n这就是记忆进入的地方：如果系统能够以某种方式自己学习，那就能减少开发者必须进行的迭代次数，让构建这类智能体变得更容易。\n所以，这是我认为“构建智能体确实不同于构建软件”的另一个角度。我也承认，这么说有点老套，所以我一直在逼自己想清楚“到底不同在哪里”，目前我总结出来的就是这两点。\n主持人：我也很想追问这一点。现在公开市场上有一个很大的争论：现有的软件公司还能不能熬过去？如果类比当年从本地部署软件（on-prem）转向云（cloud），实际上真正成功转型的公司并不多，因为事实证明，“做云软件”和“做本地软件”确实差异很大。你现在处在“人们如何用 AI 构建产品”的核心地带。你怎么看这件事？\n*** 我不是要问公开市场的投资问题，而是想问：这个变化到底有多大？你有没有看到很多人：过去很擅长“旧方法做软件”，现在也能很擅长“新方法做软件”？还是说更像是：你要么在“新方法”里长大，要么就很难真正理解它？你觉得人能跨越这个鸿沟吗？\nHarrison Chase： 我注意到现在有很多年轻创始人，这让我觉得，也许年轻人因为没有太多对“旧软件开发方式”的先入之见，反而可以更快把这些东西学起来、用起来。而且我们确实一再听到一个现象：很多在做 agent engineering 的团队成员，反而是更初级的开发者、更初级的构建者——他们确实没有那些先入之见。我们内部的应用 AI 团队，确实整体更偏年轻一些。我觉得这里面既有“人的因素”，也有“公司的因素”。\n先说公司层面：数据依然非常非常非常有价值。如果你从 harness 的角度去看——顺便说一句，我其实不认为长期来看大多数人都会自己去写 harness，因为它比做 framework 难太多了。所以我觉得大家最终会用我们提供的 harness，或者用别人的。\n那一个 harness 里面有什么？主要就是：prompt、指令，以及它连接的工具。而现有公司在这方面最大的资产之一，是他们已经拥有数据和 API。如果你过去在这块做得不错，那么把这些东西接入到 agent 上，其实会非常容易产生真实价值。\n我们前阵子和金融行业的人聊，他们就说：数据的价值只会越来越高、越来越高、越来越高。所以如果你是一个传统软件厂商，你手上有这些高价值数据，你应该能够把它暴露给智能体，让智能体去用，从中拿到很大的收益。\n不过这里还有另一部分：关于“如何使用这些数据”的指令（instructions），这一块可能更偏“新增”。\n你作为软件厂商也许一直对“怎么用这些数据”有一些想法，但你并没有把这些想法系统化、固化成可执行的“操作说明”，因为过去这件事更多是由人来完成的——很多智能体现在在做的事情，本来就是人类会做的事情。\n你当然会给人配工具，但你以前不会、或者也很难成功地把它完全自动化。而到了“智能体”这一代，这部分才真正变得可行。所以我觉得这块是新的。\n我们也看到大量需求来自“垂直领域创业公司”。Rogo 就是一个很好的例子：他们团队有人有金融行业经验，把这种行业知识带进了智能体系统里，而这之所以有效，是因为很多智能体的驱动力来自“知识”——但不是那种通用世界知识，而是 如何执行特定流程、特定模式的知识。\n所以问题就变成：做传统软件的人是不是做智能体的合适人选？我觉得我们确实看到很多非常资深的开发者在采用 agentic coding，所以某种程度上这更像是“心态问题”。但确实也可能会呈现出一种“年轻化倾向”。而公司层面，则很大程度取决于它手上的数据资产。\n主持人：所以看起来，你认为 trace 是这个新世界里 agent 开发的核心“产物”，LangSmith 在这方面帮助很大。那你觉得还有哪些核心的“产物”——或者说，可能“产物”这个词不对，应该说组件（components）？\nHarrison Chase： 对，组件。我觉得构建软件与构建智能体之间另一个差异是：评估软件时，你可以相当可靠地依赖程序化测试和断言。但智能体做的很多事情，本质上是“人类会做的事情”。因此要评估它，你必须把 人的判断 引入进来。\n这也是我们在 LangSmith 里努力解决的问题之一：你已经有了这些 traces，那么你怎么把人类判断带到 traces 上？最直接的方法当然就是：把人引进来。所以我们也看到数据标注类创业公司做得很好。我们在 LangSmith 里有一个概念叫 annotation queues（标注队列），就是把人带进来参与。因此，实际的、真实的人类判断，是其中非常重要的一部分。\n主持人：这里的“人工标注”的 trace，比如，智能体做了这些步骤，这是好还是不好。\nHarrison Chase： 有时候，人会给自然语言反馈：这很好、这很差、这里应该怎么做。有时候，人会直接“纠正它”：把正确步骤完整地写出来。这具体怎么做取决于用例，而且对做 RL 的模型公司，和对做 agent 应用的公司来说，也可能不一样。但核心就是：把人类判断带进来。\n同时，我们也看到另一条路：尝试为这种人类判断建立一些“代理指标”（proxy）。这就是 LLM-as-a-Judge 这类方法的来源：你可以跑一个 LLM 或其他模型，让它承担某种“类似人类判断”的角色，去给那些本来需要人类判断的东西打分。\n我们一直在思考的一件事是：怎么让“构建 judge”这件事变得容易。因为 judge 的关键很大一部分在于：它必须和你的人的判断、人类偏好保持一致。如果做不到，那你的 grader（评分器）就很糟糕。\n所以我们在 LangSmith 里做了一个概念叫 align evals：人类先去标注一些 traces，然后基于这些标注，构建一个 LLM judge，使它在这些样本上被校准（calibrated）。\n因为关键就在于：你要把人类判断引入进来；如果你要用 proxy 来替代它，那就必须确保这个 proxy 校准得足够好。\n主持人：有意思。我记得我们最开始和你做业务合作的时候，还在邮件里讨论过：LLM-as-a-Judge 到底是否可行。看起来它已经进步很多了。\nHarrison Chase： 是的。LM-as-a-Judge 其实有几个不同层面的用法。\n最常见的一种，是用于 eval：拿一条 trace，直接给它一个分数，比如 1 到 0，或者 0 到 10。这个我认为是可行的，而且很多人确实在做。他们会离线做，也会在线做，因为有些判断并不需要 ground truth（标准答案）。\n但我觉得另外一个更重要的场景，是你在 coding agents 里也能看到的：coding agent 往往会先工作到某一步，然后遇到错误，触发纠错。它实际上是在“评判自己刚才做的工作”。我们也在 memory 上看到同样的模式：记忆很大一部分就是 反思 traces，然后更新某些东西。所以问题是：LLM 能不能去反思 traces——无论是它自己的 trace、以前 session 的 trace，还是别人的 trace？我觉得完全可以。我们在 eval、纠错、记忆里到处都能看到这种模式，本质上其实是一回事。\nEval 是 RL 的奖励信号，\n还是工程反馈机制？\n主持人：我明白了。那接下来就很自然会问：你有了所有 traces，也有了 eval。那么这些 eval 到底是什么？它是强化学习的 reward signal？还是一种反馈机制，让工程师去改进 harness、让 agent 工程师去优化 harness？\nHarrison Chase：因为现在大家都不再手动写太多代码了，大家都在用这些 agent 工具。我们观察到一个很重要的模式：我们有一个 LangSmith MCP，也有 LangSmith fetch（一个 CLI）。因为 coding agents 特别擅长用 CLI。你把这些给智能体，它就能把 traces 拉下来，诊断哪里出了问题，然后把这些 traces 带进代码库里，从而修复它。这是我们正在看到的真实模式，而且我们非常非常非常想支持这种模式。\n所以在这一点上，相比“用 eval 做强化学习奖励信号”，我对“把 eval 当作工程反馈、用于改 harness”的路径更乐观——至少对今天做 agent 应用的公司来说是这样。\n主持人：这听起来像是递归自我改进啊。\nHarrison Chase： 我觉得是，但还是有一个人类在环。\n回到前面那个点：当它产出“初稿”时效果最好——它改 prompt，然后人类 review，这能让系统保持不跑偏。但我们确实……我们最近发布了 LangSmith Agent Builder，这是一个 no-code 的 agent 构建方式。其中一个很酷的功能就是 memory。\n现在 memory 的工作方式是这样的：当你和 agent 交互时（注意它还不是后台自动跑的那种；它不会自己拉 traces），如果你对它说：“你不该做 X，你应该做 Y”，它就会去改自己的指令——这些指令本质上就是文件——然后直接编辑这些文件。这样未来它就会按新的方式表现。\n这也是一种“自我改进”的形式。我们确实还想加入另一种机制：比如每天晚上跑一次任务，查看当天所有 traces，更新自己的指令。\n主持人： 就是那种“做梦”的机制。\nHarrison Chase： 对，“睡眠时间算力（sleep-time compute）”。\n记忆与自我改进会成为护城河吗？\n主持人：我们再多聊聊未来。你现在最兴奋的是什么？听起来你聊了很多 memory。\nHarrison Chase： 我很看好 memory。我觉得让智能体去改善自己，这非常酷，而且在很多场景下也很有用。\n但也不是所有场景都用得上。比如 ChatGPT 加了 memory 功能，我其实用得不多，我也不觉得它显著增加了我对产品的粘性。我觉得原因之一是：我去 ChatGPT 时，大多数问题都是一次性的。我不太会反复做同一件事：我可能问软件，也可能问吃的、旅行……都很零散。\n但在 agent builder 里，你通常是为特定任务构建特定工作流。比如我有一个 email agent。而且我其实……它已经给我发邮件两年了。我之前在 agent builder 之外就有一个 email agent，它带有 memory。后来我们做了 agent builder，我想把它迁移进去，但它没有我之前的那些 memories。即便它的起始 prompt 一样、工具也一样，但因为缺了记忆，它现在的体验就明显差很多。我到现在都还没完全切过去，因为它现在确实不如之前那个好用——说白了，它现在“有点烂”。\n当然，如果我持续和它交互，它会变好，它会不那么烂。但这也恰恰说明：memory 可能会成为真正的护城河（moat）。而且我绝对相信，我们已经到了一个阶段：LLM 可以看 traces，然后改变自己代码里的某些东西。问题在于：怎么把这件事做得 安全、并且在用户层面可接受。但我认为，在一些特定场景里（不是所有场景），我们会越来越多看到这种能力。至于 ChatGPT 这种通用聊天产品，我仍然不确定这种形态的 memory 是否有用，至少目前我不确定。\n主持人：你觉得和长时序智能体一起工作的 UI 会如何演化？\nHarrison Chase： 我觉得大概率需要 同步模式（sync）和异步模式（async）。\n长时序智能体运行时间可能很长，默认应该是异步管理：如果它要跑一天，你不会一直坐在那里等它结束。你很可能会启动一个、再启动一个、同时跑很多个。所以这里会涉及到异步管理：我觉得像 Linear、Jira、看板，甚至 email，都可以作为 UI 设计的参考——如何去管理一堆异步运行的 agent。\n但与此同时，很多时候你又会想切换到同步交流。因为 agent 最后给你返回一份研究报告，你可能需要立刻指出：它这里写错了，你要给反馈。聊天界面在这方面其实已经挺不错的。\n我唯一想补充的是：现在很多 agent 不仅是在“对话”，它还会去修改文件系统里的文件。所以你必须有一种方式去查看“状态”（state）——也就是它改了什么。\n这在编程领域尤其明显：IDE 依然被使用，是因为当你想手动改代码时，你需要看见那个“当前状态”。即便我启动 Claude Code，它跑完后，我有时也会打开来看它到底写了什么代码。所以“能看到状态”这件事很重要。\nAnthropic 在 Claude “co-work”（这里指那类协作式工作流）里做了一个很酷的设计：你设置它时要选择一个目录，等于你在告诉它：“这就是你的环境。”\n这在编程里当然也是常态：你打开 IDE 到某个目录。但我觉得把它明确成一个心智模型很有帮助：这就是你的 workspace（工作区）。\n这个 workspace 也不一定非得是本地目录：它可以是 Google Drive、Notion 页面，或者任何能存储状态的地方。你和 agent 就是在这个状态上协作：你启动它，让多个任务异步跑；然后切到同步模式，在 chat 里和它讨论，但同时你还能看到它正在协作的“状态”。这就是我目前看到的形态。\n主持人：所以这也就是你说的“agent inbox”的想法：为了进入 sync 模式，agent 需要能联系到你。\nHarrison Chase： 对，没错。我们大概一年前发布过 agent inbox，理念是“ambient agents”：它们在后台跑，必要时来 ping 你。但第一版其实没有 sync 模式：它 ping 你，你回一句，然后你就等它下一次再 ping 你。\n但很多时候，我切到邮件去回复它时，我其实只回很短的话，而且我不想再切出去然后干等——我（对方）很重要，所以我更想直接进入一种“同步对话”的模式，跟 agent 把这个问题当场聊完。所以我们后来做了一个关键改动：当你打开 inbox 时，会直接进入 chat，而 chat 是非常同步的。这是一个很大的 unlock（突破点）。\n我现在认为：只有 async 模式，目前还不太够。也许未来如果 agent 强到你几乎不用纠正它，那么纯异步会更可行。但至少现在，我们看到人们在 async 和 sync 之间来回切换。\n主持人： 你怎么看 code sandboxes（代码沙箱）？是不是每个 agent 最终都会配一个 sandbox？也包括“能用电脑”、能上网用浏览器这种能力？\nHarrison Chase： 这是个特别好的问题，我们也一直在想。就目前的经验来看，“写代码 / 跑代码”这条路明显比“直接操作浏览器”更成熟、更好用。\n所以短期内，如果要在这些能力里挑一个最可能成为标配的，我更看好的是 代码执行（code execution）——也就是给 agent 一个能安全运行脚本、验证结果的环境。\n另外，文件系统（file system）我几乎是“坚定派”：不管是本地目录、还是背后用数据库实现的“虚拟文件系统”，agent 总得有个地方能存状态、存中间结果、随时回查，这对上下文管理太关键了。比如：\n做 compaction（上下文压缩）时，把完整内容丢到文件里，需要再查就去读；\n工具调用返回特别长时，不塞进上下文，改成写文件、让 agent 自己按需读取。\n至于“coding”（让 agent 真正去写代码），我没那么绝对，但我大概 90% 站在“需要”这一边。因为很多长尾任务里，写脚本依然是最通用、最强的手段——你很难找到同等级的替代品。\n当然也可能出现另一类场景：如果你做的是高度重复、流程固定的事情，未必每次都要写很多代码；但即使这样，文件系统仍然重要，因为重复流程会不断产生上下文和状态，你还是要做上下文工程。\n再说浏览器使用（browser use）：从我们目前看到的效果来说，模型还不够稳定。也许可以让 coding agent 通过 CLI 的方式“间接”完成一些浏览器相关任务（算是一种近似解），我确实见过一些挺酷的实现。\n而所谓 computer use（直接操作电脑界面）则更像是介于两者之间的混合形态，目前还有不少不确定性。\n所以总结一下：我非常喜欢 code sandboxes，我觉得它会成为 agent 能力栈里很关键的一块。\n主持人：太棒了。Harrison，真的非常感谢你今天来参加节目。你一直都能在 agent 这条路上看到未来，能和你聊“上下文工程如何演化到今天的 harness 与长时序智能体”，真的特别过瘾。感谢你推动这个未来，也感谢你一直愿意和我们聊这些。\nHarrison Chase： 谢谢邀请。我希望未来还能再来一次，然后证明我今天说的全部都是错的。因为预测未来真的很难。\n参考链接：\nhttps://www.youtube.com/watch?v=vtugjs2chdA\u0026t=1s\n声明：本文为 AI 前线整理，不代表平台观点，未经许可禁止转载。\n阅读最新前沿科技趋势报告，请访问欧米伽研究所的“未来知识库”\nhttps://wx.zsxq.com/group/454854145828\n_未来知识库是“__欧米伽__未来研究所”建立的在线知识库平台，收藏的资料范围包括人工智能、脑科学、互联网、超级智能，数智大脑、能源、军事、经济、人类风险等等领域的前沿进展与未来趋势。_目前拥有超过8000篇重要资料。_每周更新不少于100篇世界范围最新研究资料。_欢迎扫描二维码或访问**https://wx.zsxq.com/group/454854145828** 进入。\n","date":"31 January 2026","externalUrl":null,"permalink":"/posts/langchain-%E5%88%9B%E5%A7%8B%E4%BA%BA%E8%AD%A6%E5%91%8A2026-%E6%88%90%E4%B8%BAagent-%E5%B7%A5%E7%A8%8B%E5%88%86%E6%B0%B4%E5%B2%AD%E4%BC%A0%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%85%AC%E5%8F%B8%E7%9A%84%E7%94%9F%E5%AD%98%E8%80%83%E9%AA%8C%E5%BC%80%E5%A7%8B%E4%BA%86/","section":"AI-Related Reposts","summary":"","title":"[Repost] LangChain 创始人警告：2026 成为“Agent 工程”分水岭，传统软件公司的生存考验开始了","type":"posts"},{"content":"Reposted from 震撼！硅谷教父马克·安德森亲授：他如何培养10岁的儿子？超级个体+E型人才是未来，AI让效率提升1000倍 by 陆向谦\n作者：赵老师\n硅谷教父的教育启示\n前几天，硅谷传奇人物马克·安德森（网景浏览器发明者、全球最大风投公司a16z创始人）在播客中，罕见地分享了他如何教育10岁儿子的方法。最震撼的不是他的投资成就，而是他的教育理念：\n\u0026ldquo;AI应该是有主动性孩子的终极杠杆。它让你能够成为主要贡献者——从物理学到编程到艺术到写作，在任何领域都能完全参与、真正改变世界。\u0026rdquo;\n\u0026ldquo;AI会让\u0026rsquo;好\u0026rsquo;的人变成\u0026rsquo;非常好\u0026rsquo;，但更重要的是，会让\u0026rsquo;非常好\u0026rsquo;的人变成\u0026rsquo;惊人地好\u0026rsquo;。普通人+AI=效率提高2倍，顶尖人才+AI=效率提高10倍、100倍甚至1000倍。\u0026rdquo;\n\u0026ldquo;未来不是T型人才，而是E型人才——至少在两个领域很深，最好三个都精通。\u0026rdquo;\n家长圈瞬间炸了。有人震惊：\u0026ldquo;E型人才是什么？\u0026ldquo;也有人质疑：\u0026ldquo;让AI当导师靠谱吗？\u0026ldquo;更有人焦虑：\u0026ldquo;我家孩子该怎么培养？\u0026rdquo;\n预约直播听干货，点击进主页看精彩案例\n但你有没有想过一个更深层的问题：当硅谷教父明确告诉你，\u0026ldquo;超级个体+E型人才\u0026quot;才是未来，而他正用这套方法教自己10岁儿子时，我们还在让孩子刷题、考级、拼学历，这到底是在帮孩子，还是在害孩子？\n什么是“超级个体”？\n马克·安德森如何教10岁儿子？关键词：超级个体 马克·安德森是谁？ - 23岁发明网景浏览器，开启互联网时代 - 创立a16z，投资Facebook、Twitter、Airbnb等几乎所有伟大科技公司 - 多次精准预测科技发展方向（\u0026ldquo;软件正在吃掉世界\u0026rdquo;） 这样一个人如何教自己10岁儿子？他给出了清晰的答案：\n目标：培养\u0026quot;超级个体\u0026rdquo;\n什么是\u0026quot;超级个体\u0026rdquo;？\n马克说：\u0026ldquo;AI会让\u0026rsquo;好\u0026rsquo;的人变成\u0026rsquo;非常好\u0026rsquo;，但更重要的是，会让\u0026rsquo;非常好\u0026rsquo;的人变成\u0026rsquo;惊人地好\u0026rsquo;。区别在哪里？\u0026rdquo;\n看懂了吗？不是培养\u0026quot;还可以\u0026quot;的人，而是培养在某个领域深度扎根、能够充分驾驭AI的\u0026quot;超级个体\u0026rdquo;。\n马克对儿子说：\u0026ldquo;AI应该是有主动性孩子的终极杠杆。你可以成为主要贡献者——从物理学到编程到艺术到写作，在任何领域都能真正改变世界。\u0026rdquo;\n陆向谦教授深以为然：\u0026ldquo;这就是我们实验室的做法，我们就带着10岁左右的孩子从小玩AI，让孩子做真实项目，参加科技名企的黑客马拉松，成为超级个体！全球10岁左右得工业级奖的孩子，几乎都是我们实验室的学生。\u0026rdquo;\nAgency（主动性）：被严重低估的核心能力\n马克·安德森特别强调一个词：Agency（主动性）。\n什么是Agency？\u0026ldquo;主动去做事情，而不是等别人告诉你。对事情负全责。能够领导项目、创造新事物。\u0026rdquo;\n为什么这个词突然在硅谷流行？\n马克说：\u0026ldquo;过去几十年，我们的文化过度强调\u0026rsquo;遵守规则\u0026rsquo;。学校系统、企业系统都在训练人\u0026rsquo;听话\u0026rsquo;、\u0026lsquo;按流程办事\u0026rsquo;。但AI时代需要的是：能够驾驭AI工具、做出独立判断、创造新价值的人。\u0026rdquo;\n他举了个例子：\u0026ldquo;学校系统越来越专注于\u0026rsquo;训练孩子遵守所有规则\u0026rsquo;。但在AI时代，如果你只是听话、按规则办事，你就是可被替代的。真正有价值的，是那些有主动性、能够定义问题、能够创造新价值的人。\u0026rdquo;\n陆向谦教授的观点特别清晰：\u0026ldquo;我们不培养\u0026rsquo;听话的好学生\u0026rsquo;，而是培养\u0026rsquo;有自己追求的AI原住民\u0026rsquo;。Google DeepMind 创始人、诺奖得主哈萨比斯从8岁开始就有自己的追求：我想做游戏、我想让电脑做大脑能做的事。整天想这一件事，从8岁一直想到现在才会这么成功。\u0026rdquo;\n看懂了吗？听话的好学生可能培养不出诺奖得主，有主动性的\u0026quot;野孩子\u0026quot;才可能。\nE型人才：未来唯一的生存模式\n马克·安德森提出了一个震撼的新概念：E型人才。\n什么是E型人才？过去我们说\u0026quot;T型人才\u0026rdquo;：一个领域很深，其他领域了解一点。\n马克说：这已经过时了。未来是E型人才——至少在两个领域很深，最好三个都精通。\n为什么？他引用了《呆伯特》漫画作者Scott Adams的理论：\n\u0026ldquo;我可以成为还不错的漫画家，也可以成为还不错的商业人士。但正是因为我既懂漫画又懂商业，我才创造出了呆伯特——世界上最成功的商业漫画之一。\u0026rdquo;\n关键洞察：\n擅长两件事的价值 大于 2倍\n擅长三件事的价值 大于 3倍\n为什么？因为你成为了\u0026quot;领域组合\u0026quot;的稀缺专家\n马克举了一个更具体的例子：产品经理、工程师、设计师的未来。\n\u0026ldquo;现在出现了一个\u0026rsquo;墨西哥对峙\u0026rsquo;：\n每个工程师都认为：有了AI，我可以自己做产品管理和设计\n每个产品经理都认为：有了AI，我可以自己写代码和做设计\n每个设计师都认为：有了AI，我可以自己做产品和写代码\n他们都是对的！ AI确实在这三个领域都已经很优秀了。\u0026rdquo;\n结果是什么？\u0026ldquo;10年后，顶尖人才会是\u0026rsquo;既能编程又能设计\u0026rsquo;的人，或\u0026rsquo;既能管理产品又能写代码\u0026rsquo;的人，或者三者兼具。这些人会成为行业的超级明星，而那些只会一个领域的人会被淘汰。\u0026rdquo;\nAI导师革命：每个孩子都能有自己的“亚里士多德”\n马克·安德森讲了一个被验证了几百年的事实：\n\u0026ldquo;一对一辅导是最有效的教育方式。\u0026rdquo; 他举例：\n亚历山大大帝的老师是亚里士多德——他征服了世界\n历史上所有的皇室、贵族都给孩子配一对一导师\n教育学研究证明：一对一辅导能让学生从50百分位提升到99百分位\n但问题是：只有最富有的人才负担得起一对一导师。\nAI改变了这一点！马克说：\u0026ldquo;现在，任何孩子都可以：和AI无限对话，问无限多的问题；得到即时反馈；让AI根据自己的理解程度调整难度；让AI出题测验自己。\u0026rdquo;\n\u0026ldquo;家长们，现在就是时候了！让孩子在传统教育基础上，加上AI一对一辅导。\u0026rdquo;\n我们实验室就是希望通过AI，给每个孩子都配上各个领域最优秀的“太子老师”（太子洗马团队），来辅导孩子成功。\n马克更进一步强调：不要只想着\u0026rsquo;让AI帮我做事\u0026rsquo;，更要想着\u0026rsquo;让AI教我做事\u0026rsquo;。\n具体怎么做？\u0026ldquo;人们还没有充分意识到这一点：你应该把每一个空闲时间都用来和AI对话，让它训练你。\u0026rdquo;\n两个具体技巧：\n观察AI的思考过程：当AI写代码或设计时，看它怎么思考、怎么做决策\n遇到问题后复盘：问AI：\u0026ldquo;我本来可以怎样避免这个错误？我应该怎么问你？\u0026rdquo;\nOpenAI CEO山姆奥特曼也是这个观点，他说：“做中学才是最有效的学习方式。”\n同样，17岁高中辍学的Gabriel用ChatGPT自学，23岁成为OpenAI核心科学家，年薪超百万美金。他也说：“是ChatGPT教会了我所有AI知识。”\n如何培养适应未来的“超级个体+E型人才”\n看到这里，很多家长肯定在想：那我现在该怎么办？\n结合马克·安德森的分享和陆向谦教授30年的实践，我给你三个建议。\n第一：培养\u0026quot;超级个体\u0026rdquo;，而不是\u0026quot;听话的好学生\u0026quot;。\n马克的核心理念：AI会让\u0026quot;非常好\u0026quot;的人变成\u0026quot;惊人地好\u0026quot;。具体怎么做？\n找到孩子真正感兴趣的领域（不是家长强迫的）\n让孩子在这个领域深度扎根\n用AI作为杠杆，放大孩子的能力\n陆教授就提到：\u0026ldquo;我们实验室从10岁左右开始，让孩子做真实项目。不是刷题，不是考级，而是做真实的、有人用的产品。我们实验室9岁的学生，就成为了全世界最年轻的黑客马拉松获奖者，12岁的学生就能打败成人技术大牛比赛拿第一。\u0026rdquo;\n第二：培养E型人才，至少精通两个领域。\n马克的建议：擅长两件事的价值大于2倍，擅长三件事的价值大于3倍。具体怎么做？\n选2-3个相关领域\n如果孩子喜欢编程：让他学一点产品思维、学一点设计\n如果孩子喜欢设计：让他学一点编程、学一点产品\n用AI学习其他领域（让AI教孩子）\n记住：不要培养\u0026quot;单一专家\u0026quot;，要培养\u0026quot;跨界高手\u0026quot;。\n第三：让AI成为孩子的导师，每天至少30分钟。\n马克的金句：\u0026quot;你应该把每一个空闲时间都用来和AI对话，让它训练你。\u0026quot; 具体怎么做？\n让孩子用AI学习（ChatGPT、Claude、DeepSeek等）\n教孩子问AI：\u0026ldquo;教我XXX的基础知识\u0026rdquo;\n让孩子观察AI的思考过程\n鼓励孩子问AI：\u0026ldquo;我本来应该怎么问你？\u0026rdquo;\n我们实验室的学生就是这样——边做项目边学，遇到不懂的问AI，效率比传统学习高100倍。\n当硅谷教父马克·安德森明确告诉你，\u0026ldquo;超级个体+E型人才+AI导师\u0026quot;才是未来，而他正用这套方法教自己10岁儿子时——\n我们还在让孩子坐在教室里刷题、考级、拼学历，这到底是在帮孩子，还是在害孩子？\n马克说：\u0026rdquo;AI是哲人石——把世界上最常见的东西（沙子）变成最稀有的东西（思想）。而每个人都可以使用这个哲人石。\u0026quot;\n属于超级个体的时代，才刚刚开始。\n以上，既然看到这里了，如果觉得不错，随手点个赞、在看、转发三连吧，如果想第一时间收到推送，也可以给我个星标⭐～\n谢谢你看我的文章，我们，下次再见。\n- END -\n分享、点赞、在看，3连3连！ ","date":"31 January 2026","externalUrl":null,"permalink":"/posts/%E9%9C%87%E6%92%BC%E7%A1%85%E8%B0%B7%E6%95%99%E7%88%B6%E9%A9%AC%E5%85%8B%E5%AE%89%E5%BE%B7%E6%A3%AE%E4%BA%B2%E6%8E%88%E4%BB%96%E5%A6%82%E4%BD%95%E5%9F%B9%E5%85%BB10%E5%B2%81%E7%9A%84%E5%84%BF%E5%AD%90%E8%B6%85%E7%BA%A7%E4%B8%AA%E4%BD%93pluse%E5%9E%8B/","section":"AI-Related Reposts","summary":"","title":"[Repost] 震撼！硅谷教父马克·安德森亲授：他如何培养10岁的儿子？超级个体+E型人才是未来，AI让效率提升1000倍","type":"posts"},{"content":"","date":"31 January 2026","externalUrl":null,"permalink":"/tags/agency/","section":"Tags","summary":"","title":"Agency","type":"tags"},{"content":"","date":"31 January 2026","externalUrl":null,"permalink":"/tags/agent/","section":"Tags","summary":"","title":"Agent","type":"tags"},{"content":"Powered by Gemini 3 Pro.\n在 Mac 上将 Python 脚本（.py）转换为独立的可执行文件（.app 或 Unix 可执行文件），最标准且高效的方法是使用 PyInstaller。这样即使对方没有安装 Python 环境，也可以直接运行你的程序。\n以下是具体的操作步骤：\n1. 准备工作 # 首先，确保你的终端（Terminal）已经安装了 pyinstaller。打开终端并输入：\npip install pyinstaller 2. 生成可执行文件 # 在终端中进入你 Python 文件所在的文件夹，然后运行以下命令：\n如果你想要一个独立的单文件： pyinstaller --onefile your_script.py 如果你写的是 GUI 界面程序（不希望运行时弹出黑色的终端窗口）： pyinstaller --onefile --windowed your_script.py 3. 获取结果 # 命令运行完成后，你会发现文件夹中多了几个东西：\ndist/ 文件夹：这里面存放着最终的可执行文件。 build/ 文件夹：存放打包过程中的临时文件（可以删除）。 your_script.spec：打包配置文件（可以删除）。 进阶工具推荐 # 如果你觉得命令行操作比较麻烦，或者需要更精美的打包效果，可以尝试以下工具：\n工具名称 特点 适用场景 Py2app Mac 原生感最强 专门为 macOS 设计，支持复杂的资源打包和图标设置。 Auto-py-to-exe 可视化操作 提供一个网页界面，通过点击按钮来配置 PyInstaller 参数。 Nuitka 运行速度更快 它将 Python 代码编译为 C++，安全性更高，速度也有提升。 💡 避坑小贴士 # 权限问题：如果双击运行提示“由于开发者无法验证”，请在 系统设置 -\u0026gt; 隐私与安全性 中点击“仍要打开”。 路径问题：如果你的程序中引用了外部图片或数据文件，建议在代码中使用动态路径获取方法，否则打包后可能会找不到文件。 芯片架构：在 Intel 芯片的 Mac 上打包的文件默认只能在 Intel Mac 上运行；在 Apple Silicon (M1/M2/M3) 上打包的同理。 需要我帮你写一段处理“打包后文件路径获取”的代码，以防止程序运行时找不到资源吗？\n","date":"31 January 2026","externalUrl":null,"permalink":"/blog---not-used/2026-01-31-%E5%A6%82%E4%BD%95%E5%B0%86python%E6%96%87%E4%BB%B6%E8%BD%AC%E5%8C%96%E4%B8%BAmac%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6/","section":"Blog - Not Useds","summary":"","title":"如何将python文件转化为mac可执行文件？","type":"blog---not-used"},{"content":"Reposted from Dan Koe：如何拥有“违法级”的专注力？ by 不安于\n【写在前面】如果你此刻正站在一个想改变、却被琐事缠住脚踝的节点上， 我花了一周时间，把 Dan Koe 的这套心法拆解、重组，做成了一套《21 天强制执行 · 行动地图（精确到小时版）》。它不是只会喊口号的鸡汤，而是一套强制重启的系统。\n👉关注公众号【不安于】，后台回复 “21”，直接发你。\n（点击即可关注）\nHow to become so focused it feels illegal # 你或许从未真正体验过，自己究竟能达到怎样的专注深度。\n不是因为你不够努力，也不是因为你不够自律，而是因为大多数人，一生都没有真正进入过那种持续、稳定、几乎不被打断的专注状态。\n如果你真的学会如何进入这种状态，很多在旁人眼中“不可能完成”的奇迹，对你而言，不过是可复制的日常。\n建立一套稳定的深度工作习惯，以心理学、效能科学和哲学作为底层支撑，这是第一步，也已经足以让你领先绝大多数人。\n但真正的关键，并不在某个技巧上，而在于你是否意识到一件事：\n我们正生活在一个极其丰盈、却高度分心的时代。\n信息、刺激、选择、诱惑，几乎在全天候争夺你的注意力。 在这样的环境里，“无法专注”并不是你的缺陷，而是这个环境设定的“出厂设置”。\n接下来我要分享的，并不是某种神奇的方法，而是让我几乎不再抗拒去做那些大多数人觉得困难、枯燥、需要长期投入的事情的底层逻辑。\n在很大程度上，我可以控制两件事：我会产生多少有价值的想法，以及我能在高强度状态下持续工作多久。\n（时代的丰盈带来了机会，却也制造了注意力的牢笼，多数人困在其中，把无法专注归罪于自己，陷入自我否定与低效内耗；而少数人能跳出这个误区，先接纳 “无法专注是环境问题” 的现实，再通过构建底层体系、掌控想法与工作时长，把专注变成可稳定复制的能力\n当注意力与工作节奏的主导权回到自己手中，深度专注就会成为一种本能，那些需要长期投入的高价值事，会从 “让人抗拒的难事”，变成 “能稳步推进的日常事”，而这，正是拉开人与人之间差距的核心所在 —— 在这个注意力稀缺的时代，谁能掌控专注，谁就能掌控自己的人生上限）\n深度工作的心理学与哲学 # 在讨论方法之前，我想先说清楚一件事。\n我并不在乎最新流行的“深度工作技巧”。\n我不在乎你工作时戴不戴帽子、不在乎你把手机调成黑白色、也不在乎你用什么方式“戒多巴胺”。\n我只关心一件事：什么真的长期有效。\n如果你需要大量外部技巧，才能勉强坐下来开始工作，那往往意味着你忽略了真正决定专注力的核心因素。\n要进入你此生最深的专注状态，你必须依次解决三个问题：\n是什么在驱动一个人，在不想做的时候依然行动；\n（比如我写文章时，曾连续一周熬夜打磨干货文，熬到凌晨时大脑疲惫、手指发麻，连一个字都不想再敲；但一想到自己的内容能帮职场新人少走弯路，想到粉丝留言说 “你的文章让我找到了职业方向”，这份价值认同便会推着我打起精神，坚持梳理完最后一个案例、核对完所有逻辑，而非半途而废）\n大脑是如何处理、筛选与管理信息的；\n（之前我准备写一篇 “AI 赋能职场” 的深度文，刚打开电脑，各类热点新闻弹窗、朋友圈里朋友的旅行分享、社群中不断弹出的闲聊消息就纷至沓来，很容易分心。于是我给自己定下标尺：只关注 AI 工具落地职场的真实案例和行业数据。随后我直接关掉所有微信、把手机扔到远处，只打开权威行业报告和真实用户体验帖，让大脑只处理这类高价值信息，很快就进入了写作的专注状态）\n如何把一天的结构，设计成更符合人类本能的节奏。\n（比如我晚上的精力和专注力最佳，擅长深度思考，就把专注写作这类高难度工作放在这个时段；上午精力平稳，便用来做选题查询、素材搜集的工作；下午精力稍缓，就安排社群互动、粉丝留言回复这类轻量事务，不硬逼自己深度专注，既高效完成各项任务，又能让大脑适时缓冲，全程不用硬撑，专注状态也能稳稳保持，关键是找到自己的专注点）\n1）最强的专注能力 # 彻底搞清楚你在做什么 # 你在做什么？为什么要做？什么时候必须完成？以及——具体该怎么完成？\n这四个问题，对应着三件事：清晰度、重要性、紧迫感。\n它们决定了干扰信号，是否还有机会入侵你的大脑。\n清晰度来自一个前提：你正在做的，是一个有挑战、但仍然可控的任务。如果一件事让你感到彻底失控，大脑就会本能地逃离。这时你要做的，不是硬扛，而是把目标拆解成你能理解、能执行的子任务。\n（清晰度的核心前提，是所做之事有挑战但可控。一旦事情让人感到彻底失控，大脑会出于本能逃离，再强的毅力也难以对抗。此时无需硬扛，把大目标拆解成能理解、可落地的子任务，让每一步行动都有明确指向，大脑才会愿意投入注意力，拒绝干扰的基础也由此建立）\n重要性，来自你对结果的真实理解：如果我不完成这件事，我的生活会继续朝哪个方向滑去？如果我完成了，哪些潜力会被真正释放出来？\n（重要性，源于对事情结果的真实深度理解，而非表面的 “应该做”。要想清楚两个核心问题：不完成这件事，生活将会朝哪个糟糕的方向滑落？完成这件事，自身的哪些潜力、机会会被真正释放？这份对结果的清晰感知，会让事情的价值变得具体可触，让注意力有了锚点，外界的琐碎干扰自然难以撼动）\n紧迫感，决定了你是现在行动，还是继续拖延。\n（紧迫感直接决定行动的时机，是区分 “现在做” 和 “继续拖” 的关键。没有紧迫感，再清晰的目标、再重要的事，也会被无限期搁置，注意力会被各种无关琐事分散；而适度的紧迫感，会倒逼大脑聚焦当下，放下犹豫和拖延，让专注从脑海中的想法，转化为立刻开始的行动，从根源上阻断干扰的入侵）\n内在动机，才是长期专注的燃料。\n（这份动机源于内心的目标、价值认同与自我期待，而非外部的逼迫或功利的诱惑；有了内在动机，三大要素才能持续发挥作用，专注也会从需要刻意维持的状态，变成一种自发的选择）\n大多数人长期停滞，并不是因为不够聪明，而是因为他们依赖的是外在动机（比如老板的鞭策）。但当你真正被一个目标吸引时，你会被一组内在动机所驱动，它们彼此叠加，让你自然进入一种稳定的“心流状态”：\n好奇心：想要理解未知、填补认知空白\n热情：对一条可能改变人生的路径持续投入\n使命感：觉得自己的行动服务于更大的意义\n自主性：掌控选择、节奏与方向\n精进感：把成长本身当作回报\n你通常从好奇开始，在持续投入中形成热情，再把热情绑定到一个更大的目标上。当你脱离默认路径，获得对生活的主导权，专注就不再是一种消耗，而是一种自然状态。\n2）你需要两种时间 # 执行时间与创造时间 # 它们是两种不同、但彼此互补的心智状态。\n早晨，更适合创造、输出与深度专注。\n下午，更适合阅读、学习、交流，为大脑输入信息。\n睡前，适合整理、复盘、清空认知残留。\n很多人把“忙”和“累”当成能力的证明，但事实是：如果你只专注那些真正能撬动结果的关键任务，4 小时的高质量工作，往往胜过 8 小时的机械执行。\n（忙≠累≠有能力，高杠杆任务才是效率核心）\n而这些高杠杆任务，几乎都离不开创造力。前提是：你必须为大脑预留足够的空白与恢复时间。如果你一整天都处在执行模式，你的大脑只会不断消耗，却无法产生新想法。\n（真正的能力，从来不是能熬多少时间、能做多少事，而是能分清主次、顺应规律，用最少的精力撬动最大的结果。当你不再把忙碌当证明，学会让大脑张弛有度，高效和成果会成为自然的结果）\n3）你之所以拖延 # 是因为你的“生存本能” # 觉得没必要 # 在现代社会，大多数人的生存威胁，已经不再来自物理层面，而是心理层面。\n我们依附于身份、立场、标签。当这些被挑战时，大脑会产生真实的威胁感。\n（当下的我们，早已摆脱了温饱、安全等物理层面的生存危机，而心理层面的内耗、执念、身份焦虑，成为了最主要的生存困扰。我们会将自我价值牢牢依附于外在的身份、立场和标签——职场 title、社会评价、他人定义的 “成功”，这些虚拟的符号成了自我认知的锚点，一旦这些被质疑、挑战或打破，大脑会触发真实的威胁感，如同面对物理危险般产生焦虑、抗拒甚至逃避）\n当你试图改变自己，比如变得更专注、更高效，你其实是在挑衅那个试图把你拉回舒适区的“旧身份”。\n（而大脑会本能地维护已有的自我认知，这份 “旧身份” 会不断把你拉回舒适区，用借口、惰性、恐惧阻碍改变的发生。很多人改变失败，并非意志力不足，而是没意识到自己对抗的不是某一个坏习惯，而是根深蒂固的自我身份认知，用意志硬抗，最终只会陷入 “坚持 - 放弃 - 内耗” 的循环）\n一旦你学会通过环境，而不是意志，来重塑身份，行动就会变得顺畅得多。\n靠近你想成为的那类人，进入你暂时还不完全适应的环境。当持续行动成为你的新常态，“不行动”，反而会让你感到不安。\n（自我改变的核心是重塑身份，而非改变行为；重塑身份的关键是借环境之力让新行为成常态，而非依赖意志力。心理内耗源于行为与身份的错位，靠意志的改变是外力逼迫，环境塑造的行为会成为自我选择，持续的新行为会让身份认知自然适配，内耗便会消失。\n真正的改变，是 “身处此境，我本如此”，用环境重塑身份、让行动常态化，想要的改变自会发生）\n写到最后 # 像“违法”一样专注，并不是天赋，而是一套可以被理解、被训练的状态。\n它不来自意志力的硬撑，而来自对人类心理、注意力与环境结构的尊重。\n感谢你读到这里。\n—— Dan\n写到这里，其实道理大家都懂。\n专注很重要、深度工作很重要、环境比意志力重要——这些话你可能早就听过无数遍了。\n真正难的，从来不是“理解”，而是执行。\n更准确地说，是——我们太习惯待在一个，让自己“感觉很安全、很舒服、很安逸”的生活结构里了。\n刷信息、回消息、被打断、再继续刷，一天结束时很累，但又说不清到底做成了什么。不是因为你懒，而是因为这个环境，本身就不鼓励你进入真正需要思考的状态。\n所以与其逼自己“更自律”，不如试着做一件更直接、也更残酷的事——主动打破那些让你过得太安逸的东西。\n给自己一个明确的时间段，哪怕只有 7 天、14 天、21 天，刻意减少刺激、减少选择、减少无意义的消耗，\n让大脑重新适应那种——安静、专注、需要独立思考的状态。一开始一定会不舒服。走神、焦躁、想逃离，都会出现。\n但那不是失败，那只是你的大脑，在重新校准。\n你不是不行，只是太久没有给过自己真正思考的空间。\n当你扛过那个适应期，你会发现，专注并不是一件需要“拼命坚持”的事，而是一种可以被重新唤醒的本能。\n也许，真正的改变，不是再学一个新方法，而是先为自己，腾出一块不被打扰的生活。这一步，值得你认真试一次。\n—— qi\n说明：\n本文基于 Dan Koe 的英文内容进行重写，融合了我个人的理解与中文语境下的现实体验。\n黑色文字为 Dan Koe 文章的直译内容；\n灰色加粗文字为我基于原文的个人思考。\n感恩大家最近的阅读和反馈。\n这几天，因为 Dan Koe 的这几篇文章，我收到了不少私信。\n很多人问我的其实是同一个问题：\n“qi，我也很向往那种——每天只专注一小时，但长期稳定推进的状态。\n可每次都卡在第三天、第五天，怎么都坚持不下来。”\n说实话，这真的不是你不自律。而是我们大多数人，从来没有真正建立过一个「可执行的行动系统」。你以为自己缺的是意志力，但实际缺的是——在情绪波动、状态下滑时，依然能推着你往前走的结构。\n也是因为这个原因，我最近一直在打磨一套东西——《21 天高效能行动指南（精确到小时版）》。它不是那种“你应该更努力”的鸡汤，而是一张在你犹豫、拖延、走神时，直接告诉你下一步做什么的行动地图。目前这份指南还在内测阶段。 如果你也在这个有点混乱的 2026 年，想重新找回对时间和行动的掌控感——欢迎添加我的工作微信：Fairy_i020。\n","date":"30 January 2026","externalUrl":null,"permalink":"/posts/dan-koe%E5%A6%82%E4%BD%95%E6%8B%A5%E6%9C%89%E8%BF%9D%E6%B3%95%E7%BA%A7%E7%9A%84%E4%B8%93%E6%B3%A8%E5%8A%9B/","section":"AI-Related Reposts","summary":"","title":"[Repost] Dan Koe：如何拥有“违法级”的专注力？","type":"posts"},{"content":"Reposted from Elon Musk和黄仁勋不会完整告诉你的招聘逻辑——学历的经济信号价值：分化与重构的真相 by 袁希\n一个价值百万美元的矛盾 # Elon Musk在推特上说：\u0026ldquo;学历对我来说不重要。\u0026rdquo;\n黄仁勋在演讲中强调：\u0026ldquo;NVIDIA招人看能力，不看文凭。\u0026rdquo;\n然后呢？\n去年SpaceX发布的推进系统工程师岗位，最终录用的候选人中，85%来自MIT、斯坦福、加州理工这样的顶尖工程院校。NVIDIA的AI研究院，几乎清一色是顶级CS PhD，发表过CVPR、NeurIPS这类顶会论文的人。\n这是说一套做一套吗？\n并不是。\n这背后的逻辑是：大众对\u0026quot;学历\u0026quot;的理解，和产业界对\u0026quot;学历信号\u0026quot;的使用，根本不在同一个认知层次。\n当所有人都在讨论\u0026quot;学历贬值\u0026quot;时，真正发生的是学历信号价值的结构性分化与重构。\n要理解这个过程，你需要像Musk和黄仁勋一样思考——从成本、概率、规模化的商业逻辑出发。更重要的是，他们在乎的从来不是那张纸，而是**\u0026ldquo;你在获得那张纸的过程中，大脑发生了什么变化\u0026rdquo;**。\n市场叙事的三大致命误区 # 误区1：\u0026ldquo;学历正在贬值\u0026rdquo;——数据不支持 # 到处都是\u0026quot;大学生找不到工作\u0026quot;的新闻，入门级职位发布自2023年1月以来下降35%。\n但看看真实数据：\n纽约联储2025年最新数据显示，大学毕业生年薪中位数约8万美元，高中毕业生4.7万美元，工资溢价超过3.2万美元（68%），这个比例接近历史最高水平。\n2024年人口普查局研究确认，学士学位持有者相比高中文凭持有者的收入溢价为80%。\n如果学历真的在贬值，这个数字应该崩塌，而不是创新高。\n但平均值掩盖了什么？\n同样来自纽约联储的数据显示：位于75百分位的大学毕业生收入比高中中位数高233%，而位于25百分位的大学毕业生仅高17%。Princeton和Vanderbilt的研究人员发现，低收入家庭完成大学学位的收入溢价自1960年以来减半。\n不是\u0026quot;学历贬值\u0026quot;，而是顶层学历价值暴涨，底层学历加速归零。\n当你听到\u0026quot;平均68%溢价\u0026quot;，你看到的是被哈佛、MIT、斯坦福这些顶层拉高的平均值。如果你拿的是一张中下游大学的文凭，你可能正在经历信号价值的自由落体。\n误区2：\u0026ldquo;AI让学历失去意义\u0026rdquo;——因果倒置 # 风投公司SignalFire的研究很有意思：15家市值最大科技公司的入门级新聘占总新聘比例，从2019年的11%降至2024年的7%，下降了近50%。\nCengage Group报告显示，2025届毕业生中仅30%在毕业时获得全职工作，低于2024届的41%。\n看起来AI在霸占大学生的就业机会？但时间线揭示了不同的真相：\n明尼阿波利斯联储数据：要求大学学位的职位发布占比早在2010年就开始下降——当时ChatGPT还要12年才会发布。2010年，每1个不要求学位的职位对应1.2个要求学位的职位；到2020年，这个比例变成0.6:1。\n旧金山联储研究指出，大学工资溢价在2007-09金融危机后就停止增长。\n克利夫兰联储2025年研究发现，21世纪以来，大学教育劳动力相对非大学劳动力的生产率优势增长已经停滞。\nAI不是原因，而是加速器。真正的结构性转变早在十几年前就开始了：\n供给爆炸\n：拥有学士学位的劳动力占比从2000年的31%跃升至2025年的45%——大学生从稀缺资源变成大路货\n需求质变\n：技术进步让企业需要的不是\u0026quot;更多受过教育的人\u0026quot;，而是\u0026quot;特定类型的高端人才\u0026quot;\nAI催化\n：ChatGPT和类似工具正在消灭的，恰恰是\u0026quot;普通大学生用4年学到的那些入门级认知技能\u0026quot;——撰写报告、数据整理、初级分析\nAI时代，企业需要的是能驾驭AI的人，而不是被AI替代的人。\u0026ldquo;能驾驭AI\u0026quot;需要的认知深度，恰恰是顶尖教育系统才能批量训练出来的。这就是Musk和黄仁勋看到的真相。\n误区3：\u0026ldquo;技能优先会取代学历\u0026rdquo;——理想与现实的鸿沟 # 81%的雇主声称在2024年使用某种形式的技能优先招聘，这个比例在2022年还只是56%。LinkedIn、各大科技公司都在高调宣布\u0026quot;取消学历要求\u0026rdquo;。\n但实际情况呢？哈佛商学院和Burning Glass Institute的综合分析揭示了残酷真相：虽然85%的公司声称采用技能优先招聘，但实际只有0.14%的聘用受到学历要求移除的影响——不到七百分之一。即使职位发布取消了学历要求，招聘经理在实际审查简历时仍然会倾向于传统学历背景。\n这不是虚伪，这是Musk和黄仁勋都心知肚明但不会公开说的商业理性。\nMusk和黄仁勋不会公开说的招聘经济学 # 真相1：学历是成本最低的初筛工具——规模化的铁律 # NVIDIA某个真实岗位：\n职位：高级GPU架构工程师\n发布一周后：收到7500份简历\nHR团队：4个人\n要求：5个工作日筛选出25人进入技术面试\n选择A：纯技能评估\n要求每个候选人提交技术白皮书（评估每份需30分钟）\n审查GitHub上的GPU相关项目（需要懂GPU架构的工程师评估）\n验证项目经验真实性（防止简历注水）\n成本： 7500 × 30分钟 = 3750小时 = 469个工作日\n即使4个人全职做，也需要117天。\n选择B：学历初筛 + 技能验证\n第一轮：筛选计算机/电子工程PhD（斯坦福/MIT/UC伯克利/CMU/UIUC等Top 20）\n用时：7500份 × 30秒 = 62.5小时\n剩余候选人：约300人\n第二轮：审查这300人的论文和GitHub\n用时：300 × 20分钟 = 100小时\n总成本： 162.5小时 = 20个工作日\n**效率差异：23倍。**黄仁勋会在公开场合说这个吗？不会。但NVIDIA的HR系统就是这么设计的。\nSHRM 2024研究显示，62%的HR专业人士认为技能验证仍是重大挑战——这不是意识形态问题，这是数学问题。\n真相2：顶尖大学提供的不是知识，而是\u0026quot;多维度筛选+高强度训练\u0026quot;的结果 # Musk真正看重什么？MIT的计算机系为什么有价值？不是因为算法课讲得比Coursera好，而是因为它运营了一个多年、多维度的人才筛选和神经重构系统。\n第一层：入口筛选 # 能进MIT的学生，已经通过了SAT/ACT高分（认知能力proxy）、高中GPA 4.0+（自律性proxy）、科学竞赛获奖（专业热情proxy）。\n这不是\u0026quot;学历歧视\u0026quot;，这是利用了MIT admissions office的筛选劳动成果。\n第二层：认知熔炉的神经重构 # MIT的6.006（算法课）每周problem set平均耗时15-20小时，期中考试平均分可能只有60分。这个过程在物理性地改变大脑。\n神经科学研究表明：大脑的突触连接强化，必须通过**\u0026ldquo;认知负荷 + 反复失败 + 艰难突破\u0026rdquo;**这个循环。被动接收信息的突触强化效果不到主动痛苦挣扎的20%。\n当你在凌晨3点盯着一道MIT的problem set，想了5小时还做不出来，抓狂、崩溃，然后第二天突然顿悟——这个\u0026quot;痛苦-突破\u0026quot;循环，正在重新布线你的神经回路。ChatGPT给你答案？你的大脑结构没有任何改变。\n真相3：\u0026ldquo;不看学历\u0026quot;是面向外行的话术，不是大众的路径 # Musk的\u0026quot;不看学历\u0026quot;到底在说什么？他说的是：如果你是那种能自学火箭科学、能独立设计出可行的推进系统、能在GitHub上展示世界级代码的外行——我确实不在乎你有没有文凭。\n问题是：这样的人占比多少？\nAmazon 2024年雇佣了2,468名编程训练营毕业生，比2021-22年增长129%。但Amazon一年总招聘量超过10万人，2,468人占比不到2.5%。\n而且这2,468人里，绝大多数不是去做核心技术岗，而是去做运维、测试、初级开发。真正的核心算法工程师、系统架构师，训练营背景的占比可能不到0.5%。\nSpaceX的招聘流程里，简历筛选算法的权重设置中，\u0026ldquo;学校tier\u0026quot;仍然是重要变量——只是这个不会写进招聘JD而已。\n分化与重构的深层机制 # 机制1：网络资本的指数级分化 # 低收入家庭完成大学学位的收入溢价自1960年以来减半。为什么同样是\u0026quot;大学毕业生\u0026rdquo;，穷人的文凭贬值得更快？\n路径A（精英家庭的孩子）：哈佛 → 教授实验室（父母人脉） → 硅谷VC实习（校友） → 顶会论文 → Stripe/OpenAI（内推）。\n路径B（第一代大学生）：州立大学 → 信息gap → 缺乏guidance → 简历海投被过滤。\n同样花4年时间，顶层学生和底层学生获得的\u0026quot;信号强度\u0026quot;可能差10倍。这不是学历贬值，这是学历信号的马太效应。\n机制2：AI重新定义了\u0026quot;价值创造点\u0026rdquo;——入门阶梯消失 # Burning Glass Institute总裁Matt Sigelman说：\u0026ldquo;雇主在入门级明显更倾向于裁员，而在许多情况下会加大对更有经验专业人士的招聘。\u0026rdquo;\n传统路径： 入门级岗位（2-3年）→ 中级岗位（3-5年）→ 高级岗位 AI后新现实： AI（替代入门级）→ 人类（直接需具备判断/决策/创新能力）\n看看NVIDIA 2024年的招聘模式变化： 从招100个应届PhD慢慢培养，转变为招20个顶尖应届PhD（必须有成果）+ 80个资深工程师。不是不招大学生，而是只招\u0026quot;已经在大学期间证明了自己的大学生\u0026quot;。\n机制3：大学期间\u0026quot;你做了什么\u0026quot;正在成为比\u0026quot;你上了什么大学\u0026quot;更重要的信号 # 候选人A：MIT CS，GPA 3.8，按部就班上课。\n候选人B：MIT CS，GPA 3.6，NeurIPS一作，PyTorch贡献者，OpenAI实习。\n毫无悬念选B。因为B用4年时间完成的不只是\u0026quot;学历获取\u0026quot;，而是建立了动态portfolio。\n但这个重构有个残酷的前提：只有顶尖大学的学生，才有足够的资源、信息、网络去完成B的路径。\n他们真正想要的是什么 # 1. 抽象思维的自动化 # \u0026ldquo;如何优化星舰的燃料加注流程？\u0026ldquo;普通工程师会去搜现有方案，顶尖工程师下意识就能抽象成数学模型。差异不在\u0026quot;知识量\u0026rdquo;，而在思维的自动化程度——就像钢琴家看到乐谱，手指自动就知道怎么弹。\n2. 在模糊性中快速建立框架的能力 # \u0026ldquo;设计一个新的GPU架构来优化LLM训练。\u0026ldquo;黄仁勋看重的是你能不能在30分钟内建立起分析框架，是不是从第一性原理出发思考。这种能力从哪来？从你在MIT做6.824分布式系统时，连续3个月debug一个没有标准答案的project里来。\n3. 超长周期的专注力和抗挫折能力 # SpaceX的真实工作场景需要连续3个月解决一个bug。能扛住这个的人，通常在大学期间经历过类似\u0026quot;地狱模式\u0026quot;的训练（如PhD答辩被碾压）。这种经历训练了延迟满足和恢复力。AI可以给你答案，但不能替你经历那个痛苦的神经重构过程。\n给决策者的真实框架 # 框架1：不是\u0026quot;要不要大学\u0026rdquo;，而是\u0026quot;如何最大化大学4年的信号强度\u0026rdquo; # 学历的价值 = 学校tier × 大学期间的作为 × 专业匹配度\n**如果能进入Top 20：**不要只刷GPA。找教授做research，做开源贡献，利用校友网络。目标是毕业时拥有\u0026quot;MIT文凭 + 3篇顶会 + Google实习\u0026quot;这种组合。\n如果只能进入中游大学：需要更强的自驱力。线上建立GitHub Portfolio，在Kaggle拿名次，参加创业比赛。你需要建立足够强的替代信号来弥补学校tier的不足。\n框架2：基于真实数据的ROI计算 # 真实的公式应该是：\n期望ROI = (溢价 × 就业概率 × 职业生涯长度 × (1-AI替代风险)) - 成本\n不同学校、不同专业，这个结果可能差20倍。\n最底层的真相 # 真相1：学历从来都是社会分层工具，AI只是在\u0026quot;升级\u0026quot;这个工具的精度 # AI时代，分层工具从\u0026quot;大学 vs 非大学\u0026quot;升级为\u0026quot;学历 + 论文 + GitHub + 实习\u0026quot;的多维验证。这提高了分辨率，也加高了壁垒。\n真相2：Musk和黄仁勋其实是\u0026quot;学历价值重构\u0026quot;的最大受益者 # 当大众相信\u0026quot;学历无用\u0026quot;时，中下层减少教育投资，精英层继续强化投入。结果是SpaceX和NVIDIA能更高效地筛选出顶尖人才，且议价能力可能更强。\n真相3：大学从\u0026quot;知识提供者\u0026quot;转变为\u0026quot;认知训练场\u0026rdquo; # 知识传授ChatGPT做得更好。但AI无法复制：强制性的认知地狱、高密度的同辈竞争、稀缺的网络节点、系统性的信号组合。\n市场不同情误解规则的人 # 主流叙事告诉你：\u0026ldquo;学历正在贬值，技能优先时代来临，大学不再重要。\u0026rdquo;\n**数据告诉你：**学历工资溢价68-80%，接近历史最高；但75百分位是233%，25百分位仅17%；85%公司说技能优先，实际只有0.14%的招聘受影响。\n**Musk和黄仁勋的行为告诉你：**他们说\u0026quot;不看学历\u0026quot;，但招聘系统仍优先筛选顶尖大学；他们要的不是文凭，而是\u0026quot;在获得文凭过程中被高强度训练重构过的认知系统\u0026quot;。\n最关键的真相：\n真正有价值的不是\u0026quot;名校\u0026quot;标签，而是千锤百炼形成的思维素养——抽象思维自动化、在模糊性中快速建立框架、超长周期的专注力和抗挫折能力。\n名校通过系统设计批量培养这些能力。非名校生也完全可以达到，但需要更强的自驱力和更清晰的路径规划。\n理解规则的复杂性，看穿叙事和现实的gap，基于数据做理性决策。\n不管你在哪条路径，核心目标都是：通过高强度、长周期的认知训练，重构你的思维系统。\n留给你思考的问题 # 当Elon Musk说\u0026quot;我不在乎你的文凭\u0026quot;时，他真正的意思是：\n\u0026ldquo;如果你的大脑已经通过某种方式（无论是MIT的认知地狱，还是自学时的极限挑战）完成了足够强度的神经重构，证明了你拥有在高不确定性环境下快速学习、抗压、创新的能力——那么这个能力的来源我不在乎。\u0026rdquo;\n\u0026ldquo;但统计上，这样的人99%来自顶尖教育系统或付出了超常努力的自我训练。所以我的招聘系统仍然会把学历（或同等水平的能力证明）作为最经济的初筛工具。\u0026rdquo;\n这就是学历信号价值重构的完整逻辑。\n理解这一点，你就理解了AI时代的游戏规则。\n核心洞察：不是名校的问题，而是思维素养的千锤百炼 # 读到这里，我们需要澄清一个最本质的误区：问题的本质从来不是（或不仅仅是）那张印有名校Logo的纸。\nMusk和黄仁勋所筛选的，本质上是一种经过高强度结构化训练后产生的\u0026quot;思维素养\u0026quot;和\u0026quot;认知耐力\u0026quot;——抽象思维的自动化、在模糊性中快速建立框架的能力、超长周期的专注力和抗挫折能力。\n名校之所以有价值，是因为它们提供了一个系统化的、高压的、难以逃避的**\u0026ldquo;认知熔炉\u0026rdquo;**环境，让学生被迫进行成千上万次的逻辑推演、假设验证和挫折修复，从而完成物理层面上的\u0026quot;神经重构\u0026quot;。\n名校生的优势不是\u0026quot;更聪明\u0026quot;，而是\u0026quot;系统设计\u0026quot; # 名校提供的系统性优势包括：\n强制性认知地狱：\n不交作业就挂科，逼你解决困难\n同辈压力机制：\n室友都在图书馆，社会压力驱动你前进\n导师权威：\n教授说\u0026quot;这个必须懂\u0026quot;，你就得硬着头皮啃\n声誉锁定：\n考进名校退学成本太高，形成承诺机制\n资源密度：\n实验室、图书馆、同学、校友网络形成的信息场\n这个\u0026quot;被迫完成认知升级\u0026quot;的系统，对大部分人来说，是最高效的让你持续在认知地狱里待4年的社会机制。但这不是唯一的机制。\n非名校生的路径：更难，但完全可行 # 关键认知：非名校生可以达到同样的认知高度。\n数据支持：Amazon 2024年雇佣2,468名编程训练营毕业生——虽然只占总招聘的2.5%，但对你个人来说，这是100%的可能性。这2,468个真实的成功案例证明：路径存在，且每年在扩大。\n如果你没有名校的系统支持，你需要自己创造这个系统：\n1. 创造\u0026quot;强制机制\u0026quot;（替代名校的外部压力） # 公开承诺：\n在社交媒体宣布学习目标和时间表，利用社会压力监督自己\n金钱绑定：\n报名训练营或课程（形成沉没成本，逼迫自己完成）\n找Accountability Partner：\n找志同道合的人互相监督（线上社区、学习小组）\n设置里程碑：\n每月公开展示学习成果（博客、GitHub、视频）\n2. 主动寻找\u0026quot;高强度项目\u0026quot;（替代名校的课程设计） # 开源贡献：\n给顶级开源项目贡献代码（从小bug开始，逐步承担复杂feature）——这是最接近\u0026quot;名校作业\u0026quot;强度的训练\n竞赛驱动：\n参加Kaggle竞赛瞄准top 1%（需要几百小时高强度投入）\n论文复现：\n从头实现顶会论文，debug到work（训练深度理解能力）\n构建复杂系统：\n做一个需要3-6个月才能完成的side project（训练长周期专注力）\n3. 建立\u0026quot;替代性信号\u0026quot;（让HR看到你的能力） # GitHub Portfolio：\n持续1年+的高质量commit记录（证明持续输出能力）\n技术博客：\n展示深度思考，不是tutorial而是原创洞察（证明理解深度）\n开源影响力：\n成为某个工具的核心贡献者或maintainer（可验证的能力证明）\n竞赛成绩：\nKaggle、黑客马拉松的获奖记录（可量化的排名）\n行业认证：\nAWS、NVIDIA DLI等权威认证（补充技术深度）\n4. 补足\u0026quot;信息Gap\u0026quot;（这是最容易被忽视的） # 找Mentor：\n通过LinkedIn、Twitter主动联系行业内的人（很多人愿意帮助真正努力的年轻人）\n加入专业社区：\nSlack/Discord群，观察高手如何思考和解决问题\n解读招聘JD：\n不只看明面技能清单，理解\u0026quot;隐藏要求\u0026quot;是什么\n关注行业动态：\n订阅高质量newsletter，跟踪技术趋势\n真实案例的启示 # 那2,468名被Amazon雇佣的训练营毕业生，他们的共同特征不是\u0026quot;运气好\u0026quot;，而是：\n在没有deadline的情况下，保持了高强度学习（自律）\n在没有同辈竞争的情况下，实现了自我驱动（内驱力）\n在失败多次后，还能继续尝试（韧性）\n在看不到明确回报的情况下，投入了几千小时（延迟满足）\n这些品质，MIT学生也需要，但MIT的系统设计帮他们降低了\u0026quot;逆人性\u0026quot;的门槛。\n非名校生需要完全靠自己跨越这个门槛——但这绝对可以做到。\n给非名校生的三个关键建议 # 1. 不要被\u0026quot;学历无用论\u0026quot;欺骗\n误区：\u0026ldquo;学历无用，我随便自学就行\u0026rdquo; → 错。自学要达到名校生水平，需要更强的自律+更多的时间+更清晰的方向。但这可以实现。\n2. 也不要被\u0026quot;名校崇拜\u0026quot;吓退\n误区：\u0026ldquo;进不了名校就没希望了\u0026rdquo; → 错。路径更难，但机会真实存在。关键是你要建立足够强的\u0026quot;替代信号\u0026quot;，让HR相信你的能力。\n3. 理解核心目标：神经重构，而非文凭收集\n不管你在哪条路径，核心目标都一样：通过高强度、长周期的认知训练，重构你的思维系统。名校提供了一个更高效的环境，但不是唯一的环境。\n**最重要的问题是：**你是否愿意并且能够主动进入认知地狱，并且在里面待足够长的时间？\n如果答案是yes，那么你的起点在哪里，真的没有那么重要。\n参考文献 # \\[1\\] Federal Reserve Bank of New York. (2025, April). \u0026ldquo;Is College Still Worth It?\u0026rdquo; Liberty Street Economics. Retrieved from https://libertystreeteconomics.newyorkfed.org/2025/04/is-college-still-worth-it/\n\\[2\\] U.S. Census Bureau. (2024, September). \u0026ldquo;New U.S. Census Bureau Research Shows Growing College Earnings Premium.\u0026rdquo; Retrieved from https://www.aplu.org/news-and-media/blog/2025/09/09/new-u-s-census-bureau-research-shows-growing-college-earnings-premium/\n\\[3\\] Federal Reserve Bank of New York. (2020). \u0026ldquo;College Graduate Wage Distribution Data.\u0026rdquo; The Labor Market for Recent College Graduates. Retrieved from https://www.newyorkfed.org/research/college-labor-market\n\\[4\\] Bleemer, Z., \u0026amp; Quincy, S. (2025). \u0026ldquo;Changes in the College Mobility Pipeline since 1900.\u0026rdquo; NBER Working Paper No. 33797. Retrieved from https://fordhaminstitute.org/national/commentary/historical-trends-college-wage-premium\n\\[5\\] SignalFire. (2024). \u0026ldquo;Entry-Level Hiring Trends in Technology.\u0026rdquo; Market Research Report.\n\\[6\\] CNBC. (2025, November 15). \u0026ldquo;AI puts the squeeze on new grads—and the colleges that promised to make them employable.\u0026rdquo; Retrieved from https://www.cnbc.com/2025/11/15/ai-puts-the-squeeze-on-new-grads-looking-for-work.html\n\\[7\\] Federal Reserve Bank of Minneapolis. (2025). \u0026ldquo;What Happened to the College Wage Premium?\u0026rdquo; Retrieved from https://www.minneapolisfed.org/article/2025/what-happened-to-the-college-wage-premium\n\\[8\\] Federal Reserve Bank of San Francisco. (2023, August). \u0026ldquo;Falling College Wage Premiums by Race and Ethnicity.\u0026rdquo; FRBSF Economic Letter. Retrieved from https://www.frbsf.org/research-and-insights/publications/economic-letter/2023/08/falling-college-wage-premiums-by-race-and-ethnicity/\n\\[9\\] TestGorilla. (2024). \u0026ldquo;The State of Skills-Based Hiring 2024 Report.\u0026rdquo; Retrieved from https://www.testgorilla.com/skills-based-hiring/state-of-skills-based-hiring-2024/\n\\[10\\] Harvard Business School \u0026amp; The Burning Glass Institute. (2024). \u0026ldquo;Skills-Based Hiring: The Long Road from Pronouncements to Practice.\u0026rdquo; Retrieved from https://www.burningglassinstitute.org/research/skills-based-hiring-2024\n\\[11\\] Society for Human Resource Management (SHRM). (2024). \u0026ldquo;Skills Validation Challenges in Modern Hiring.\u0026rdquo;\n\\[12\\] The Interview Guys. (2025, December). \u0026ldquo;The State of Skills-Based Hiring in 2025.\u0026rdquo; Retrieved from https://blog.theinterviewguys.com/the-state-of-skills-based-hiring/\n\\[13\\] RETS Associates. (2025, July 31). \u0026ldquo;AI Is Wrecking an Already Fragile Job Market for College Graduates.\u0026rdquo; Retrieved from https://retsusa.com/ai-is-wrecking-an-already-fragile-job-market-for-college-graduates/\n\\[14\\] National University. (2025, September 22). \u0026ldquo;59 AI Job Statistics: Future of U.S. Jobs.\u0026rdquo; Retrieved from https://www.nu.edu/blog/ai-job-statistics/\n\\[15\\] Federal Reserve Bank of Atlanta. (2025, May 21). \u0026ldquo;By Degree(s): Measuring Employer Demand for AI Skills by Educational Requirements.\u0026rdquo; Retrieved from https://www.atlantafed.org/cweo/workforce-currents/2025/05/21/by-degrees-measuring-employer-demand-for-ai-skills-by-educational-requirements\n\\[16\\] Federal Reserve Bank of Cleveland. (2025, March 31). \u0026ldquo;Demand for College Labor in the 21st Century.\u0026rdquo; Economic Commentary. Retrieved from https://www.clevelandfed.org/publications/economic-commentary/2025/ec-202504-college-labor-demand-21st-century\n\\[17\\] Bersin, J. (2025, December). \u0026ldquo;Yes, AI Is Really Impacting The Job Market. Here\u0026rsquo;s What To Do.\u0026rdquo; Retrieved from https://joshbersin.com/2025/12/yes-ai-is-really-impacting-the-job-market-heres-what-to-do/\n\\[18\\] St. John\u0026rsquo;s University. (n.d.). \u0026ldquo;How AI Is Changing the Job Market for Today\u0026rsquo;s College Students.\u0026rdquo; Retrieved from https://www.stjohns.edu/news-media/johnnies-blog/ai-impact-students-entering-job-market\n注：本报告所有数据和结论均基于上述权威机构的公开研究，引用标注见正文。完整数据集和方法论可通过上述链接查阅。\n","date":"30 January 2026","externalUrl":null,"permalink":"/posts/elon-musk%E5%92%8C%E9%BB%84%E4%BB%81%E5%8B%8B%E4%B8%8D%E4%BC%9A%E5%AE%8C%E6%95%B4%E5%91%8A%E8%AF%89%E4%BD%A0%E7%9A%84%E6%8B%9B%E8%81%98%E9%80%BB%E8%BE%91%E5%AD%A6%E5%8E%86%E7%9A%84%E7%BB%8F%E6%B5%8E%E4%BF%A1%E5%8F%B7%E4%BB%B7%E5%80%BC%E5%88%86%E5%8C%96%E4%B8%8E%E9%87%8D%E6%9E%84%E7%9A%84%E7%9C%9F%E7%9B%B8/","section":"AI-Related Reposts","summary":"","title":"[Repost] Elon Musk和黄仁勋不会完整告诉你的招聘逻辑——学历的经济信号价值：分化与重构的真相","type":"posts"},{"content":"Reposted from 推荐我日常高频使用的8个Skills，产出效率翻一倍 by AI编程实验室\n大家好，我是鲁工。\n最近一个月，Claude Code推出并成为开放标准的Skills生态彻底爆发了。\n从Anthropic官方到社区开发者，各种Skills层出不穷，风头甚至超出此前的MCP。\n作为最早使用Skills的一批人，我前前后后折腾了不少Skills，最终沉淀下来8个日常高频使用的。今天分享给大家，每个都是我实际在用的，并且是能真正转化为效率和生产力的。\n1. planning-with-files：加强版plan模式 # Claude Code老手应该都有这个体会，200k的上下文空间是真不够用。对话一长，前面的内容就会被遗忘。planning-with-files这个Skill的思路非常巧妙：它把Context Window当成RAM，把文件系统当成磁盘。\n安装后，Claude在开始复杂任务前，会自动创建三个Markdown文件：task_plan.md（任务规划）、findings.md（发现记录）、progress.md（进度日志）。每做两步操作就自动保存一次，每次做重要决策前都会重新读一遍计划文件。\n对于经常做复杂项目的开发者来说，这个Skill几乎是必装的。skill地址：\nhttps://github.com/OthmanAdi/planning-with-files\n2. superpowers：SDD的skills版 # superpowers是我目前用得最多的Skills集合，没有之一。它不是一个单独的Skill，而是一整套软件开发工作流框架，本质上是规范驱动开发（SDD）的skills版本。\n它的核心理念是：不要让AI上来就写代码。先用/superpowers:brainstorm做需求探索和设计，再用/superpowers:write-plan拆分实现计划，最后用/superpowers:execute-plan分批执行。整个过程强制执行TDD（测试驱动开发），先写测试再写代码，写完代码再重构。这个跟planning-with-files部分功能有重叠，但问题不大。\n除了核心的三板斧，它还有代码审查、系统化调试、Git Worktree管理等十几个子Skills。而且这些Skills会根据上下文自动触发，不用手动调用。\n如果你觉得Claude Code写代码太莽，经常拆东墙补西墙，那superpowers会非常对你胃口。skill地址：\nhttps://github.com/obra/superpowers\n3. frontend-design：告别AI千篇一律的UI审美 # 这是Anthropic官方出品的Skill，专门解决一个痛点：AI生成的前端页面长得都一样。清一色的Inter字体、紫色渐变背景、圆角卡片，一眼就知道是Vibe出来的UI。\nfrontend-design这个Skill会引导Claude做更大胆的设计决策。比如选择独特的字体组合（而不是默认的Arial和Inter），使用更有视觉冲击力的配色方案，根据设计风格匹配对应的实现复杂度（极简风格要求精准的留白和排版，而非简单地少放元素）。\n实际效果确实肉眼可见地好了。特别是搭配React + Tailwind使用，生成的页面质感和之前完全不在一个水平线上。\n不过要注意，它主要改善的是视觉设计层面，交互逻辑和业务功能还是得自己把关。skill地址：\nhttps://github.com/anthropics/skills\n4. NotebookLM Skill：让Claude直接查你的知识库 # NotebookLM很强大，这个应该没有人否认，我去年开始就把内容整理都交给NotebookLM了。这个skill能让Claude Code直接和Google NotebookLM对话，查询你上传到NotebookLM里的文档，拿到带引用来源的回答。\n举个使用场景：你把项目的技术文档、设计规范、API文档全部上传到NotebookLM，然后在Claude Code里写代码的时候，它可以直接去查这些文档，而不是靠自己XJB猜。因为答案全部来自你自己上传的资料，幻觉的概率大大降低。\n它还支持自动追问，会主动去挖掘细节信息、边界情况和最佳实践。认证也是持久化的，登录一次就行。skill地址：\nhttps://github.com/PleasePrompto/notebooklm-skill\n5. Obsidian Skills：Obsidian用户的福音 # 这个Skill出自kepano之手（Obsidian的创始人Steph Ango），算是Obsidian官方认证了。\n它让Claude Code能够直接创建和编辑Obsidian的三种原生文件格式：Obsidian Flavored Markdown、Obsidian Bases和JSON Canvas。放到Obsidian vault的.claude目录下就能用，兼容Claude Code和Codex CLI。\n我平时用Obsidian做知识管理和项目笔记，有了这个Skill之后，可以直接在Claude Code里操作Obsidian笔记，比如整理会议记录、生成项目文档、创建Canvas看板等。GitHub上8.7k星，社区认可度非常高。\n围绕Obsidian + Claude Code的生态其实已经很丰富了，还有obsidian-claude-code（原生插件）、obsidian-plugin-skill（Obsidian插件开发专用）等一系列工具，感兴趣可以进一步探索。这两个结合到一起真的能干很多事，只是我没有时间一一折腾。\nskill地址：\nhttps://github.com/kepano/obsidian-skills\n6. Remotion Skills：用代码做视频 # Remotion是一个用React做视频的框架，简单说就是：视频的每一帧都是一个React组件。而Remotion Skills就是让Claude Code具备这个框架的专业知识。这个我们号之前也写过好几篇文章来描述具体教程。\n安装之后，你可以用自然语言描述想要的视频效果，Claude会生成对应的React代码，实时预览，满意了再渲染成MP4。社区里有一些增强版本，还支持TTS语音生成、预置的标题幻灯片、代码块展示、图表动画等组件。\n我主要用它做技术演示视频和产品介绍短片。最大的好处是可以精确控制每一个动画细节，而且所有内容都是代码定义的，修改起来比传统视频剪辑方便很多。\n使用建议：不要一次描述整个视频，一个composition一个composition地来，迭代优化效果会好很多。\n官方文档：\nhttps://www.remotion.dev/docs/ai/skills\n社区增强版：\nhttps://github.com/wshuyi/remotion-video-skill\n7. Skill Creator：skill制造机 # 这也是Anthropic官方出品的Skill，专门用来帮你创建新的Skill。\n如果你有特定的工作场景想让Claude表现更好，比如特定框架的最佳实践、团队编码规范、特定领域的专业知识，都可以用Skill Creator来快速生成一个自定义Skill。\n它会通过问答的方式引导你定义Skill的名称、描述、触发条件、具体指令等，最终生成一个规范的SKILL.md文件。整个过程不需要写代码，只需要回答问题就行。\n实际上每个Skill的结构非常简单：一个SKILL.md文件，顶部是YAML元数据（名称和描述），下面是Markdown格式的指令。加载时只消耗约100个token做元数据扫描，激活后也就不到5k token。非常轻量。\n对于想入门Skills开发的人来说，用这个Skill来学习是最快的路径。\nskills地址：\nhttps://github.com/anthropics/skills\n8. research-skills：我自己做的科研写作工具包 # 最后一个是我自己开发的Skills集合，专门面向科研场景。\n做这个的初衷是，我平时写医学影像AI方向的综述论文和研究计划，流程比较固定但又很繁琐。于是把这些经验沉淀成了三个Skill：\nMedical Imaging Review：医学影像AI综述写作。包含一个结构化的7阶段写作流程，覆盖CCTA、肺部、脑部、心脏、病理、眼底等细分领域，支持Zotero文献管理集成。\nPaper Slide Deck：论文自动转PPT。支持从PDF论文中自动检测和提取图片，提供17种视觉风格模板，集成了Nano Banana API做slide生成，导出PPTX和PDF。\nResearch Proposal：博士研究计划撰写。遵循Nature Reviews风格的学术写作规范，支持中英双语输出，最终产出2000-4000词的研究计划，包含40+参考文献。\n如果你也在做学术研究相关的工作，欢迎试用和反馈。\n项目地址：https://github.com/luwill/research-skills\n以上就是我目前日常高频使用的8个Claude Code Skills。总结一下适用场景：\n项目管理：planning-with-files 开发流程：superpowers 前端设计：frontend-design 知识查询：NotebookLM Skill 笔记管理：Obsidian Skills 视频制作：Remotion Skills Skills开发：Skill Creator 科研写作：research-skills Skills的安装方式主要有三种：一是通过/plugin install命令一键安装（适用于已上架marketplace的Skills），二是手动clone到~/.claude/skills/目录。具体安装方式每个Skills的GitHub README里都有说明，还有一种就是通过vercel的npx skill命令来执行安装。\n友情提醒：跟MCP一样，Skills宜精不宜多，定期清理不用的Skills。\n最后，做个小调研。AI编程实验室将于年后正式推出Claude Code入门和Vibe Coding实践课程，这里先收集一下市场需求：\n我是鲁工，九年AI算法老兵，AI全栈开发者，深耕AI编程赛道。欢迎关注，感兴趣的朋友也可以加我微信（louwill_）交个朋友。\n\u0026gt;/ 作者：鲁工\n","date":"30 January 2026","externalUrl":null,"permalink":"/posts/%E6%8E%A8%E8%8D%90%E6%88%91%E6%97%A5%E5%B8%B8%E9%AB%98%E9%A2%91%E4%BD%BF%E7%94%A8%E7%9A%848%E4%B8%AAskills%E4%BA%A7%E5%87%BA%E6%95%88%E7%8E%87%E7%BF%BB%E4%B8%80%E5%80%8D/","section":"AI-Related Reposts","summary":"","title":"[Repost] 推荐我日常高频使用的8个Skills，产出效率翻一倍","type":"posts"},{"content":"Reposted from 木头姐：智能体改写赚钱逻辑，钱先流向 3 个方向 by AI深度研究员\n全文 3,000字 | 阅读约 8 分钟\nYour browser cannot play this video. Download video.\n（Cathie Wood：AI 时代财富新定义）\n钱，从来不迷信谁更聪明。\n它只信一件事：谁更能干。\n最近，一只龙虾刷屏硅谷。开源智能体 MoltBot（它因为商标问题 Clawdbot 改名而来 ） 火到出圈：它不光会聊天，更真能交付任务。\n与此同时，ARK Invest 创始人木头姐在最新年度报告中明确指出：AI 推理成本将每年下降70%-99%，全球GDP年增速可能突破7%，通胀甚至长期低于1%。\n把这两件事放在一起看：一边是智能体正在大量落地，另一边是推理成本每年暴跌。这意味着，AI 不再只是演示工具，而是可以大规模部署的劳动力。\n当智能体变成劳动力，赚钱逻辑就变了。钱开始流向能交付的那一方，木头姐给出3个方向：\n数字劳动力：MoltBot 这样的智能体，正在从聊天工具变成能交付任务的数字员工。\n实体劳动力：Robotaxi 从技术展示走向商业闭环，2030年全球市场可能达到34万亿美元。\n底层基础设施：推理成本暴跌、核能重启、太空数据中心，让 AI 成为像水电一样的基础设施。\n这不是未来，这是现在。\n第一节｜MoltBot 背后：数字劳动力市场已开启 # MoltBot 火了，但它不是大厂产品，而是开源社区里自发诞生的小项目。\n短短几天内，这只龙虾在硅谷圈子里迅速传播，被用来代办任务、归类笔记、早起提醒、管理邮箱。木头姐形容它像个人工智能实习生，在你睡觉时还在帮你整理生活。\n但这不只是个有趣的工具。她的研究团队指出：这类智能体，不再是聊天机器人，而开始像劳动力一样被部署。看信息、下决策、做执行。用木头姐的话说：MoltBot 不是在对话，是在交付。\n这背后，一个新市场正在成形。\n几年前，AI 还是个问答工具：问它问题，等它回答。但 MoltBot、GPTAgent这些项目出来后，最明显的变化是：人不再只是提问，而是直接安排工作。\n比如打开 MoltBot，只需要说一句：把我过去三天的短信、邮箱和备忘录里的会议邀请都提取出来，做一个时间表发给我。就能得到一份 Word文档、日历文件和总结报告。\n这种“任务→完成”的交互方式，让 AI 正式开始接手以前需要人类助理才能完成的工作。\n木头姐认为：这是数字劳动力的起点。\n有人会问：这不是早就有了吗？为什么到了2026年，才突然集中爆发?\n答案在于:几件事凑到一起，让智能体从能用变成了好用。\nAI 能力跃升了。\n它处理速度从 30 秒降到 3 秒；\n它能读的资料从几页变成上百页文档；\n它从需要手把手教，到说一句话就能执行一整套流程。\n更关键的，是这些系统已经足够开源和本地化。\nMoltBot 的出现，让开发者可以在个人电脑上直接装一个智能体，不依赖云端，不需要登录账户。从公司到个人，谁都能动手部署自己的AI实习生。\n木头姐在访谈中提到 ARK 的变化。他们的首席 AI 分析师用了 MoltBot 后，工作效率明显提升。整个团队也是如此：我们没多招人，但交付速度快了一倍。\n以前，一个人只能做一个人的活。\n现在，一个人可以配几个智能体，让每个智能体专做一类任务：收集数据、写初稿、理解政策变动、生成展示文稿、整理会议纪要。\n当智能体能干一个实习生的活，真正的问题不是 AI 会不会干活，而是这些数字劳动力该怎么定价。\n这，就是木头姐说的数字劳动力市场。\n第二节｜Robotaxi：从技术叙事到商业闭环 # 智能体是看不见的数字劳动力，但还有一种劳动力，正在马路上跑起来。\n过去几年，大家对自动驾驶的认知还停留在烧钱、遥遥无期、还在测试上。但在木头姐看来，Robotaxi 正从技术叙事变成收入来源。它不仅能跑，而且能算出现金流。\n她在这次对话中明确表示:\n“Robotaxi 是我们未来五年最看好的商业模式，它的市场规模不只是大，而是已经能够被清晰量化。”\n1、赚钱路径清晰了:更少的车，更高的效率\n一辆 Robotaxi 的利用率可以达到50-60%，而私家车只有4-5%。这意味着更少的车，能服务更多的需求。\n她提到一个数据：Uber现在只覆盖美国1%的城市里程，用了14万辆车。要覆盖100%的城市里程，只需要2400万辆Robotaxi。这还不到美国现有汽车保有量(4亿辆)的十分之一。\n关键是：没有司机成本、车辆自动回充、AI 自我调度，边际成本极低。过去是一个司机配一辆车，现在是一个调度后台配一城的车。\nRobotaxi 不只是新交通工具。它是稳定可规模化的自动化运营，与电力、AI芯片、路权调度绑定，成为城市基础设施的一部分，能对接真实订单产生收入。\n这意味着，Robotaxi 是可复制的盈利模型，而不只是科技展品。在木头姐的投资框架里，这类项目可以像早期特斯拉那样，既能对外融资讲故事，又能自我造血产生现金流。\n2、钱会流向哪里？\n过去谈 Robotaxi，焦点都在车能不能跑、法规通不通。现在木头姐更关注的是另一个问题：谁能从Robotaxi规模化运营里，分得真实收入?\n她看好四类玩家:\n调度平台商，能接入多个Robotaxi品牌、做城市级路线规划和订单匹配的公司;\n能源服务商，掌握车辆夜间充电、路线中转、电网平衡的调配能力;\n芯片和算力基础设施提供者，为推理、路径规划提供稳定处理能力的底层服务;\n城市与地产开发商。在Robotaxi成本下降后，原本偏远的地段反而变成了新价值洼地。\n这已经不是单点技术创新，而是一个经济链条在重构。从交通到城市布局，从能源调度到消费习惯。\n她说：当车开始自己运营，城市的税收结构也会变。\n3、技术不是问题，条件正在成熟\n木头姐明确表示：Robotaxi 的技术准备，其实早就完成。真正拦着它的是监管节奏、基础设施跟不上、AI 运营成本没降下来。\n但现在，这三个条件正在同时被突破:\n监管方面：多个城市已批准无人车夜间运营; 基础设施方面：多地新建Robotaxi专用充电站和等候区; 成本方面：AI 的每公里运营成本已经低于人类司机。\n不少车厂过去十年在亏钱造概念，现在终于到了把 Robotaxi 变成盈利出口的节点。\n木头姐特别强调特斯拉的优势。特斯拉的成本结构比 Waymo 低50%，定价可以做到每英里20美分，而Uber现在是2.8美元。按照这个趋势，到2030年，全球Robotaxi生态系统可能达到 34 万亿美元。\nMoltBot 是数字劳动力，Robotaxi 是实体劳动力。\n但它们能大规模运转，都依赖同一件事：让 AI 运行起来的成本，要足够低。\n第三节｜推理成本暴跌：AI正在变成基础设施 # MoltBot和Robotaxi能用起来，因为有一个成本在暴跌。\n这个成本，指的就是推理成本。木头姐在访谈中反复强调：推理成本每年下降70-99%，这个变化让一切商业模型都能重新算一遍。\n1、什么是推理成本?\n不是训练一整个大模型花的钱，而是每次你用AI做一件事，它背后实际消耗的电、芯片、内存资源。\n比如你输入一段话，让Claude/GPT 帮你写一份方案，那一瞬间服务器在后台调用模型、生成回复，消耗的资源，就是推理成本。\n过去一次可能要几毛钱，现在可能只要几厘钱。不是模型变便宜，是用模型做事开始变便宜了。\n这个变化对普通用户影响不大，但对企业决策至关重要。\n当推理成本高，AI是演示工具；当推理成本低到可以大规模部署，它就成了劳动力。这轮AI增长不是靠堆人，也不是靠提价，是靠成本通缩。\n2、通缩改变了竞争逻辑\n当推理成本变得像水电一样便宜，企业就不再问AI能不能做，而是问：你每运行一次，花我多少钱?我能让AI替我做几件事?\n这时候，所有 AI 工具、平台、服务商的商业模型，都要重算一遍。\nClaude、ChatGPT 等的模型公司会被问：你们这个 Agent 跑10次，能省几个人?\n电力平台会被问：你能不能在晚高峰给我压缩电力成本?\nAI 芯片平台要回答：你能不能让每秒处理的数据翻一倍，但电费不变?\n资金不再盯着谁模型大，而是盯着谁能把每次运行成本压得更低、服务交付得更稳定。\n3、电力和算力，成了决定胜负的关键\n这一轮成本下降的背后，基础设施在加速升级。\n木头姐特别提到三个方向:\n核能重启。她指出如果70年代没有过度监管核能，今天的电价能低40%。现在美国多个州正在重启核电站，中国一次性建设28座大型核反应堆。更便宜的电力，意味着更便宜的 AI 运行成本。\n太空数据中心。SpaceX的可重复使用火箭让轨道数据中心成为可能，太空太阳能效率是地面的 6 倍。这将大幅降低数据中心的电力和散热成本，让AI推理变得更经济。\n分布式能源系统。她提到电网效率问题:晚上用电少，白天根据天气又过度使用。未来Robotaxi本身就是移动的储能设备，可以平衡电网负荷，让整个系统的能源利用率更高。\n这些变化叠加起来，让 AI 可以像基础设施一样被接入、定价、规模化使用。\n推理成本每降一个点，就有一批新应用能落地。\n成本降下来，钱就流过去。\n结语｜钱往哪流，已经有了答案 # AI 智能体不是下一件事，而是已经在干活的事。\n木头姐没谈模型有多强，她看的全是交付能力：\nMoltBot 这样的数字助理，让一个人的产出翻倍；\nRobotaxi这样的实体劳动力，2030年市场可能达到34万亿美元；\n推理成本每年暴跌70-99%，让AI变成像水电一样的基础设施。\n钱，已经开始流向能交付的那一方。\n不是谁更聪明，而是谁更能干。\n识自AI\n📮 本文由AI深度研究院出品，内容整理自ARK Invest《2026 Big Ideas》报告、Cathie Wood在Moonshots播客访谈及Bloomberg采访等网上公开素材，属评论分析性质。内容为观点提炼与合理引述，未逐字复制原访谈材料。未经授权，不得转载。\n星标公众号，👆 点这里1. 点击右上角2. 点击\u0026quot;设为星标\u0026quot;←AI深度研究员⋮←设为星标\n参考资料：\nhttps://www.youtube.com/watch?v=VoW13oUTTV0\u0026pp=2AatDA%3D%3D\nhttps://www.youtube.com/watch?v=VTKPbxhP8jE\nhttps://www.youtube.com/watch?v=wTKHzbLQfyc\n来源：官方媒体/网络新闻\n排版：Atlas\n编辑：深思\n主编: 图灵\n--END\u0026ndash;\n","date":"30 January 2026","externalUrl":null,"permalink":"/posts/%E6%9C%A8%E5%A4%B4%E5%A7%90%E6%99%BA%E8%83%BD%E4%BD%93%E6%94%B9%E5%86%99%E8%B5%9A%E9%92%B1%E9%80%BB%E8%BE%91%E9%92%B1%E5%85%88%E6%B5%81%E5%90%91-3-%E4%B8%AA%E6%96%B9%E5%90%91/","section":"AI-Related Reposts","summary":"","title":"[Repost] 木头姐：智能体改写赚钱逻辑，钱先流向 3 个方向","type":"posts"},{"content":"","date":"30 January 2026","externalUrl":null,"permalink":"/tags/video/","section":"Tags","summary":"","title":"Video","type":"tags"},{"content":"","date":"30 January 2026","externalUrl":null,"permalink":"/tags/writing/","section":"Tags","summary":"","title":"Writing","type":"tags"},{"content":"Powered by Gemini 3 Pro.\n这是一句非常深刻且直击本质的论断。要理解“人和AI的区别在于直觉”，我们需要深入探讨什么是人类的直觉（Intuition），以及AI目前运作的底层逻辑（计算与概率）究竟有何不同。\n这句话的核心在于区分**“生物性的感知”与“数学性的预测”**。\n以下我们可以从四个维度来拆解和理解这句话：\n1. 直觉是“经验的瞬间压缩” vs. AI是“数据的暴力计算” # 人类的直觉并不是凭空而来的魔法，它通常是基于长期经验积累后的潜意识快速处理。\n人类模式： 心理学家丹尼尔·卡尼曼（Daniel Kahneman）在《思考，快与慢》中将其称为系统1（System 1）。\n当一位经验丰富的消防员突然大喊“撤退！”，哪怕他还没意识到为什么，几秒后地板就塌陷了。这是因为他的大脑在潜意识中捕捉到了微小的热量变化或声音模式。\n特点： 这种处理是隐性的、模糊的、跳跃的，且往往只需要少量样本（Small Data）就能形成。\nAI模式： AI（特别是基于深度学习的大模型）看起来也有“直觉”，比如AlphaGo下的那步“第37手”棋，连人类棋手都看不懂，觉得是神之一手。\n但本质上，这是基于海量数据的概率最大化。AI没有“感觉”，它是在高维空间中计算出了胜率最高的路径。\n特点： 它是显性的数学权重、精确的、依赖大数据的。如果数据样本不够，AI就无法形成这种“伪直觉”。\n结论： 人的直觉是**“灵光一现”（基于少量的质的感悟），AI的“直觉”是“算力涌现”**（基于海量的量的堆叠）。\n2. 身体感知（Embodiment）与情感连接 # 直觉往往与我们的身体和情感紧密相连，而AI是“无体”且“无情”的。\n直觉不仅在大脑，也在身体里： 我们常说“gut feeling”（肠胃的感觉/直觉）。当我们觉得某个人“不可信”时，可能是我们的身体捕捉到了对方微表情的不协调，产生了一种生理上的不适感。 情感驱动的价值判断： 人的直觉包含道德和审美判断。艺术家作画时的一笔“直觉”，包含了他的痛苦、喜悦和对美的渴望。AI可以模仿梵高的画风，但它无法理解由于“孤独”而产生的那一笔触。 区别在于：\n人： “我觉得这样做是对的。”（包含伦理、身体感受、情绪）。 AI： “根据训练集，这样做符合99.8%的分布规律。”（纯统计学）。 3. 处理“模糊性”与“未定义问题”的能力 # 现实世界充满了模糊、矛盾和未定义的情况，这是直觉发挥作用的主战场。\n人类直觉擅长“跨域跳跃”： 我们可以把钓鱼的直觉用到管理团队上，或者把听音乐的感觉用到编程架构上。直觉允许我们在信息极度匮乏时，通过联想和隐喻做出决策。 AI需要清晰的边界： AI在规则明确的游戏（如围棋、编程）中可以战胜人类。但在规则模糊的场景（如“如何让这间屋子更有氛围感”或“如何安慰一个失恋的朋友”）中，AI只能通过模仿以往的对话来应对，它没有真正的“同理心直觉”。 4. “知道”与“理解”的鸿沟 # 这就是著名的**“中文房间”**哲学问题。\nAI 可以输出完美的答案，但它并不理解这个答案的含义。它只是预测下一个字出现的概率。 人类拥有元认知（Metacognition）。我们的直觉不仅仅是给出一个答案，还伴随着一种“我知道我知道”的确信感（或者犹豫感）。 比喻：\nAI 像是一个读过图书馆里所有书的图书管理员，它能瞬间帮你找到书的位置，能背诵内容，但它从未真正生活过。 人类 像是一个历经沧桑的老水手，虽然读书不多，但只要看一眼云的形状，闻一下风的味道，就知道暴风雨要来了。 总结：如何看待这句话？ # 说“区别在于直觉”，其实是在强调生命的独特性。\nAI 的直觉是“相关性”的极致： 它发现事物之间的联系（A出现通常伴随B），速度快且精准。 人的直觉是“因果性”与“意义”的结合： 我们不仅在寻找规律，更是在寻找解释和目的。 在未来，AI可能会通过模拟变得越来越像拥有直觉（比如现在的推理模型o1，开始尝试慢思考），但只要它没有肉体感受、没有生存本能、没有自主意识，它的“直觉”就永远只是数学拟合，而非生命冲动。\n人类的直觉，是我们在混乱宇宙中导航的指南针；而AI，则是帮我们划船的高效引擎。\n","date":"30 January 2026","externalUrl":null,"permalink":"/blog/%E4%BA%BA%E4%B8%8Eai%E7%9B%B4%E8%A7%89%E7%9A%84%E6%9C%AC%E8%B4%A8%E5%8C%BA%E5%88%AB/","section":"AI-Generated Blog","summary":"","title":"人和AI的区别在于直觉","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n所谓**“投资的全局观”**（Global/Holistic View of Investment），是指投资者跳出单一标的（如某只股票）、单一市场或单一时间点的局限，站在更高、更系统的维度审视投资行为的一种思维方式。\n它要求你既看**“森林”（宏观经济、周期），也看“树木”（具体资产）；既看“收益”，更看“风险”**。\n简单来说，没有全局观的投资者是在“赌博”或“碰运气”，而有全局观的投资者是在“配置资源”。\n以下从核心定义和实践方法两个维度为您拆解：\n一、 什么是投资的全局观？ # 投资的全局观通常包含三个维度的“全”：\n1. 视角的全局：自上而下的框架 (Top-Down) # 这是最核心的定义。它意味着你的投资决策链条是：宏观经济 大类资产 行业/赛道 具体标的。\n没有全局观： 听到消息说“某家公司要发新产品了”，马上买入。 有全局观： 先看现在处于经济周期的哪个阶段（衰退还是过热？利率是升是降？）。如果宏观环境是紧缩的，即使这家公司很好，现在可能也不是好的买入时机，或者应该通过配置防御性资产（如债券）来对冲。 2. 资产的全局：跨资产类别的配置 (Multi-Asset) # 全局观意味着理解各类资产之间的相关性。你的眼里不应该只有“股票”，而应该有股票、债券、商品（黄金、原油）、房地产、现金甚至另类资产。\n核心逻辑： 东方不亮西方亮。当股市下跌时，国债或黄金可能会上涨。全局观就是利用这些不相关甚至负相关的资产构建组合，让财富曲线平滑增长，而不是坐过山车。 3. 时间的全局：穿越周期的思维 (Long-Term Cycle) # 全局观要求拉长焦距，区分**“短期波动”（Noise）和“长期趋势”**（Trend）。\n例子： 一个季度财报不好是短期波动，但人口老龄化、能源转型（如ESG）是长期趋势。有全局观的投资者不会因为几天的涨跌而焦虑，而是关注长达5-10年的大周期。 二、 如何做到投资有全局观？ # 建立全局观不是一蹴而就的，可以通过以下四个步骤进行训练：\n第一步：建立“周期感” (Locate the Cycle) # 学会判断当下处于经济周期的什么位置。最经典的工具是**“美林时钟”**（Investment Clock）。\n怎么做： 关注两个核心指标——经济增长（GDP）和通货膨胀（CPI）。 复苏期（高增长、低通胀） 股票为王 过热期（高增长、高通胀） 商品为王 滞胀期（低增长、高通胀） 现金/防守 衰退期（低增长、低通胀） 债券为王 第二步：根据自身情况定“坐标” (Know Yourself) # 投资的全局观不仅看市场，更要看自己。这被称为**“资产负债表思维”**。\n怎么做： 不要问“现在买什么最好”，而要问“我的钱能放多久”。 如果这笔钱明年要买房（短期负债），哪怕股市机会再好，全局观也要求你必须配置低风险资产。 公式： 投资策略 = (你的目标 + 你的风险承受力) - 市场环境。 第三步：构建“反脆弱”的组合 (Asset Allocation) # 不要把鸡蛋放在一个篮子里，也不要放在“属性相同”的篮子里（比如买了科技股，又买了科技基金，这不算分散）。\n怎么做： 检查你的持仓。如果股市大跌50%，你的总资产会缩水多少？如果通胀突然飙升，你有没有抗通胀的资产（如黄金、REITs）？ 建议： 即使你是激进投资者，也保留一定比例的“压舱石”资产（如国债或高等级债券）。 第四步：警惕“幸存者偏差” (Avoid Biases) # 很多时候我们看不清全局，是因为我们只盯着成功的案例。\n怎么做： 在研究一个投资机会时，刻意去寻找**“反面观点”。如果所有人都在狂热讨论某个板块，全局观要求你思考：“如果市场共识错了，会发生什么？”** 总结与行动建议 # 投资的全局观，本质上是一种“承认自己无法预测未来，所以通过系统布局来应对不确定性”的智慧。\n","date":"30 January 2026","externalUrl":null,"permalink":"/blog/%E4%BB%80%E4%B9%88%E6%98%AF%E6%8A%95%E8%B5%84%E7%9A%84%E5%85%A8%E5%B1%80%E8%A7%82/","section":"AI-Generated Blog","summary":"","title":"什么是投资的全局观？","type":"blog"},{"content":"Powered by Gemini 3 Pro.\n在AI时代，\u0026ldquo;平庸\u0026quot;的定义正在发生根本性的改变。过去，平庸可能意味着技能不熟练；而在AI时代，平庸意味着\u0026quot;可被标准化\u0026quot;和\u0026quot;缺乏独创性\u0026rdquo;。凡是能够被SOP（标准作业程序）化、大量重复、单纯依赖记忆或基础逻辑推演的工作，AI都能比人类做得更快、更廉价。\n要避免成为被算法淹没的大多数，你需要从单纯的\u0026quot;执行者\u0026quot;进化为\u0026quot;驾驭者\u0026quot;和\u0026quot;创造者\u0026quot;。以下是几个核心维度的破局策略：\n1. 重新定义核心能力：从\u0026quot;回答问题\u0026quot;转向\u0026quot;提出问题\u0026quot; # AI是目前人类历史上最强大的\u0026quot;答题机器\u0026quot;。在过去，能迅速给出正确答案的人是专家；但现在，答案往往唾手可得。\n培养\u0026quot;提问力\u0026quot;（Prompt Engineering的本质）： 能够精准地定义问题、拆解复杂困境，并向AI提出高质量指令的能力，将比解决具体技术细节更重要。 判断力高于执行力： AI可以生成一百种方案，但它无法决定哪一种最符合当下的商业伦理、团队现状或长远战略。你需要具备更高维度的审美和决策能力，充当\u0026quot;总编辑\u0026quot;或\u0026quot;总指挥\u0026quot;的角色。 2. 深耕\u0026quot;高感性\u0026quot;与\u0026quot;高接触\u0026quot;领域 # AI擅长处理数据（Data），但不擅长处理情感（Empathy）和复杂的即兴互动。人类的温度是机器难以模拟的壁垒。\n情绪价值与叙事能力： 无论从事什么行业，学会讲故事、建立信任、理解他人的潜台词、进行复杂的谈判和说服，这些基于人性的技能将变得极度稀缺且昂贵。 提供定制化体验： 标准化的服务由AI提供，而你应当专注于那些需要高度个性化、非标且充满人文关怀的服务领域。 3. 成为\u0026quot;半人马\u0026quot;（Centaur）：人机协作的超级个体 # 不要试图与AI比拼它擅长的事情（如记忆海量知识、快速编写代码模版、处理大数据），而是要学会骑在AI背上。\n将AI视为外脑： 拒绝抵触，熟练掌握各类AI工具。让AI承担繁琐、重复的\u0026quot;脏活累活\u0026quot;，将释放出的精力全部投入到最具创造性、最需要灵感的环节（即\u0026quot;深度工作\u0026quot;）。 一人公司化： 借助AI，一个人的产出能力可以放大十倍。你可以尝试独立完成过去需要一个团队才能完成的项目（如全栈开发、多媒体内容制作），这种综合产出能力是平庸者无法具备的。 4. 建立\u0026quot;跨界综效\u0026quot;（Synergy） # AI目前的模型训练大多基于单一领域的深度学习，或者虽然通识但缺乏跨领域的深刻洞察。\n做\u0026quot;T型\u0026quot;甚至\u0026quot;π型\u0026quot;人才： 在一个领域精深是不够的，你需要将两个看似无关的领域结合起来。例如：不仅懂编程，还懂心理学；不仅懂金融，还懂艺术设计。 创新发生在边缘： 绝大多数创新都发生在学科的交叉点。AI很难自发产生跨界的\u0026quot;疯狂联想\u0026quot;，而这正是人类创造力的源泉。 5. 保持\u0026quot;认知弹性\u0026quot;（Cognitive Flexibility） # 知识的半衰期正在急剧缩短。你今天引以为傲的技能，可能三年后就是一个API接口。\n终身学习的元能力： 比学什么更重要的是\u0026quot;如何快速学习\u0026quot;。你需要建立一套属于自己的知识管理体系，能够快速吸纳新知，并迅速遗忘过时的旧知。 拥抱不确定性： AI擅长在确定性规则下通过计算寻找最优解，而人类更擅长在信息不全、规则模糊的混乱环境中寻找方向。 总结 在AI时代，\u0026ldquo;平庸\u0026quot;就是做一个只会按部就班的标准件。 要脱颖而出，你必须让自己的工作含有更高浓度的主观判断、人际情感和跨界整合能力。不要做AI的竞争对手，要做它的指挥官。\n","date":"30 January 2026","externalUrl":null,"permalink":"/blog/%E5%9C%A8ai%E6%97%B6%E4%BB%A3%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%88%90%E4%B8%BA%E5%B9%B3%E5%BA%B8%E7%9A%84%E5%A4%A7%E5%A4%9A%E6%95%B0/","section":"AI-Generated Blog","summary":"","title":"在AI时代如何避免成为平庸的大多数","type":"blog"},{"content":"Reposted from Prism使用初感 by 白格尔的黑猫\nlatex是我步入大学后第一个熟练掌握的课外技能。 说实话，昨天早上刷到OpenAI做了prism这样一个latex编辑器的时候还是挺惊喜的，在此之前，我一般使用overleaf来写latex文档，但苦于我们学校没有买overleaf的会员，我在期末周赶小论文时，写到一半便超出编译时长，无法编译，网上各种奇技淫巧诸如换编译器版本、编译质量等等都不奏效，这让我大为光火，再也不用overleaf了。当场便学着使用vscode进行本地编译，也成功了，之后大多时候就本地编译了。 prism完全免费，只需要你的ChatGPT账号登录即可，主页面非常简洁，一目了然。\n在编译中文文章时，需要在开头加上\n%! TEX program = xelatex 并将\n\\documentclass{article} 改为\n\\documentclass[fontset=ubuntu]{ctexart} 我把上个学期某个小论文的zip上传上来，经过以上设置，可以顺利编译。\n当然，prism最大的亮点应该是搭配ChatGPT 5.2模型使用。上传图片默认是从图片中提取公式，不需要其他任何指令。\n例如我把一张包含麦克斯韦方程组的图片直接放入对话中。\nChatGPT就能直接以代码块的形式直接给出latex公式，没有一句废话，这对于我来说是一个非常好的功能，既不用反复和ChatGPT强调输出latex格式不要废话，又能够避免图片上传限制问题。\n上图是在写实验报告时调教ChatGPT的过程。\n还有其他功能就是能够使用ChatGPT对bug进行修复，分享文档进行协助，以及语音输入等等。\n当然prism界面也可以实现像ChatGPT那样创建多个聊天，更加有序。\n看下来一圈，prism作为一个完全免费的latex编辑器是很优秀的产品，不过你的论文是否会用于大模型的训练尚不清楚，但对于我这样只是偶尔会用latex写写实验报告、提升课程小论文逼格的低年级学生，prism绝对是首选。对于像我这样有一些latex基础的同学，这是一个很顺手的工具，对于没有latex基础的同学，搭配AI和latex手册，上手编几篇论文就能够入门latex。不过对于科研人员，或许老老实实本地编译你的论文是一个更稳妥的选择。\nlatex始终也只是一个工具而已，OpenAI将它变得更顺手、可用、易得，对于小白，不再需要一步一步跟着指导部署本地编译器，对于像我这样偶尔写一篇论文的学生，不需要再绞尽脑汁去思考怎样压缩编译时长而不是思考我的论文本身。\n我暂时想不出仅仅只有10秒免费编译时长的overleaf不被人唾弃的理由。\n","date":"29 January 2026","externalUrl":null,"permalink":"/posts/prism%E4%BD%BF%E7%94%A8%E5%88%9D%E6%84%9F/","section":"AI-Related Reposts","summary":"","title":"[Repost] Prism使用初感","type":"posts"},{"content":"Reposted from Science | 谁在利用人工智能进行编程？生成式人工智能的全球扩散和影响 by 图灵财经\n原创 图灵财经 2026年1月29日 09:02\n点击蓝字 关注我们\n文献信息\nWho is using AI to code? Global diffusion and impact ofgenerative AI\n谁在利用人工智能进行编程？生成式人工智能的全球扩散和影响\n_作者：_Simone Daniotti, Johannes Wachs, Xiangnan Feng, Frank Neffke\n来源：Science\n时间：2026年1月\nINTRODUCTION\n生成式编码工具承诺带来巨大的生产率提升，但不均衡的采用可能扩大技能与收入差距。**我们训练了一个神经分类器，用以在 160,097 名软件开发者的 3,000 多万条 GitHub 提交中识别由 AI 生成的 Python 函数，从而追踪这些工具以多快、在何处被采用。**当前，AI 在美国编写的 Python 函数比例估计为 29%，其相对其他国家的领先优势正在缩小。**我们估计以在线代码贡献衡量的季度产出因此增加了 3.6%。AI 似乎更有利于经验丰富的资深开发者：他们的生产率提高，并且更愿意扩展到软件开发的新领域。**相反，早期职业阶段的开发者从 AI 采用中未显示出显著收益。这可能扩大技能差距，并重塑软件开发中未来的职业阶梯。\n据支持者称，人工智能（AI）——尤其是生成式人工智能（genAI）——将大幅提升我们的生产率，并彻底改变我们的工作方式。例如，genAI 预计将在越来越多的任务中补充或替代人类。这迫使个人、企业与政策制定者在重大不确定性下，就 genAI 的使用与监管作出重要决策。利害攸关：genAI 已通过 ChatGPT 或 Claude 等工具广泛可得，能够直接补充人类思考，并具备成为一种可解决多种问题的通用目的技术的潜力。\n迄今为止的实验与准实验性证据支持 genAI 具有变革潜力这一观点：在多种职业中，使用 genAI 会提高个体劳动者的生产率与产出。大语言模型（LLM）所有者报告的调查与数据表明，这些技术正在快速扩散。然而，关于 AI 对国内生产总值（GDP）与就业的总量影响的估计往往较为温和，这表明我们距离清晰把握 AI 的整体影响仍有很大差距。 我们确知，采用存在显著异质性，这可能导致经济分化。尽管 genAI 在劳动年龄人口中使用广泛，但自报的采用率在不同人口特征、资历、工作经验与行业之间差异显著。来自招聘广告与公司网站的证据表明，genAI 的采用在不同地理区域之间也存在差异。如果 genAI 的确显著提高生产率，那么任何采用障碍都将对国内与跨国不平等产生重要后果。然而，从历史上看，蒸汽机、发电机与计算机等通用目的技术的宏观生产率效应往往需要较长时间才会显现。综合而言，这导致我们对当下 genAI 影响存在较大不确定性。 要化解这种不确定性，需要在全球层面准确确定采用率、使用强度与生产率效应。展示 genAI 采用在人口与行业维度存在异质性的调查往往聚焦于单一国家。此前使用调查数据比较不同国家 AI 采用的研究发现了国内与跨国差异，但由于各调查在样本加权与分析期间上的差异，限制了我们直接比较观测到的采用率。在 genAI 情境下，为避免被评判，受访者可能会低报使用情况，尤其是在工作场景中。尽管如此，调查仍为理解采用模式提供了宝贵资源。类似地，随机对照试验与自然实验不可或缺，因为它们通过设计衡量 genAI 采用的因果效应。然而，这些研究通常把“获得 genAI 工具访问权”等同于“接受处理”，而不量化被处理个体在实验期间实际使用 genAI 的程度。此外，调查与实验往往只在较短时期内观察个体，这限制了我们了解采用的动态，并限制了我们观察那些更慢显现的采用效应。 为开始弥补这些缺口，我们提出：是否可以不依赖自我报告，而是用机器学习直接、随时间追踪地衡量个体对 genAI 的采用与使用强度？如果可以，这样的衡量能告诉我们 genAI 的采用速度如何？这在不同国家与人口特征之间是否存在差异？genAI 如何影响个体产出？个体特征（如经验）如何调节这种影响？ 研究设计概述\n为回答这些问题，**我们在 genAI 主要应用领域之一——软件开发——以细粒度展开研究。**软件开发是一个重要且高价值的行业，并且对 genAI 具有独特暴露。为此，我们设计并实现了一个机器学习分类器，用于在 GitHub 上基于开源 Python 项目的 3,000 多万次软件开发者贡献（即提交）中，识别在很大程度上由 AI 辅助编写的代码。为了训练该分类器，我们构建了一个定制训练集，将既有来源与一种生成合成训练数据的程序相结合。这使我们能够在细粒度层面分析 AI 生成代码的变化模式。我们利用这一新的微观数据来源，研究六个主要国家中 genAI 在编码使用上的扩散速度、这种扩散与人口特征之间的关系，以及它对一个包含 100,097 名美国软件开发者样本的编程活动的影响。\n识别 AI 生成代码\n为**收集一个大型编码活动数据集，我们汇集了 100,097 名美国 GitHub 用户对基于 Python 的开源项目的全部提交，并递归克隆与每个项目相关的所有 GitHub 目录。**接着，我们又为另外五个软件开发大国（中国、法国、德国、印度与俄罗斯）加入提交数据：对每个国家—年份随机抽取 2,000 名开发者（共 60,000 名开发者）。然后，我们分析这些提交以评估 AI 生成代码的普遍程度。 图 1 描述了我们如何将这些代码贡献分类为“人类生成”或“AI 生成”。我们将分析限制在代表“函数”的代码块上，以聚焦于一种细粒度、相对自洽、但仍具有实质内容的代码单元。我们首先构建一个“真实标签”数据集，收集我们确信由人类程序员/开发者编写的 Python 函数。为此，我们选取了 2018 年编写的函数，因为这些函数早于有能力的 genAI 模型发布。由于编程风格会随时间演化，我们又加入了来自 HumanEval 数据集的 2022 年与 2024 年函数。为了加入功能相似但由 genAI 编写的函数，我们采用两步程序：第一步，对每个由人类编写的函数，我们让一个 LLM 用英文描述该函数，并说明其输入与输出类型；第二步，我们将该文本输入另一个 LLM，并请求模型据此生成一个函数。我们使用两个不同的 LLM，避免在人类代码与其“转写”之间制造不必要的强相关，同时确保训练数据中的（合成）AI 生成函数在功能上与原始人类函数尽可能接近。 随后，我们在该数据集上训练一个机器学习分类器。我们使用 GraphCodeBert（一个面向代码的预训练语言模型）对每个函数进行表征，将函数嵌入到高维向量空间中；该表征使用函数的 token、注释以及变量的数据流图。生成的向量被输入分类器，用以判断一个给定函数是由人类还是由 genAI 编写。 结果（Results）\n该分类器表现非常好：其样本外 ROC AUC 得分为 0.96，平均真阳性率为 0.95。我们将该分类器应用于从 2019 年初到 2024年末、从3,100 万次对 Python 项目的贡献中提取出的 500 万个函数，覆盖美国全体基于 GitHub 的用户以及另五国的抽样用户。在补充材料中，我们显示该分类器也能正确识别在我们数据收集结束后推出的更新 LLM 所生成的代码，以及在现实世界与 LLM 交互中产生的代码，尽管准确率略低。用这些更新 LLM 产生的代码对分类器进行再训练可进一步提升性能。 图 2A 绘制了美国开发者的 AI 采用轨迹。**采用率在重大 AI 进展之后急剧上升，其中包括 Copilot、ChatGPT 与第二代 LLM 的发布。**图 2B 将美国与我们覆盖的另外五个主要国家进行比较，展示美国取得并持续保持了早期领先。到 2024 年末，美国约 29% 的 Python 函数由 AI 生成；德国与法国紧随其后，约为 23%/24%。印度在最初采用滞后后接近 20%。相比之下，俄罗斯与中国迄今仍属于较晚采用者。 聚焦美国开发者总体，我们发现：AI 采用率随开发者在 GitHub 上活跃年限的增加而下降。图 3B 显示，最有经验的开发者在其代码中约 27% 使用 genAI；而刚加入 GitHub 平台的开发者，这一比例约为 37%。相反，使用（自报的）基于名字推断性别的算法，我们发现男性与女性之间没有差异。 为评估 genAI 如何影响开发者产出数量与代码性质，我们使用带有用户固定效应与季度固定效应的回归模型。这类模型在控制全经济趋势的同时，比较同一开发者在不同时点的产出（以季度提交次数衡量）。这些模型表明 genAI 对开发者生产率具有显著影响。我们在不同提交集合上得到一致结果：所有提交、修改多个文件的提交（通常需要在脚本之间导航依赖关系），以及向脚本新增库导入的提交（通常引入新功能）。从 0% genAI 使用提高到 29% genAI 使用（即 2024 年末美国的估计采用率），与各类提交的提交率增加 3.6% 相关。然而，这些与生产率相关的关联完全由资深用户驱动：对资深用户而言，29% 的采用率意味着提交率增加 6.2%。相比之下，在早期职业阶段用户中我们未观察到统计显著效应。 **除了活动率上升，AI 采用还与对新库及库组合的更高尝试相关；既有研究将其解释为创新信号。**由于库往往聚焦特定功能（如可视化、自然语言处理、Web 交互或数据库操作），这些发现表明 genAI 帮助开发者将能力扩展到新的软件开发领域。在 2024 年末美国开发者的平均 AI 使用率下，我们的模型预测：使用 genAI 达到 29% 平均水平的开发者，将实现 2.7% 更多的新增库组合。结果对“识别新增库引入方式”的变化是稳健的。观察到的效应不太可能源于加入冷门库：若仅使用最常见的 5,000 个库，或先将库聚合为 124 个粗类别，结论变化不大。\n讨论（Discussion）\n我们的目标是以微观层面、全球尺度衡量软件开发者对 genAI 的使用。聚焦软件开发劳动力，我们展示了 genAI 的扩散过程及其对开发者产出数量与代码性质的影响。为此，我们开发了一个新的 genAI 分类器，用于识别 GitHub 提交中的 AI 生成函数。将其应用于覆盖六个主要国家的软件开发活动的大型数据集，我们记录到在关键 genAI 发布后不久，AI 生成代码出现明显增长峰值。与此同时，我们也观察到国家之间存在显著差异：美国领先但优势正在缩小，德国与法国紧随其后，印度快速追赶，而截至 2024 年末中国与俄罗斯仍相对滞后。与既有研究一致，我们估计早期职业阶段开发者采用率更高。然而，不同于多数既有工作，我们未发现男性与女性之间存在显著差异。 我们还发现 genAI 重塑了编程工作的规模与性质。利用“同一开发者内部差异”（比较同一开发者采用 genAI 前后），我们显示 AI 采用显著提高产出。使用 genAI 的开发者也更可能在其代码中引入新的软件库组合，这表明他们借助不熟悉的构件进入新的技术领域。然而，生产率与探索收益几乎完全集中在资深开发者身上。相比之下，尽管早期职业阶段开发者更频繁使用 genAI，但并未获得相同收益。 我们关于“早期职业阶段开发者使用更多 AI 但收获更少”的观察，可能反映了不同开发者在更广泛任务集合上利用 genAI 的能力差异。例如，资深开发者更快地解释并发现 AI 生成代码中的错误。该解释得到相关研究的支持：该研究显示，获得 genAI 访问权使资深开发者将更少时间用于协调活动、将更多时间用于编码。 我们的发现既复现也扩展了其他研究结论。本研究估计美国最新采用率约为 29%，与微软与亚马逊所宣称的编码工作采用率非常接近。这表明，尽管我们聚焦开源 Python 库的代码，我们的结果与其他情境的估计高度一致，并可能超越本研究特定设定而具有一定外推性。 **不同于多数其他研究，我们的方法改进与研究设计使我们能够比较各国早期采用率。我们发现美国开发者存在清晰且持续的领先。中国与俄罗斯等国家 LLM 使用可能更低，原因包括供给侧差异（OpenAI 与 Anthropic 等提供者会阻断访问）与需求侧差异（审查限制本地使用，尽管许多用户通过 VPN 连接）。**不过，其他主要国家正在快速追赶，从而削弱美国的先发优势。**本研究的另一特征是：既有文献通常聚焦“获得 genAI 访问权”，从而得到所谓意向性处理的简化因果效应，而非 genAI 本身；或只在受控实验中观察使用。相比之下，我们的方法可以量化这项新技术在真实工作活动中的使用强度。**最后，我们指出，我们关于跨国 genAI 使用的证据，与更广义、覆盖 genAI 时代之前的企业层面 AI 采用调查研究相互补充；尽管两者水平不可直接比较，但都记录到 AI 使用存在持续的跨国差距。 关于 genAI 的生产率效应，我们的估计通常小于随机对照试验与利用自然实验的研究所报告的结果。在稳健性检验中，我们检验了“采用收益的非线性或阈值效应”能否解释这种差异，但几乎没有证据支持这一假设。更有希望的解释是测量误差，它很可能使效应估计向下偏误。与此一致，补充材料中的图 S6 显示，如果对测量误差进行校正，我们的效应估计会显著提高。此外，我们显示有利效应集中在资深开发者，而早期职业阶段开发者几乎不受益。因此，既有研究报告的更高效应估计也可能反映了其所分析的人群与遵从样本差异。同时，资深与初级开发者之间从 genAI 获益的差距，使得关于未来职业与学习路径的可得性与性质存在很大不确定性。\n本研究存在若干局限。**第一，我们的分析聚焦软件开发。**尽管这限制了范围，但该行业的工作特别适合以所需细粒度进行定量分析，从而研究 AI 如何影响劳动者及其工作。**在软件开发内部，我们只关注 Python 的开源贡献。**尽管 Python 使用广泛，不同编程生态的采用模式可能不同。我们认为，基于 GitHub 开源 Python 代码得到的估计在经济上具有意义，因为开源软件支撑了大多数商业技术栈并创造显著价值。GitHub 在协作、网络化与信号传递中的核心地位也进一步将我们的证据与职业活动联系起来。此外，我们在美国得到的 AI 使用估计与美国头部企业所报告的 AI 使用情况高度一致，也提升了我们对外部有效性的信心。\n更一般而言，我们也未考虑同事之间可能存在的外部性、以及企业间生产率异质性；这些都可能与 genAI 如何影响编程活动相关。除企业之外，我们的地理分析仅覆盖部分国家，未来应扩展到不同收入水平的国家。就中国的特定情形而言——其编程社区还依赖另一协作平台 Gitee——我们仅聚焦 GitHub 项目可能会使估计存在一定额外风险。最后，关于 genAI 的效应，我们还可以用许多其他方式评估开发者生产率，从而更关注代码质量，例如跟踪问题如何解决、代码合并情况、以及测试覆盖率。尽管原则上可行，但这类分析需要新的数据收集与谨慎的指标设计，因此我们将 genAI 对代码质量影响的问题留待未来研究。\ngenAI 在编码中创造了多少价值？尽管难以给出确定答案，本研究提供了该拼图的重要部分。**基于对约 900 种职业的详细任务调查与工资统计的分析，我们估计美国每年在与编码活动相关的劳动力成本上的支出在 6,370 亿至 10,630 亿美元之间。若假设我们估计的 2024 年末 29% 扩散率（基于开源 Python 贡献）能代表总体代码，那么 genAI 编码助手在美国每年的价值取决于其提高生产率的程度。**使用我们自身较为保守的基准估计，genAI 会使提交量增加 3.6%。若假设这些提交反映了有价值的代码贡献，则我们的计算意味着 genAI 每年产生 230 亿至 380 亿美元的额外代码价值。该估计假设不同编程语言的生产率增益相似。在更保守情景下，如果 Python 以外的生产率效应可忽略不计，则 genAI 的价值将降至该数值的约 17%（约 40 亿至 60 亿美元），并使用 Python 在 GitHub 代码中的占比估计。 相比之下，软件开发中的多项实验室实验与现场实验都得到更大的 genAI 对任务完成时间的因果效应——这可能是比提交量更相关的衡量指标。对这些研究取平均得到：在 29% 采用率下，生产率提升约为 6.0%–15.7%。这将把 genAI 对美国编码活动的直接影响转化为 380 亿至 1,670 亿美元的范围。然而，这些估计忽略了 genAI 可能降低代码市场价格这一点：这会为代码消费者带来成本节约，同时降低供应方（程序员/开发者）的利润；将这种一般均衡效应纳入会进一步扩大可能结果范围。论文中的材料与方法显示这主要影响估计的上界，而下界几乎不受影响。这些粗略测算的结论是：尽管 genAI 对美国经济的总价值存在不确定性，但最可能是显著的，至少在数百亿美元量级。\n鉴于 genAI 已快速扩散到美国之外，即使仅限软件行业，全球成本节约也将更大。此外，**我们目前仍处于一项看似新的通用目的技术的扩散曲线早期阶段。从历史经验看，通用目的技术的早期生产率效应往往难以识别，因为需要时间将其整合进企业工作流与流程、培训员工并积累充分发挥潜力所需的互补资产。**基于此，我们在关于 genAI 生产率效应的讨论中更倾向于“乐观”一侧。 我们关于这些效应以及 genAI 异质扩散的结果，对政策制定者与研究者提出重要问题。我们需要理解 AI 采用的障碍：这些障碍是否类似于以往激进创新，还是这一时代有所不同？此外，这些障碍不仅需要在个体层面理解，也需要在企业、区域与国家层面理解。\n如何获取文章？\n关注本公众号：图灵财经\n点击文末**“阅读全文”**获取\n来源：Science\n编辑：卢思锦\n精彩推荐\n研究速递|Science：生成式人工智能生产力效应的实验证据\n人工智能与管理：自动化-增强悖论\n研究速递|Nature：人工智能和科学研究中的理解幻觉\n研究速递|图灵转型：人工智能、智能增强和技能溢价\n经典重温|人工智能和数据网络效应对创造用户价值的作用\n更多精彩内容\n[\n](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NjAxMzIwNw==\u0026action=getalbum\u0026album_id=2388894035618103297#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NjAxMzIwNw==\u0026action=getalbum\u0026album_id=2388894035618103297#wechat_redirect\")[\n](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NjAxMzIwNw==\u0026action=getalbum\u0026album_id=2393733589902622723#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NjAxMzIwNw==\u0026action=getalbum\u0026album_id=2393733589902622723#wechat_redirect\")[\n](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NjAxMzIwNw==\u0026action=getalbum\u0026album_id=2410581627799404548#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NjAxMzIwNw==\u0026action=getalbum\u0026album_id=2410581627799404548#wechat_redirect\")[\n](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NjAxMzIwNw==\u0026action=getalbum\u0026album_id=2432252325055758337#wechat_redirect \u0026ldquo;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NjAxMzIwNw==\u0026action=getalbum\u0026album_id=2432252325055758337#wechat_redirect\")\n","date":"29 January 2026","externalUrl":null,"permalink":"/posts/science--%E8%B0%81%E5%9C%A8%E5%88%A9%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BF%9B%E8%A1%8C%E7%BC%96%E7%A8%8B%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%85%A8%E7%90%83%E6%89%A9%E6%95%A3%E5%92%8C%E5%BD%B1%E5%93%8D/","section":"AI-Related Reposts","summary":"","title":"[Repost] Science | 谁在利用人工智能进行编程？生成式人工智能的全球扩散和影响","type":"posts"},{"content":"Reposted from 实测 Prism：OpenAI 的论文写作工具，完全免费 by 赛博禅心\n如果你是 LaTeX 苦手，这个产品值得一试\nOpenAI 发布了它的 LaTeX 写作工具 Prism，内置 AI，界面大概是这个样子。注意：这个目前的定位是 AI 配合你写，而不是 AI 写\n当收到 Prism 发布消息后，我把有关 Prism 的资料都丢了进去，让它帮我写一篇关于「AI for Science 未来一年趋势」的 Paper\n给它的提示词很简单：\n帮我完成一篇 paper，从 OpenAI 发布 Prism 事件出发，结合市面上的信息，预测未来 1 年 AI for Science 会产生哪些变化，相关的材料在文件目录里了\n然后它就开始干活了，大概两分钟\nPrism 界面，左边是 LaTeX 代码，右边是实时预览\n它先写了个中文版，结果所有中文都渲染失败了。让它改成英文重写，几分钟后就出来一篇完整的论文框架，有摘要、有章节、有引用格式\n最后输出的 paper，结构完整，引用格式也对\n确实是有用的，尤其在赶工的时候\n我用 Prism 写的那篇 paper，附在文末，感兴趣的可以看看\nPrism 是什么 # 1 月 27 日，OpenAI 发布 Prism，一个免费的、云端的 LaTeX 写作工具，集成了 GPT-5.2\nKevin Weil 在发布会上的原话：2025 年是 AI 改变软件工程的一年，2026 年是 AI 改变科研的一年\n定位直白：Cursor 做的是 AI 编程，Prism 做的是 AI 科研写作\n技术底子来自 OpenAI 去年收购的 Crixet，一个小型云端 LaTeX 编辑器。收购后把原来的 AI 助手换成了 GPT-5.2\n核心能力有几个：\n项目级上下文\nAI 读的不是单条聊天记录，是整个论文项目。你的章节结构、公式、引用、图表，它都看得到。所以改东西的时候，它知道上下文\n原地编辑\n不用复制粘贴。你说「把第三章的论证加强一下」，它直接在文档里改。改完会显示增删了多少行，你可以选择接受或撤销\n文献检索\n内置 arXiv 搜索，可以在写作过程中直接查文献、插引用\n图片转 LaTeX\n拍一张白板上的公式或者草图，它能转成 LaTeX 代码\n图片转 LaTeX 功能\n还有个语音编辑模式，可以用语音说修改指令。这个我没试\n语音模式，用嘴改论文\n免费的代价 # 完全免费，无限项目，无限协作者。任何 ChatGPT 个人账户都能用\n这里有个问题：你的论文 OpenAI 都能看到\nPrism 目前不支持零数据保留（Zero Data Retention），会保留请求日志。用户内容默认可能被用于训练未来模型，虽然可以在设置里关掉\n德国 Heise Online 的评价是：「必须假设 OpenAI 可以查看所有内容」\n如果你在写涉及商业机密或敏感 IP 的东西，这个要掂量一下\n和 Overleaf 比 # 我之前用的 Overleaf，一个很棒的工具，目前也有 2000 万用户，日活 40 万\n相比之下，Prism 的 AI 集成深度明显更强。Overleaf 去年加了个第三方的 Writefull 做 AI 功能，但那个是外挂式的，不是原生的\nPrism 免费，Overleaf 付费版每月 21 美元\n对于没有机构账号的学生和独立研究者，Prism 的门槛更低\nOpenAI 想干什么 # OpenAI 内部成立了一个「OpenAI for Science」团队，Prism 是第一个产品\n他们披露的数据：ChatGPT 每周收到 840 万条科学和数学相关查询，130 万科学家每周用 ChatGPT 做研究，2025 年科学类查询增长 47%，科学用户的消息发送频率是普通用户的 3.5 倍\n这些用户已经在用 ChatGPT 了，但体验是割裂的：一边是编辑器，一边是聊天窗口，来回复制粘贴\nPrism 把这两个东西合到一起了\n商业逻辑很清楚：用免费工具把这 130 万周活科学用户转化到自己的平台上，等用户习惯形成了，再推企业版收钱。顺便，用户上传的研究内容还能拿来训练模型\n还有什么问题 # 幻觉\nGPT-5.2 的幻觉率比之前降了 26%，但没消失。测试发现故意输入错误内容时，AI 会「以热情的自信」编造东西\nNeurIPS 2025 有个案例：GPTZero 在 4000 多篇被接受的论文中发现「数十篇」包含 AI 生成的虚假引用\n审稿压力\n有人担心这会引发「AI 辅助投稿海啸」，进一步加重审稿人的负担\n命名\nPrism 和美国国安局的 PRISM 监控项目同名，和 GraphPad Prism 统计软件也撞名\n最后 # Kevin Weil 对 Prism 的定位：将有 10,000 项科学进展可能不会发生或不会那么快发生，而 AI 将是其中的贡献者。它不会是闪耀的灯塔，只是渐进的、复利式的加速\n这个期望管理还算务实\nPrism 现在可以免费用，地址是 prism.openai.com\n下面这个，是 Prism 一键生成的 Paper\n","date":"29 January 2026","externalUrl":null,"permalink":"/posts/%E5%AE%9E%E6%B5%8B-prismopenai-%E7%9A%84%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E5%B7%A5%E5%85%B7%E5%AE%8C%E5%85%A8%E5%85%8D%E8%B4%B9/","section":"AI-Related Reposts","summary":"","title":"[Repost] 实测 Prism：OpenAI 的论文写作工具，完全免费","type":"posts"},{"content":"","date":"29 January 2026","externalUrl":null,"permalink":"/tags/latex/","section":"Tags","summary":"","title":"LaTeX","type":"tags"},{"content":"","date":"29 January 2026","externalUrl":null,"permalink":"/tags/prism/","section":"Tags","summary":"","title":"Prism","type":"tags"},{"content":"Reposted from Alpha School：当 AI 成为孩子的私人老师，一切都变了 by 旷野路标\n当效率被重新定义，学习不再是一场马拉松，而是一次精准的冲刺。\n本期播客音频由 AI 生成，它用对话的方式，对下面的长文内容进行了浓缩与解读。点开听听吧～也很期待您的关注和反馈！\n\\[阅读时长：10分钟\\]\n引言 # 真正的教育革命，从不在喧嚣中发生，而在一个安静的选择里开始。\n如果有人告诉你，一所学校的学生每天只花 2 小时学习核心课程，成绩却能排到全美前 1% 到 2%，你会相信吗？\n这不是科幻故事，而是正在美国德克萨斯州真实发生的事情。一所叫 Alpha School 的学校，正在用 AI 彻底重新定义我们对教育的理解。\n第一部分 # 一个颠覆常识的实验 # 让 AI 做 AI 擅长的事，让人做人擅长的事。\nAlpha School 的创始人 MacKenzie Price 在创办这所学校之前，并不是教育行业的人。他来自科技和商业领域，这反而让他用一种全新的视角去审视教育这个已经几百年没有根本性变革的行业。\n他的核心洞察很简单：传统课堂的效率低得惊人。\n想想看，在一间传统教室里，一位老师面对 30 个学生，每个学生的水平不同，学习速度不同。老师只能按照一个固定的节奏讲课。结果就是，学得快的学生无聊到发呆，学得慢的学生焦虑到崩溃，真正处于\u0026quot;刚刚好\u0026quot;节奏的学生可能只有少数几个。\nAlpha School 做了一件大胆的事：把学科教学完全交给 AI，让人类教师去做 AI 做不了的事情。\n第二部分 # 2 小时的魔法 # 教育从来不是一刀切的流水线，而是为每个灵魂量身定制的旅程。\n每天早上，Alpha School 的学生会花大约 2 个小时进行核心学科的学习。但这 2 个小时和传统课堂完全不同。\n每个学生面前是一个 AI 驱动的学习平台。这个平台会根据每个学生当前的水平，精确地推送适合他们的学习内容。如果你已经掌握了某个知识点，系统不会让你反复做无聊的重复练习；如果你在某个概念上卡住了，系统会用不同的方式重新讲解，直到你真正理解为止。\n这就是所谓的\u0026quot;掌握式学习\u0026quot;（Mastery-based Learning）。与传统学校\u0026quot;按时间推进\u0026quot;的模式不同，掌握式学习的逻辑是：你什么时候真正学会了，什么时候才往下走。\n传统学校的问题在于，它本质上是一个\u0026quot;基于时间\u0026quot;的系统。不管你有没有真正理解，到了期末就要考试，然后大家一起进入下一章。很多孩子在前面的知识上还有漏洞，后面的内容就越来越跟不上，像滚雪球一样越积越多。\n而 AI 驱动的个性化学习，彻底解决了这个问题。MacKenzie 用了一个很形象的说法：传统教育就像让所有人穿同一个尺码的鞋子跑步，有人穿着合脚跑得飞快，有人穿着太大或太小的鞋子磕磕绊绊。\nAI 做到的事情，就是给每个人一双完全合脚的鞋。\n第三部分 # 令人震惊的数据 # Alpha School 将 5 小时的低效苦读，转化为 1 小时的智能学习\nAlpha School 的学生在全国标准化考试中的表现令人瞩目。他们的平均成绩排在全美前 1% 到 2%。\n更让人惊讶的是，这些学生并不是经过精心挑选的\u0026quot;天才儿童\u0026quot;。\nMacKenzie 强调，他们的学生来自各种各样的背景，有些孩子来之前甚至被贴上了\u0026quot;学习困难\u0026quot;的标签。\n但在这个系统中，几乎所有的孩子都能达到非常出色的水平。\n学习效率是传统学校的两倍，时间却只有五分之一。\n这意味着，同样的学习成果，Alpha School 的学生用的时间不到传统学校学生的十分之一。\n哈佛大学在 2024 年底发布的一项研究也从侧面印证了这种模式的有效性。\n研究发现，在物理课程中，使用 AI 导师的学生比由哈佛教授授课的学生表现出更深层次的参与度和更好的学习效果。\n第四部分 # 我不是不聪明，只是还没有投入时间 # 真正的教育，不是往脑子里塞知识，而是帮一个人重新认识自己。\n比学术成绩更让 MacKenzie 骄傲的，是学生们心态上的转变。\n在传统学校里，当一个孩子在某个科目上遇到困难，很容易就会形成一种自我认知：\u0026ldquo;我不是学数学的料\u0026rdquo;，或者\u0026quot;我就是不擅长写作\u0026quot;。这种认知一旦形成，就会变成一个自我实现的预言，孩子从此放弃努力，成绩自然越来越差。\n但在 Alpha School，学生们有一种完全不同的心态。当他们遇到困难时，他们的反应是：\u0026ldquo;我不是不聪明，我只是还没有在这个领域投入足够的时间。\u0026rdquo;\n这种心态的差异看似微小，却有着天壤之别。\nMacKenzie 把这称为：“基于能力的自信”（Confidence based on Competence）。\n他认为，当今社会流行的那种\u0026quot;你很棒、你很聪明\u0026quot;的空洞鼓励，对孩子并没有真正的帮助。孩子们不傻，当父母告诉他们\u0026quot;你很聪明\u0026quot;，但他们的成绩和实际表现并不支持这个说法时，他们内心是矛盾和困惑的。\nAlpha School 走的是相反的路。他们不会空洞地告诉孩子\u0026quot;你很棒\u0026quot;，而是通过实际的学习成果让孩子亲身体验：\n我投入了时间和努力，我真的做到了。\n这个过程中有一个很巧妙的设计，叫做**“信心锚点”（Confidence Anchor）**。比如八年级科学相对容易达到全国前 1% 的水平，学校就会引导学生先在科学上取得突破。\n当学生发现自己竟然能在全国排名中名列前茅时，他们会想：\u0026ldquo;我从来没想过自己能在科学上这么出色。\u0026ldquo;然后，当他们在数学或英语上遇到挑战时，就可以对自己说：\u0026ldquo;如果我在科学上能做到，数学肯定也行。\u0026rdquo;\n这才是真正的教育。不是往脑子里塞知识，而是帮助一个人重新认识自己。\n第五部分 # 教师的角色被重新定义 # 最好的老师，不是站在讲台上的权威，而是坐在身旁的引路人。\n在 Alpha School 的模式下，教师的角色发生了根本性的变化。他们不再是站在讲台上传授知识的人（这部分工作交给了 AI），而是变成了\u0026quot;引导者\u0026rdquo;（Guide）。\n他们的核心工作变成了两件事：\n确保 AI 系统正在为每个学生提供正确的学习节奏和难度\n激励和引导学生，这是最重要的一点。\nMacKenzie 说了一句很有意思的话：“如果一个孩子在我们的系统中表现不好，那是学校的错，不是学生的错。”\n这和传统学校的逻辑完全相反。在传统学校，如果学生成绩差，要么是\u0026quot;这个孩子不够聪明\u0026rdquo;，要么是\u0026quot;这个孩子不够努力\u0026quot;。\n但在 Alpha School，他们认为只有两种可能：要么是 AI 系统没有给到正确的学习节奏和难度，要么是学校没有做好激励工作。\n这种思维方式的转变，本身就是一场革命。\n第六部分 # 不是白板论，是给每个人合适的路径 # 认知负荷各异，天赋不尽相同，但这不妨碍我们抵达同一终点。接纳不同的学习路径。\n有人会质疑：你们是不是在说所有孩子都是一样的，只要方法对了就能成为天才？这不是忽视了个体差异和天赋吗？\nMacKenzie 对此的回答很坦诚。他承认 IQ 的差异是真实存在的。在认知负荷理论（Cognitive Load Theory）中，每个人大脑能同时处理的信息量确实不同，这和 IQ 有关。IQ 较低的学生可能需要更多次的重复练习才能掌握同样的内容。\n但关键在于，这并不意味着他们学不会，只是需要更多的时间。 而掌握式学习的美妙之处就在于，它允许每个学生按照自己的节奏来。\n并不是每个学生都会成为 MIT 的天体物理学专业学生，但他们完全可以扎实地掌握 K-12 阶段的所有核心知识，然后带着这些知识和能力去找到自己真正擅长和热爱的方向。\n第七部分 # AI 时代，还需要学知识吗 # 知识是地基，但批判性思维、沟通、创造力与协作，才是通往未来的四把钥匙。\n很多人在 AI 时代会问一个问题：既然 ChatGPT 什么都能回答，我们还需要让孩子学那么多知识吗？\nMacKenzie 的答案是坚定的：需要，而且比以往任何时候都重要。\n他的逻辑是这样的：首先，大脑里有知识储备的人，思考的质量完全不同。类比是人类最强大的思维工具之一，当你在向别人解释一个复杂概念时，如果能找到一个对方已经理解的事物来做类比，理解效率会成倍提升。但类比的前提是，你的大脑里要有足够多的\u0026quot;素材库\u0026quot;。\n其次，知识让你的大脑成为一个更有趣的地方。当你能产生更复杂的想法，当你能随时调取各种知识来支撑你的思考，你的精神世界是更丰富的。\n最后，也是最实际的一点：要成为一个优秀的批判性思考者，你必须有知识作为基础。 没有知识储备的人讨论问题，就像没有弹药的士兵上战场。我们大概都遇到过那种场景，有人在滔滔不绝地讨论一个话题，但其实对这个话题一无所知，只是在\u0026quot;空谈\u0026quot;。\n不过，MacKenzie 也强调，知识只是基础，在此之上，未来真正重要的是他所说的\u0026quot;四个 C\u0026quot;：\n批判性思维（Critical Thinking）\n沟通能力（Communication）\n创造力（Creativity）\n协作能力（Collaboration）。\n传统的\u0026quot;读写算\u0026quot;已经不够了，这四个 C 才是 AI 时代人类最需要的核心能力。\n第八部分 # 让孩子爱上学校 # 在访谈中，MacKenzie 分享了一个他从创校第一天就坚持的信念：孩子必须热爱学校。\n注意，他说的不是\u0026quot;热爱学习\u0026quot;。因为学习有时候确实像吃蔬菜一样，不是每个孩子每分钟都会觉得很有趣。但学校作为一个整体体验，应该让孩子觉得每天都很期待。\n在 Alpha School，2 小时的核心学习结束后，剩下的时间用来做各种项目式学习、团队协作、创业实践和其他孩子们真正热爱的活动。这些活动不是\u0026quot;课外活动\u0026quot;或者\u0026quot;奖励时间\u0026quot;，它们和核心学习一样重要。\n因为学校释放出来的大量时间，孩子们可以深入探索自己的兴趣，可以参与真实的项目，可以学习如何与他人协作，如何应对失败，如何坚持不懈。这些东西，才是一个人走向社会后真正需要的能力。\n第九部分 # 普鲁士模式的终结 # AI 不是要取代教育，而是要解放教育。\nMacKenzie 在访谈中提到，今天的学校系统本质上还是 200 多年前普鲁士模式的延续。那个模式的设计初衷是为工业革命培养标准化的工人：听指令、守纪律、按时完成任务。\n但我们已经不再生活在那个时代了。\nAI 的出现，让我们第一次有了技术手段来实现真正的个性化教育。一个 AI 导师可以同时为每一个学生提供完全定制化的学习体验，这在传统模式下是不可能的，除非你请得起一对一的私人教师。\nAI 不是要取代教育，而是要解放教育。 它把教师从重复性的知识传授中解放出来，让他们有精力去做真正重要的事情：激励学生、引导成长、培养品格。\nAlpha School 目前还在不断发展中，他们也在探索如何让更多的学校和家庭能够使用他们的 2 小时学习模块。这意味着，即使你不认同 Alpha School 的其他教育理念，你也可以把这个 AI 学习工具与你自己偏好的教育方式结合起来。\n结语 # 教育的未来 # 教育的未来，不是让所有人走同一条路，而是让每个人找到属于自己的节奏。\nAlpha School 的故事给我们的启示远不止于\u0026quot;AI 可以帮孩子学得更快\u0026quot;这么简单。它真正触及的是一个更深层的问题：我们的教育系统，到底是在帮助孩子发现自己的潜力，还是在系统性地扼杀它？\n当一个\u0026quot;学习困难\u0026quot;的孩子来到 Alpha School，在几个月内就能达到全国前列的水平，我们不得不问：这个孩子之前真的有\u0026quot;学习困难\u0026quot;吗？还是说，是那个一刀切的教育系统出了问题？\nAI 时代的教育革命才刚刚开始。Alpha School 只是一个先行者，但它已经用实际数据证明了一件事：当我们把正确的工具交到孩子手中，给他们合适的节奏和足够的支持，几乎每个孩子都能做到远超我们想象的事情。\n教育的未来，不是让所有人以相同的速度走同一条路，而是让每个人找到属于自己的节奏，走出属于自己的路。\n\\[全文完\\]\n对于 AI 驱动的个性化教育，你怎么看？\n我们也邀请对 AI 与未来教育感兴趣、希望继续讨论交流的朋友加入我们的微信讨论群，请添加下方微信，通过后会拉你入群。\n主编：大圣不是圣 # 社群主理：尼安 # 参考资料\n\\[1\\] Alpha School Interview: https://www.youtube.com/watch?v=DuCO3dngans\n","date":"28 January 2026","externalUrl":null,"permalink":"/posts/alpha-school%E5%BD%93-ai-%E6%88%90%E4%B8%BA%E5%AD%A9%E5%AD%90%E7%9A%84%E7%A7%81%E4%BA%BA%E8%80%81%E5%B8%88%E4%B8%80%E5%88%87%E9%83%BD%E5%8F%98%E4%BA%86/","section":"AI-Related Reposts","summary":"","title":"[Repost] Alpha School：当 AI 成为孩子的私人老师，一切都变了","type":"posts"},{"content":"Reposted from Dan Koe: 未来10年，最重要的技能是什么？​ by 爱晒太阳的L.\n最近看了油管大神Dan Koe的几篇文章，一个在2026年开年就写出两篇阅读过亿文章的内容创业者，好奇他都在说些什么，我打算挑几个感兴趣的话题，概括分享一下他的文章。今天是第三篇。\nDan Koe ：想把话说得有水平？这里有4个方法\n外网1.7亿阅读爆文｜用1天重启人生\nPs：上图是他主页的截图，少工作，多挣钱，享受生活，我很喜欢。\nAI越来越强大，技能更新的速度快得吓人，学到手的东西，好像刚刚熟练，就已经开始贬值。于是出现了一个尖锐的问题：如果技能都会过时，那我们到底该学什么？\n先说结论：高主动性（High agency）\n从去年开始，这个词搜索量暴涨500%，成为创业圈、AI圈、独立创作者甚至高端社群的顶级关键词。Elon Musk等大佬反复用它形容自己和最欣赏的人。很多顶级招聘直接写：We’re looking for high-agency people。接下来我们通过Dan Koe来了解一下为什么它这么火，它到底是什么、以及普通人怎么提升这项能力。\n1\n主动性（Agency）到底是什么？\n很多人把 高主动性”理解成 很拼、执行力强，其实不然。真正的Agency，是未经允许，就迭代行动的能力(我之前一直觉得它只主动推动事情落地的能力）。\nAgency is the ability to iterate without permission.\n主动性，就是未经允许就能不断试错迭代的能力。\nTo have agency is to be the subject of a sentence, rather than its direct object. It is the tendency to act, rather than wait to be acted upon.\n— Devon Eriksen\n拥有主动性，就是做句子的主语，而不是宾语；是主动去行动，而不是等着被别人推着走。\n大多数人活得像个宾语（这个比喻也是很贴切了）：等老板安排工作、等社会认可自己、等别人点头才敢迈出一步。而高主动性的人，是给自己的人生当导演：我想干什么，就先动手干，干砸了就改，改了再干，直到做成为止。\n你有没有这种经历：\n写几篇文章没人看就直接放弃？\n学一门新技能做了两天，就觉得 “好像不适合我”？\n那其实就是在等外部的许可—— 等数据好看、等马上见效、等别人认同。\n真正的主动性，是把人生当成一场永不结束的实验：错了就认，调整后再来，不被一次失败劝退，也不被 “大家都这么做” 绑架。\n2\n做低主动性的人又怎样？\n**低主动性（low agency）的人，其实是被“习得性无助”困住了。他们最大的问题不是懒、不是笨，而是脑子里有一套严重扭曲的信念系统，****它会让你把难的目标直接看成不可能的目标。**简单说：你不是做不到，而是大脑根本不让你去想能做到这件事。这背后的机制，其实早在1967年就被心理学家Martin Seligman用狗实验证明了——它叫“习得性无助”（learned helplessness）。实验大概是这样的：\n研究者把狗分成三组，\n第1组：有电击，可以自主关掉电击（有控制权）。\n第2组：做什么都没电击。\n第3组：不管怎么挣扎都持续电击（完全无控制）。\n后来，把所有狗放到一个新箱子，只要跳过一个小矮墙，就能逃掉电击，超级简单。结果呢？前2组狗很快就学会跳墙逃跑。但第3组——那些之前无论怎么努力都逃不掉的狗，大多数直接躺平了。它们呜呜叫、承受电击，却连试都不试跳墙。\n为什么？因为它们已经被训练相信：我的行为对环境没任何影响。**回到我们自己，社会、学校、职场、家庭……其实在对大多数人做同样的事。**从小到大，我们被反复教育/经历：你不行，别想了、这条路太难了，普通人别做梦、稳定最重要，别瞎折腾……一次次努力无效的体验积累下来，你就习得性无助了。\n于是，当真正的人生机会出现时（比如副业、跳槽、创业、追热爱），大脑自动弹出：这太难了，我肯定不行、别人行是因为有资源/背景，我没有、失败了更惨，还是忍着吧。明明矮墙就在那儿，一跳就自由了，你却宁愿继续挨电击——因为你已经被训练到：连尝试的念头都不敢有。这就是低主动性最可怕的地方：它不是没能力，而是连认为自己有能力这个前提都被剥夺了。\n高主动性的人，不是天生不怕疼，而是他们没被社会“电”到彻底躺平。他们保留了那份“也许我能试试看”的信念。所以，打破低能动性的第一步，不是突然变得很拼，而是先质疑那个让你躺平的信念：真的是不可能吗？一旦你开始问这个问题，习得性无助的链条，就开始松动了。\n3\nAI 时代，为什么主动性才是王牌？\n现在 AI 发展得这么猛，大家最怕的就是工作被 AI 取代，但作者认为，AI 其实把主动性的价值放大了 10 倍。\nAI is not a threat to the high agency. You now have access to any knowledge you would ever need to achieve whatever you want. And yet\u0026hellip; people still do nothing with that information.\nAI 对高主动性的人不是威胁。你现在就能获取任何知识，去实现任何你想要的…… 但很多人拿到信息，还是什么都不做。\n问题不是 有没有资源，而是有没有主动去用资源。AI 让 “知道” 这件事变得超级容易，但 去做、改错、再做”的核心动作，AI 永远代替不了。\n想做内容？AI 能生成 1000 条爆款猜想，但谁来定品牌调性、谁来持续迭代、谁来真正懂用户和人性？终究还是得靠人。\n想创业？AI 能帮写商业计划、做设计图，但品牌愿景、核心使命、面对挫折时的持续试错，AI 没有这份灵魂。\n想学技能？免费知识遍地都是，但坚持下去的毅力、及时调整方向的灵活、不怕丢脸试错的勇气，这些都是独属于人的特质。\n一句话总结：AI 干掉的是只会按部就班的 “工具人”，放大的是有想法、敢行动的 “人生导演”。\n4\n普通人怎么练出 “高主动性”？\nDan Koe是真能输出啊，方法论一套一套的 =P，但真的有用，一起来看看这次又是啥：\n先找一个值得追求的方向——任何方向都可以。没人一开始就清楚自己想要什么，但我们都深知自己不想要什么，先找一个你 “不想再忍受” 的点，人生的方向感，往往从讨厌的事开始，而这份厌恶，就能成为未来的目标锚点。然后跟着这几步走：\n**定一个触手可及的小目标，**别一上来就喊 财务自由，先定 3 个月赚到第一个 1 万这种具体又可行性高的。\n**研究别人的成功路径，**搜罗个大平台，看优质视频、学靠谱课程、找行业导师，梳理可复制的方法。\n**自己上手大胆实验，**大部分尝试都会失败，没关系，失败本就是试错的一部分。\n总结规律、提炼原则，找到那些真正管用的核心方法，抓住能放大效果的杠杆。\n打造属于自己的流程，结合你的性格、生活节奏，把方法改成适合自己的样子。\n**把你的方法教给别人，**教的过程，才是真正把知识吃透、变成自己能力的过程。\n你的人生游戏，现在可能还停留在 “教程模式”：NPC 给你安排好所有任务，按部就班，索然无味。但只要你敢主动 “破关”，自己设计下一级的挑战，这场人生游戏，会瞬间变得超级好玩。\nThe most important boss fight of your life is pursue your own path.\n你人生最重要的一场 Boss 战，就是去追自己的路。\n","date":"28 January 2026","externalUrl":null,"permalink":"/posts/dan-koe-%E6%9C%AA%E6%9D%A510%E5%B9%B4%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%8A%80%E8%83%BD%E6%98%AF%E4%BB%80%E4%B9%88/","section":"AI-Related Reposts","summary":"","title":"[Repost] Dan Koe: 未来10年，最重要的技能是什么？","type":"posts"},{"content":"Reposted from skills.sh 排行榜前 10：最受欢迎的 Agent Skills 全解析 by AI一人公司实战\n背景：为什么需要 Agent Skills？\n这两年 AI 编程工具爆发式增长——Claude Code、Cursor、GitHub Copilot、Windsurf\u0026hellip; 每个工具都在快速进化。\n但你会发现一个问题：不同的 AI 工具，默认能力差异很大。\n比如 Claude Code 擅长系统架构分析，Cursor 更懂上下文补全，Copilot 嵌入 IDE 体验最好。如果你用 Claude Code 开发 React，它可能不会主动遵循 Vercel 的最佳实践；如果你用 Cursor 做 SEO 优化，它可能不知道从何入手。\nAgent Skills 就是为了解决这个问题而生的。\n它是一个\u0026quot;技能插件系统\u0026quot;——你可以把特定的知识、规则、最佳实践，打包成一个 Skill，让任何 AI 编程工具\u0026quot;加载\u0026quot;这个技能后，就能获得对应的专业能力。\n什么是 skills.sh？ # skills.sh 是一个 Agent Skills 目录，由 Vercel 运营。\n你可以把它理解成\u0026quot;Agent 版的 npm\u0026quot;——上面汇集了各种可以增强 AI 编程工具的技能包。\n截至 2026 年 1 月，skills.sh 已经收录了 200+ 个 Agent Skills，覆盖前端、后端、设计、营销、安全等各个领域。\n支持的 AI 编程工具 # 工具 支持情况 Claude Code ✅ 完全支持 Cursor ✅ 完全支持 GitHub Copilot ✅ 完全支持 Windsurf ✅ 完全支持 Continue ✅ 完全支持 OpenCanvas ✅ 完全支持 其他 10+ 工具 ✅ 完全支持 -\u0026ndash;\nAgent Skills 如何工作？ # 传统 AI 编程 vs 使用 Skills # 传统方式：\n你 → AI 工具 → 通用模型 → 输出（可能不够专业）\n使用 Skills：\n你 → AI 工具 → 加载 Skill → 专业模型 → 输出（符合特定规范）\n一个实际例子 # 假设你用 Claude Code 开发一个 Next.js 应用：\n不加 Skill 时：\n你：帮我写一个 React 组件\nClaude：好的，这是组件代码\u0026hellip;（按通用方式写）\n加上 vercel-react-best-practices 后：\n你：帮我写一个 React 组件\nClaude：好的，我会遵循 Vercel React 最佳实践：\n使用客户端组件 \u0026lsquo;use client\u0026rsquo;\n避免在客户端组件中直接导入服务器组件\n使用动态导入优化代码分割\n\u0026hellip;（输出符合 Vercel 规范的代码）\n如何安装和使用 Agent Skills？ # 方式一：命令行安装（推荐） # npx skills add vercel-labs/agent-skills --skill \u0026quot;vercel-react-best-practices\u0026quot;\n安装后，该技能会自动被你的 AI 工具识别。\n方式二：在对话中引用 # 大多数 AI 编程工具支持在对话中直接引用 Skill：\n你：请使用 @vercel-react-best-practices 帮我审查这个组件\nAI：好的，我会按照 Vercel React 最佳实践来审查\u0026hellip;\n方式三：项目级配置 # 你可以在项目根目录创建配置文件，指定项目默认使用的 Skills（具体格式因工具而异）。\nClaude Code 中的使用技巧 # Claude Code 对 Skills 的支持非常友好：\n全局安装\n：使用 npx skills add 安装的 Skill 会被 Claude Code 自动识别\n对话引用\n：你可以在对话中直接引用技能名称\n查看已安装 Skills\n：npx skills list\n移除 Skill\n：npx skills remove \u0026lt;skill-name\u0026gt;\n-\u0026ndash;\n前 10 Skills 排行榜 # 1vercel-react-best-practices（59.3K 安装）\n**分类：**前端开发React\n**来源：**Vercel 官方\n为什么第一？\nVercel 是 Next.js 的开发公司，他们的 React 最佳实践是经过大规模生产验证的。60K+ 安装量说明这个技能几乎是 React/Next.js 开发者的\u0026quot;标配\u0026quot;。\n功能：\n提供 React 和 Next.js 的最佳实践指南，包含 40+ 条优化规则，涵盖：\n性能优化\n：代码分割、懒加载、图片优化\n代码规范\n：组件设计、状态管理、Hooks 使用\n架构模式\n：服务端组件 vs 客户端组件、数据获取策略\n部署优化\n：Vercel 平台特定的优化建议\n实际效果示例：\n不加 Skill：Claude 可能写出一个通用的 React 组件\n加上 Skill 后：Claude 会主动建议：\n这个组件应该用 \u0026lsquo;use client\u0026rsquo; 吗？\n是否需要动态导入来减少初始包大小？\n图片是否应该用 next/image 优化？\n适合场景：\n用 React/Next.js 开发 Web 应用\n希望代码符合 Vercel 推荐的标准\n团队需要统一的代码规范\n追求极致性能的项目\n安装：\nnpx skills add vercel-labs/agent-skills --skill \u0026quot;vercel-react-best-practices\u0026quot;\n2web-design-guidelines（44.9K 安装）\n**分类：**UI/UX 设计\n**来源：**Vercel 官方\n为什么第二？\n独立开发者往往没有专业设计师支持，这个技能让 AI 变成你的\u0026quot;虚拟 UI 设计师\u0026quot;，帮你避免常见的设计错误。\n功能：\n包含 100+ 条网页设计和 UI/UX 审查规则，涵盖：\n布局原则\n：视觉层次、信息架构、响应式布局\n色彩系统\n：对比度、色彩搭配、暗色模式\n排版规范\n：字体选择、行高、字间距\n可访问性\n：A11Y 标准、键盘导航、屏幕阅读器支持\n交互设计\n：微交互、动效、反馈机制\n实际效果示例：\n不加 Skill：AI 可能只关注功能实现\n加上 Skill 后：AI 会提醒：\n按钮对比度不够，可能影响可访问性\n这个表单缺少错误状态反馈\n移动端布局需要优化触摸目标大小\n适合场景：\n开发需要兼顾设计的项目\n想让 AI 帮助审查 UI 设计\n缺乏专业设计师但希望界面专业\n需要遵循可访问性标准\n安装：\nnpx skills add vercel-labs/agent-skills --skill \u0026quot;web-design-guidelines\u0026quot;\n3remotion-best-practices（42.5K 安装）\n**分类：**视频开发Remotion 框架\n**来源：**Remotion 官方\n什么是 Remotion？\nRemotion 是一个革命性的框架——让你用 React 代码来写视频。想象一下，你可以像写网页一样写视频，实现程序化视频生成、批量渲染、数据驱动内容等。\n功能：\n提供使用 Remotion 的最佳实践，包括：\n性能优化\n：视频渲染性能、内存管理\n代码结构\n：组件复用、组合模式\n渲染策略\n：并发渲染、分片渲染\n媒体处理\n：音频、视频、图片的最佳处理方式\n实际效果示例：\n不加 Skill：AI 可能写出能跑但性能一般的 Remotion 代码\n加上 Skill 后：AI 会建议：\n这个视频应该用多个序列并行渲染\n使用 composition 的静态数据可以优化渲染速度\n音频应该预加载避免卡顿\n适合场景：\n用 Remotion 开发视频内容\n程序化生成视频（如数据可视化视频、个性化营销视频）\n需要批量生成相似结构的视频\n视频自动化生产流程\n安装：\nnpx skills add remotion-dev/skills --skill \u0026quot;remotion-best-practices\u0026quot;\n4find-skills（22.6K 安装）\n**分类：**工具技能发现\n**来源：**Vercel 官方\n为什么需要它？\nskills.sh 上有 200+ 个技能，手动找效率很低。这个技能就像 Skills 世界里的\u0026quot;Google\u0026quot;。\n功能：\n帮助你发现和搜索其他有用的 Agent Skills：\n智能搜索\n：根据你的需求推荐合适的技能\n分类浏览\n：按技术栈、场景浏览技能\n热门排行\n：了解当前最受欢迎的技能\n相似推荐\n：找到与你已装技能类似的其他技能\n实际使用示例：\n你：我在用 Next.js 开发，需要处理支付功能\nAI（使用 find-skills）：让我帮你找找支付相关的 Skills\u0026hellip;\n找到：stripe-best-practices, payment-integration-guide\n适合场景：\n想探索更多可用的技能包\n不确定某个领域是否有现成的技能\n技能生态的\u0026quot;入口工具\u0026quot;\n需要为新项目选择合适的技能组合\n安装：\nnpx skills add vercel-labs/skills --skill \u0026quot;find-skills\u0026quot;\n5frontend-design（20.0K 安装）\n**分类：**前端开发设计\n**来源：**Anthropic（Claude 母公司）官方\n官方出品的意义\n这是 Anthropic 官方发布的前端设计指南，专门优化 Claude 在前端设计和实现方面的表现。相当于 Claude 自己的\u0026quot;前端设计说明书\u0026quot;。\n功能：\n帮助 AI 更好地进行前端设计和实现：\n设计系统\n：组件库设计、设计令牌（Design Tokens）\n响应式设计\n：移动优先、断点策略、弹性布局\n现代 CSS\n：CSS Grid、Flexbox、自定义属性\n可访问性\n：ARIA、键盘导航、语义化 HTML\n性能优化\n：关键渲染路径、资源优化\n与 web-design-guidelines 的区别：\nweb-design-guidelines\n：更偏设计审查和 UI/UX 原则\nfrontend-design\n：更偏技术实现和工程化\n适合场景：\n需要设计和实现前端界面\n希望 AI 理解现代前端设计原则\n从设计稿到代码的转换\n构建可复用的组件库\n安装：\nnpx skills add anthropics/skills --skill \u0026quot;frontend-design\u0026quot;\n6agent-browser（10.6K 安装）\n**分类：**工具浏览器自动化\n**来源：**Vercel 官方\n为什么重要？\nAI 编程工具的短板之一是\u0026quot;不能上网\u0026quot;。这个技能让 AI 获得浏览器能力，可以打开网页、获取信息、执行自动化操作。\n功能：\n让 Agent 能够操作浏览器：\n网页访问\n：打开 URL、等待加载、处理重定向\n信息提取\n：获取页面内容、截图、提取结构化数据\n自动化操作\n：点击、填表、滚动、等待元素\n测试支持\n：E2E 测试、视觉回归测试\n实际使用示例：\n你：帮我分析竞品网站的定价页面\nAI（使用 agent-browser）：\n打开目标页面\n截图并分析定价结构\n提取价格信息\n总结定价策略\n适合场景：\n需要抓取网页内容\n自动化浏览器操作（测试、爬虫）\n让 AI 能够\u0026quot;上网\u0026quot;查信息\nE2E 测试自动化\n安装：\nnpx skills add vercel-labs/agent-browser --skill \u0026quot;agent-browser\u0026quot;\n7skill-creator（9.6K 安装）\n**分类：**工具技能开发\n**来源：**Anthropic 官方\n为什么要创建自己的 Skill？\n现成的 Skills 再好，也比不上你自己定制的 Skill——它可以包含你的项目规范、团队约定、业务逻辑等独特知识。\n功能：\n帮助你快速创建自己的 Agent Skills：\n模板生成\n：快速生成 Skill 项目结构\n格式规范\n：确保 Skill 符合标准格式\n测试框架\n：测试你的 Skill 是否正常工作\n发布指南\n：如何发布到 skills.sh\n实际使用示例：\n你：帮我创建一个公司内部 React 规范的 Skill\nAI（使用 skill-creator）：\n生成 Skill 项目结构\n添加你的规范文档\n编写测试用例\n指导你发布到私有仓库\n适合场景：\n想封装自己的专业知识为技能包\n团队内部需要统一的代码规范\n希望向社区贡献技能\n为特定业务领域定制 AI 能力\n安装：\nnpx skills add anthropics/skills --skill \u0026quot;skill-creator\u0026quot;\n8seo-audit（6.0K 安装）\n**分类：**营销SEO\n**来源：**MarketingSkills 社区\n独立开发者的刚需\n做独立产品，流量是生命线。SEO 是获取免费流量的核心渠道，但很多开发者不懂 SEO。这个技能让 AI 变成你的 SEO 专家。\n功能：\n对网站进行 SEO 审计，检查：\n页面结构\n：标题、描述、H 标签\n内容优化\n：关键词密度、内容质量\n技术 SEO\n：Meta 标签、结构化数据、站点地图\n性能因素\n：加载速度、移动友好性\n外部因素\n：反向链接、域名权威\n实际使用示例：\n你：帮我审计我的落地页 SEO\nAI（使用 seo-audit）：\n检查页面 Meta 信息\n分析关键词覆盖\n检查结构化数据\n给出优化建议清单\n适合场景：\n需要优化网站 SEO\n运营独立站/博客\n希望提升搜索引擎排名\n做 SaaS/内容产品需要自然流量\n安装：\nnpx skills add coreyhaines31/marketingskills --skill \u0026quot;seo-audit\u0026quot;\n9audit-website（5.8K 安装）\n**分类：**工具网站审计\n**来源：**SquirrelScan 社区\n与 seo-audit 的区别\nseo-audit 专注 SEO，audit-website 是全方位体检——性能、安全、SEO、可访问性、合规性等。\n功能：\n全面审计网站，包括：\n性能审计\n：Lighthouse 评分、加载时间、资源优化\n安全检查\n：HTTPS、头部安全、XSS/CSRF 防护\nSEO 审计\n：搜索引擎优化检查\n可访问性\n：A11Y 标准、键盘导航、屏幕阅读器\n最佳实践\n：现代 Web 标准、浏览器兼容性\n实际使用示例：\n你：我的网站要上线了，帮我全面检查\nAI（使用 audit-website）：\n性能：85分（需优化图片）\n安全：良好（HTTPS 配置正确）\nSEO：中等（缺少结构化数据）\n可访问性：需改进（对比度不足）\n\u0026hellip;给出详细的改进清单\n适合场景：\n网站上线前的全面检查\n定期网站健康检查\n需要系统性的网站优化建议\n客户交付前的质量保证\n安装：\nnpx skills add squirrelscan/skills --skill \u0026quot;audit-website\u0026quot;\n10supabase-postgres-best-practices（5.7K 安装）\n**分类：**后端开发数据库\n**来源：**Supabase 官方\n什么是 Supabase？\nSupabase 是\u0026quot;开源的 Firebase\u0026quot;——提供数据库、认证、存储、实时订阅等功能，让你快速搭建后端。它是独立开发者的热门选择。\n功能：\nSupabase 的 Postgres 数据库最佳实践：\n数据库设计\n：表结构、索引策略、关系设计\n查询优化\n：SQL 性能优化、执行计划分析\n安全实践\n：RLS（Row Level Security）、权限管理\n数据迁移\n：版本控制、迁移管理\n扩展使用\n：PostGIS、pg_stat_statements 等\n实际使用示例：\n你：帮我设计用户表和订阅表\nAI（使用 supabase-postgres-best-practices）：\n设计表结构和关系\n添加合适的索引\n配置 RLS 策略确保数据安全\n写迁移脚本\n适合场景：\n使用 Supabase 作为后端\n使用 PostgreSQL 数据库\n需要数据库优化和规范\n快速搭建 SaaS 产品后端\n安装：\nnpx skills add supabase/agent-skills --skill \u0026quot;supabase-postgres-best-practices\u0026quot;\n分类总结 # 把这 10 个技能按类别整理：\n类别 Skills 前端开发 vercel-react-best-practices, frontend-design UI/UX 设计 web-design-guidelines 视频开发 remotion-best-practices 工具类 find-skills, agent-browser, skill-creator 营销/审计 seo-audit, audit-website 后端/数据库 supabase-postgres-best-practices 如何选择适合你的技能？ # 如果你是前端开发者：\n必装：vercel-react-best-practices\n推荐：web-design-guidelines, frontend-design\n如果你是全栈开发者：\n前端：vercel-react-best-practices\n后端：supabase-postgres-best-practices\n如果你在做独立产品：\n审计类：audit-website\n营销类：seo-audit\n如果你想探索更多：\n先装：find-skills 最后 # skills.sh 的排行榜更新很快，这 10 个只是当前最热门的。\n建议你访问 https://skills.sh/ 查看最新排行，根据自己的技术栈选择合适的技能。\n实战技巧 # 技能组合推荐 # 全栈独立开发者：\nnpx skills add vercel-labs/agent-skills --skill \u0026quot;vercel-react-best-practices\u0026quot; npx skills add anthropics/skills --skill \u0026quot;frontend-design\u0026quot; npx skills add supabase/agent-skills --skill \u0026quot;supabase-postgres-best-practices\u0026quot; npx skills add squirrelscan/skills --skill \u0026quot;audit-website\u0026quot;\n内容创业者：\nnpx skills add coreyhaines31/marketingskills --skill \u0026quot;seo-audit\u0026quot; npx skills add vercel-labs/agent-skills --skill \u0026quot;web-design-guidelines\u0026quot; npx skills add anthropics/skills --skill \u0026quot;frontend-design\u0026quot;\nNext.js 开发者：\nnpx skills add vercel-labs/agent-skills --skill \u0026quot;vercel-react-best-practices\u0026quot; npx skills add vercel-labs/agent-skills --skill \u0026quot;web-design-guidelines\u0026quot;\n使用建议 # 先装核心技能\n：不要一次装太多，先用最核心的\n明确引用\n：对话时明确指定使用哪个 Skill\n定期更新\n：Skills 会持续迭代，定期更新获取最新改进\n关注官方\n：优先使用官方发布的 Skills（质量更可靠）\n常见问题 # Q：Skills 会影响 AI 的通用能力吗？\nA：不会。Skills 是\u0026quot;增强\u0026quot;而非\u0026quot;限制\u0026quot;，AI 仍可以使用其通用知识。\nQ：可以同时使用多个 Skills 吗？\nA：可以。你可以在对话中引用多个 Skills，AI 会综合它们的建议。\nQ：Skills 是免费的吗？\nA：skills.sh 上的 Skills 都是免费的。有些 Skills 可能依赖第三方服务（如 agent-browser 可能需要 Puppeteer）。\nQ：如何创建自己的 Skill？\nA：使用 skill-creator Skill，它会指导你完成创建过程。\nClaude Code 和 Cursor 的 Skill 互通吗？\nA：大部分是互通的，因为它们使用相同的 Skills 生态系统。但具体使用方式可能有差异。\n你用过哪些 Agent Skills？有什么推荐？欢迎在评论区分享。\n","date":"28 January 2026","externalUrl":null,"permalink":"/posts/skills.sh-%E6%8E%92%E8%A1%8C%E6%A6%9C%E5%89%8D-10%E6%9C%80%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%9A%84-agent/","section":"AI-Related Reposts","summary":"","title":"[Repost] skills.sh 排行榜前 10：最受欢迎的 Agent Skills 全解析","type":"posts"},{"content":"Reposted from Agent Skills 完全指南：从原理到实战彻底搞懂！ by ConardLi\nAgent Skills 最近非常的火，它是既 MCP 后 Anthropic 推出的又一个 Agent 领域的行业标准。\n它的成长路线和 MCP 也非常像，25 年 10 月份发布时只有 Anthropic 自家产品支持，后来 Cursor、Codex、Opencode、Gemini CLI 等产品看到了 Skills 的优势于是纷纷开始支持。\n再后来社区开始涌现大量的开源 Skills 以及 Skills 开放市场，当下大家已经默认 Skills 成为了又一个扩展 Agent 能力的标准实践。\n简单来说，Skills 的作用就是将那些重复性的、专业的流程进行打包封装。当你需要使用某种能力时，不再需要像过去那样每次都去查阅手册或重新输入冗长的提示词，而是像调用工具一样直接使用。\n在本篇文章中，我们将从浅入深，和大家一起学习以下知识：\nSkills 入门理解：Skills 到底是什么？长什么样？怎么工作的？\nSkills VS MCP：Skills 和 MCP 的区别是什么，MCP 会被淘汰吗？\nSkills 初步尝试：去哪里找 Skill？怎么使用 Skill？怎么自己创建一个 Skill？\nSkills 实战使用：如何用 Skills 实现外部知识检索？比传统 RAG 的优势在哪？\nSkills 安全分析：Skills 的安全性如何？使用它有哪些风险？\n一、 Skills 入门理解 # 1.1 Skills 到底是什么？ # 在传统的 AI 聊天模式中，AI 的能力取决于：\n它原本学过什么（训练数据）\n你临时在对话框里告诉它什么（提示词、工具、记忆）\n这就像你招了个什么都懂一点的实习生，每次干活你都得重新教一遍。\n而 Agent Skills 带来了一种全新的玩法：模块化能力插件。\n你可以把 Claude（支持 Skills 的客户端）想象成一个超级大脑，而 Agent Skills 就是给这个大脑安装的外接工具箱。\n这个工具箱里不仅有工具本身，还包含了详细的 “官方使用说明书”，大脑不需要理解具体有哪些工具以及工具的用法是什么，只需要在需要使用某个工具时查看工具说明书，再把工具拿出来用。\n1.2 Skills 长什么样？ # Agent Skills 的官方文档中强调了一个核心关键词：File-system based（基于文件系统）。\n如果你写过代码，可能很容易理解。\n要编写一个程序，并不一定所有代码都是我们自己写的。\n我们可能会通过 import xxx 来引入一些外部包，这些包存放在固定的位置（如 node_modules）。\n当程序需要调用这些包的能力时，就会从指定文件夹取出对应的代码然后执行。\nAgent Skills 也是类似的逻辑，每个 Skill 都是一个实实在在存在的文件夹，它存放在一个固定的位置（如 .claude/skills）这个文件夹里装着下面几样东西：\n指令（SKILL.md）： 告诉 AI 怎么干活的 SOP。\n参考（reference）： 更详细的参考文档（可选）。\n脚本（scripts）： 比如 Python 代码，让 Skill 也能调用外部能力（可选）。\n资源（assets）：图片、模版等可能使用到的资源（可选）。\n如果你在你的 Agent（如 Claude Code）执行目录（如你的项目代码目录）下放了这个文件夹，\n那下次和 Agent 对话的时候就能自动根据你的需求匹配到这个 Skill，不需要再进行任何额外的配置。\n比如，你希望 Agent 帮你润色文章，就可以编写一个下面这样的 Skill：\n上面的三根短横线部分相当于 Skill 的「身份证」：\nname 是它的唯一标识，起个简单好记的英文名字就行\ndescription 则决定什么时候会触发这个 Skill，描述这个 Skills 是做什么的、遇到什么样的用户请求应该用它、提醒读者：描述越具体，越容易在正确场景被调用\n下面就是 Skill 的正文部分：\n目标：简单描述清楚这个 Skill 要做的事情\n使用步骤：列出 Skill 的操作流程（先搞清楚想要什么风格、再读原文、再改写、最后规定输出格式）\n注意事项：告诉模型「什么不要做」（不要乱加内容、不要替用户做决定、有歧义要提醒）\n看起来挺普通的？似乎很多能力都可以做这件事？\n可以把这段文字和要润色的文章直接发给大模型？\n可以把这段文字放到系统提示词？\n可以把这段固定的流程封装为一个 Workflow？\n可以把这段文字编写为一个 Agent.md 或者项目级的 Rules？\n这些方式看似不同，但本质上只是把提示词放在了不同的位置，你给 AI 的每次对话都会带上这些提示词。\n在真实的业务场景中，一个 Agent 不可能只干一件这么简单的事。大家试想一下，如果你要给 AI 装 50 个技能，每个技能都有几千字的说明书，要是系统一启动就把这些全塞进 AI 的脑子（Context Window）里，那么就会：\n成本爆炸，每次对话可能都会消耗几万 Token。\nAI 的注意力也会被分散，变得“这也想干，那也想干”。\nSkill 的出现就是为了解决这种问题，它有一个非常核心的机制，叫渐进式披露（Progressive Disclosure）。说人话就是：按需加载，用多少拿多少。\n1.3 Skills 的核心机制 # 这是我觉得 Agent Skills 设计得最聪明的地方。你可以把它想象成我们在图书馆查资料的三个步骤，非常直观：\n第一层：先看目录（元数据 Metadata） 什么时候加载？ 系统刚启动的时候。\n加载什么？ 只加载每个技能的名字和一段简短的描述。\n有什么用？ 这一层占用的资源极少，可能就几百个 Token。它的作用就是告诉 Claude：“嘿，你的工具箱里有‘查周报’、‘处理 Excel’ 这几个工具哦。”\n结果： Claude 知道自己 “会什么”，但还不知道 “具体怎么做”。\n第二层：翻开手册（指令 Instructions）\n什么时候加载？ 当你说 “帮我把这个 Excel 处理一下” 的时候。\n加载什么？ Claude 发现这事儿归 “Excel 处理” 这个技能管，于是它才会通过后台命令，去读取那个文件夹里的 SKILL.md 文件。\n有什么用？ 只有在这个时候，那些详细的操作步骤、注意事项才会进入 AI 的脑子。\n第三层：动手干活（运行时资源 Runtime Resources）\n什么时候加载？ 真正执行具体步骤的时候。加载什么？\n参考（reference）： 用户下达的任务可能是分析 Excel，也可能是创建 Excel，这两个操作可能有完全不同的处理步骤，详细的步骤不一定都在 SKILL.md 中，可以分开放在不同的参考文献（reference）下，当 Claude 识别到你要做的是分析 Excel 时，才会去查阅分析 Excel 的 reference。\n脚本（scripts）：Skill 中可以内置一些可执行的 Excel 处理脚本，在 SKILL.md 或者具体的参考文献（reference）下会告诉你应该调用以及如何调用这些脚本。还有最重要的一点，Claude 只需要按照指引执行脚本，而脚本本身的代码是不会塞给 AI 去读的，你完全不用担心一个超大代码文件会消耗 Token。\n这意味着：一个 Skill 可以打包整套说明文档、大量的执行脚本，但只要任务不需要，这些内容就永远不会占用上下文。\n二、Skills VS MCP # 看到这，你可能会觉得 Skills 和 MCP 有点像？\n它们似乎都可以做到按需加载、给 AI 扩展外部能力？\n这也是很多同学可能会弄混的问题。\n2.1 MCP 有什么问题 # 在 全网最细，一文带你弄懂 MCP 的核心原理！ 中，我们介绍了 MCP 出现的意义和执行原理：\nMCP（Model Context Protocol，模型上下文协议）是由 Anthropic 公司推出的一个开放标准协议，它就像是一个 “通用插头” 或者 “USB 接口”，制定了统一的规范，不管是连接数据库、第三方 API，还是本地文件等各种外部资源，都可以通过这个 “通用接口” 来完成，让 AI 模型与外部工具或数据源之间的交互更加标准化、可复用。\n所以 MCP 的本质，还是在做 “标准化”，它让给 AI 扩展外部能力这件事更 “标准化”。\n假如你的 Agent 连接了多个 MCP，它似乎也能实现 “按需加载”（根据用户的意图决定调用哪个工具）。\n但这个 “按需加载” 背后的代价是非常巨大的，在 MCP 的架构下，仅仅是“连接”这个动作，就已经在透支你的额度了。\n这是由 LLM 的工具调用机制决定的。为了让 AI 知道它有哪些能力可用，每一个连接的 MCP Server 必须在对话开始前，将其所有工具的完整定义（名称、详细描述、参数 Schema、使用示例）一次性注入 LLM 的上下文中。\n每个 MCP Server 一般都会包含大量的工具，比如 Github MCP ，它自己就包含了 30 多个工具：\n假如每个工具消耗 500 个 Token，那只链接这一个工具就需要消耗将近 20000 Token。\n在真实环境下，一个 Agent 不会仅链接一个 MCP Server。\n假如你只问了 AI 一个非常简单的问题（1+1=？），Agent 已经烧掉了大几万的 Token，这个成本是非常恐怖的。\n更深层的问题在于链接过多的 MCP Server 可能导致 LLM 的 “注意力” 下降，从而降低工具调用的准确性。\n我在之前的文章中有讲过一个专门测试 MCP Server 调用准确度的基准：MCP Atlas（世界最顶级的大模型，都在 PK 些啥？ （大模型评估完全指南）），在这个基准中包含了 40 多个不同服务器、300 多个工具的复杂环境。\n模型必须自己发现合适的工具、正确调用，并把多步结果汇总成最终答案。目前最强的 Claude Opus 4.5 也只能拿到 62% 的准确率，这个值还会随着工具的增多而进一步下降。\n而我们上面讲到的 Skills 的核心机制：渐进式披露 ，恰好可以解决这两个问题：\n节省 Token：首次链接时，相比 MCP 需要将 40 多个 MCP Server 下 300 个工具全部塞进模型上下文（消耗数万 Token），模型只需要加载 40 个 Skills 的元数据（几千 Token）。\n提升注意力： 面对几百个工具，AI 很容易分心。Skills 采用的是“漏斗式”引导：先通过目录判断大方向，确认要干活了，再加载具体的说明，最后通过说明找到详细的文档和脚本最后再执行。让 AI 每次只专注于当前任务。即使是能力稍弱的模型，在这种机制下也能保持极高的调用准确率。\n2.2 MCP 会被淘汰吗？ # 看到这你可能会问了，Skills 看起来更智能、更节省资源，那 MCP 会被淘汰吗？\n结论是：MCP 不会被完全淘汰，但对它的需求会大幅减少！\n首先，MCP 协议层的价值不可替代： MCP 的真正价值不在于它如何把文本塞进 Prompt，而在于它制定了一套标准接口。\n它统一了 AI 连接世界的方式。如果你是一个通用的三方平台（高德地图、Notion 等），想发布一个工具让其他 Agent 都能用上你的能力，那首先选择的还是 MCP。\n但是，如果你有一些重复性的工作流，比如要以固定的流程读写本地文件、要用一个标准的范式来 Review 代码、有一套固定的风格来编写文章，这些场景都推荐使用 Skill 来实现。\n在过去这几个需求中的本地文件读写、链接 Github、给文章生成图片这些需要链接外部世界的能力都得通过 MCP 去实现，但现在你可以都把它们打包到 Skill 里。\n未来的格局可能是这样的（来自宝玉老师）：\nAgent 本身内置部分核心能力（bash、read、edit、write）\n少数通用 MCP Server 负责远程连接（数据库、云 API、SaaS 集成）\n大量 Skills 负责封装标准工作流、连接本地知识库\n两者在必要时协作，但 Skills 会承担绝大部分 “教 AI 怎么做事” 的工作（这其中也包含教 AI 怎么用 McpServer、怎么用其他 Skills、怎么更好的调用核心能力）\n三、Skills 的初步尝试 # 3.1 去哪找 Skills？ # 和 MCP 一样，Skills 成了开放标准后开始爆发式增长，社区出现了大量的开源 Skills，很多 Skills 开放市场也应运而生，之前大部分 MCP Market 也都增加了 Skills 的分类：\nhttps://skillsmp.com/\n我们可以看到 skillsmp 中的 Skills 数量在最近经历着爆发式增长，这个增长速度要比之前的 MCP 爆火的时候还要快。这就不得不提 Skills 的另一大优点：编写门槛低！\nMCP 虽然有一套标准的规范，但终究还是要靠代码编写的，即便有了 AI 辅助，对于小白来讲还是有一定的门槛的。\n而 Skills 就不一样了，只要你会写提示词，就能写 Skill，可以预见的是，之前那些大量的固定工作流在未来可能都会被编写为 Skill，这也意味着 Agent 的编写门槛被再一次大幅降低了！\n3.2 怎么使用 Skills？ # 我们随便进入一个 MCP 市场，然后搜索我们要使用的 Skills，比如这里我们还以绘图软件 Excalidraw 为例：\n可以看到社区已经有大量 Excalidraw 的 Skill 了，我们这里选择 Star 最多的一款：\n进入详情后，我们选择一个最简单的安装方式，直接把这个 Skill 下载到本地，点击 wget skill.zip：\n然后我们把这个压缩包解压，你就会看到熟悉的目录。接下来，你只需要把这个目录下载到指定的位置：\n不同客户端的目录大同小异，基本上都是 .agentName/skills 目录，这里我们使用最近比较火的 OpenCode 进行演示（大家看可以自行选择 Cusor、Codex 等支持 skills 的客户端），所以我们创建一个新的文件夹，然后把刚刚下载的文件夹放到 .opencode/skills 目录下：\n接下来，我们在这个目录下打开 opencode 客户端，输入下面的提示词：\n帮我绘制一个架构图，讲解什么是 5W2H 分析法，直接帮我在当前目录下生成一个 excalidraw 文件。\n你不需要手动去 “安装” 或 “运行” Skill，只要文件放对位置了，OpenCode 的 AI 就会自动根据用户的需求判断要调用这个 Skill，然后帮我生成了代码：\n我们将生成的代码粘贴到 https://excalidraw.com/，就可以看到已经生成好的架构图：\n3.3 创建你的第一个 Skill # 下面，我们一起来尝试做第一个 Skill，虽然 Skill 的开发门槛低，但这不意味着我们就要自己写！\nAnthropic 官方直接给我们提供了一个 生产 Skills 的 Skill：Skill Creator。你不需要写一行代码或配置文件，只需要用自然语言告诉它你想做什么，它就会自动为你生成一个符合标准的 Skill 包。\n接下来，按照刚才的流程，我们把这个 Skill 下载下来，放到 .opencode/skills 目录下：\n然后我们给出下面的提示词：\n帮我创建一个可以准确获取当前系统时间的 Skill，描述使用中文，脚本使用 Node.js。\n然后，opencode 识别到我们的需求，开始调用 skill-creator：\n然后我们打开本地的 .opencode/skills 目录，发现多了一个 current-time-node skill，包含一个 SKILL.md 加一个获取准确时间的 Node.js 脚本：\n接下来，我们询问 opencode：“获取当前系统时间”，然后它就会自动找到刚刚生成的 Skill 并调用里面的脚本：\n最后 # 本期教程我们就先讲到这。\n大家已经了解了 Agent Skill 的基本原理，以及如何使用和创建一个 Skill。\n如果本期教程对你有所帮助，希望得到一个免费的三连和关注。\n下一期，我们会进入实战章节，一期来使用 Agent Skill 实现一个知识库检索的功能，相比传统的 RAG ，它的效果究竟怎么样呢，我们下期见。\n关注《code秘密花园》从此学习 AI 不迷路，相关链接：\nAI 教程完整汇总：https://rncg5jvpme.feishu.cn/wiki/U9rYwRHQoil6vBkitY8cbh5tnL9\n相关学习资源汇总在：https://github.com/ConardLi/easy-learn-ai\n如果本期对你有所帮助，希望得到一个免费的三连，感谢大家支持！\n","date":"27 January 2026","externalUrl":null,"permalink":"/posts/agent-skills-%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82/","section":"AI-Related Reposts","summary":"","title":"[Repost] Agent Skills 完全指南：从原理到实战彻底搞懂！","type":"posts"},{"content":"Reposted from Claude Skills、n8n 都火了，但中国头部企业真正缺的，不是执行智能体：如何构建“决策型智能体”的组织结构？ by 硅谷大胡子君\n开篇\n最近，Claude Skills 爆火，带火了的执行器 Remotion。n8n, dify持续爆火，带起一批 agent 工具和 automation agency。\n今天，工具越来越强，执行越来越快，ROI 看起来也越来越清晰。\n(made with bytebase \u0026lsquo;star history\u0026rsquo;)\n但一个更根本的问题正在被忽略：自动执行，真的构成长期竞争力吗？ROI 真的算对了吗？\n智能体的两种形态：\n分别是，执行型智能体 与 **决策型智能体。**两者在企业中各自承担的的两类完全不同的职责。\n前者解决的是：\n在目标已确定的前提下，如何把动作跑得更快、更便宜、更可规模化；\n后者关注的则是：\n在判断尚未稳定之前，系统应如何与人共同承担不确定性，避免过早放大。\n本文将以 n8n 代表执行型智能体工具，以 Agentbase 代表决策型智能体的实践框架，并对 Claude Skills 的意义，做一个初步拆解。\n执行型 Agent 的第一道天花板\n当 agent 介入企业系统后，行为形态本身发生了跃迁。传统企业后端，默认的是一次人类操作 → 一次系统响应。而 Agent 的工作方式，是由一个目标触发成千上万次并行的子任务、数据库查询与内部 API 调用，在毫秒级别递归展开。\n在旧系统看来，这样的访问模式，结构上已经接近一次 DDoS——系统从未被设计来承接这种行为密度。\n当 Agent 在这样的架构下被无节制地放大执行，风险可能被无限放大：fake 内容、合规漏洞、隐私侵蚀，以及对公共空间的持续挤压，都会在规模化执行中被指数级放大。\n在这种背景下，真正危险的是在判断尚未稳定之前，Agent 系统已经开始替你放大执行。这也是为什么，今天最先规模化落地的 agent，几乎都停留在系统边缘：\n投放\n内容生成\nSEO / GEO\n外围数据处理\n它们并不是因为“更重要”，而是因为越靠近核心系统，越容易触发架构极限与治理冲突。所以，模型能力不是执行型 agent 的第一道天花板，企业系统本身才是。\n企业系统，需要怎样的 AI 护城河\n真正的 AI 护城河应该是在真实业务压力下\n知道什么值得做？\n什么必须砍掉？\n什么即使能自动化，也应该先不做？\n当业务判断尚未稳定时，系统是否应该继续放大执行？\n——这些，叫定义权。这是任何执行型 Agent 都做不了的。\n在 B 端，围绕“用 AI 强化企业业务定义权”这件事，Palantir 几乎是一骑绝尘。\nPalantir 的真正护城河\n是 Decision Before Scale：这正是 Palantir 与大多数 Agent 工具的根本差异所在。Palantir 从来不是一家“自动化公司”，它的核心能力，也不是“帮你把事情做快”。它解决的是一个更稀缺的问题：在放大执行之前，判断是否已经值得被放大。\n在 Palantir 的世界里，AI 的第一任务不是执行，而是通过研究企业的业务本体与决策结构，重构判断如何被做出、被验证、被托付的方式。\n这也是为什么 Palantir 的产品总是看起来“慢”“重”“不性感”：\n它要求人明确假设\n要求判断被结构化\n要求每一次放大，都能被解释、被暂停、被回溯\n在一个 Agent 可以轻易把错误方向指数级放大的时代，先确认方向是否正确反而成了最稀缺、也最有价值的能力。\n中国头部企业们真正缺的，不是执行 agent\n今天的中国，我们急需在飞奔的 n8n 平台们之前架起一道 AI 决策之门，去回答一个被长期回避的问题：\n在什么情况下，判断应该交给 AI；\n在什么情况下，必须由人来做？\n这将决定，企业是否具备把 AI 转化为持续创新能力的组织结构，\n而不仅仅是局部提效。\n当竞争节奏被不断拉快，\n哪些判断必须被系统化、结构化，\n才能被规模复制？\n为了支撑这些判断，\n企业的数据、系统与组织边界，\n是否需要被重新设计？\n从下一章节开始，本文将尝试把“智能体”从工具层的热闹中抽离出来，拆解它在企业中真正应该承担的判断角色与执行角色，并由此讨论：在不同判断状态下，系统与人应如何分工。\n01\n企业 Agent 选型指南\n结论先行：大多数企业现在买到的，是执行型智能体； 真正构成长期护城河的，是决策型智能体。二者解决的问题，根本不同，却又互补。二者巧妙合力，便是企业级智能体的终极形态。我们先来逐个看。\n执行型智能体\n如果你现在的问题是——我们已经确定要做什么，只是希望更快 / 更便宜 / 更规模化，ROI 可以短期量化，错了可以随时回滚。你需要的是：执行型智能体。典型特性有：\n目标清楚（投放、SEO、视频、线索跟进）\nKPI 清楚（ROI、转化率、排名）\n错了可以快速回滚\n决策责任被摊薄（错了是 campaign / 素材 / 渠道）\n在这些场景里，判断已经稳定， 所以 workflow / agent 非常有效。代表形态有 n8n、Claude Skills、各类 Agent 工具 / Automation Agency；他们做的都是在判断已经确认之后，把执行跑得更顺。\n决策型智能体\n如果你现在真正卡住的是——我们还不确定方向是不是对的、执行看起来很忙，但增长质量在恶化、半年后才知道错没错、一旦错了，是方向性代价。你需要的是：决策型智能体\n典型场景\n是否该继续加预算？\n是执行效率问题，还是客户结构变了？\n要不要继续放大，还是该停、该砍、该转向？\n一句话：在判断尚未稳定之前，让系统和人一起承接不确定性。这类判断通常满足四个条件：\n判断高频（每天 / 每周反复出现）\n判断直连 P\u0026amp;L（放大就是真金白银）\n出错成本滞后显现（3–6 个月才爆雷）\n人已经明显扛不住（但没有地方甩锅）\n如果你要的是效率，用执行型智能体。如果你要的是方向，用决策型智能体。效率可以外包， 但方向一旦错了，没有工具能救你。\n同时，两者在责任上是互补的。后文所有讨论，都是围绕这两类智能体如何分工展开。\n02\n案例说明（全文锚点，非常关键）\n场景****设定：\n我们来看一个最折磨人的中层判断：这是一个判断尚未稳定的典型场景。\n某业务线在投一个核心渠道，当前 ROI 还可以，但明显开始波动，团队已经连续 2 周在讨论类似问题：「这条视频要不要加 5% 预算？」\n这个问题表面看起来是：“这条视频要不要加 5% 预算？”\n但业务负责人如果有选择，她真正想判断的是：“我们现在遇到的， 是执行效率问题，还是用户 / 市场结构已经发生变化**？**”\n这两个判断的后果完全不同：\n如果是执行问题 → 继续自动化、继续放大\n如果是结构变化 → 自动化 = 加速走偏\n执行型智能体 n8n 典型解法：\n设规则：CTR \u0026gt; X；转化率 \u0026gt; Y\n满足条件 → 自动加 5%；\n不满足 → 不加 / 降\n这一步完全合理，而且在“判断已稳定”的世界里，是最优解。\n但不能告诉你： 你现在是不是应该继续放大。\n你可能会问：n8n 熟练工难道不会在 workflow 里加个判断节点，不就能找到客户结构变化，这有啥难的？\n答案是：他们当然会。但那恰恰是问题所在！\n为什么“加一个判断节点”反而是错的？因为这个问题有三个致命特征：\n没有单一数据源能回答：CRM 数据、转化率、跟进效率都只能解释“局部现象”\n正确性无法在短期内被验证：半年后才知道，错了不可逆\n判断责任无法被流程化分摊：不是 campaign 的锅，不是 agent 的锅。最终一定回到：“是谁决定继续放大的？”\nworkflow agent 执行器的本质是“把责任往下压”。而真正的 AI 辅助的判断的本质是：责任必须被显性化、被共同承接。\n决策型智能体的典型解法：\nAgentbase 把“判断本身”变成一个可被系统承接、观察、暂停的对象。具体只做三件事：\n**把隐含的判断假设显性化：**我们现在假设，方向是对的，只是在调强度\n结构化“验证这个假设”的观测任务：哪些信号在支持？哪些信号在反驳？\n在判断未稳定时，阻止系统继续放大：不是优化执行，而是按下刹车\n我们可以用一个简单的 JSON 结构来描述这一整条判断任务，从假设 → 观测 → 状态。\n① 定义判断对象（Judgment Object）\n**把隐含的判断假设显性化：**我们现在假设，方向是对的，只是在调强度。这几行非常重要，它并没有在做执行，而是声明：“这不是一个操作，这是一个需要承担后果的判断。”\n② 显性化判断假设（Assumption）\n结构化“验证这个假设”的观测任务：哪些信号在支持？哪些信号在反驳？这一段在企业里几乎从不被写出来，但它每天都在被“默认同意”（不应该）。\n③ 定义“支持 / 反驳假设”的观测任务\n（不是 action）\n支持信号（Support Signals）\n反驳信号（Contradiction Signals）\n在判断未稳定时，阻止系统继续放大：不是优化执行，而是按下刹车。注意：\n这里没有 if / then\n没有自动动作\n只有：「这些数据是用来判断什么的」\n④ 判断状态机（核心）\n⑤ 行为约束（不是建议，是规则）\n这就是 n8n 永远不会主动做的一步：系统亲手按下“别再加速”的刹车。\n用一句人话翻译整条任务结构：\n我们现在不是在决定要不要加 5%，而是在让系统持续回答一个问题：‘我们是不是还在正确的方向上？’如果是，系统可以自己跑；如果不是，人必须回来接住判断。\n03\n谁来写这么复杂的任务结构？\nFollow 我的 Agentbase 写作的朋友可能已经猜到，这个任务结构正是我反复在写的 MCL(Model Context Language)。MCL 不是手写的，MCL 是由 自然语言的「判断定义」→ SDK 自动生成。\n那人到底要做什么？\n业务负责人只需要完成 一件事：把“我们现在真正不确定的是什么”，说成一句能被追问的话。比如：\n「我们现在不是在决定要不要加 5%， 而是在判断：我们是不是还在正确的方向上？」\n⚠️注意：这不是什么高深判断力，这是所有 BU 负责人、创始人、业务 owner 每天都在做、但被系统长期忽略的日常判断语言。\nSDK / MCL 自动生成发生在这里\n一旦人类把判断说成这种结构：\n判断对象是什么（方向是否正确）\n为什么重要（继续放大会放大错误）\n什么时候要停（信号开始分裂）\nSDK 就可以自动生成你看到的那条 MCL：\njudgment object\nassumption\nsignals\nstate\npolicy\n关键是如何把判断说到“系统听得懂”的程度，这不难，是“业务负责人级日常判断”的一次结构化。\n04\n两种智能体的结构分工\n以上其实正是 Agentbase 的核心架构，目前尚未有一套实施好的 SDK —— 这里当然不是能力不足👾，是刻意把‘执行复杂度’留在企业已有体系中。\n因为，企业自己不仅能做，而且相比 n8n，开发量明显更小。\nworkflow真实开发成本在哪？\n要把流程拆到极细，要处理大量异常分支，要维护不断变化的规则！而且前提是：判断已经对了。\n所以你会看到大量智能体 Agency 团队，非常熟练，非常忙，也非常依赖人工经验！\nAgentbase 开发量反而更小\n因为它不负责执行、不负责优化、不负责覆盖所有分支。它只负责三件事：\n定义判断对象\n监听关键证据\n决定「是否允许自动化继续放大」\n这意味着执行仍然可以交给 n8n / tool，Agentbase 站在 执行之上。是一个 判断 gate / breaker / governor。\n所以企业完全可以用 Agentbase 的 Playbook，用现有工程团队自己实现一个「简化版 MCL」，而且不会和现有工具冲突。\n执行到底怎么“交给 n8n”？\nAgentbase / MCL 不取代 n8n，而是站在 n8n 之上，决定 n8n 现在是否应该继续自动跑。\n正确的分工是这样的：\nn8n 负责怎么做已确认过的动作、明确的执行路径、可回滚的操作、明确的 KPI，比如：加预算 5%、换素材、推送线索、跑 SEO pipeline、生成视频、发布、监控。所以，n8n = 执行引擎\nAgentbase / MCL 负责什么？\n判断这个动作是否还“配得上自动化”。\n执行是在放大信号，还是在放大噪音；\n是否需要人回来接判断。\n所以，Agentbase = 判断闸门（governor / circuit breaker）\n一个具体 Agentbase + n8n 的例子：\n工程团队继续用 n8n 跑所有执行， 但每一个 workflow 的入口， 都加一个判断 gate。具体流程是：\nn8n 要执行某个动作（比如加 5%）\n先调用一个 Judgment API\nAPI 返回三种状态之一：\nALLOW → 继续跑\nPAUSE → 停止放大\nESCALATE → 需要人类 review\n这一步几乎不增加执行复杂度，但在战略上是质变\n05\n任务结构，将加速数据资产的智能化\nAgentbase 不连接数据，它决定哪些数据值得被连接：而这将加速企业数据资产智能化的节奏！\n我们仍旧用 5% 预算这个例子。\n当定义了这个判断：「我们要验证： 当前素材 + 人群结构是否仍然成立」，系统立刻会反问（人也会第一次被迫面对）：\n❓那我们有没有跨渠道的素材表现数据？\n❓有没有新老用户留存对比？\n❓有没有加预算前后的结构性变化记录？\n你会突然发现：原来你的企业根本没为这种判断准备数据接口。再下一步便水到渠成地将正确的数据源开放给 AI。\n看到没有？Agentbase 的作用不是直接连数据库，而是 把“判断需要什么证据”说清楚，这样数据平台（CRM / CDP / 数仓 / BI）才知道哪些字段值得被 agent 访问。\n这时发生的不是“技术选型”，而是认知暴露：把企业既有数据资产，变成智能体可用资产”的前置步骤。\n06\n现实那么卷，哪有空决策？\n你也许会问：「我们的企业哪需要那么多判断、决策？市场已经这么卷了，我必须全速执行啊！」\n但你有没有想过：\n每一个「要不要加 5%」的“执行问题”，\n背后真正没有答案的，其实是——\n「我们为什么还要继续加？」\n于是你会看到这些熟到不能再熟的动作：\nCTR 下滑 → 换素材\nROI 波动 → 调预算\n转化下降 → 换渠道\n增长放缓 → 加 agent\n乍一看，全是执行问题。但实际上，它们共同在回避一个事实：组织正在用执行，掩盖尚未被确认的判断。\n我来说几句真实企业里每天都会出现、但从不被系统接住的话：\n「我们是不是已经把这个渠道吃干了？」\n「这是执行没到位，还是用户已经换了？」\n「是我们不够 aggressive，还是方向已经不对？」\n「再加下去，是优化，还是赌？」\n注意：这些话几乎从不出现在 PRD、会议纪要、系统里，只存在于 BU 负责人脑子里、老板的焦虑里、“再看看吧”的拖延中。\n为什么在最卷的市场里，判断反而更多？\n因为卷意味着：\n边际收益越来越薄\n错误不会立刻暴露\n“错方向 + 高效率 = 灾难”\n于是问题悄然变成了：\n我们现在还能不能继续靠执行解决问题？\n但这正是一个危险信号：\n判断尚未稳定，但组织假装它稳定了。\n回到那个「5%」的问题\n现在可以非常精确地区分两种情况：\n情况 A ｜执行型智能体的主场\n大家非常确信方向是对的\n只是想跑得更快\n错了能马上换\n执行型 agent 完胜\n情况 B｜Agentbase 场景\n表面在调 5%，实际在赌方向\n错误 3–6 个月后才显现\n一旦错，没人敢负责\n在这里，执行越自动化，风险越大\n所以，在最卷的市场里，企业不是没有判断，是不敢承认——“现在加速，本身就是一种判断。”\n这正是决策型智能体存在的理由：当判断尚未稳定时，系统是否还应该继续放大。\n这正好解释了，为什么 Claude Skills 会在这个时间点突然爆发。\n07\nClaude Skills 为什么会火？\n因为它精准击中了一个被长期忽视的痛点：“任务不是 workflow，但也还没到业务系统。”\nClaude Skills 做的，是把大量通用型、高频、低风险的任务，封装成一种可被反复调用、可被组合的“任务模版”：\n读 / 写 PDF、Excel、Word\n解析文件、提取结构、生成摘要\n在 Claude 内部，通过 file system 管理、复用这些能力\n它让 AI 从「一次性对话」，变成了「可重复工作的能力集合」。但请注意：这些 Skills 的共同特征是——它们几乎不涉及业务判断。\nClaude Skills 的边界在哪里？\n你仔细看就会发现：\nSkills 是 通用的\n输入输出是 结构化的\n成功与否是 即时可验证的\n错了几乎没有长期后果\n它们解决的是：「在目标已明确、判断已稳定的前提下，如何把一类任务交给 AI，反复、可靠地完成。」\n这也是为什么 Claude 的 Skills 深度绑定在自己的系统架构里：文件系统、上下文管理、模型调用，本质上是工具层能力的增强。\n从这个角度看，Claude Skills 更接近的是“高级工具箱 + 任务模版层”，而不是企业真正焦虑的那一层：“在判断尚未稳定之前，系统该不该继续往前跑？”\n也正因为如此，Claude Skills 反而暴露了一个空位\nClaude 能把「任务」封装得非常漂亮，但它不会、也不可能替企业回答这样的问题：\n我们现在是在优化执行，还是在赌方向？\n这个判断，哪些证据支持？哪些证据反驳？\n如果判断未被验证，系统是否应该暂停放大？\n因为这些判断：\n每个企业都不一样\n深度嵌入业务结构\n错误往往数月后才显现\n责任无法简单归因\n它们不属于通用 Skills，\n而属于企业自身的“判断结构”。\nClaude Skills 提供的是 “任务模版层”\nn8n 等工具解决的是 “执行自动化层”\n而 Agentbase 关注的，是它们之上的那一层：“判断如何被定义、被验证、被暂停、被托付。”\n这也正好引出最后一个问题：如果判断越来越多、越来越细、越来越贴近现场，而责任却始终集中在少数人身上——决策型智能体，为什么会成为一个巨大的市场？\n08\n决策智能体，为什么是一个巨大的市场？\n头部企业正在出现一种新的“结构性断裂”：\n判断数量在指数级上升\n判断责任却无法被规模复制\n决策失误的成本，开始呈非线性放大\n在这种结构下，判断不再只是能力问题，而变成了系统性稀缺资源。\n谁能让判断被拆解、被验证、被托付、被暂停，谁就能让组织在不确定性中继续扩张。\n这才是决策智能体成为巨大市场的根本原因。\n人类正在被迫用“执行自动化”， 掩盖“判断已经开始失真”的事实。\n决策智能体解决的是：“谁来为不确定负责， 以及系统是否能在不确定时， 不再继续放大错误。”\n","date":"27 January 2026","externalUrl":null,"permalink":"/posts/claude-skillsn8n-%E9%83%BD%E7%81%AB%E4%BA%86%E4%BD%86%E4%B8%AD%E5%9B%BD%E5%A4%B4%E9%83%A8%E4%BC%81%E4%B8%9A%E7%9C%9F%E6%AD%A3%E7%BC%BA%E7%9A%84%E4%B8%8D%E6%98%AF%E6%89%A7%E8%A1%8C%E6%99%BA%E8%83%BD%E4%BD%93%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E5%86%B3%E7%AD%96%E5%9E%8B%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84/","section":"AI-Related Reposts","summary":"","title":"[Repost] Claude Skills、n8n 都火了，但中国头部企业真正缺的，不是执行智能体：如何构建“决策型智能体”的组织结构？","type":"posts"},{"content":"Reposted from 全球首发！一人公司报告: 百页级全AI制作 by 远方的家\n清华大学新闻与传播学院与人工智能学院双聘教授沈阳教授团队，倾力打造《一人公司报告1.0》。\n本报告采用“一人公司”式的人机协同工作流，由2位研究者分别对多个智能体进行综合调度，并在全新的GSC研究方法下完成整体写作与审校。\n报告历时15天完成，相较传统同类研究型报告通常需要6个月及以上的制作周期，一人公司工作流模式大幅压缩了研究与制作时间；解读截止时间为2026年1月26日。\n在“人工主导与校核”的原则下实施四轮“人工+ 人工智能”交叉迭代，资料检索、初稿生成、结构梳理、语言润色、核心判断、逻辑框架搭建等步骤均由多智能体合作完成。文末附获取方式。\n核心内容抢先看：\n以下为报告全文：\n【图文来源】微信公众号：清新研究\n# 本文图文来源于网络，版权属于原作者或网站，内容为作者观点，并不代表本公众号赞同其观点及对其真实性负责。如有版权等问题，请与管理员邮箱联系，将立刻进行相应处理。\n【远方的家】集锦来自中国科学院汪寿阳研究员及其学生们的日常随笔，分享各类热点新闻、趣闻、消息。\n微信号：homeofcas\n投稿、意见，请直接回复或发信至：amssmadis@163.com\n","date":"26 January 2026","externalUrl":null,"permalink":"/posts/%E5%85%A8%E7%90%83%E9%A6%96%E5%8F%91%E4%B8%80%E4%BA%BA%E5%85%AC%E5%8F%B8%E6%8A%A5%E5%91%8A-%E7%99%BE%E9%A1%B5%E7%BA%A7%E5%85%A8ai%E5%88%B6%E4%BD%9C/","section":"AI-Related Reposts","summary":"","title":"[Repost] 全球首发！一人公司报告: 百页级全AI制作","type":"posts"},{"content":"","date":"26 January 2026","externalUrl":null,"permalink":"/tags/solopreneur/","section":"Tags","summary":"","title":"Solopreneur","type":"tags"},{"content":"Reposted from Top 10热门Agent Skills，我试了个遍，发现真的能让生产力翻倍 by 二哥狗腿子\n大家好，我是二哥呀。\n如果这几个月你有关注 AI 编程圈子，应该会明显感觉到一个变化：大家不再只讨论哪个模型更强，而是开始讨论「怎么让 AI 更好地干活」。\n这背后其实有一个很朴素的需求，我们需要的不是一个会聊天的 AI，而是一个能真正理解项目、能写完整代码、能解决问题的工程助手。\n这种转变下，Agent Skills 这个概念就开始频繁出现在视野里了。\n简单来说，Skills 就是给 AI Agent 装上的「技能插件」，让它掌握特定领域能力。就好比你玩游戏给角色学技能一样，AI 也可以通过安装 Skills 变得更厉害。\n前两天我刷到一个叫 skills.sh 的网站，上面列出了各种热门 Skills，总安装量已经突破 20 万+。\n我花了两天时间，把这些 Top 10 热门 Skills 一个个试了一遍，今天就把我的实测体验和思考分享给大家。\n01、Agent Skills 到底是什么 # 这个我们之前的文章分享过，这里再次强调下。\nPrompt 更像是一次性指令。你在某个对话里写了一段很详细的提示词，AI 按照你的要求去执行。但这个提示词很难复用，下次换个项目、换个场景，你又得重新写一遍。\nSkills 则是可复用的能力模块。它把某个领域的最佳实践、工作流程、技术规范都封装好，AI 可以直接调用。\n就好比你是一个 Java 开发，你熟悉 Spring Boot、MyBatis、Redis 这些技术栈，这些就是你的「Skills」。当 AI 也掌握这些 Skills 时，它就能像你一样思考和编码。\n举个例子，vercel-react-best-practices 这个 Skill 目前安装量 43.3K，排在整个榜单的第一名。\n它里面封装了 React 开发的一系列最佳实践：组件怎么拆分、状态怎么管理、性能怎么优化。当 AI 装上这个 Skill 后，它写出的 React 代码就会自然遵循这些规范，而不是像普通 prompt 那样需要你一遍遍强调。\n从技术实现上看，Skills 就是一个个 Git 仓库，里面有 SKILL.md 文件描述能力，还有一些配套的代码和配置。安装的时候，只需要一条命令：\nnpx skills add \u0026lt;owner/repo\u0026gt; 这个命令会把 Skill 的配置信息写入你的项目，AI 编程工具（比如 Claude Code、Cursor、Windsurf 等）就能识别并调用这些能力了。\n02、Top 10 热门 Skills 横评 # 好了，我们来看实战。我把 Top 10 Skills 分了类，方便大家按需选择。\n前端类 # 排在前三的 vercel-react-best-practices、web-design-guidelines、frontend-design 都是前端方向的。这三个我都试了，体验确实不错。\nvercel-react-best-practices 我用它重构了一个 React 组件。之前的代码是直接用 AI 写的，能用但不够规范。\n装上这个 Skill 后，AI 主动帮我做了几件事：把大组件拆成了小组件、把状态提升到合适的位置、加了必要的性能优化。整个过程我没怎么干预，AI 就按照 Vercel 的规范把代码改得更好了。\nweb-design-guidelines 这个 Skill 更有意思。它不是教你写代码，而是教你怎么做设计。\n我问它「帮我设计一个开发者工具的落地页」，它不是直接给我代码，而是先问我的目标用户是什么、核心卖点有哪些、希望用户有什么样的情绪体验。这些问题问得还挺专业的，明显有产品思维在里面。\nfrontend-design 是 Anthropic 官方的 Skill，安装量 11K。\n它和 web-design-guidelines 的区别在于，它更偏向「把设计变成代码」。我给了一个 Figma 设计稿，它直接生成了对应的前端代码，而且用的还是 Tailwind CSS，刚好符合我的技术栈。\n框架最佳实践类 # remotion-best-practices 是关于 Remotion 框架的，安装量 26.4K。\nRemotion 是一个用 React 写视频的工具，挺小众但很酷。我之前用 Remotion 做过动画视频，当时踩了不少坑。这个 Skill 把 Remotion 的最佳实践都总结好了：怎么组织 timeline、怎么做性能优化、怎么导出不同格式的视频。\n试了一下，我用它重新写了一个 Remotion 项目，代码结构清晰了很多，而且 AI 还主动提醒我几个容易踩的坑，比如视频渲染时的内存管理问题。\n工具能力类 # skill-creator 这个 Skill 安装量 5.2K，它的作用是「教你如何创建自己的 Skill」。这个思路挺好的，就像授人以渔。\n我用它尝试写了一个「Spring Boot 最佳实践」的 Skill，它会一步步引导你：这个 Skill 的定位是什么、能解决什么问题、需要包含哪些知识模块。\n不过我平常更喜欢使用Claude直接来写Skills。这俩其实是一个东西。\nagent-browser 是给 AI 装上浏览器能力的，安装量 4.3K。之前 AI 只能处理代码和文本，装上这个后，它可以直接访问网页、抓取数据。我试了一下让它抓取某个网站的公开 API 文档，然后生成对应的调用代码，确实省了不少事。\n专业领域类 # building-native-ui 是 Expo 团队出的，专门针对原生 UI 开发，安装量 3.3K。\n如果你用 React Native 做移动开发，这个 Skill 会很有用。它里面封装了很多原生组件的使用规范，比如导航怎么搭、状态栏怎么适配、动画怎么做。\nseo-audit 和 audit-website 是关于网站优化的，安装量都是 **3K+**。\n前者偏向 SEO，会分析你的网站在搜索引擎上的表现；后者偏向性能和安全，会检查加载速度、代码质量、安全漏洞。我拿自己的博客试了一下，确实发现了一些可以优化的地方。\n数据库类 # supabase-postgres-best-practices 是 Supabase 团队出的，安装量 3.1K。Supabase 是一个开源的 Firebase 替代方案，底层用的是 PostgreSQL。\n这个 Skill 封装了 PostgreSQL 的最佳实践，比如表怎么设计、索引怎么优化、查询怎么写。我试了一下让它帮我优化一个慢查询，它给出的建议还挺专业的。\n03、如何安装和使用 # 体验了一圈，我发现 Skills 的安装和使用其实挺简单的。\n第一步，选择合适的 Skill # 你可以去 skills.sh 这个网站上浏览，上面有所有 Skills 的介绍、安装量、最后更新时间。\n安装量高的说明经过了很多人的验证，一般比较靠谱。最后更新时间也很重要，有些 Skill 可能已经半年没更新了，这种就要谨慎选择。\n第二步，使用命令安装\n假设你想装 vercel-react-best-practices，只需要在终端执行：\nnpx skills add vercel-labs/agent-skills 这个命令会做几件事：克隆对应的 Git 仓库、把 Skill 配置写入你的项目、如果有依赖的话会自动安装。\n第三步，在 AI 编程工具中调用\n装好之后，你就可以在 Claude Code、Cursor、Windsurf 这些工具里直接使用了。你不需要显式地「启动」某个 Skill，AI 会根据你的需求自动判断应该调用哪个能力。\n比如我在 Claude Code 里说「帮我重构这个 React 组件」，它就会自动调用 vercel-react-best-practices 里的规范。你可以在输出日志里看到 AI 引用了哪些 Skills，这个过程是透明的。\n04、我的使用建议 # 试了这么多 Skills，我有几个实用的建议想分享给大家。\n不要贪多，按需安装\n我看到有些开发者一口气装了十几个 Skills，其实没必要。Skills 装多了会有两个问题：一是 AI 在调用时要遍历更多能力，响应会变慢；二是不同 Skills 之间可能有冲突，反而影响效果。\n我建议是「按需安装」，你当前项目需要什么能力就装什么。比如你最近在写 React，就装 vercel-react-best-practices；如果你要做 SEO 优化，再装 seo-audit。\n优先选择官方或知名团队的 Skills\n从榜单上看，排名靠前的 Skills 基本都是官方或者知名团队出的。比如 Anthropic 官方的 frontend-design、Expo 团队的 building-native-ui、Supabase 的 supabase-postgres-best-practices。这些 Skills 的质量有保证，而且更新也比较频繁。\n对于个人开发的 Skills，我会看几个指标：安装量、最后更新时间、GitHub 上的 star 数、issues 的处理情况。如果这些数据都不错，说明这个 Skill 比较活跃且可靠。\n把 Skills 当成辅助，不要完全依赖\n这一点特别重要。Skills 确实能提升 AI 的能力，但它不是银弹。我在使用过程中就遇到过，AI 按照 Skill 的规范写代码，但没考虑到我项目的特殊情况，反而需要我去调整。\n所以我的做法是，把 AI 生成的代码当成「参考」，我会仔细审查每一段代码，确认它是否符合项目需求、有没有潜在问题。Skills 能帮我节省时间，但不能替代我的判断。\n尝试创建自己的 Skill\n如果你在某个领域有丰富的经验，可以考虑把自己的最佳实践封装成 Skill。一方面可以帮助其他开发者，另一方面也能加深自己的理解。\nskill-creator 这个 Skill 就是专门教你做这件事的。它会一步步引导你：Skill 的定位、解决的问题、包含的知识模块、如何测试和验证。\n关注 2026 年的新动态\n2026 年被称为「Skills 元年」，这个领域发展得非常快。谷歌的 Antigravity 已经支持 Agent Skills，越来越多的 AI 编程工具也在接入这个生态。\n我建议大家可以多关注 skills.sh 这个网站，或者订阅相关的技术博客，及时了解最新动态。\n05、ending # 花了两天时间测试这些 Skills，我的整体感受是：Agent Skills 确实是 2026 年的一个技术趋势，它让 AI 从「通用助手」变成了「领域专家」。\n以前我们用 AI 写代码，可能只是一次性对话。现在有了 Skills，AI 可以持续学习、积累经验，甚至在不同项目之间复用能力。这种转变对于提升工程效率是有实际价值的。\n但我也要提醒一句，Skills 再强，也只是工具。真正决定项目质量的，还是开发者自己的判断和经验。AI 能帮你写代码，但不能替你做决策；AI 能帮你优化性能，但不能替你理解业务。\n从职业发展的角度看，我建议大家可以把 Agent Skills 当成一个技能点去学习。一方面，它能提升你的开发效率；另一方面，懂得如何使用和创建 Skills，本身也是 2026 年开发者的一项核心竞争力。\n还没有体验过的同学，可以选一个自己感兴趣的 Skill 试一试。相信我，你会打开新世界的大门。\n参考资料：\nThe Agent Skills Directory - skills.sh\n2026年AI编程的分水岭:为什么懂Agent Skills的人已经赢了?\n2026年Skills元年正式开启！谷歌Antigravity支持Agent Skills\nawesome-agent-skills GitHub 仓库\nClaude Code Skills 国内实践全指南\nClaude Code 又推出了Skills！！（保姆级安装和使用教程分享）\n","date":"25 January 2026","externalUrl":null,"permalink":"/posts/top-10%E7%83%AD%E9%97%A8agent/","section":"AI-Related Reposts","summary":"","title":"[Repost] Top 10热门Agent Skills，我试了个遍，发现真的能让生产力翻倍","type":"posts"},{"content":"Reposted from 如何用Gemini+NotebookLM暴力吞噬全球顶级认知？把3小时的学习压缩进10分钟（附全套SOP） by 管三\n你好，我是管三，清华大学出版社《AI一人公司》作者。\n对一人公司来说，你觉得最贵的成本是什么？\n是钱？\n我觉得是时间。\n为啥？\n因为钱是可再生资源，时间是不可再生资源。\n谁能够在短时间内完成多关键的事，谁就有更大机会赚到更多钱。\n而想要赚到更多钱，除了效率高之外，最快的路就是去学这个领域已经在顶峰的人。\n对于我们做自媒体、做IP的人来说，很多顶级的认知和搞钱思维，都在YouTube上。\n比如这两年我一直在研究一人公司模式，我知道油管上也有个博主，叫Dankoe，它是非常有名的一人公司倡导者。\n于是我之前在YouTube上花了不少时间去看他的长视频，但说实话很煎熬，一方面是英语不好，听着费劲，虽然有中文字幕，但看着累，甚至觉得他提的有些概念有点宏观，稍微走神就跟不上。\n另外一方面就是他的视频都是长视频，都是几十分钟起步的，想做笔记，还得反复回放。\n这种传统的学习模式很痛苦，博主喂什么，你吃什么。\n今天这篇文章，我分享一个AI主动掠夺式的学习法。\n复盘我是如何利用 Gemini + NotebookLM 这套组合拳。\n把一下午的学习时间压缩到10分钟，直接把Dan Koe一条视频精华吸收干净的。\n没用过Gemini的，可以看我之前写过的这篇文章。全网最全Gemini使用指南，看完效率提升90%（实操喂饭级教学，一看就会用）\n你掌握这个方法后，就可以快速吸收全球顶尖的认知，以及快速进入一个行业。\n第一步：让Gemini当星探，只看最好的 # YouTube上内容虽然很好，但太多了，比如我要研究“一人公司”这个话题，我就要找含金量最高的那个视频，其他的视频我一秒都不想浪费。\n因为Gemini和youtube都是谷歌旗下的平台，Gemini能够直接打通YouTube上的内容。\n那我就直接进入Gemini的官网：gemini.google.com\n直接给Gemini发送下面这个提示词：\nGemini，我想用你更好的帮我吸收youtube上面的视频，因为我要在上面学习，里面有一些博主讲的内容我很喜欢，但是我英语不好，我也听不懂。我一直在研究一人公司，然后youtube上面有一个博主叫dankoe，在我们国内很有名，我想去研究一下他关于一人公司这个话题下一些观点。你帮我把dankoe在youtube上面发过的所有关于一人公司的视频链接都发给我\nGemini 会瞬间帮我过滤掉那些无关的视频，甩给我几条核心内容，并附带了YouTube上对应的视频链接，以及推荐理由，真的很省时间。\n第二步：不用去看视频，用NotebookLM直接扒出逐字稿 # 拿到视频链接，不用去下载字幕，时间不够的话，也不用费大量时间去硬听原视频，毕竟太吃力了。\n我们需要的是视频里的原汁原味的信息。\nNotebookLM是谷歌旗下的一款神级笔记工具。\n进入****NotebookLM官网：\nhttps://notebooklm.google.com/\n进去后新建一个笔记本。\n**骚操作来了，**你不需要下载视频，直接点击“添加来源”，选择“YouTube网站”，把Gemini给到我们的链接粘贴进去。\n比如我就选择dankoe《将知识变现：如何把你的大脑产品化》这一期视频的链接，点击插入。\n点插入之后，他会自动的帮你先针对这个视频做一个总结\n接着，可以在文本框，发送这段提示词：\n把全视频的逐字稿翻译成中文，按时间戳分段显示\n瞬间，NotebookLM 就把整个视频的逐字稿“扒”下来了。\n不管这视频是一个小时还是两个小时，不管语速多快，它现在已经是一份你可以随意调用的中文文档了。\n这一步能让你快速学习到原汁原味的原文，但读起来还是太枯燥，且太费时间了，所以进行第三步。\n第三步：让AI深度分析视频逐字稿，学习精华 # 这一步是核心。普通的AI总结只会告诉你视频讲了什么，给你总结一下，那太浅了。\n我们要像拆解精密仪器一样，把博主的思维逻辑拆出来。\n我给 NotebookLM 发送了这组指令：\n你是世界顶级的商业拆解专家，精通“一人公司”模式。基于你刚刚提取并翻译好的中文逐字稿，帮我进行深度拆解，输出中文：\n核心论点： 用一句话总结这个视频在讲什么核心认知差？\n逻辑框架： 他是用什么样的逻辑推导出来的？（请用 1. 2. 3. 的步骤形式呈现他的思维链条）。\n金句与时间戳： 提取文中引发共鸣的5-10个金句（中英对照），并附上大概的时间位置，方便我回看视频听语气。\n概念词典： Dan Koe喜欢发明新词，请把这些词提取出来，并用大白话解释它的真实含义。\n这个指令结构你也可以参考，结果非常震撼，它总结得非常好。\n我帖一部分notebooklm总结的内容的截图，大家可以稍微看下。\n还给出很多很好的金句，真的非常棒，这些金句都是原汁原味的，如果要你自己手动总结，估计得累死。\n比如我就很喜欢里面讲到的这些金句：\n“劳工被锁定在薪水和日程表中，而创造者则创造自己的薪水和日程表。“\n“如果我能获得一个读者，我就能获得一百万个。”\n如果不通过这种深度拆解，光看视频，大概率就听个热闹，很难第一遍就抓住这个核心骨架。\n第四步、让AI把内容进行本土化 # 学习的终点不仅仅是知道了，更得要能用了，因为dankoe是做的海外自媒体，它不一定完全和我们国内的一样，但底层逻辑是一样的。\n于是，我为了更好地去理解如何具体去应用他的方法，我让AI做最后一步本土化。\n我接着在NoteBookLM的对话框输入这个提示词：\n结合Dan Koe的上述观点，请帮我进行“中国本土化”的迁移：\n比如场景置换，比如当他提到Newsletter时，对应国内是公众号，请把他的这套打法，通过中国国内一人公司的视角重新演绎一遍。\n以及给出落地行动清单，如果我要教我的学员执行这套理论，请列出他们明天就能做的具体动作（SOP）。\n瞬间，就会发现他帮我们总结的内容就非常接地气了。比如他总结到：\n拒绝内卷和35岁危机的唯一解法，是建立个人资产。在中国，这不只是做自媒体，而是把你的认知、经验、踩过的坑打包成一个不需要你实时在场的“产品”。你不是在找一份工作，你是在经营一家以你名字命名的“一人无限责任公司。\n这样你就能够学到原汁原味且真正有价值的内容了。\n通过这个案例，我想表达的是，AI的确方便了我们的学习生活中的方方面面。\n以前，你也许多花3小时，只能模模糊糊听懂大概，现在，你花10分钟，就能把顶级高手的思维模型拆解得一清二楚，并且直接落地成你的SOP。\n之所以用Notebook LM，是因为很适合用来学习，它非常忠实于原文，不会乱发散，不会乱编，你给它什么视频，它就只回答视频里的内容。\n非常适合整理资料、提取字幕、做摘要、做研究，\n你还可以把这些分析拆解出来的文本，保存到笔记。点击保存到笔记\n然后再把保存好的笔记转换为来源。\n最终可以把它做成播客、思维导图、ppt等，方便复习。\n比如我把它做成一个ppt，如下：\n是不是非常不错？\n今天的文章就分享到这里啦，大家可以去试试！主页还有很多AI干货文章，欢迎阅读。\n关于作者：\n我是管三，一个用AI武装到牙齿的一人公司实践者，借助AI做短视频涨粉百万，写出多篇爆款文章，直播超过1000场，不讲虚的，教你怎么用AI提效，搞定IP、流量和变现。\n朋友圈会分享我的日常深度思考，欢迎链接。\n【铁粉福利】免费送你一份我原创7万字的《AI一人公司创富57条秘籍》《AI一人公司实战圈会员招募说明书·2026》加我微信领取，加时备注：公众号\n最后，如果你想在2026年真正用好AI提效，想借助AI打造个人IP、想获取流量与变现，想做好一人公司，强烈推荐加入我的社群AI一人公司实战圈，千万不要闭门造车，因为AI变化太快了。\n我们在AI领域深耕多年，目前社群已超过300人加入，一顿火锅钱，我和水哥陪伴你一年，具体详情看👉管三【2026·AI一人公司实战圈社群】详解（咨询前请看这一篇）\n推荐阅读：\n👆点击上方图片，即可跳转阅读\n","date":"25 January 2026","externalUrl":null,"permalink":"/posts/%E5%A6%82%E4%BD%95%E7%94%A8geminiplusnotebooklm%E6%9A%B4%E5%8A%9B%E5%90%9E%E5%99%AC%E5%85%A8%E7%90%83%E9%A1%B6%E7%BA%A7%E8%AE%A4%E7%9F%A5%E6%8A%8A3%E5%B0%8F%E6%97%B6/","section":"AI-Related Reposts","summary":"","title":"[Repost] 如何用Gemini+NotebookLM暴力吞噬全球顶级认知？把3小时的学习压缩进10分钟（附全套SOP）","type":"posts"},{"content":"","date":"25 January 2026","externalUrl":null,"permalink":"/tags/notebooklm/","section":"Tags","summary":"","title":"NotebookLM","type":"tags"},{"content":"Reposted from 达沃斯现场｜吴恩达：门槛没了，AI 创业只剩 3 种能力 by AI深度研究员\n全文 2,000字 | 阅读约 6 分钟\nYour browser cannot play this video. Download video.\n(2026达沃斯：吴恩达等嘉宾达沃斯圆桌对谈片段)\n门槛没了。真的没了。\n以前几个月才能做出来的 MVP，现在几天就能上线。\n当任何人都能快速做出 AI 产品，问题变了：你做的，到底有没有价值？用户买单吗？能撑得起一家公司吗？\n2026 年 1 月 22 日，达沃斯会议期间，吴恩达、OpenAI 欧洲负责人、Cerebras 战略官和 ETH AI Center 负责人坐在一起，参加了一场名为《AI 时代的创业》的圆桌讨论。\n他们给出的答案是：速度，已经不是优势，而是及格线。\n门槛没了之后，AI 创业还剩什么能赢？\n答案是三种能力：\n第一，重构流程的能力。用 AI 设计新流程，而不是优化旧流程。\n第二，全栈开发的能力。技术和产品都得会，一个人干全队的活。\n第三，做成产品的能力。把 Demo 变成能用、能做大的产品。\n光快，不够。\n做对，才是硬道理。\n第一种能力：用 AI 重构流程 # 在这场达沃斯圆桌对谈里，吴恩达讲了一个企业最典型的误区。\n他说，现在很多公司部署 AI，最常见的做法就是：找一个环节，用 AI 替代人工。比如贷款审批，把某一步从人工 1 小时压到 10 分钟。\n看起来像是提高了效率，实际上只是改快了一小步，整个产品形态并没有改变。\n还是贷款这个例子。传统流程要走营销、申请、初审、复审、执行等五六步。如果 AI 已经能做出可信的自动批准结果，那就不应该去优化旧流程里的某一步，而是应该打造一个 10 分钟批贷的全新产品。\n这个差别，不是速度快不快，而是产品逻辑是不是从 AI 能力出发重新设计的。\n在他看来，如果其他环节不变，AI 只是一个效率工具。真正该做的，是围绕新能力，重构整个流程。\nOpenAI 欧洲业务负责人 Laura 接着从用户视角补充说：\n“企业的老习惯是哪里慢就改哪里，换掉一个环节，结果发现根本没变，问题还在。真正有效的 AI 部署，是把旧流程推倒，从头设计”\n她强调，AI 最该改的，是客户从接触到拿到结果的整个体验，而不是只盯着某一个环节。\n说白了，AI 创业的第一种能力，就是能看到一个可以被 AI 彻底重构的场景，然后做出从一开始就不一样的产品。\n判断标准很简单：\n如果去掉 AI，产品照样能用，那你做的可能只是个工具。\n如果去掉 AI，产品就不能用了，那才算一个真正的 AI 产品。\n第二种能力：一个人干一支队伍的活 # 流程重构需要什么样的人来执行？\n这是第二个问题。\n在以往，创业团队通常需要一个产品经理负责想清楚用户要什么，一个工程师负责把功能写出来，再配上运营、设计、前台、招聘……每个角色各有分工。\n但现在，吴恩达说的情况已经变了。\n他说，开发成本越来越低后，一个人如果既能写代码、又能理解用户，还能判断下一步该做什么，就能替代一整支传统团队。\n“我们以前是一个产品经理配几个工程师，后来发现最有效的组合，是把他们合成一个人。”\n他在 AI Fund 就是这么做的。招前台、HR、财务，都优先考虑会写代码的人。甚至连 CFO，都能自己写出内部使用的自动化脚本，不用再花几千美元去找供应商开发。\n为什么需要这种全栈能力？\n吴恩达认为：AI 工具把“怎么做”变得很容易，真正拖慢进度的，是“要做什么”这件事没人决策。\n以前，工程师可能要等产品经理写完需求文档、设计评审、开个会才动手。现在，工具快了，模型强了，工程师常常第二天就做好了。\n反过来，是产品经理跟不上工程师。\n所以他说，在他的公司，有时为了不浪费工程资源，团队配置直接精简：1 个产品配 1 个工程师，甚至让一个人兼顾产品和工程。而且他发现，那些速度最快、反应最灵活的创业者，往往都是既能动手，又懂用户。\nCerebras 的战略官 Andy 也表示，技术能力只是基础，创业者还得懂得如何拆解问题、如何组建团队、如何从用户视角判断产品方向。最优秀的技术创始人，都具备同理心、产品判断力和讲故事的能力，而不仅仅只是会写代码。\n这就是第二种全栈开发能力：既能动手做，又能判断做什么。\n在人人都能用 AI 写代码的年代，一人顶多岗不是压榨，是 AI 创业的标配。\n第三种能力：把 Demo 做成产品 # 快速做出来只是第一步，真正难的是怎么把一个 Demo 变成能让成千上万用户天天用、用得稳的产品。\n吴恩达说：\n“很多创业者能做出 Demo，但做不大，卡住的不是技术，是产品没做到位。”\nETH AI 中心的 Alex 进一步解释：很多项目失败不是因为模型不够好，而是没把 Demo 打磨成真正能用的产品。展示一个好看的 PPT 很容易，但要让它能被很多人用、出了问题能解决、还能一直好用，那就是另一回事了。\n什么叫“打磨成真正能用的产品”？\nLaura 举了个例子。有个叫 Fyxer AI 的创业公司，只做了一件事：帮用户写和回复电子邮件。\n听起来不复杂，但他们做得非常细：哪些邮件需要立刻处理、哪些可以跳过、什么语气更合适……产品上线 6 个月，就拿下了数百万的年收入。\nLaura 的总结是：Fyxer AI 不是在节省发邮件的时间，而是在改善整个沟通体验。\n反过来看，很多 AI 创业公司失败，不是因为不会做，而是因为没想清楚这些问题：\n数据进来了怎么清洗？\n用户提的反馈怎么用？\n出错了谁来修、怎么修？\n新用户怎么上手？老用户怎么留住？\nAI 创业的第三种能力，就是要把 Demo 做成能持续运转的产品，打通从开发、使用、反馈到优化的整个链路。\n在开发成本极低的今天，能做出闭环，才是真正的壁垒。\n结语｜开发容易，做成难 # 吴恩达说：开发成本正在归零，该做的就是大量试错。\n但这也意味着，Demo 满天飞的时代，真正稀缺的不是技术，是把东西做成的能力。\n留下来的，是那些能用 AI 重构流程、一个人干全栈活、把 Demo 做成产品的人。\n门槛没了，能力就是新门槛。\n识自AI\n📮 本文由AI深度研究员出品，内容整理自达沃斯 AI House 圆桌对谈《Unprecedented Scale – Building Startups in the Age of AI》等网上公开素材，属评论分析性质。内容为观点提炼与合理引述，未逐字复制原对谈材料。未经授权，不得转载。\n星标公众号，👆 点这里1. 点击右上角2. 点击\u0026quot;设为星标\u0026quot;←AI深度研究员⋮←设为星标\n参考资料：\nhttps://www.youtube.com/watch?v=dLwVrlzZly4\nhttps://www.linkedin.com/posts/ai-house-davos_when-anyone-can-ship-an-ai-product-in-days-activity-7417839632358412288-8sz1\nhttps://ch.linkedin.com/company/eth-ai-center\nhttps://www.linkedin.com/posts/ai-house-davos_when-anyone-can-ship-an-ai-product-in-days-activity-7417839632358412288-8sz1\n来源：官方媒体/网络新闻\n排版：Atlas\n编辑：深思\n主编: 图灵\n--END\u0026ndash;\n","date":"24 January 2026","externalUrl":null,"permalink":"/posts/%E8%BE%BE%E6%B2%83%E6%96%AF%E7%8E%B0%E5%9C%BA%E5%90%B4%E6%81%A9%E8%BE%BE%E9%97%A8%E6%A7%9B%E6%B2%A1%E4%BA%86ai-%E5%88%9B%E4%B8%9A%E5%8F%AA%E5%89%A9-3-%E7%A7%8D%E8%83%BD%E5%8A%9B/","section":"AI-Related Reposts","summary":"","title":"[Repost] 达沃斯现场｜吴恩达：门槛没了，AI 创业只剩 3 种能力","type":"posts"},{"content":"Reposted from 中英双语 | 蒸汽、钢铁与无限心智 Steam, Steel, and Infinite Minds by By Ivan Zhao\n作者简介： 赵伊（Ivan Zhao），Notion 联合创始人兼 CEO。作为极简主义设计与工具哲学的拥趸，他致力于重塑人类处理信息的方式，被视为现代协作软件领域的领军人物。\n文章简介： 《蒸汽、钢铁与无限心智》是 Ivan Zhao 的深度思考之作。他将 AI 比作数字时代的“钢铁”，认为我们正处于从“更换水轮机”到“电力革命”的范式转移中。文章指出 AI 不仅是更快的搜索工具，更是能自主行动的**“无限心智”**，预示着知识工作将从人力驱动转向智能代理驱动的全新时代。\nSteam, Steel, and Infinite Minds\nEvery era is shaped by its miracle material. Steel forged the Gilded Age. Semiconductors switched on the Digital Age. Now AI has arrived as infinite minds. If history teaches us anything, those who master the material define the era. # 每个时代都由其奇迹材料塑造。钢铁铸就了镀金时代，半导体开启了数字时代。如今，人工智能以 “无限心智” 的形态降临。历史若能昭示什么，那便是：掌控这一材料的人，将定义这个时代。 # Left: teenage Andrew Carnegie and his younger brother. Right: Pittsburgh steel factories during the Gilded Age.左图：少年时期的安德鲁・卡内基与弟弟；右图：镀金时代的匹兹堡钢铁厂。 # In the 1850s, Andrew Carnegie ran through muddy Pittsburgh streets as a telegraph boy. Six in ten Americans were farmers. Within two generations, Carnegie and his peers forged the modern world. Horses gave way to railroads, candlelight to electricity, iron to steel.\n19 世纪 50 年代，安德鲁・卡内基还是个在匹兹堡泥泞街道上奔波的报童。彼时，六成美国人都是农民。短短两代人时间里，卡内基与同代人共同铸就了现代世界 —— 马匹被铁路取代，烛光让位于电力，铁器升级为钢铁。\nSince then, work shifted from factories to offices. Today I run a software company in San Francisco, building tools for millions of knowledge workers. In this industry town, everyone is talking about AGI, but most of the two billion desk workers have yet to feel it. What will knowledge work look like soon? What happens when the org chart absorbs minds that never sleep?\n从那以后，工作场景从工厂转向了办公室。如今，我在旧金山经营着一家软件公司，为数百万知识工作者打造工具。在这座产业之城，人人都在谈论通用人工智能（AGI），但全球 20 亿办公室职员中的大多数，尚未真切感受到它的影响。不久之后，知识工作将呈现怎样的面貌？当组织结构图中纳入了 “永不休眠的心智”，又会发生什么？\nEarly movies often looked like stage plays, with one camera focused on the stage.早期电影往往酷似舞台剧，只用一台摄像机对准舞台拍摄。\nThis future is often difficult to predict because it always disguises itself as the past. Early phone calls were concise like telegrams. Early movies looked like filmed plays. (This is what Marshall McLuhan called \u0026ldquo;driving to the future via the rearview window.\u0026rdquo;)\n未来之所以难以预测，是因为它总以过去的模样伪装自己。早期的电话沟通如同电报般言简意赅，早期的电影宛如拍摄下来的舞台剧 —— 这正是马歇尔・麦克卢汉所说的 “通过后视镜驶向未来”。\nThe most popular form of AI today looks like Google search of the past. To quote Marshall McLuhan: \u0026ldquo;we are always driving into the future via the rearview window.\u0026rdquo;\n如今最普及的人工智能形态，恰似过去的谷歌搜索。正如马歇尔・麦克卢汉所言：“我们总是通过后视镜驶向未来。”\nToday, we see this as AI chatbots which mimic Google search boxes. We\u0026rsquo;re now deep in that uncomfortable transition phase which happens with every new technology shift.\n如今，我们看到的便是模仿谷歌搜索框的人工智能聊天机器人。我们正深陷于每一次新技术变革都会伴随的尴尬过渡期。\nI don\u0026rsquo;t have all the answers on what comes next. But I like to play with a few historical metaphors to think about how AI can work at different scales, from individuals to organizations to whole economies.\n对于未来会发生什么，我并非知晓所有答案。但我喜欢借助几个历史隐喻，思考人工智能如何在不同层面 —— 从个人、组织到整个经济体 —— 发挥作用。\nIndividuals: from bicycles to cars（个人层面：从自行车到汽车） # The first glimpses can be found with the high priests of knowledge work: programmers.\n这一变革的最初迹象，出现在知识工作的 “高阶从业者”—— 程序员身上。\nMy co-founder Simon was what we call a 10× programmer, but he rarely writes code these days. Walk by his desk and you\u0026rsquo;ll see him orchestrating three or four AI coding agents at once, and they don\u0026rsquo;t just type faster, they think, which together makes him a 30-40× engineer. He queues tasks before lunch or bed, letting them work while he\u0026rsquo;s away. He\u0026rsquo;s become a manager of infinite minds.\n我的联合创始人西蒙曾是我们口中的 “10 倍程序员”，但如今他几乎不再亲自写代码。走过他的办公桌，你会看到他同时调度着三四个人工智能编程代理 —— 它们不只是打字更快，更能自主思考，这让西蒙俨然成为了 “30-40 倍工程师”。他会在午饭前或睡前下达任务队列，让这些代理在他离开时继续工作。他已然成为 “无限心智的管理者”。\nA 1970s Scientific American study on locomotion efficiency inspired Steve Jobs\u0026rsquo;s famous \u0026lsquo;bicycle for the mind\u0026rsquo; metaphor. Except we\u0026rsquo;ve been pedaling on the Information Superhighway for decades since.20 世纪 70 年代《科学美国人》一篇关于移动效率的研究，启发史蒂夫・乔布斯提出了著名的 “心智自行车” 隐喻。然而，自那以后的几十年里，我们一直在 “信息高速公路” 上奋力蹬着这辆 “自行车”。\nIn the 1980s, Steve Jobs called personal computers \u0026ldquo;bicycles for the mind.\u0026rdquo; A decade later, we paved the \u0026ldquo;information superhighway\u0026rdquo; that is the internet. But today, most knowledge work is still human-powered. It\u0026rsquo;s like we\u0026rsquo;ve been pedaling bicycles on the autobahn.20 世纪 80 年代，史蒂夫・乔布斯将个人电脑称为 “心智的自行车”。十年后，我们铺就了 “信息高速公路”—— 也就是互联网。但如今，大多数知识工作仍依赖人力驱动，就像我们一直在高速公路上蹬着自行车前行。\nWith AI agents, someone like Simon has graduated from riding a bicycle to driving a car.借助人工智能代理，像西蒙这样的人已经从 “骑自行车” 升级为 “开汽车”。\nWhen will other types of knowledge workers get cars? Two problems must be solved.其他类型的知识工作者何时才能拥有自己的 “汽车”？有两个问题必须解决。\nComparing with coding agent, why is it more difficult for AI to help with knowledge work? Because knowledge work is more fragmented and less verifiable.与编程代理相比，人工智能为何更难助力通用知识工作？因为知识工作更分散，且可验证性更低。\nFirst, context fragmentation. For coding, tools and context tend to live in one place: the IDE, the repo, the terminal. But general knowledge work is scattered across dozens of tools. Imagine an AI agent trying to draft a product brief: it needs to pull from Slack threads, a strategy doc, last quarter\u0026rsquo;s metrics in a dashboard, and institutional memory that lives only in someone\u0026rsquo;s head. Today, humans are the glue, stitching all that together with copy-paste and switching between browser tabs. Until that context is consolidated, agents will stay stuck in narrow use-cases.\n其一，场景碎片化。对于编程而言，工具和相关场景往往集中在一处：集成开发环境（IDE）、代码仓库、终端。但通用知识工作的场景却分散在数十种工具中。试想，一个人工智能代理要起草产品简报，需要从 Slack 对话、战略文档、仪表盘里上季度的指标数据，以及仅存在于某个人脑海中的组织记忆中提取信息。如今，人类是连接这一切的纽带 —— 通过复制粘贴、在浏览器标签页间切换来整合信息。在这些场景被整合之前，人工智能代理只能局限于狭窄的应用场景。\nThe second missing ingredient is verifiability. Code has a magical property: you can verify it with tests and errors. Model makers use this to train AI to get better at coding (e.g. reinforcement learning). But how do you verify if a project is managed well, or if a strategy memo is any good? We haven\u0026rsquo;t yet found ways to improve models for general knowledge work. So humans still need to be in the loop to supervise, guide, and show what good looks like.\n其二，缺乏可验证性。代码具有一种神奇的特性：可以通过测试和报错来验证其正确性。模型开发者利用这一点训练人工智能，使其在编程方面不断进步（例如强化学习）。但如何验证一个项目是否管理得当？一份战略备忘录是否优质？我们尚未找到方法来优化通用知识工作相关的人工智能模型。因此，人类仍需参与其中进行监督、指导，并定义 “优质” 的标准。\nThe Red Flag Act of 1865 required a flag bearer to walk ahead of the vehicle while it drove down the street (repealed in 1896). An example of undesirable \u0026ldquo;human in the loop.\u0026ldquo;1865 年的《红旗法案》规定，车辆在街上行驶时，必须有一名持旗手在前方步行引导（该法案于 1896 年废除）。这是一个 “人类参与闭环” 的负面案例。\nProgramming agents this year taught us that having a \u0026ldquo;human-in-the-loop\u0026rdquo; isn\u0026rsquo;t always desirable. It\u0026rsquo;s like having someone personally inspect every bolt on a factory line, or walk in front of a car to clear the road (see: the Red Flag Act of 1865). We want humans to supervise the loops from a leveraged point, not be in them. Once context is consolidated and work is verifiable, billions of workers will go from pedaling to driving, and then from driving to self-driving.今年，编程代理让我们明白，“人类参与闭环” 并非总是可取的。这就像让人为检查工厂生产线上的每一颗螺栓，或让人事先走到汽车前方清理道路（参见 1865 年《红旗法案》）。我们希望人类能从一个更具杠杆效应的角度监督这些闭环，而非深陷其中。一旦场景整合完成、工作具备可验证性，数十亿工作者将从 “蹬自行车” 升级为 “开汽车”，进而迈向 “自动驾驶” 的新阶段。\nOrganizations: steel and steam（组织层面：钢铁与蒸汽） # Companies are a recent invention. They degrade as they scale and reach their limit.\n公司是近代才出现的组织形式。随着规模扩大，它们会逐渐 “退化”，最终触及增长上限。\nOrganizational chart for the New York and Erie Railroad, 1855. The modern corporation and org chart evolved with the railroad companies, which were the first enterprises that needed to coordinate thousands of people across great distances.1855 年纽约 - 伊利铁路公司的组织结构图。现代企业及其组织结构图是随着铁路公司发展而来的 —— 铁路公司是最早需要协调数千人跨远距离协作的企业。\nA few hundred years ago, most companies were workshops of a dozen people. Now we have multinationals with hundreds of thousands. The communication infrastructure (human brains connected by meetings and messages) buckles under exponential load. We try to solve this with hierarchy, process, and documentation. But we\u0026rsquo;ve been solving an industrial-scale problem with human-scale tools, like building a skyscraper with wood.\n几百年前，大多数公司都是只有十几人的小作坊。如今，我们已有员工数十万的跨国企业。沟通架构（通过会议和信息连接起来的人类大脑）在指数级增长的压力下不堪重负。我们试图通过层级制度、流程和文档来解决这个问题，但这无异于用人力规模的工具解决工业规模的问题 —— 就像用木材建造摩天大楼。\nTwo historical metaphors show how future organizations can look differently with new miracle materials.\n两个历史隐喻，或许能揭示未来组织在新奇迹材料的加持下会呈现怎样的新形态。\nA wonder of steel: the Woolworth building was the tallest building in the world upon completion in NYC, 1913.钢铁的奇迹：1913 年，伍尔沃斯大厦在纽约落成时，是当时世界上最高的建筑。\nThe first is steel. Before steel, buildings in the 19th century had a limit of six or seven floors. Iron was strong but brittle and heavy; add more floors, and the structure collapsed under its own weight. Steel changed everything. It\u0026rsquo;s strong yet malleable. Frames could be lighter, walls thinner, and suddenly buildings could rise dozens of stories. New kinds of buildings became possible.\n第一个隐喻是钢铁。19 世纪，在钢铁出现之前，建筑的高度上限只有六七层。铁虽坚固，但脆且重 —— 再增加楼层，建筑就会因自身重量坍塌。钢铁改变了一切：它坚固且富有韧性，框架可以更轻便，墙体可以更单薄，建筑 suddenly 能矗立数十层。全新类型的建筑成为可能。\nAI is steel for organizations. It has the potential to maintain context across workflows and surface decisions when needed without the noise. Human communication no longer has to be the load-bearing wall. The weekly two-hour alignment meeting becomes a five-minute async review. The executive decision that required three levels of approval might soon happen in minutes. Companies can scale, truly scale, without the degradation we\u0026rsquo;ve accepted as inevitable.\n人工智能就是组织的 “钢铁”。它有能力在整个工作流程中保持场景连贯性，在需要时精准呈现决策，而不产生冗余信息。人类沟通不再需要充当 “承重墙”：每周两小时的同步对齐会议，可缩短为五分钟的异步审阅；原本需要三层审批的高管决策，或许很快能在几分钟内完成。企业得以实现真正的规模化发展，而不必承受我们曾以为不可避免的 “规模退化”。\nA mill with a water wheel to power its operations. Water was powerful but unreliable and restricted mills to a few locations and seasonality.依靠水车驱动的工厂。水力虽强劲，但不稳定，且限制了工厂的选址（需靠近水源）和运营的季节性。\nThe second story is about the steam engine. At the beginning of the Industrial Revolution, early textile factories sat next to rivers and streams and were powered by waterwheels. When the steam engine arrived, factory owners initially swapped waterwheels for steam engines and kept everything else the same. Productivity gains were modest.\n第二个隐喻与蒸汽机有关。工业革命初期，早期纺织厂都建在河流溪边，依靠水车驱动。蒸汽机出现后，工厂主们起初只是用水车替换成蒸汽机，其余一切照旧，因此生产力提升十分有限。\nThe real breakthrough came when factory owners realized they could decouple from water entirely. They built larger mills closer to workers, ports, and raw materials. And they redesigned their factories around steam engines (Later, when electricity came online, owners further decentralized away from a central power shaft and placed smaller engines around the factory for different machines.) Productivity exploded, and the Second Industrial Revolution really took off.\n真正的突破，发生在工厂主们意识到可以彻底摆脱水力依赖之时。他们将更大的工厂建在靠近工人、港口和原材料的地方，并围绕蒸汽机重新设计工厂布局（后来电力出现后，工厂主们进一步去中心化，不再依赖中央传动轴，而是为不同机器配备小型发动机）。生产力随之爆发，第二次工业革命才真正全面展开。\nThis 1835 engraving by Thomas Allom depicts a textile factory in Lancashire, UK. It was powered by steam engines.这幅 1835 年由托马斯・阿洛姆创作的版画，描绘了英国兰开夏郡的一家纺织厂，该厂由蒸汽机驱动。\nWe\u0026rsquo;re still in the \u0026ldquo;swap out the waterwheel\u0026rdquo; phase. AI chatbots bolted onto existing tools. We haven\u0026rsquo;t reimagined what organizations look like when the old constraints dissolve and your company can run on infinite minds that work while you sleep.\n如今，我们仍处于 “替换水车” 的阶段 —— 将人工智能聊天机器人简单嫁接到现有工具上。我们尚未重新构想：当旧有的限制不复存在，当公司可以依靠 “永不休眠的无限心智” 运转时，组织会呈现怎样的形态？\nAt my company Notion, we have been experimenting. Alongside our 1,000 employees, more than 700 agents now handle repetitive work. They take meeting notes and answer questions to synthesize tribal knowledge. They field IT requests and log customer feedback. They help new hires onboard with employee benefits. They write weekly status reports so people don\u0026rsquo;t have to copy-paste. And this is just baby steps. The real gains are limited only by our imagination and inertia.\n在我所在的 Notion 公司，我们已经开始了尝试。除了 1000 名员工外，目前已有 700 多个人工智能代理在处理重复性工作：记录会议纪要、解答问题以整合组织内部的隐性知识、处理 IT 需求、记录客户反馈、帮助新员工熟悉员工福利、撰写每周状态报告（省去人们复制粘贴的麻烦）。而这仅仅是起步阶段。真正的收益，只受限于我们的想象力和惯性。\nEconomies: from Florence to megacities（经济体层面：从佛罗伦萨到特大城市） # Steel and steam didn\u0026rsquo;t just change buildings and factories. They changed cities.钢铁和蒸汽不仅改变了建筑和工厂，更改变了城市。 # Until a few hundred years ago, cities were human-scaled. You could walk across Florence in forty minutes. The rhythm of life was set by how far a person could walk, how loud a voice could carry.\n几百年前，城市都是 “人力规模” 的。你只需四十分钟就能走完佛罗伦萨全城，生活节奏由 “人能走多远、声音能传多远” 决定。\nThen steel frames made skyscrapers possible. Steam engines powered railways that connected city centers to hinterlands. Elevators, subways, highways followed. Cities exploded in scale and density. Tokyo. Chongqing. Dallas.\n后来，钢铁框架让摩天大楼成为可能，蒸汽机驱动的铁路将市中心与腹地连接起来，电梯、地铁、高速公路相继出现。城市的规模和密度呈爆炸式增长 —— 东京、重庆、达拉斯，皆是如此。\nThese aren\u0026rsquo;t just bigger versions of Florence. They\u0026rsquo;re different ways of living. Megacities are disorienting, anonymous, harder to navigate. That illegibility is the price of scale. But they also offer more opportunity, more freedom. More people doing more things in more combinations than a human-scaled Renaissance city could support.\n这些城市并非佛罗伦萨的 “放大版”，而是全新的生活方式。特大城市令人迷茫、充满匿名性、难以导航 —— 这种 “难以理解性” 是规模扩大的代价。但与此同时，它们也提供了更多机遇、更多自由：更多人以更多样的组合方式做更多事情，这是文艺复兴时期 “人力规模” 的城市无法承载的。\nI think the knowledge economy is about to undergo the same transformation.我认为，知识经济即将经历同样的变革。\nToday, knowledge work represents nearly half of America\u0026rsquo;s GDP. Most of it still operates at human scale: teams of dozens, workflows paced by meetings and email, organizations that buckle past a few hundred people. We\u0026rsquo;ve built Florences with stone and wood.\n如今，知识工作贡献了美国近一半的国内生产总值（GDP）。但其中大部分仍以 “人力规模” 运转：几十人的团队、以会议和电子邮件为节奏的工作流程、人数超过数百就会不堪重负的组织。我们用 “石头和木材” 建造了一个个 “佛罗伦萨”。\nWhen AI agents come online at scale, we\u0026rsquo;ll be building Tokyos. Organizations that span thousands of agents and humans. Workflows that run continuously, across time zones, without waiting for someone to wake up. Decisions synthesized with just the right amount of human in the loop.\n当人工智能代理大规模投入应用，我们将开始建造 “东京”：由数千名人工智能代理和人类共同组成的组织、跨时区持续运转且无需等待任何人醒来的工作流程、仅需适量人类参与监督的决策过程。\nIt will feel different. Faster, more leveraged, but also more disorienting at first. The rhythms of the weekly meeting, the quarterly planning cycle, and the annual review may stop making sense. New rhythms emerge. We lose some legibility. We gain scale and speed.\n这一切会让人感到陌生：起初会更快、更具杠杆效应，但也更令人迷茫。每周会议、季度规划、年度评审的节奏可能不再合理，新的节奏将应运而生。我们会失去一些 “可理解性”，但会收获规模与速度。\nBeyond the waterwheels（超越水车时代） # Every miracle material required people to stop seeing the world via the rearview mirror and start imagining the new one. Carnegie looked at steel and saw city skylines. Lancashire mill owners looked at steam engines and saw factory floors free from rivers.\n每一种奇迹材料，都要求人们放下 “后视镜” 看世界，转而构想全新的可能。卡内基看到钢铁，便预见了城市天际线；兰开夏郡的工厂主看到蒸汽机，便想到了摆脱河流束缚的工厂车间。\nWe are still in the waterwheel phase of AI, bolting chatbots onto workflows designed for humans. We need to stop asking AI to be merely our copilots. We need to imagine what knowledge work could look like when human organizations are reinforced with steel, when busywork is delegated to minds that never sleep.\n如今，我们仍处于人工智能的 “水车时代”—— 将聊天机器人简单嫁接到为人类设计的工作流程中。我们需要停止只把人工智能当作 “副驾驶”，而应构想：当人类组织被 “钢铁” 加固，当繁杂事务被委托给 “永不休眠的心智”，知识工作会呈现怎样的全新形态？\nSteel. Steam. Infinite minds. The next skyline is there, waiting for us to build it.\n钢铁、蒸汽、无限心智。下一片城市天际线已然浮现，等待我们去建造。\n","date":"23 January 2026","externalUrl":null,"permalink":"/posts/%E4%B8%AD%E8%8B%B1%E5%8F%8C%E8%AF%AD--%E8%92%B8%E6%B1%BD%E9%92%A2%E9%93%81%E4%B8%8E%E6%97%A0%E9%99%90%E5%BF%83%E6%99%BA-steam-steel-and-infinite-minds/","section":"AI-Related Reposts","summary":"","title":"[Repost] 中英双语 | 蒸汽、钢铁与无限心智 Steam, Steel, and Infinite Minds","type":"posts"},{"content":"","date":"23 January 2026","externalUrl":null,"permalink":"/tags/opinion/","section":"Tags","summary":"","title":"Opinion","type":"tags"},{"content":"Reposted from 不用担心我的 Skill 过时了，推荐一个 Claude Code Skill 更新检查工具 by 阿衡的AI日常\n🐒 大家好，我是阿衡，一年经验用了十次的游戏后端开发，现在是自由职业、独立游戏开发者。\n非专业 AI 玩家，日常关注 AI 编程方向的内容。\n**🎯 这是 Claude Code Skills 系列，介绍一个检查 Skill 更新和推荐好用\nSkill 的小工具。**\n之前我们聊了怎么给 Claude Code 装 Skill。\nClaude Code Skills：从手写到工具化，教 AI 新技能的完整指南\n装完之后，新问题来了：这些 Skill 有更新吗？我怎么知道？\n说实话，Claude Code 本身是没有这个功能的。你装了十几个 Skill，想知道哪个过时了，只能一个一个去 GitHub 看——这也太累了。\n所以我找了个工具，专门解决这个问题。\n这工具是干嘛的 # skills-updater，顾名思义，就是帮你检查已安装技能有没有更新。\n它能做两件事：\n第一，扫描你本地装的所有 Skill，对比远程版本，告诉你哪些该更新了。\n第二，如果你不知道装什么好，它还能从 skills.sh 拉取热门排行榜，推荐一些好用的技能给你。\n怎么安装 # 安装很简单，直接在 Claude Code 中说：\n1 帮我把 https://github.com/yizhiyanhua-ai/skills-updater 克隆到 ~/.claude/skills/ 目录 或者直接说：\n1 安装 skills-updater 技能 装完之后，你可以在 ~/.claude/skills/ 目录下看到 skills-updater 文件夹，说明安装成功了。\n怎么用 # 用起来很自然，就像跟 Claude 聊天一样。\n1、检查更新，直接说：\n\u0026ldquo;检查 skills 更新\u0026rdquo;\n或者：\n\u0026ldquo;我的技能有更新吗\u0026rdquo;\nClaude 会调用这个 Skill，扫描你所有已安装的技能，然后告诉你结果。\n输出结果分几种状态。\n✅ 已是最新，不用管，放心用。\n🔄 有更新可用，会显示当前版本和最新版本，问你要不要更新。\n⚠️ 版本未知，这个等下单独说，这里是个坑 （可以看到我这里的官方技能就是版本未知……\n2、推荐技能，可以说：\n\u0026ldquo;推荐一些好用的 skills\u0026rdquo;\n它会从 skills.sh 拉取热门榜单，列出一些高下载量的技能。\n是一个发现新玩具的好方法。\n进阶：修复官方 Skill 的版本信息 # 就像前面留的坑，我安装的 Anthropic 官方的一些技能（比如 example-skills、document-skills），检查出来都是\u0026quot;版本未知\u0026quot;⚠️。\n为什么？\n因为这些技能是通过 marketplace 方式安装的，安装时没有记录版本信息。本地的 installed_plugins.json 里，version 字段直接写的是 unknown。\n怎么解决？让 Claude 帮你重新安装一遍，转成用 git commit SHA 追踪版本。\n直接跟 Claude 说：\n\u0026ldquo;帮我重新安装 anthropic 官方的 example-skills，之前可能是因为 marketplace 安装的没有版本信息\u0026rdquo;\nClaude 会自动帮你处理：先拉取最新的 marketplace 仓库，获取最新的 commit SHA，然后删除旧的缓存目录，用新的版本号重新安装，最后更新 installed_plugins.json。整个过程大概两三分钟，不需要你手动操作。\n修复完之后，再跑一次检查更新，就能看到正确的版本号了。以后有更新也能正常检测。\n局限性 # 诚实地说，这个工具不是万能的。\n第一，依赖版本信息。 它需要从 marketplace.json 或 GitHub API 获取远程版本。如果技能作者没有提供版本信息，就没法对比。\n第二，安装方式有限制。 通过 npx 或 git clone 安装的技能，一般都能正常检测。但如果你是直接复制文件夹安装的，那就检测不到了——因为根本没有版本信息可查。\n第三，\u0026ldquo;版本未知\u0026quot;不代表过时。 有些技能就是没有版本号，不影响使用。只是你没法通过这个工具判断它是否需要更新。\n所以，这个工具更适合管理那些 npx 或者 git 安装的技能。对于一些手动安装的、实验性的技能，还是得自己盯着。\n最后 # 一个小工具，解决一个小痛点。\n装 Skill 容易，管理 Skill 麻烦。\n有了这个检查器，至少不用一个一个去 GitHub 翻了。\n相关链接：\nskills-updater 仓库：\nhttps://github.com/yizhiyanhua-ai/skills-updater\nskills.sh 技能市场：\nhttps://skills.sh\n💬 下一篇可能会聊聊怎么自己写一个 Skill，或者分享一些我觉得好用的技能。有什么想看的，评论区告诉我！\n👍 觉得有用的话，记得点赞+转发，让更多人看到这篇文章！\n","date":"22 January 2026","externalUrl":null,"permalink":"/posts/%E4%B8%8D%E7%94%A8%E6%8B%85%E5%BF%83%E6%88%91%E7%9A%84-skill-%E8%BF%87%E6%97%B6%E4%BA%86%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AA-claude-code/","section":"AI-Related Reposts","summary":"","title":"[Repost] 不用担心我的 Skill 过时了，推荐一个 Claude Code Skill 更新检查工具","type":"posts"},{"content":"Reposted from 792万之后：不可替代性时代的生存法则 by 袁希重构教育\n792万新生儿，是坏消息吗？ # 取决于你站在哪一边。\n如果你的生存依赖于规模——依赖人多、市场大、流量多——这是灾难。\n如果你的生存依赖于不可替代性——这是40年来最大的机会。\n因为你的竞争对手正在消失。\n我不想再讨论\u0026quot;危机\u0026quot;。铺天盖地的专家已经说了无数遍：养老崩溃、经济下滑、劳动力短缺。\n但这些宏观判断对你没有任何意义。因为这不是选择题，是现实题。低生育已经到来，不会因为焦虑而改变。\n真正重要的问题是：在这个不可逆的新世界里，你该站在哪一边？\n一、筛选机制启动：从数量游戏到质量游戏 # 过去40年，中国的增长逻辑是什么？\n人多 = 市场大 = 规模效应 = 低成本 = 竞争力。\n这套逻辑造就了一切：制造业崛起、房地产狂飙、教培遍地开花、餐饮连锁扩张。\n谁能把一件事标准化、规模化、快速复制，谁就赢。\n但这套逻辑正在失效。\n792万不是一个数字，是一个信号：中国正在从\u0026quot;数量游戏\u0026quot;切换到\u0026quot;质量游戏\u0026quot;。\n这意味着什么？\n意味着在数量游戏里胜出的人、产业、能力，在质量游戏里可能一文不值。\n这是一次底层规则的切换。而大多数人还在用旧地图找路。\n二、穿透三层的同一个词：不可替代性 # 我观察到三个层面正在发生同样的位移：\n旧逻辑（人口红利时代） 新逻辑（人口收缩时代） 产业靠规模 产业靠不可替代性 市场靠数量 市场靠深度关系 职位靠身份 职位靠价值交付 穿透这三层的是同一个词：不可替代性。\n让我一层层拆开。\n第一层：产业——规模神话的黄昏 # 西贝这些年的摇摆非常典型。\n过去的餐饮逻辑是：人口多 → 家庭多 → 聚餐多 → 标准化连锁最赚钱。于是中央厨房、预制菜、流程化出餐、全国复制——这在\u0026quot;人多 + 便宜劳动力\u0026quot;的时代几乎是最优解。\n但今天的真实已经变了：家庭规模变小，年轻人独居化，人工成本上升，情绪消费大于\u0026quot;吃饱\u0026quot;。\n于是出现一个致命矛盾：你越标准化，越像机器；而顾客要的却是\u0026quot;人味\u0026quot;。\n西贝的问题不是预制菜，是逻辑。它仍在\u0026quot;规模供给\u0026quot;的旧世界里打转，而低生育时代的餐饮，本质是情绪产业，不是热量产业。\n教育更明显。\n过去靠什么？人口红利、升学焦虑、大班复制、名师流水线。\n今天呢？孩子少了，家长更理性，AI能教基础知识，人只剩\u0026quot;陪伴价值\u0026quot;。\n东北正在整治\u0026quot;课上不讲、课后补讲再收费\u0026quot;的现象。这不是个案，这是旧教育模式的挽歌——当人口减少、信息透明后，规模化收割再也玩不下去。\n什么产业会活下来？\n不是更大的，是更不可替代的。\nAI和机器人替代的不是\u0026quot;工作\u0026quot;，是\u0026quot;可标准化的工作\u0026quot;。任何能被流程化、批量复制的事情，都会被机器接管。\n留下来的，只有机器做不了的事：情绪、信任、定制、长期关系。\n第二层：市场——\u0026ldquo;高端\u0026quot;不是价格高，是价值密度高 # 市场正在两极分化：\n机器侧：标准咨询、基础诊断、通用课程、客服问答、流程执行——这些会被AI工具化，价格趋近于零。\n人侧：需要\u0026quot;被好好对待\u0026quot;的一切——情绪支持、深度陪伴、个性化定制、长期信任关系。\n你会发现一个规律：越需要\u0026quot;被好好对待\u0026quot;的，越属于人。\n但这里有一个陷阱。\n当我说\u0026quot;进入高端市场\u0026rdquo;，很多人会误解为\u0026quot;赚有钱人的钱\u0026quot;。\n错了。\n高端不是价格高，是价值密度高。\n什么是价值密度？\n•低价值密度：卖一杯标准化咖啡，任何人都能做\n•高价值密度：帮一个创业者想清楚他的商业模式，只有你能做\n一个陪诊师，可能比三甲医院的普通医生更被需要——不是因为他医术更高，是因为他能在病人最恐惧的时刻握住他的手，帮他理解那些冷冰冰的检查报告意味着什么。\n高端定制的本质不是\u0026quot;服务有钱人\u0026quot;，是\u0026quot;提供无法被复制的价值\u0026quot;。\n第三层：个人——从\u0026quot;我是谁\u0026quot;到\u0026quot;我解决什么问题\u0026quot; # 这是对普通人冲击最大的一层。\n过去的公式是：职业身份 = 尊严。\n你是医生，你有荣耀。你是律师，你有地位。你是公务员，你有安全感。你在大厂，你有光环。\n这套公式正在失效。\n因为身份是静态的、可被替代的、可被取消的。\n•AI能做初诊，医生的身份开始贬值\n•模板能写合同，律师的身份开始贬值\n•标准流程被机器接管，一切\u0026quot;按规矩办事\u0026quot;的身份都在贬值\n新时代的公式是：你解决什么问题 = 你的价值。\n一个医生的身份可以被AI诊断取代。但一个能让绝望的病人重获希望的人，永远有价值。\n一个老师的身份可以被AI课程取代。但一个能在孩子迷茫时帮他找到方向的人，永远有价值。\n这就是\u0026quot;从身份到价值\u0026quot;的真正含义：\n旧时代问：你是什么身份？\n新时代问：你解决什么问题？\n问题解决能力是动态的、可迁移的、可累积的。它不依附于任何机构、任何职位、任何名片。\n三、未来的价值公式 # 如果我要用一个公式概括未来什么样的人最有价值，那就是：\n价值 = 专业深度 × 关系深度\nAI能提供专业深度。它比任何人都懂医学、法律、金融的知识。\n但AI没有\u0026quot;关系\u0026quot;。它不认识你，不理解你的恐惧，不知道你凌晨三点睡不着是因为什么。\n专业，正在被AI商品化。\n关系，正在成为最后的稀缺资源。\n所以未来最有价值的人是谁？\n既有专业深度，又能与特定的人建立深度关系的人。\n这就是\u0026quot;私人定制 + 专业陪伴\u0026quot;的本质。\n五年后，所有真正有价值的服务都会走向这个方向：教育陪伴、健康陪伴、决策陪伴、心理陪伴、养老陪伴——\n不是更标准，是更懂你。\n四、机器化的人 vs 完整的人 # 说到这里，我要讲一个更根本的问题。\n如果一个20岁的年轻人问我：\u0026ldquo;我该怎么为这个时代做准备？\u0026rdquo;\n我的回答不是学什么技能、进什么行业。\n我的回答是：你必须成为一个完整的人，而不是一台机器。\n什么是机器化的人？\n•学习方式：等待投喂，被动接收标准答案\n•做决定依据：别人都这么做，所以我也这么做\n•面对不确定性：恐惧、逃避、等待指令\n•与他人的关系：工具性的、可替换的、浅层的\n•对自己的认知：我是一个岗位、一个身份、一张名片\n什么是完整的人？\n•学习方式：主动探索，在混乱中建立自己的理解框架\n•做决定依据：我相信什么，我要什么，我愿意为什么负责\n•面对不确定性：接受它是常态，在不确定中寻找可能性\n•与他人的关系：深度的、不可替代的、基于真实的\n•对自己的认知：我是一个有独特经历、独特视角、独特价值的人\n机器化的人会被机器替代。\n完整的人才能驾驭机器。\n过去的教育在批量生产机器化的人——标准化输入、标准化输出、标准化评价。\n这套系统在数量游戏里是最优解。\n但在质量游戏里，它生产的是被淘汰的人。\n五、可迁移能力：真正的护城河 # 恒定的职业正在消失。\n你今天的岗位，五年后可能不存在。你今天的技能，十年后可能毫无价值。\n唯一不会贬值的，是可迁移的能力。\n三种迁移能力：\n地理迁移：城市之间、线上线下、国内国外。你能不能在任何地方创造价值？\n能力迁移：老师 → 学习陪跑，医生 → 健康顾问，销售 → 关系经营。你的能力能不能换一个场景依然有效？\n身份迁移：从\u0026quot;岗位人\u0026quot;到\u0026quot;价值人\u0026quot;。你能不能脱离机构、脱离职位，依然被需要？\n副业不是补贴，是能力验证场。\n如果你只能在一个岗位上创造价值，你就是脆弱的。\n如果你能在主业之外，用另一种方式被人需要，你就有了第二条生命线。\n从小就要培养：表达、组织、关系、服务。\n这些不是\u0026quot;软技能\u0026quot;，这是未来的硬通货。\n六、行动清单：30天重新定位 # 不要等。\n改变不是渐进的，是在你对现状彻底厌倦的那一刻发生的。\n下面是一个30天的思考框架，不是让你学新技能，是让你重新定位自己。\n【第一周：审计】 # 列出你目前工作中\u0026quot;可被标准化\u0026quot;的部分——这些会被替代\n列出你目前工作中\u0026quot;依赖深度关系\u0026quot;的部分——这些是你的资产\n问自己：如果我的岗位明天消失，我还能为谁解决什么问题？\n【第二周：定义】 # 写下三个你真正擅长解决的问题（不是岗位职责，是真实问题）\n写下三种人，他们需要你这种能力但目前没有找到你\n用一句话回答：我能为谁提供什么不可替代的价值？\n【第三周：验证】 # 找到一个人，用你的能力帮他解决一个真实问题\n不收钱，只验证：你的价值判断是对的吗？\n收集反馈：他真正需要的是什么？你提供的和他需要的差距在哪？\n【第四周：迁移】 # 问自己：这个价值，能不能换一个场景依然成立？\n问自己：这个价值，能不能变成一个持续的服务而不是一次性的帮忙？\n问自己：如果我要把这件事做成副业，第一步是什么？\n七、真正的危险 # 低生育不是灾难，是旧世界的告别仪式。\n792万是一个筛选机制的启动信号。它在问每一个人：\n你靠规模生存，还是靠不可替代性生存？\n你是一个身份，还是一个价值？\n你是机器化的人，还是完整的人？\n真正的危险不是人少了。\n真正的危险是——你还活在\u0026quot;人多\u0026quot;的思维里。\n你的竞争对手正在消失。\n问题是，你是那个消失的，还是那个留下来的？\n最后送大家一句话：\n“旧秩序的废墟上人群如灰烬消散，唯有那些拒绝成为复制品的人，在坍塌中成为了自己的光源。”\n—— 袁希\n","date":"21 January 2026","externalUrl":null,"permalink":"/posts/792%E4%B8%87%E4%B9%8B%E5%90%8E%E4%B8%8D%E5%8F%AF%E6%9B%BF%E4%BB%A3%E6%80%A7%E6%97%B6%E4%BB%A3%E7%9A%84%E7%94%9F%E5%AD%98%E6%B3%95%E5%88%99/","section":"AI-Related Reposts","summary":"","title":"[Repost] 792万之后：不可替代性时代的生存法则","type":"posts"},{"content":"Reposted from Skills的最正确用法，是将整个Github压缩成你自己的超级技能库 by 数字生命卡兹克\n昨天写了一篇关于在扣子上使用Skills的文章。\n里面用的案例，特别简单，就是把Github上一个非常经典的开源项目，封装成一个Skill，方便我们以后进行调用。\n这么做的原因特别简单，就是我一直觉得，重复造轮子是一件特别呆逼的事情，互联网三十年，开源世界大神这么多，其实你能想象到的绝大多数需求，都有大佬和真神们，在前方铺路，做出了现成的产品，然后开源了出来，给非常非常多的人用。\n其实现在非常非常多的一些商业APP，特别是一些所谓的格式工厂、压缩之类的，绝大多数都是把一些大佬的开源工具，做个前端，给大家用。\n之前我觉得没啥问题，确实，Github上面很多的开源项目，都是没有GUI的，全部需要部署，部署以后还是用命令行操作，真的，光环境这一条，就能卡死绝大多数的普通用户。\n我自己，之前就是被挡在门外的普通用户。\n有太多太多好玩的、实用的、很屌的开源项目，我用不了了。\n比如格式转化这破事，没有AI之前，我每次就是去Google搜，MP3转WAV\u0026hellip;\n然后就看着各种各样你也不知道是不是有刺客的链接，在向你招手。。。\n所以，Skills一来，从文件结构上，它是可以把脚本和Prompt打包在一起的，这一点，跟单Prompt或者脚本完全不一样，再加上现在一些Coding能力强的基模和Agent，我觉得，它天然的擅长把很多的大佬们的开源项目Skill化，从而在Agent里面，为我所用。\n而且你要相信那些历史悠久的经典开源项目，经历了无数的时间和使用者的鞭打，不管是成功率还是稳定性还是效率，都远超绝大多数的你根据需求，让AI临时去写的一些代码\u0026hellip;\n所以就搞了这么个东西，其实不止Coze，当你在OpenCode或者Claude Code这种支持Skills的产品里，只要你装了那个Claude官方那个能生成Skills的Skill，也就是skill-creator，打包Github上的开源项目，也是完全没问题的。\n这种方式，就能最快速度，越过所谓的本地整合包，变成一个类似于Agent的产物，让你能快速的用上。\n比如昨天扣子文章中，我把视频处理的开源项目FFmpeg和图片视频处理项目ImageMagick，封装成了一个多模态素材处理的Skill，它大概就是这个效果。\n然后呢，在文章中一个有趣的评论，引起了我的注意。\n这个评论的问题没啥毛病，因为github上那么多开源项目，离大众肯定还是非常的遥远，我因为知道有特定的项目可以去处理特定的事，所以封装成Skill就特别的简单，但是大多数的普通人，可能连github是什么都不知道，那怎么封装呢？\n这确实是个问题。\n我当时想了两分钟，然后我一寻思，不对啊，这不都有AI了吗\u0026hellip;\n于是，我就回了一句：\n没想到，引起了好几个朋友非常正向的反馈。\n这个时候，我才意识到，其实，我的很多的小技巧，对于蛮多人来说，还是挺有价值的。\n所以这块，我觉得我觉得可以单独拎一篇文章，来给大家讲一讲，普通人怎么把整个github，当成自己的弹药库，做成skill，让自己真正的，变得三头六臂无所不能。\n比如，我自己现在，就已经封装了很多的skills。\n哦这个管理skills的skill，也是我自己建的一个skill，要不然感觉每次进到文件里看太麻烦了，我就可以直接用这个skill，对我本地的所有skill进行卸载删除修改优化操作\u0026hellip;\n举一个例子。\n我相信大家经常都有一个需求，就是去各种视频网站上，下载视频，比如Youtube、B站等等。\n我自己也有。\n那我们就可以直接打开ChatGPT，选中GPT-5.2 Thinking（目前我认为搜索能力最好、幻觉程度最低的模型），当然，你用别的也行，一般来说问题都不大。\n然后直接提出你的问题：\n有没有那种就是去各种视频网站上，下载视频，比如Youtube、B站等等的github上的开源项目。\n在GPT搜索了一阵子以后，就会给你推荐一个，在github上，几乎封神的项目。\n它叫做，yt-dlp。\ngithub上143k的star，说是真神，也不为过。\n支持上千个网站。\n这，就是yt-dlp，我觉得最伟大的项目之一。\n你要相信，在这个世界上，在这个互联网上，有无数的大神和前人，已经为你铺好了前路。\n你要相信，你的需求，永远不是这个世界上第一个提出这个需求的人，也绝对不是最后一个。\n你要相信，人类在这几十年所积攒的历史，几乎覆盖了世界所有的领域，互联网，永远都是那个最深、最广的宝藏。\n你要相信，在这一刻，你搜出来这个开源项目的这一刻，这就是人类开源精神的涓涓长河，在你面前展开的绝美的画卷。\n我时常赞美这世界上，每一个愿意开源、每一个无私的将自己的知识分享出来的前辈们，正是因为他们，才让我们，能站在他们的肩上，去摘更美的星辰。\n我们直接复制yt-dlp的github链接。\n然后把这段Promtp发给你装好了skill-creator的OpenCode或者Claude Code：\n帮我把这个开源工具https://github.com/yt-dlp/yt-dlp打包成一个Skill，只要我后续给出视频链接，就可以帮我下载视频。\n这块如果还不懂或者不知道的skill-creator是啥的，可以去看我之前的那篇文章：\n一文带你看懂，火爆全网的Skills到底是个啥。\n一般我的做法对打包，是先让Agent进行规划，然后再去写整个的Skill，这样我自己感觉，成功率会高一点、后期稳定性也会更强一点。\n相对应的，OpenCode就是开启Plan模式。\n然后，Agent就会开始调用skill-creator这个生成器，开始分析yt-dlp这个项目，然后开始规划要怎么打包封装成一个Skill。\n规划了一通以后，OpenCode就分析完了，向我提出了几个问题。\n我也给出了我的回答。\n然后它就会继续规划，最终给我一个非常明确的计划。\n我觉得没有问题了，这个时候，我就会切换到正式的开发模式。\n也就是这个模式，然后发一句话，开始开发！\nOpenCode就会开始了。\n过了一会，大概2分钟以后，这个基于yt-dlp的视频下载Skill，就开发完成了。\n我们试一试。\n比如OpenAI刚刚出的Youtube访谈视频，我想下载下来。\n直接就把链接扔给OpenCode就行，这里可以注意一个小技巧，就是所有的涉及到这种需要运行程序的Skills，在第一次运行的时候，都无脑推荐在OpenCode里使用GPT 5.2 Codex（如果你有的话），体验会比Claude 4.5 Opus好N倍。\n大概就是：构建Skills的时候Claude 4.5 Opus，如果这些开源项目封装好了，在第一次运行的时候用GPT 5.2 Codex，后续就无所谓了。\n第一次运行，其实会遇到很多问题，比如说Youtube防爬机制很强，需要你装个浏览器扩展导出Cookie，比如要安装一些其他的项目等等，不过这些AI都会指导你干好。\n然后一顿操作，这个项目，就下载好了，全程大概也就几分钟。\n之所以是几分钟，还是因为，这是第一次。\n而后续，只需要，十几秒。\n这时候，其实你还可以做一个事，就是，把前面的那些为了下载视频而做的一些事情和经验，直接跟AI说：\n把这些经验，都更新到video-downloader这个skill里，下次就别这么慢了。\n然后，它就会自己对他的Skill文件进行修改，下次，这些事情，就不用干了，随开随下，快到起飞。\n这就是我的自己纯为了自己方便的一个skill全流程：\n根据一个需求，用AI搜索github上得开源项目，把开源项目使用AI进行Skill化，首次运行后，寻找BUG和问题，重新迭代Skill，至此，Skill固化，形成我的主Agent中一个可靠的技能。\n不止是一个下载视频的需求。\n还可以是，把一个web项目，打包成一个轻量级的桌面APP。\n于是，找到了Pake。\nGithub上一个45k的超棒的项目，那就，直接Skill化，以后，你的网页开发完，直接就可以用Pake skill，一句话变成桌面APP。\n你还可以，直接做一个究极万能的格式转化工厂。\n直接把这些最牛逼的格式转化项目，直接封装在一起，做成一个万能的格式转化Skill。\n从此，你无需各种奇怪的格式转化器，一个skill，解决所有。\n你还可以，把ArchiveBox转成Skill，从此，你有想保存下来的网页，都可以发送给ArchiveBox Skill来以无数种你想要的格式，帮你保存下来。\n支持N种格式，真的。\n甚至，你可以把著名的Ciphey，转成一个Skill。\n从此，你就可以，在你的本地，配合Agent，直接破译密码。。。\n这些，全部都可以Skill化，全部都可以加入到你的Agent之中，成为，你最坚实的技能，成为，你最恐怖的弹药库。\n而我提到的这些，仅仅只是Github上开源项目的冰山一角。\nGithub上牛逼的开源项目，那些人类的经验、人类的光芒。\n本就灿烂如星海。\n因为Skills的诞生，因为Agent的强大，现在，每个人、每个普通人，你的背后，都是全人类过去数十年的积累，只要你想，他就可以为你所用。\n你无需三头六臂，你无需头上长角，你已经拥有了海量的知识和技能。\n如果回到3年前的你的面前，你觉得，他跟你如今可以做到的事、如今的能力边界，还有任何可比性吗？\n朋友，这样璀璨、这样伟大、这样能让你成为超人的时代。\n真的不会让你兴奋吗？\n以上，既然看到这里了，如果觉得不错，随手点个赞、在看、转发三连吧，如果想第一时间收到推送，也可以给我个星标⭐～谢谢你看我的文章，我们，下次再见。\n\u0026gt;/ 作者：卡兹克\n\u0026gt;/ 投稿或爆料，请联系邮箱：wzglyay@virxact.com\n","date":"21 January 2026","externalUrl":null,"permalink":"/posts/skills%E7%9A%84%E6%9C%80%E6%AD%A3%E7%A1%AE%E7%94%A8%E6%B3%95%E6%98%AF%E5%B0%86%E6%95%B4%E4%B8%AAgithub%E5%8E%8B%E7%BC%A9%E6%88%90%E4%BD%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E8%B6%85%E7%BA%A7%E6%8A%80%E8%83%BD%E5%BA%93/","section":"AI-Related Reposts","summary":"","title":"[Repost] Skills的最正确用法，是将整个Github压缩成你自己的超级技能库","type":"posts"},{"content":"Reposted from NotebookLM终极神器来了！这个命令行工具，能让AI自动处理海量文档​ by 天亦同学\n▲▲ 点击上方公众号卡片，回复 PPT ，即可获得包含“PPT提示词、PPT乱码修改可编辑”等场景的《Notebooklm PPT高级教程》，点击 星标 第一时间接收教程推送\n你好，我是天亦，一名企业AI战略顾问、AI讲师。\n如果说AI工具有何颠覆性创新，Google推出的NotebookLM必定占据一席之地。\n它凭借强大的Gemini模型与多模态生成能力，已成为内容创作与研究分析的利器。\n然而，传统网页端操作仍存在效率瓶颈。\n现在，开发者社区带来了革命性解决方案：notebooklm-py。\n这款开源工具将NotebookLM完整接入命令行环境，让AI知识处理迈入自动化新纪元。\n一、 NotebookLM命令行工具：核心价值解析 # 该项目在GitHub发布后迅速获得技术圈关注，它本质上填补了官方能力的空白：\nnotebooklm-py：为Google NotebookLM提供了缺失的API支持。实现研究工作流自动化，从文档生成播客，并将NotebookLM集成到AI智能体中——全部通过Python或命令行完成。\n其核心价值在于将交互式操作转化为可编程指令。\n如图所示，工具已实现思维导图生成、音频播客制作等任务的流水线处理：\n二、 三种部署模式，满足不同场景需求 # 1. 基础环境准备\n# 基础库安装pip install notebooklm-py 2. 三种集成方案\nClaude Skills集成（最适合AI智能体用户） # 通过命令行界面安装，或者让Claude Code来安装 命令行界面操作（适合自动化脚本开发） # 1. 首次运行先要登录认证（会打开浏览器） Python API调用（适合二次开发集成） import asyncio 三、 功能矩阵全览：从内容生成到智能研究 # 该工具的功能覆盖远超基础问答，形成完整的知识处理生态：\n四、 目标用户画像：谁最需要这个工具？ # 专业研究者：需要处理大量文献、数据报告的技术调研人员\n内容创作者：定期产出播客、视频脚本的多媒体内容团队\n知识管理师：构建个人知识体系、需要高效消化信息的终身学习者\nAI智能体开发者：基于Claude Code/Gemini CLI构建复杂工作流的工程师\n五、 趋势洞察：命令行交互代表未来方向 # 当前AI产品过度追求界面炫技，但真正的高阶用户更需要可编程性与自动化能力。\nNotebookLM本身具备顶尖的RAG（检索增强生成）能力，而命令行工具将其转化为知识处理的自动化管道。\n未来趋势已然明朗：信息从多元渠道（PDF、视频、网页）自动流入，经AI解析重组后，按需输出目标格式（思维导图、播客、PPT）。\nnotebooklm-py正是构建该自动化流程的核心组件。\n项目地址：https://github.com/teng-lin/notebooklm-py\nNotebookLM PPT制作8大高阶官方玩法实测\n一文读懂NotebookLM你的全能AI知识库助手\nNotebookLM教程40个核心问答从入门到精通\n欢迎转发分享给你朋友家人一起学习\n如果本文有启发，点个推荐谢谢支持\n#Notebooklm #notebooklm教程 #AI生成PPT\n","date":"20 January 2026","externalUrl":null,"permalink":"/posts/notebooklm%E7%BB%88%E6%9E%81%E7%A5%9E%E5%99%A8%E6%9D%A5%E4%BA%86%E8%BF%99%E4%B8%AA%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E8%83%BD%E8%AE%A9ai%E8%87%AA%E5%8A%A8%E5%A4%84%E7%90%86%E6%B5%B7%E9%87%8F/","section":"AI-Related Reposts","summary":"","title":"[Repost] NotebookLM终极神器来了！这个命令行工具，能让AI自动处理海量文档","type":"posts"},{"content":"Reposted from 火爆全网的Skills，终于有了最简单的打开方式。 by 数字生命卡兹克\n昨天，扣子来了一波大更新，直接更新到了2.0版本。\n甚至连logo都更新了。\n我觉得值得写一篇来聊聊。\n因为他们，上了两个我觉得非常实用也非常及时的功能：\nSkills和长期计划。\n最近Skills有多火，我就不说了。\n2024年，Prompt工程。\n2025年，上下文工程。\n2026年，Skills工程。\n大概就是这样的程度。\n如果有对Skills还不了解的朋友，可以去看我的这篇文章：一文带你看懂，火爆全网的Skills到底是个啥。\n已经有大量的产品，都已经支持SKills了，比如OpenCode、CodeX、Antigravity，也都在最近，全都支持了。\n但是吧，你会发现，这些全部都是Coding工具，要么是CLI、要么是IDE，我虽然现在天天在Antigravity里用OpenCode+Skills嗨的很爽，但是这玩意，对普通人来说，门槛还是太高了。\n就像OpenCode那个狗东西，对普通人最友好的GUI客户端版本，一堆BUG，每天要么白屏要么报错，大家看看我的OpenCode评论区里都少问题和BUG就知道了，逼得人回去用终端里面用TUI，但是那玩意，门槛又太高，死循环了。。。\n而愿意在这些工具里面折腾一下Skills的用户，已经是偏极客偏专业一点的了。\n对于更多的朋友来说，安装不来，终端不知道是什么，SKills的文件夹找不到，Github上的项目看不懂，我要怎么创建，等等等等。\n这个痛点和gap真的巨大，因为我说实话Skills，明明是一个非常ToC的技能，类似于Prompt，但是却没有看到，一些更普通的方式，能让大家更方便的用上Skills。\n直到这一次扣子2.0的更新，让我觉得，普通用户，也终于可以用上、并且可以创建自己的Skills了。\n毕竟，扣子本身就是个Agent产品，支持SKills，真的顺理成章。\n扣子网址在此：https://www.coze.cn/\n进入以后，在你的首界面对话框上，直接按下@键，就可以看到，你目前可以调用的技能，也就是Skills。\n现在有了写作的、帮你做PPT的、帮你做设计的、帮你做视频的等等等等的技能。\n这些全部都是官方内置好的，你可以直接用。\n当然，如果你不满足于只用官方技能，那当然有个对小白还蛮友好的东西，\n你如果不想自己创造技能，也可以调用别人的，这些技能已经全部封装好了，开箱即用。\n当然，用别人的技能，肯定不是大家最看重的，我觉得AI时代，最重要的，应该是抽象出自己的技能。\n我之前在公司里跟大家说：\n\u0026ldquo;未来一个人，能不能根据自己的需求，最快速度手搓产品或工作流来解决自己的需求，然后抽象形成skills进入到主Agent，成为你最牛逼的AI助理，就是一个人最强的竞争力，任何一件非与人沟通的事，如果要重复3次及以上，都应该全部Skill化。\u0026rdquo;\n这是我自己非常强调的观点，任何可以复用的技能，一定要抽象成技能，一定要，Skill化。\n在扣子里，我觉得最重要的，就是极低成本的，帮你把你的经验，Skill化。\n点击商店右上角的创建技能。\n你就会进入一个跟对话不一样的开发界面，然后，tab光标，已经定位在了技能这个地方。\n其他的那些tab你也不需要关注，只需要关注这个tab就可以。\n目前，在扣子上，创建技能有两种方式，都比较直观，一种面对普通用户，一种面对专业者。\n第一种特别简单，就是口喷式Skills开发，类似于Claude官方他们出的那个可以生成Skills的skill-creator。\n而在扣子里，这个变成了最主流的构建技能方式。\n毕竟，真的不会有太多的人，会亲自去修改、去编写Skills的文件，因为那玩意，说复杂，也还是有点复杂的。\n比如说，我有一个想做的就是一个能简单处理视频的Skill。\n它的作用，就是帮我把视频导出一个10M以内放在公众号文章里面的GIF，又或者帮我转视频格式，又或者把一堆序列帧拼成视频等等等等。\n这个东西，过去我们要打开剪映、打开AE、PR来处理，还是挺麻烦的，那其实就非常适合做成一个Skill。\n做法也特别简单，因为有一个现成的、究极经典的开源项目，叫做FFmpeg。\n以前这种项目，对于我们普通人来说，部署或者使用起来，都非常的麻烦，因为一旦涉及到本地和命令行，就把大多数的普通用户，拒绝在了门外。\n而现在，你只需要把这个开源项目，打包成一个Skill，你就可以，直接用上了，对，Skill就是这么神奇。。。\n做Skill也特别的简单，直接用嘴构建。\n我就把这个项目的Github链接发了过去，然后说：\n帮我把这个开源工具https://github.com/FFmpeg/FFmpeg，打包成一个Skill，方便我以后直接调用它来对我的视频进行格式转化、分辨率修改等等。\n点击发送，就OK了。。。。\n它就会自己开始读取Github链接，开始构建。\n大概一两分钟以后，这个Skill，就构建好了。\n看着完全没啥问题。\n这个时候，我们选择右上角的部署，然后点击开始部署。\n一堆花里胡哨之后。\n这个项目，很快就构建完成了。\n这时候，你就可以，在你的对话中，选择调用这个技能了。\n我随手扔了一个视频进去，就是海辛和阿文那个超级好看的猫和孔雀的镜头。\n然后，让它给我搞一个小于10M的gif。\n大概也就几十秒，扣子就调用这个Skill，把视频导出成了一个gif，效果极好。\n而且我看了下大小，确实10M以下。\n完美。\n这个时候，你可能想问，我还想处理图片怎么办。\n其实，你不止可以把一个开源项目打包成一个Skill，方便更多的普通用户用上，也可以，把多个项目，打包在一起，只要他们的大概用途是类似的。\n还有一个经典的处理图片的开源项目，叫做ImageMagick。\n我们就可以把视频处理、图片处理合并在一起，直接整成一个Skill，帮你处理后续所有的素材。\n没错，你现在看到的，其实就是很多格式工厂的雏形。。。\n发送过去，大概几分钟以后，这个Skill就建立好了，同时可以处理视频和图片。\n这个Skill，你就可以用来，处理比较复杂且连续的任务。\n比如：\n2分钟之后，全自动处理完毕。\n所有要求全部执行到位，就问你爽不爽。\n做好的技能，在技能商店，我的技能里就能看到。\n点击每个技能的更多按钮，就能上架到商店。\n走完流程以后，你的技能，就可以在技能商店里，给所有的用户们用上了。\n我把这个视频图片处理的技能，也上架了，如果不想再自己建一个的，也可以用我的这个。\n链接在此：https://www.coze.cn/?skill_share_pid=7597007752606679066\n说完了用嘴构建技能的方式，还有另一种，对专业用户比较友好的，或者你以前已经通过Claude Code或者OpenCode啥的，构建了大量的Skills，想在扣子上用的。\n扣子也提供了一个非常有效的办法。\n就是，上传文件包。\n把你的原来的某一个Skill的文件夹，直接打包成一个.zip格式的压缩包，或者就直接用.skill的包，上传进来。\n扣子就会自动识别，新建技能。\n比如我之前做的github整合包生成器。\n你就可以直接把那个压缩包，上传上去，\n然后，这个技能，就做完了，直接平移到了扣子上。\n这个没上架给大家用，不是因为这个有啥机密，单纯的就是现在成功率还稍微有点低\u0026hellip;等我再改一下\u0026hellip;调好了再给大家分享出来。\n说实话，扣子这一波，对于Skills的门槛降低，让它进入更多普通人的手里，还是有非常强的推动作用的。\n唯一不足的就是，扣子2.0上，技能只能用单个的，不能多个Skill互相结合调用，这个目前来看，还是有一点点掣肘，希望扣子赶紧更新。\n而除了SKills之外，扣子的另一个功能，也是我觉得非常有用的功能，扣子的产品团队，这次好像突然开了窍。\n这个功能，就是长期计划。\n长期计划简单说，就是你给AI定个目标，它帮你一步步简化，你只需要执行，不需要考虑其他的。\n这个东西非常的有意思，点击加号，就是这个创建长期计划了。\n我还真给我自己建了一个。\n就是上周二的时候，我肝到凌晨三点，第一次感觉心脏喘不上气。\n第二天就打开京东下单了一个跑步机，当时，我给自己2026年定了一个很重要的目标和长期计划。\n就是，健康的活着。。。\n所以，正好，我就让扣子给我建立了一套2026年可长期运行的身体健康计划。\n它会先问问你现在的情况，再根据实际来规划。\n大概等一会，扣子给我生成了2026年全年健康执行路径规划书和第一周的试执行方案\n我大致看了一眼，还算比较靠谱。\n还会自动添加到日程里，每天到点了来给你提醒。\n这个功能相当不错，每次你跟它的对话，还会在过程中，不断的修改\n但是，有个很遗憾的点。\n它只能在你开着扣子的网页时，才能弹通知给你，扣子的APP端还不支持。\n毕竟，手机端的提醒才是真提醒，网页端的\u0026hellip;主要是很少能有人长时间的开着网页。。。\n不过感觉扣子的APP端应该也会很快就支持，毕竟这是个刚需，在手机上使用长期计划，真的就非常非常的丝滑了。\n接下来就看扣子怎么把Skill联动、App端通知这些关键短板补上了。\n等这些补齐，普通用户能用上的AI助手。\n那就是，真正的AI助手了。\n以上，既然看到这里了，如果觉得不错，随手点个赞、在看、转发三连吧，如果想第一时间收到推送，也可以给我个星标⭐～谢谢你看我的文章，我们，下次再见。\n\u0026gt;/ 作者：卡兹克\n\u0026gt;/ 投稿或爆料，请联系邮箱：wzglyay@virxact.com\n","date":"20 January 2026","externalUrl":null,"permalink":"/posts/%E7%81%AB%E7%88%86%E5%85%A8%E7%BD%91%E7%9A%84skills%E7%BB%88%E4%BA%8E%E6%9C%89%E4%BA%86%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E6%89%93%E5%BC%80%E6%96%B9%E5%BC%8F/","section":"AI-Related Reposts","summary":"","title":"[Repost] 火爆全网的Skills，终于有了最简单的打开方式。","type":"posts"},{"content":"Reposted from 谷歌最新预测：2026，普通人工作方式将彻底改变 by 笔记侠\n商业趋势\n笔记君说：\n你有没有过这种体验？\n写周报时，翻遍五六个系统扒数据；跟客户沟通时，反复解释同一个问题；处理工作流程时，卡在跨部门对接的环节动弹不得……我们总说AI能提高效率，但以前的AI，更像个“问答机器”——你问它才答，你不说它就躺平。\n但Google Cloud刚出的《AI智能体趋势2026》报告说，2026年这一切要变了。AI会从“只会回答问题的工具”，变成能听懂目标、拆任务、跨系统自己干活的“得力帮手”（也就是报告里说的AI智能体）。\n这不是遥远的畅想，而是已经在发生的现实。今天就跟你掰开揉碎了聊：这波AI变革到底会怎么改咱们的工作，普通人该怎么抓住机会？\n一、核心转变：\n从“人亲自干活”，到“人管AI干活”\n这波AI变革最核心的变化，不是“干活更快了”，而是“干活的方式变了”。\n以前咱们谈AI，总说“帮人把事做快”——比如AI帮你写初稿、算数据，最后还是得你逐字改、逐题核对。\n但2026年的AI智能体，厉害在“能自主搞定一整套事”：你只要告诉它“要达成什么目标”，它会自己拆分成小任务，调用公司的各种系统，一步步推进，最后给你一个结果。\n随之而来的，是咱们的角色大变身：从“亲自执行的打工人”，变成“指挥AI的管理者”。\n打个比方，以前做市场经理，得自己写文案、找数据、盯竞品、做报告，一天忙得脚不沾地。2026年，你手下会有五个“AI专属助理”：\n数据助理：扒遍公司内外的结构化数据，找出市场趋势；\n分析助理：24小时盯竞品动态、社交媒体口碑，每天给你发一页核心洞察；\n内容助理：按公司的品牌语气，写好社交媒体文案和博客初稿；\n创意助理：给文案配图片、剪视频；\n报告助理：每周自动拉取campaign数据，生成分析总结。\n你要做的，不是自己写文案、找数据，而是：告诉它们这周的核心目标（比如“推广新产品，吸引年轻用户”），给点策略指引（比如“重点突出性价比”），最后检查一下结果有没有问题，拍板定夺就行。\n说白了，AI把重复、繁琐的执行活全包了，咱们只需要聚焦“定方向、做判断、把关结果”。\n而且这不是空想。数据显示，现在已经有52%的公司，把AI智能体用在了生产环境里：客户服务、市场运营、技术支持、产品创新，到处都有它们的身影。\n比如全球最大的纸浆制造商Suzano，用AI智能体把员工的自然语言（比如“查一下某类物料的库存”）变成系统能识别的查询指令，5万名员工查数据的时间直接减少95%；电信公司TELUS更狠，5.7万名员工日常用AI，平均每次交互能省40分钟。\n二、五大趋势：\n未来，AI智能体将渗透到工作的方方面面\n如果说核心转变是“道”，那这五大趋势就是“术”。我们来看看这些AI帮手会出现在哪些场景，怎么改变咱们的工作和生活。\n1.每个员工都有“专属AI助理”：个人能力直接翻倍\n以前的AI工具，要么是公司统一配的“大杂烩”，要么得自己找插件拼凑，用起来特别别扭。未来，每个员工都会有“量身定制”的AI助理。\n这个助理懂公司的业务语境：能访问内部知识库、客户数据、历史工作成果，不会像通用AI那样“说外行话”；它还能跟你配合默契：你把重复的活（比如整理会议纪要、跟进待办事项、初步筛选邮件）交给它，自己专注于创新、谈判、战略思考这些“高价值活”。\n这里要澄清一个误区：不是有了AI助理，你就没主动权了。它更像一个“超级执行者”，在你的指导和监督下干活，比如写合同，AI可以初稿，但最终的风险把控、条款谈判，还是得你上。\n就像媒体行业，AI能帮你整理海量素材，但讲什么故事、怎么讲得动人，还是得靠人的创造力。\n2.公司流程变成“数字流水线”：从头到尾自动跑\n如果说每个员工的AI助理是“单兵作战”，那公司核心流程的AI智能体系统，就是“团队协作”。\n以前公司的流程，比如采购、客户支持、安全运营，都是“人对接系统、人对接人”，中间容易卡壳：比如网络出问题，得先让技术部门检测，再让售后通知客户，流程走下来大半天。未来，AI智能体系统会把这些环节串起来：\n发现网络异常后，AI先自动尝试修复；修复不了，自动在现场服务系统创建工单；同时同步给客户联络中心，告知客户情况——整个过程跨系统、跨部门，不用人手动干预，人类只需要在关键节点监督、拍板。\n要实现这种“流水线”，靠的是两个关键技术：\nA2A协议：相当于AI之间的“普通话”，不同开发者、不同框架的AI能互相沟通协作；\nMCP协议：相当于AI和公司系统的“数据线”，能让AI安全访问实时数据（比如库存、订单、客户信息），而不是靠“过时的知识库”干活。\n比如动物保健公司Elanco，用AI智能体处理每个生产基地2500多份非结构化文件（比如政策、流程文档），自动分类、提取关键信息、排查冲突，避免了因为信息过期或冲突导致的生产力损失——以前这种损失在大型基地可能高达130万美元。\n3.客户服务从“被动响应”到“主动服务”：像有了“私人管家”\n你有没有吐槽过传统客服？重复说问题说三遍，转人工要等半天，最后还没解决。这就是“规则型自动化”的局限，只能机械响应，不会灵活处理。\n未来的客户服务AI智能体，会变成你的“私人管家”。\n它能记住你的历史信息：你上周买了件蓝色毛衣，今天打电话，它一接就知道“你可能是要退换货”；它还能主动解决问题：物流延误了，不等你投诉，它已经查到是配送车坏了，自动安排明天最早配送，还给你充了10美元补偿，发短信跟你确认时间。\n数据显示，现在已经有49%的公司把AI智能体用在客户服务上，这是最成熟的落地场景之一。\n比如家居建材品牌家得宝（Home Depot），做了个叫Magic Apron的AI智能体，24小时在线给客户提供装修指导：怎么装柜子、选哪种油漆、看产品口碑，就像身边有个装修老师傅，随叫随到。\n而且这种“管家式服务”不局限于消费端。比如工厂里，AI智能体能分析生产数据，发现某个班次效率低，会主动给出建议：“可以调整设备参数，或者给员工做个专项培训”，相当于给管理者配了个“生产顾问”。\n4.安全防护：从“喊警报”到“自动灭火”\n现在的公司安全部门，最头疼的是“告警疲劳”：每天收到成千上万个安全告警，分析师根本看不过来，很可能漏掉真正的威胁。就像家里装了100个烟雾报警器，天天响，真着火了反而没反应。\n**未来的安全AI智能体，会从“只喊警报”变成“主动灭火”。**它能自动分流告警（哪些是误报，哪些是真威胁），调查分析（威胁来自哪里，影响多大），甚至在授权范围内直接采取行动（比如拦截恶意攻击、修复漏洞）。\n比如cybersecurity公司Specular，用AI智能体自动化攻击面管理和渗透测试，帮企业快速找到安全漏洞；另一家公司Torq的AI安全分析师Socrates，能自动完成90%的一级分析任务，人工操作减少95%，响应速度快了10倍——安全人员不用再埋头处理重复告警，能专注于设计防御架构、猎捕高级威胁。\n5.能不能规模化赚钱，看员工会不会“管AI”\n最后这个趋势，是所有变化的关键：AI智能体能不能给公司带来持续价值，核心不是买了多少技术，而是员工会不会用。\n现在专业技能的“半衰期”越来越短，技术领域可能只有2年。也就是说，你现在学的技能，2年后可能就过时了。而AI的普及，会让“会不会管AI”变成职场的核心竞争力。\n但现在有个落差：84%的员工希望公司多提供AI学习资源，但只有29%的员工觉得公司在积极推动AI应用。而且“AI管家”“AI编排者”这种新角色，市场上根本招不到现成的人，只能靠公司内部培养。\n怎么培养？报告里给了一套实用方法，核心是五个支柱：\n1.定目标：比如“让100%员工在工作中用AI”，而且要可衡量；\n2.找支持：组建“高管赞助人（给钱给资源）+推动者（鼓动员工参与）+技术专家（落地解决方案）”的团队；\n3.造氛围：搞游戏化交流、案例分享，奖励创新用法；\n4.融日常：把AI融入工作流，比如办内部黑客松、实践挑战，让员工在干活中学习；\n5.守规则：明确哪些数据能给AI用，怎么识别AI相关的安全威胁。\n比如电信公司TELUS和Google合作搞了AI技能培训，结果96%的员工说用AI的信心提升了，员工会用AI了，公司的效率和创新力自然上来了。\n三、AI时代，这五种人很难替代\n聊完了AI智能体的趋势，咱们回到最实际的问题：既然AI能帮着干活、跑流程，那普通人怎么才能不被替代？\n答案很简单：**AI越能干，就越需要有人“管着它、盯着它、落地它、担着它”。**未来3-5年是AI缓冲期，咱们只要找准自己的位置，就能在变革中站稳脚。总结下来，有五种角色永远稀缺：\n1.决策者：给AI定方向的“指挥官”\nAI再厉害，也得有人告诉它“要做什么、为什么做”。就像前面说的市场经理，AI助理团队再能打，也得靠你定核心目标——是推广新产品还是维护老客户，是突出性价比还是强调品牌感。\n以前咱们做执行，满足于“按流程干完”就行；现在得主动思考“为什么要做这件事”“要达成什么结果”。\n比如用AI写方案，不能只说“帮我写个推广方案”，而要明确“针对25-30岁职场人，推广一款通勤背包，核心卖点是轻便防水，预算5万，要包含社交媒体和线下快闪活动”——这样AI才能精准发力。\n说白了，决策者的核心价值是“定战略、掌方向”，这是AI学不会的。它能执行，但没法判断“这件事该不该做”“这么做对公司长期有没有好处”。\n2.提问者：能问对问题的“掌舵人”\n如果暂时做不到决策者的高度，那从“会提问”开始也完全可以。提问的水平，直接决定了AI的输出质量。\n很多人用AI之所以没效果，就是提问太随意。\n比如想让AI生成配图，只说“给我一张漂亮的图”，结果全看运气；但如果你说“我想表达‘异乡人思念家乡’，要用温暖的水彩风格，画面里要有老房子、路灯、飘着的炊烟，能不能给我三个构图建议并简单解释”，得到的结果大概率就是你想要的。\n提问的关键，是先想清楚自己的目标，再把目标拆成具体的问题。职场里常说“会提问的人，思考一定不差”，AI时代更是如此——你能问出精准的问题，就意味着你已经想透了事情的关键。\n3.看门人：给AI把关的“质检员”\n现阶段的AI还有个小毛病：偶尔会“胡说八道”（也就是常说的“AI幻觉”），比如给你编一个不存在的数据，或者生成不符合公司规范的内容。这时候就需要“看门人”——用自己的专业经验，判断AI的输出是不是靠谱。\n比如Elanco用AI处理生产文件，AI能自动分类、提取信息，但最终还是需要熟悉生产流程的员工把关：“这个条款是不是和最新政策冲突？这个数据是不是准确？”；再比如用AI写合同，AI能搭框架，但涉及法律风险、核心权益的条款，还得靠法务人员审核。\n看门人不用学新技能，只要你在自己的领域里够专业、够细心，就能胜任。毕竟AI谈论你不熟悉的领域时，你可能觉得它无所不知，但一碰到你的专业，它有没有胡说，你一眼就能看出来。\n4.执行者：连接虚拟与现实的“实干家”\n你可能会想：“执行的活不都被AI抢了吗？”其实不然，AI能在电脑里跑流程、做分析，但最终还是要有人把事情落到现实里。\n比如物流智能体能安排好配送路线，但包裹还是得靠快递员送到你手上；AI能给出工厂设备的调整建议，但最终还是得靠技术人员去操作；AI能生成装修方案，但敲墙、刷漆、装柜子，还是得靠工人师傅来干。\n虚拟世界的决策，永远需要现实世界的人来落地。而且现在很多公司看似人多，但真正脚踏实地干活的执行者并不多，只要你靠谱、敏捷，能把AI的计划变成实实在在的结果，就永远有你的位置。\n5.责任人：为结果兜底的“担当者”\nAI是工具，没有办法承担责任。比如AI推荐的营销方案出了问题，损失谁来担？AI处理客户数据时泄露了隐私，责任谁来负？这时候就需要“责任人”——对最终结果负责，出了问题敢担当、能解决。\n未来，“谁来担责”会成为AI时代的核心议题。比如合规智能体自动更新了工作流，但如果不符合监管要求，还是得有人站出来调整、承担后果；客户服务AI出了错，还是得有人主动联系客户道歉、弥补。\n无论你是决策者、提问者，还是看门人、执行者，最终都得是责任人。毕竟AI可以帮你干活，但没法替你担责——而“敢担当、能扛事”，永远是职场最稀缺的品质。\n结语：\n2026年的机会，本质是“人的解放”\n聊了这么多，你可能会问：AI这么厉害，会不会取代人？\n答案是：不会取代人，但会取代“只会执行的人”。\nAI智能体不是抢工作，而是把我们从重复、繁琐、耗精力的低价值工作中解放出来，让你专注于只有人能做的事：创造性的思考、战略性的决策、有同理心的沟通。\n这波变革的学习曲线可能有点陡，但机会属于那些“现在就开始行动”的人：今天学着跟AI配合，学着定方向、提对问题、把好关、落好地、担好责，明天你就是职场里的“稀缺人才”，而不是被淘汰的“执行者”。\n说到底，2026年的AI变革，看起来是技术的升级，本质是“人的升级”。它让企业变得更快、更智能，也让每个人都有机会发挥自己的天赋和创造力。\n未来决定现在。看清未来将发生什么，才能真正明白当下应该做什么。\n我们认为，未来由四个关键领域塑造：哲学、AI科技、经济与政治。\n为什么是这四个？\n哲学是元起点，是意义与方向的锚点，为一切行动提供终极燃料；\n科技（尤其是AI）是文明进步的底座，是驱动世界向前的“发动机”；\n经济是转化器，它把科技力量转化为真实的财富与市场机会；\n政治是适配性结构，它给哲学、科技与经济提供运行框架与秩序。\n哲学为根，科技为器，经济为用，政治为治。这四者环环相扣，层层支撑，相互交织，在动态的演进中共同推动现实走向未来。\n正是在这样的时代背景下，笔记侠创立了中国首个面向企业家的PPE（政治、经济、哲学）书院。\n我们致力于帮助大家回到决策的源头，重构底层认知逻辑，掌握未来五年的核心判断与决策能力。\n**如今，众多深耕于AI、全球化等前沿领域的优秀创业者，都已加入笔记侠PPE书院。\n**\n未来已来，让我们一起成为清醒而笃定的决策者。\n欢迎你扫描下方海报二维码，咨询课程详情。\n您也可以点击“阅读原文”，填写笔记侠PPE课程26级报名表并咨询详情。\n参考资料： 1.《重磅｜谷歌2026AI趋势报告(下)：技术之外，人是决定性力量》，AI组织进化论；\n2.《重磅｜谷歌2026AI趋势报告(上)：当智能体全面进入工作，价值链、流程、职责与能力会有哪些变化?》，AI组织进化论；\n3.《AI时代，留给普通人的五个位置》，罗辑思维。\n好文阅读推荐：\n何帆开年演讲：这，是年轻人的红利！\n下一个10年，商业的底层逻辑变了！\n**“子弹笔记”**是笔记侠的矩阵公众号，聚焦职场效率追求、人际关系与高潜成长者，帮你3分钟吃透核心观点和方法论。欢迎关注～\n分享、点赞、在看，3连3连！ ","date":"20 January 2026","externalUrl":null,"permalink":"/posts/%E8%B0%B7%E6%AD%8C%E6%9C%80%E6%96%B0%E9%A2%84%E6%B5%8B2026%E6%99%AE%E9%80%9A%E4%BA%BA%E5%B7%A5%E4%BD%9C%E6%96%B9%E5%BC%8F%E5%B0%86%E5%BD%BB%E5%BA%95%E6%94%B9%E5%8F%98/","section":"AI-Related Reposts","summary":"","title":"[Repost] 谷歌最新预测：2026，普通人工作方式将彻底改变","type":"posts"},{"content":"Reposted from 2026 最新Claude Skill 仓库合集 by 吴哥AI实操笔记\n大家好，我是吴哥，专注AI编程、AI智能体。立志持续输出、帮助小白轻松上手AI编程和AI智能体。\n2026年了，吴哥汇总了最新仓库合集。\n本文重点内容：用一张对比表带你选对最热 Skill 仓库、搞清 Skills vs Prompt vs MCP，并在 10 分钟内装好一套“能持续复用”的技能栈。建议看完就去做：先装 3 个，再写 1 个自己的。\n阅读信息：预计 8 分钟｜适用人群：小白/进阶 记住，别再把“会写提示词”当能力，把“能复用流程”才叫落地，真实力。\n核心问题清单 # Q1：Skills 到底是什么？和 Prompt、MCP 有什么本质区别？\nQ2：这么多仓库，谁是“生产级样板”，谁是“百科导航”，谁是“黑马能力”？\nQ3：怎么避免“装得越多越卡”？怎么管理版本、审计风险、持续升级？\n先搞清“选型逻辑”，再谈“装哪些仓库”。\n工具卡 # anthropics/skills（官方示范库）\n用途：直接提供一批可运行的 Skills（文档处理、测试、工作流等），也是“Skills 应该怎么写”的参考实现。\n适合：第一次入坑、想要“拿来就能跑”的人；也适合作为团队内 Skill 编写规范的模板。\nComposioHQ/awesome-claude-skills（高密度导航/分类）\n用途：把大量技能按场景分类，提供“从需求到技能”的检索入口（你不需要自己在 GitHub 大海捞针）。\n适合：已经知道自己要做什么（如：代码审查、TDD、文档流水线），需要快速选技能的进阶用户。\nagentskills/agentskills（开放标准/规范与SDK）\n用途：当你想让技能“写一次，多处可用”（Claude / Copilot / VS Code 等），这里是规范与参考 SDK 的总开关。\n适合：团队/组织要落地；你不想被单一平台锁死。\n官方库教你“怎么做对”，导航库帮你“选得更快”，标准库保证你“走得更远”。\n底层逻辑： # 判断：Skills 解决的不是“模型会不会写代码”，而是“你的流程能不能被稳定复用”。\n证据：Anthropic 明确把 Skills 定义为“文件夹化的指令/脚本/资源”，并强调三层渐进式加载：先加载元数据、触发后加载指令、必要时再加载附加文件；这样你可以装很多技能而不一次性挤爆上下文。\n启示：很多人说“AI 编程不落地”，其实是把问题当成“换个更强模型”——但真正的瓶颈是缺少可复用的工程做法（测试、评审、发布、规范、回滚、文档）。Skills 让这些做法变成“随用随取”的技能卡片。\n建议：先用官方技能跑通一个闭环，再把你自己的团队流程固化成 1 个 Skill。\n2026 热门仓库对比表 # 仓库 星标 核心价值 最适合谁 一句话评价 anthropics/skills 44.2k 官方“生产级示范 + 可直接用”的技能集 新手/团队起步 先抄作业 ，再改成你自己的流程 ComposioHQ/awesome-claude-skills 20.9k 高密度分类导航（选技能更快） 进阶/多场景 你不缺技能，你缺“目录” agentskills/agentskills 6.1k 开放标准 ：规范/文档/SDK 团队/平台化 写一次，多处跑，降低锁定 muratcankoylan/Agent-Skills-for-Context-Engineering 7.3k 上下文工程（诊断/优化/评估） 想把Agent做稳的人 不做上下文工程，Agent必然漂 heilcheng/awesome-agent-skills 1.4k 跨平台“技能/教程/工具”百科 想全景扫描 适合“逛”，别一口气全装 gotalab/skillport 229 技能管理/分发（CLI/MCP 思路） 多机器/多项目 管理一次，多处同步 kirodotdev/powers 137 为 Kiro 代理做的“按需加载能力包” Kiro 深度用户 解决“工具太多=上下文过载” K-Dense-AI/claude-scientific-skills 6.4k 科学/数值/数据/ML 向技能集合 科研/量化/工程分析 技能栈一旦专业化，效率会断层领先 三个最常见误区（以及怎么避免） # 误区：装得越多越强纠正：Skills 的设计原则就是“渐进式披露”，理论上你可以装很多，但前提是只在需要时触发加载；否则你会把上下文浪费在“用不到的说明书”上。\n误区：Skills = Prompt 模板纠正：Prompt 更像一次性对话指令；Skills 是“文件系统里的可组合资源”（说明 + 脚本 + 模板），可以被多个工具重复触发。\n误区：只看星标不看风险纠正：官方工程博客直接提醒“恶意 skills 风险”，尤其是带脚本/依赖/外联指令的技能，装之前要审计。\n10 分钟安装：一条命令把技能放到正确位置 # 不同平台的“技能目录”略有差异，但核心就两类：项目级（跟仓库走）与 个人级（跟你走）。GitHub Copilot 的文档把这两类路径讲得很清楚（例如 .claude/skills、.github/skills、~/.claude/skills 等）。\n最通用的做法（个人级）：\nmkdir -p ~/.claude/skills git clone \u0026lt;你选中的技能仓库\u0026gt; ~/.claude/skills/\u0026lt;repo-name\u0026gt; （路径与“Skill 是文件夹 + SKILL.md”这一结构保持一致即可。\n如果你懒得手动装，社区也在做“统一安装器”方向（例如 OpenSkills 的 npx 工具），适合“先跑起来再说”的人。\n可复制提示词：让 AI 帮你“选 3 个技能 + 组 1 条工作流” # Prompt：技能选型（从仓库到清单）\n你是我的“Agent Skills 选型顾问”。我的场景是：【在这里写你的场景】。 目标：用最少技能跑通一个可复用闭环（10-30分钟内可验证）。 请输出： 1) 我应该优先选的 3 个仓库（说明理由：生产级/导航/标准/管理各取其一） 2) 每个仓库里我应该先装的 2-3 个技能（写出用途/触发关键词/预期产出） 3) 一个最短工作流：输入 -\u0026gt; 过程 -\u0026gt; 输出（含验证点） 约束：不要推荐“装很多”，只给能立刻用的最小集合。 Prompt：把你的团队流程固化成第一个 SKILL.md\n你是“Skill 作者”。我要把下面流程固化成一个 Skill： 流程名称：【例如：PR 代码评审+单测补齐+变更说明】 输入信息：【仓库结构/语言/测试框架/规范链接或片段】 输出要求：【产物格式：Checklist、PR 模板、命令、报告结构】 请生成： 1) SKILL.md 的 YAML frontmatter（name/description） 2) SKILL.md 主体：分步骤、含检查点、含失败回滚策略 3) 可选：建议我拆分成哪些附加文件（比如 reference.md / checklist.md） 这套结构正是官方“SKILL.md + 元数据 + 渐进加载”的推荐方式。\n合集清单：\n\\[1\\]: https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview \u0026ldquo;Agent Skills - Claude Docs\u0026rdquo; 备注：官方文档｜解释 Skills 是什么、基本概念与使用方式｜适合作为“定义/规则/术语”权威出处（非开源仓库）\n\\[2\\]: https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills \u0026ldquo;Equipping agents for the real world with Agent Skills \\ Anthropic\u0026rdquo; 备注：官方工程博客｜讲清“为什么要 Skills（渐进式披露/可治理）”的设计动机与方法论｜适合引用做“趋势与原理”（非开源仓库）\n\\[3\\]: https://github.com/anthropics/skills \u0026ldquo;GitHub - anthropics/skills: Public repository for Agent Skills\u0026rdquo; 备注：开源仓库（官方精选）｜生产级 Skills 示例与最佳实践｜新手抄作业/团队定规范首选\n\\[4\\]: https://github.com/anthropics/skills?utm_source=chatgpt.com \u0026ldquo;anthropics/skills: Public repository for Agent Skills\u0026rdquo; 备注：同 \\[3\\]（带参数链接）｜建议正文引用时统一用 \\[3\\]，避免“带追踪参数”\n\\[5\\]: https://github.com/ComposioHQ/awesome-claude-skills \u0026ldquo;GitHub - ComposioHQ/awesome-claude-skills: A curated list of awesome Claude Skills, resources, and tools for customizing Claude AI workflows\u0026rdquo; 备注：开源仓库（Awesome 导航）｜分类清晰、覆盖面广｜你知道要做什么时，用它快速“找技能/找资源”\n\\[6\\]: https://github.com/agentskills?utm_source=chatgpt.com \u0026ldquo;Agent Skills\u0026rdquo; 备注：GitHub 组织主页｜聚合标准/生态相关仓库入口｜适合做“生态\n\\[7\\]: https://github.com/ComposioHQ/awesome-claude-skills/activity \u0026ldquo;Activity · ComposioHQ/awesome-claude-skills · GitHub\u0026rdquo; 备注：活动页（更新强度）｜看维护是否活跃、近期提交频率｜写“热门/持续更新”时可用作旁证\n\\[8\\]: https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering/activity \u0026ldquo;Activity · muratcankoylan/Agent-Skills-for-Context-Engineering · GitHub\u0026rdquo; 备注：活动页（黑马仓库更新强度）｜用于判断作者是否持续迭代｜建议配合主仓库页一起引用\n\\[9\\]: https://github.com/heilcheng/awesome-agent-skills \u0026ldquo;GitHub - heilcheng/awesome-agent-skills: A curated list of skills, tools, tutorials, and capabilities for AI coding agents (Claude, Codex, Copilot, VS Code)\u0026rdquo; 备注：开源仓库（跨平台 Awesome）｜覆盖 Claude/Codex/Copilot/VS Code 等｜适合做“全景扫描”，不建议一口气全装\n\\[10\\]: https://github.com/gotalab/skillport \u0026ldquo;GitHub - gotalab/skillport: Bring Agent Skills to Any AI Agent and Coding Agent — via CLI or MCP. Manage once, serve anywhere.\u0026rdquo;\n备注：开源仓库（技能管理/分发工具）｜更偏“管理器/同步器”，不是技能合集本体｜适合多项目、多机器统一管理\n\\[11\\]: https://kiro.dev/powers/ \u0026ldquo;Powers - Kiro\u0026rdquo; 备注：产品能力页｜Kiro 的 Powers（类 Skills 能力包）说明与用法｜适合对比“Claude Skills vs Kiro Powers”（非开源仓库）\n\\[12\\]: https://github.com/K-Dense-AI/claude-scientific-skills/blob/main/docs/open-source-sponsors.md \u0026ldquo;claude-scientific-skills/docs/open-source-sponsors.md at main · K-Dense-AI/claude-scientific-skills · GitHub\u0026rdquo; 备注：开源仓库内文档页｜赞助/开源声明等信息入口｜若要介绍科学技能集，\n\\[13\\]: https://docs.github.com/copilot/concepts/agents/about-agent-skills \u0026ldquo;About Agent Skills - GitHub Docs\u0026rdquo; 备注：官方文档（GitHub Copilot Agents）｜从 Copilot 视角解释 Agent Skills｜用于论证“Skills 跨平台落地”（非开源仓库）\n\\[14\\]: https://github.com/numman-ali/openskills?utm_source=chatgpt.com \u0026ldquo;numman-ali/openskills: Universal skills loader for AI coding \u0026hellip;\u0026rdquo; 备注：开源仓库（通用 Skills Loader）｜偏“加载器/运行时”，解决不同平台/目录结构的兼容问题｜适合工程化落地与自动安装脚本化\n这是今天分享内容，希望整理内容对你有所帮助，感谢阅读。\n如果你对AI编程感兴趣，欢迎交流，进群领取吴哥AI编程手册详细资料福利(PS:群已超200人）。要是觉得今天这碗饭喂得够香，随手点个赞、在看、转发三连吧！\n","date":"18 January 2026","externalUrl":null,"permalink":"/posts/2026-%E6%9C%80%E6%96%B0claude-skill-%E4%BB%93%E5%BA%93%E5%90%88%E9%9B%86/","section":"AI-Related Reposts","summary":"","title":"[Repost] 2026 最新Claude Skill 仓库合集","type":"posts"},{"content":"Reposted from OpenSpec 功能详解：5 分钟搞懂 AI 编程的\u0026quot;规范驱动\u0026quot;核心 by 贾克斯的平行世界\n贾克斯\n读完需要\n5\n分钟\n速读仅需 3 分钟\n1\n为什么有时候让 AI 发起提案\u0026quot;时灵时不灵\u0026quot;？\n前两天有朋友看了我写的《如何用 AI + OpenSpec 驱动团队迭代开发》后，问我一个很有趣的问题：\n\u0026ldquo;为什么有时候我让 AI 发起 OpenSpec 提案，时灵时不灵？\u0026rdquo;\n其实这个问题很简单，答案就藏在 OpenSpec 的工作原理中。\n今天这篇文章，5 分钟的时间帮你快速了解 OpenSpec 的核心原理——它究竟是如何让 AI\u0026quot;听话\u0026quot;地按照规范来工作的。\n2\n快速认识 OpenSpec\nOpenSpec 是一个规范驱动开发工具，核心理念极其简单：\n“让 AI 明确知道\u0026quot;知识在哪、如何用、为什么这样做”\n官网：https://openspec.dev/\n2.1\n安装与初始化\n# 全局安装 OpenSpec 初始化时，OpenSpec 会提示你选择使用的 AI 工具（Claude Code、Cursor、Trae、Qoder 等）。\n3\nOpenSpec 如何\u0026quot;教\u0026quot;AI 工作？\nOpenSpec 的核心机制，是通过一套规范注入系统，让 AI 在每次对话前先\u0026quot;学习\u0026quot;项目规范。\n3.1\n不同 AI 工具的初始化差异\n根据你使用的 AI 工具不同，OpenSpec 会生成不同的目录结构。这背后的设计理念是：最大限度地适配各工具的特性。\n3.2\n📍 场景 1：Claude Code\nClaude Code 在执行了 OpenSpec Init 后的目录结构如下：\n.claude/ commands/openspec 这个目录定义了三个不同的命令，每个命令文件中所写的提示词，都是 AI 在执行该命令时需要参考的\u0026quot;规范\u0026quot;。上述三个命令分别是：\napply.md：表示执行已批准的变更\narchive.md：归档已完成的变更\nproposal.md：发起新变更提案\n当我们需要发起新的提案时，可以直接使用：/openspec:proposal 就可以触发该指令，此时 AI 就会根据 proposal.md 中所定义的规范，来创建一个新的变更提案。\n核心文件解读：AGENTS.md\n这个文件是 Claude Code 每次对话时的\u0026quot;第一课\u0026quot;，内容如下：\n\u0026lt;!-- OPENSPEC:START --\u0026gt; 工作原理：\nClaude Code 启动时自动读取 AGENTS.md\n判断用户请求是否触\u0026quot;提案/变更\u0026quot;等关键词\n如果触发，自动加载 openspec/AGENTS.md 中的详细规范\nAI 按照规范执行任务\n3.3\n📍 场景 2：Trae（字节跳动）\nOpenSpec 在初始化时可选择的AI 工具中是不支持 Trae 的，但是很多朋友是基于 Trae 在开发。\n所以对于使用 Trae 的朋友，我们在执行 OpenSpec Init 的时候，可以选择最后一个选项 Other Tools (适用于 VsCode 等）\n此时初始化后的目录结构如下：\n项目根目录/ 关键差异：需要手动配置\n与 Claude Code 不同，老版本的 Trae 不会自动读取 AGENT.md。此时你需要手动将规范内容添加到 Trae 的\u0026quot;项目规则\u0026quot;中。\n但是对于Trae 2026 年 1 月份最新的一次版本变更中，也已经兼容了读取 AGENT.md 文件作为项目规则来使用。\n所以使用老版本 Trae 的朋友需要基于下述步骤进行配置：\n打开 Trae 的项目设置\n找到\u0026quot;项目规则\u0026quot;配置\n将 AGENT.md 的内容粘贴进去\n保存后，Trae 每次对话都会加载该规则\n配置完成后，Trae 的工作流程与 Claude Code 类似：\n每次对话自动加载项目规则\n判断是否触发 OpenSpec 规范\n根据规范执行对应任务\n3\nOpenSpec 规范核心要点\n无论使用哪种 AI 工具，OpenSpec 的核心工作流都是一致的。理解这套规范，你就能更好地与 AI 协作。\n三阶段工作流：\n阶段1：创建变更（Proposal） 何时必须创建提案？\n场景 是否需要提案 新增功能或能力 ✅ 必须 破坏性变更（API/Schema） ✅ 必须 架构或模式调整 ✅ 必须 Bug 修复（恢复既有行为） ❌ 跳过 拼写、格式、注释修正 ❌ 跳过 非破坏性依赖升级 ❌ 跳过 常用命令：\nopenspec list # 列出所有变更 💡 小贴士：作为人类开发者，你无需记忆这些命令。AI 会自动执行相应的操作来检查和管理变更提案。你只需要理解这套规范的工作流程，就能与 AI 配合无间。\nopenspec/project.md 的作用\n这个文件是项目的\u0026quot;知识库\u0026quot;，用于存放：\n项目目标和背景\n核心业务术语\n技术栈说明\n详细文档索引\n4\n常见问题解答\n4.1\nQ1：为什么有时候 AI 不触发 OpenSpec 规范？\nA：这通常是因为触发条件未被满足。\nOpenSpec 的触发机制基于关键词匹配（如\u0026quot;提案\u0026quot;、\u0026ldquo;变更\u0026rdquo;、\u0026ldquo;规范\u0026quot;等）。如果你的请求不包含这些关键词，AI 则不会加载 OpenSpec 规范。\n解决方案：\n明确使用触发词：\u0026ldquo;帮我创建一个变更提案\u0026rdquo;\n直接指定文件：\u0026ldquo;先阅读 openspec/project.md 再回答\u0026rdquo;\n使用斜杠命令：/openspec:proposal（如果工具支持）\n5.2\nQ2：project.md 中的业务知识什么时候生效？\nA：只有触发 OpenSpec 规范后才会读取。\n这是一个重要的设计权衡：\n知识类型 存放位置 触发条件 通用开发规范 /AGENTS.md 每次对话自动加载 OpenSpec 工作流 openspec/AGENTS.md 触发关键词后加载 业务上下文 openspec/project.md 通过规范索引间接加载 实践建议：\n将通用规则（如项目结构、编码风格）放在 /AGENTS.md 中\n将业务知识索引也写在 /AGENTS.md 中，便于日常对话触发\n或者在对话中明确要求 AI 先阅读特定文档\n5.3\nQ3：如何让 AI 自动检索相关背景知识？\nA：这是 OpenSpec 的进化方向。\n目前最佳实践是：\n在 /AGENTS.md 中建立业务知识索引\n采用提案方式讨论业务逻辑（自动触发规范）\n对话中明确指定：\u0026ldquo;先阅读 docs/xxx.md 再回答\u0026rdquo;\n6\n五、总结：OpenSpec 的核心价值\n回到开篇的问题：为什么有时候让 AI 发起提案\u0026quot;时灵时不灵\u0026rdquo;？\n答案现在很清楚了：\n触发机制：AI 需要识别到特定关键词才会加载 OpenSpec 规范\n工具差异：不同 AI 工具对规范文件的支持程度不同\n知识分层：业务知识与开发规范需要合理分层存放\nOpenSpec 的核心价值在于：通过\u0026quot;规范注入\u0026quot;让 AI 从\u0026quot;项目小白\u0026quot;成长为\u0026quot;熟悉业务的开发伙伴\u0026quot;。\n它不是银弹，但当你理解了它的工作原理后，就能让 AI 在团队协作中发挥真正的作用。\n当然，在有需要的时候，我们也可以修改 OpenSpec 初始化时所生成的一系列.md文件，直接变更规范，使其更加符合企业内的业务流程。\n欢迎日常交流 # AI 驱动团队开发是这个时代的新命题，欢迎大家加微信互相交流心得。\n👉 想要进群的朋友，扫码时备注 “AI实验群”，看到消息后会第一时间拉你进群。\n群定位：AI工具提效/实战经验互助\n群规则：不水群、不广告、干货优先\n好文章值得被更多人看见！既然看到这里了，随手点个赞👍和关注，并转发给更多的朋友吧！感谢。\n\u0026gt; 作者：数字生命贾克斯、微信：x_h886688\n","date":"18 January 2026","externalUrl":null,"permalink":"/posts/openspec-%E5%8A%9F%E8%83%BD%E8%AF%A6%E8%A7%A35-%E5%88%86%E9%92%9F%E6%90%9E%E6%87%82-ai-%E7%BC%96%E7%A8%8B%E7%9A%84%E8%A7%84%E8%8C%83%E9%A9%B1%E5%8A%A8%E6%A0%B8%E5%BF%83/","section":"AI-Related Reposts","summary":"","title":"[Repost] OpenSpec 功能详解：5 分钟搞懂 AI 编程的\"规范驱动\"核心","type":"posts"},{"content":"Reposted from Antigravity更新了Skill，Skill将是全网即将统一的核心功能！ by 老金带你玩AI\nAntigravity 更新 Skill几天了，老金刚有空写。\n老金可以趁机再给大家说一遍Skill是什么，它为什么受到全网推崇。\nClaude Code在25年的10月就发布了Agent Skills，并在2026年的1月，确立了“全 Skill 化”的架构，并开源其他任意平台可接入使用。\n它把扩展 AI 能力这件事，回归到了最本质、最极客的方式：文件即技能。\nSkills 是怎么个事儿？ # 别被名字唬住了。\nSkill 仅仅就是一个文件夹。\n对，你没听错。\n你想让 Agent 会写 Python？你就往项目里丢个 python_expert 文件夹。 你想让它会自动部署？丢个 auto_deploy 文件夹。 你想让它懂你们公司的代码规范？丢个 team_guidelines 文件夹。 Antigravity 会自动扫描这些文件夹，读取里面的\u0026quot;说明书\u0026quot; (SKILL.md)，然后瞬间\u0026quot;学会\u0026quot;这些技能。\n这就是 降维打击。以前我们要去某个\u0026quot;插件市场\u0026quot;搜半天，现在直接 Ctrl+C Ctrl+V 文件夹，技能就装好了。\n核心解密：完整的 Skill 文件夹结构 # 一个标准的 Skill 文件夹，结构清晰得让人感动。老金带你拆解一下：\n📂 my-custom-skill/ ├── 📄 SKILL.md # 必选：Skill 的“灵魂”。定义功能描述、触发场景及 Claude 的思考逻辑。 ├── 📄 config.json # 必选：安全性与元数据。定义权限边界（联网、读写）和版本信息。 ├── 📄 requirements.txt # 可选：Python 依赖定义（若有脚本，推荐包含以实现自动隔离安装）。 ├── 📄 package.json # 可选：Node.js 依赖定义（替代 requirements.txt）。 ├── 📄 reference.md # 可选：长文档。存储 API 字典或复杂规范，通过“渐进式披露”节省上下文。 ├── 📄 examples.md # 可选：少样本学习 (Few-shot)。提供最佳实践案例供 Claude 参考。 ├── 📂 scripts/ # 可选：可执行逻辑。存放 Python/Bash/JS 脚本，由 Claude 调度执行。 │ └── 🔧 main_logic.py ├── 📂 assets/ # 可选：静态资源。如预设的代码模板 (.txt)、提示词片段或测试数据。 ├── 📂 tests/ # 可选：质量保证。存放针对 scripts 的单元测试，确保 Skill 更新后依然稳健。 └── 📄 .clauderules # 可选：局部约束。定义在此 Skill 激活时 Claude 必须遵守的特定行为准则。 1. 核心大脑：SKILL.md (必选) # 这是灵魂。只要这个文件存在，Agent 就知道自己会了啥。里面分两部分：\nYAML 头（元数据）：\n--- name:\u0026#34;code-security-audit\u0026#34; description:\u0026#34;用于扫描当前目录下的代码漏洞，建议在提交 PR 前使用\u0026#34; # 2026 规范：工具名建议使用小写 snake_case allowed-tools: [\u0026#34;ls\u0026#34;, \u0026#34;grep\u0026#34;, \u0026#34;read_file\u0026#34;, \u0026#34;view_code_definitions\u0026#34;] # 独立上下文运行，保护主对话的 Token 额度 context:\u0026#34;fork\u0026#34; # 定义此 Skill 归属于哪类 Agent（如编码、运维、测试） agent:\u0026#34;software-engineer\u0026#34; # 允许用户在终端输入 /code-security-audit 快速启动 user-invocable:true # 新增：定义此 Skill 的核心唤醒词 keywords: [\u0026#34;security\u0026#34;, \u0026#34;audit\u0026#34;, \u0026#34;vulnerability\u0026#34;] --- Markdown 正文（指令）：\n用人话写清楚怎么干 给具体示例和最佳实践 可以引用其他文件（通过链接） 2. 详细文档：reference.md (可选) # 把复杂的API说明、参数详解放这里。\nSKILL.md 里引用：\n## 详细说明 完整的API文档见 [reference.md](reference.md) 3. 使用示例：examples.md (可选) # 放几个真实例子，让 Agent 照着抄。\n4. 工具脚本：scripts/ (可选) # 关键特性：脚本不会加载到上下文，直接执行，只消耗输出结果的 token。\n适合放：\n复杂的验证逻辑 数据处理脚本 需要保持一致性的操作 在 SKILL.md 里告诉 Claude 执行脚本：\n运行验证脚本： ```bash python scripts/validate.py input.txt 如果对你有帮助，记得关注一波~\n手把手：3分钟搓一个\u0026quot;自动发布\u0026quot;技能 # 别光看，动手。假设我们要搞一个 一键发版 的技能。\n第一步：建房 # 在项目根目录（或者你习惯放文档的地方），建个文件夹 `publish_skill`。\n第二步：写说明书 (`SKILL.md`) # 直接新建 `publish_skill/SKILL.md`，把下面这段粘进去：\n--- name: auto-publish description: 当用户说\u0026#34;发布\u0026#34;、\u0026#34;上线\u0026#34;或\u0026#34;publish\u0026#34;时，使用此技能执行自动发布流程 allowed-tools: Bash, Read --- # 自动发布技能指南 看到用户想要发布，别废话，按这个流程走。 ## 1. 安全红线检查 (Critical) 在干活前，必须先检查 git 状态，确保没有未提交的更改。 ## 2. 执行发布脚本 环境干净的话，直接运行发布脚本。 ## 3. 汇报结果 把脚本输出的最后一行发给用户。 第三步：给它工具 (scripts/) # 在 publish_skill/scripts/ 里放个 do_publish.sh：\n#!/bin/bash set -e # 遇到错误立即退出 echo \u0026#34;🔄 正在打包...\u0026#34; # npm run build # npm run test echo \u0026#34;✅ 发布成功！版本号 v1.0.1\u0026#34; 记得给脚本加执行权限：\nchmod +x scripts/do_publish.sh 完事了。\n现在你回到对话框，跟 Antigravity 说：\u0026ldquo;帮我发布一下\u0026rdquo;。\n它会立刻读取那个 Markdown，先检查 Git，然后跑脚本。\n这一套行云流水，全是你定义的标准动作。\n为什么说这招\u0026quot;太狠了\u0026quot;？ # 1. 一键复用，秒杀配置 # 当你把团队的代码规范、发布流程、数据库查询方式，写成几个 Skill 文件夹。\n新人入职？\n直接把文件夹发给他。\n\u0026ldquo;把这个丢你项目里\u0026rdquo;。\n啪，他的 Agent 瞬间拥有了和你一样的经验和权限。\n这省的不是配置时间，是沟通成本啊！\n2. 透明，完全透明 # 没有任何黑盒逻辑。Agent 为什么这么做？\n去读 SKILL.md。Agent 这里做错了？去改 SKILL.md。\n你在调试 Agent，就像在调试代码一样可控。\n3. 社区即仓库 # 虽然官方没搞什么 App Store，但 GitHub 才是最大的 Store。\n以后肯定各种大佬开源自己的 Skill 文件夹：\n\u0026ldquo;老金的 React 调优技能包\u0026rdquo;\n\u0026ldquo;某大厂的 Go 语言最佳实践包\u0026rdquo;\n下载下来，丢进去，你的 AI 就升级了。\n⚠️ 老金的特别提醒：安全！安全！还是安全！\n虽然“Ctrl+C”装技能很爽，但老金必须多句嘴：技能文件夹里的 scripts/ 是有执行权限的。\n如果你从网上随便下个“大神包”，里面可能藏着删除数据库或者上传密钥的恶意脚本。\n在运行任何不明来源的 Skill 前，记得先扫一眼 config.json 里的权限声明，这是咱极客的基本操守。\n老金的最后建议 # 既然 Antigravity 给了这把\u0026quot;瑞士军刀\u0026quot;，咱们就别把它当普通水果刀用了。\n建议大家现在就做一件事：把你手头最重复、最繁琐的工作流，写成一个 SKILL.md。\n哪怕只是一个简单的 \u0026ldquo;Git 提交规范检查\u0026rdquo;，你会发现，让 AI 严格按文档干活的感觉，真的 太爽了。\n话不多说，建文件夹去了！\n往期推荐：\n提示词工工程（Prompt Engineering）\nLLMOPS(大语言模运维平台)\nWX机器人教程列表\nAI绘画教程列表\nAI编程教程列表\n","date":"17 January 2026","externalUrl":null,"permalink":"/posts/antigravity%E6%9B%B4%E6%96%B0%E4%BA%86skillskill%E5%B0%86%E6%98%AF%E5%85%A8%E7%BD%91%E5%8D%B3%E5%B0%86%E7%BB%9F%E4%B8%80%E7%9A%84%E6%A0%B8/","section":"AI-Related Reposts","summary":"","title":"[Repost] Antigravity更新了Skill，Skill将是全网即将统一的核心功能！","type":"posts"},{"content":"Reposted from Skills：Claude Code 官方 Skills 功能介绍和社区 skills 库 by 嘿哥的AI基地\n点击下方👇 嘿哥的AI基地 关注公众号\n一起探索AI的世界\nSkills 最近太火了，那Skills到底是什么呢？我们怎样才能使用Skills呢？\nSkills 是 模块化、可复用、可组合的AI能力单元 。每个Skill都设计用来完成一项特定的、相对独立的任务。\n今天我们就来带着大家一起看看 Claude Code 官方 Skills 怎么使用，并且看看除了 Claude Code 官方 Skills 之外还有没有其它 Skills 。\n一、Claude Code 官方 Skills 介绍 # 1、功能介绍 # Claude Code 官方 Skills 总共有16个，我们以表格的形式来给大家简单介绍一下它们的功能。\nSkill 名称 功能描述 algorithmic-art 使用 p5.js 创建算法艺术，支持种子随机性和交互式参数探索。用于生成艺术、流场、粒子系统等创作。 brand-guidelines 应用 Anthropic 官方品牌色彩和排版规范。适用于需要符合公司视觉设计的场景。 canvas-design 创建精美的视觉艺术作品（.png 和 .pdf 格式）。适用于制作海报、艺术作品、设计作品等。 doc-coauthoring 引导用户进行结构化的文档协作工作流。用于撰写文档、提案、技术规范、决策文档等。 docx 全面的 Word 文档 (.docx) 创建、编辑和分析工具。支持跟踪更改、评论、格式保留和文本提取。 frontend-design 创建高质量的前端界面。适用于构建网页组件、页面、仪表板、React 组件等。 internal-comms 内部沟通资源包，帮助撰写各类内部沟通内容，如状态报告、领导层更新、公司通讯等。 mcp-builder 指导创建高质量的 MCP 服务器，使 LLM 能够通过设计良好的工具与外部服务交互。 pdf 全面的 PDF 操作工具包。支持提取文本/表格、创建 PDF、合并/拆分文档、处理表单等。 pptx 演示文稿创建、编辑和分析工具。用于处理 PowerPoint 文件 (.pptx)。 skill-creator 指导创建有效的 Skills。用于扩展 Claude 的能力，添加专业知识和工作流。 slack-gif-creator 专为 Slack 优化的动画 GIF 创建工具。提供约束验证工具和动画概念。 theme-factory 使用主题样式化工具包的主题工具。包含 10 个预设主题，可应用于幻灯片、文档、报告等。 web-artifacts-builder 使用现代前端技术创建复杂的 Claude.ai HTML 构件。适用于需要状态管理、路由或 shadcn/ui 组件的场景。 webapp-testing 使用 Playwright 与本地 Web 应用交互和测试的工具包。支持验证前端功能、调试 UI 行为、截图等。 xlsx 全面的电子表格创建、编辑和分析工具。支持公式、格式、数据分析和可视化。 2、安装 Skills # 我们以 Claude Code 为例来为大家介绍一下怎么使用 Skills。\nClaude Code 的安装方法大家可以参考下面这篇文章。\nAI编程：Claude Code 和 GLM-4.7，AI编程强强组合\nClaude Code 官方 Skills 获取地址： https://github.com/anthropics/skills\n下载 Skills： 进入 Claude Code 官方 Skills 获取地址 后我们点击如下按钮下载ZIP文件：\n安装 Skills： 文件下载后，我们解压该文件，该文件解压后，里面有个skills文件夹，这里面就包含了Claude Code官方提供的16个skills，如下：\nSkills安装有两种方式：\n1）. 全局安装：\n将ZIP文件解压后的skills文件夹复制到 C:\\Users\\你的用户名\\.claude\\ 目录。\n这样是对所有项目生效。\n2）. 局部安装：\n将ZIP文件解压后的skills文件夹复制到项目根目录下的 .claude\\ 目录。\n这样只对当前项目生效。\n查看 Skills： 1）.我们先创建一个skill项目，如下：\n2）.进入该项目目录，如下：\n3）.在这里输入 cmd ，如下：\n如此便可打开终端后直接进入项目根目录。\n4）.输入 claude 命令，如下：\n5）.输入 /skills 命令，便可看到刚才安装的16个skills，如下：\n使用 Skills： 接下来我们用一个示例来简单看一下skills的使用方法。\n我们使用如下提示词：\n请创建一个交互式的数据可视化仪表板，包含图表筛选、数据更新和导出功能。 我们观察创建过程，并没有看到哪里有使用了skills的记录，不过我们可以看到 Claude Code 是先规划再实现的。我们先不管这个，既然都开始了，我们等实现完成后看看效果如何。\n如下是实现效果：\n这个界面看着还可以哈，不过我们并不想让它去直接规划实现，而是使用skills去完成。\n我们进入Claude后，输入 /web 后我们可以看到如下命令：\n我们发现这个命令跟我们刚才添加的 skills 中的 web-artifacts-builder 名称是相同的。\n其实这就说明这个skill是可以通过 /web-artifacts-builder 命令去手动调用的，所以，接下来我们将之前的提示词调整如下：\n请使用 /web-artifacts-builder 创建一个交互式的数据可视化仪表板，包含图表筛选、数据更新和导出功能。 使用该提示词后我们就会惊奇的发现，这次确实使用 web-artifacts-builder skill去实现了。如下：\n实现效果：\n3、使用示例 # 下面我们来挑选其中的几个Skills来为大家展示一下使用方法。\nalgorithmic-art 功能介绍： 使用 p5.js 创建算法艺术，支持种子随机性和交互式参数探索。用于生成艺术、流场、粒子系统等创作。\n使用示例： 请用算法艺术创建一个具有流动场效果的粒子系统作品，使用种子随机性确保每次都能重现相同的视觉效果。\n大家可以看到，我们输入提示词后，Claude Code 会自动选择 algorithmic-art skill 去创作。\n创作结果：\n说实话有点专业，看不太懂，咱也不敢发表意见。\ncanvas-design 功能介绍： 创建精美的视觉艺术作品（.png 和 .pdf 格式）。适用于制作海报、艺术作品、设计作品等。\n使用示例： 请为我的技术会议创建一张精美的海报，主题是AI与机器学习，采用现代极简风格。\n创作结果：\nfrontend-design 功能介绍： 创建高质量的前端界面。适用于构建网页组件、页面、仪表板、React 组件等。\n使用示例： 请使用 frontend-design skill为一个电商网站设计一个购物车组件，包含商品列表、数量调整、价格计算和结账按钮。\n创作结果：\npptx 功能介绍： 演示文稿创建、编辑和分析工具。用于处理 PowerPoint 文件 (.pptx)。\n使用示例： 请为我创建一个产品发布会演示文稿，包含10页，涵盖产品介绍、功能展示和路线图。\n创作结果：\n这个\u0026hellip;不用我多说了，效果怎么样，大家一目了然。\n可能也怪我，只发了一句话，其它啥信息都没有给人家提供，巧妇难为无米之炊么。\ntheme-factory 功能介绍： 使用主题样式化工具包的主题工具。包含 10 个预设主题，可应用于幻灯片、文档、报告等。\n使用示例： 请应用Ocean主题来美化这个演示文稿，统一配色和字体风格。\n我们就来美化一下上面生成的 产品发布会演示文稿 吧。\n创作结果：\n看着确实美化了哈，美化后看着顺眼多了。\nxlsx 功能介绍： 全面的电子表格创建、编辑和分析工具。支持公式、格式、数据分析和可视化。\n使用示例： 请使用 /xlsx 读取这个销售数据表格，按地区汇总销售额，并创建一个数据透视表进行可视化分析。\n但是生成之前没有销售数据表格怎么办？我们让 Claude Code 帮我们生成一份吧。\n提示词如下：\n我需要测试 /xlsx ，但是我没有销售数据表格，请帮我先生成一份销售数据表格。 数据很快就生成好了，如下：\n现在我们使用这个数据来做可视化分析。\n创作结果：\n二、skills 库 # 1、Claude Code 官方 Skills # 地址：\nhttps://github.com/anthropics/skills\n2、Agent Skills 市场 # 地址：\nhttps://skillsmp.com/zh\n3、Skill Manager | 技能管理器 # 地址：\nhttps://github.com/buzhangsan/skill-manager/tree/main\n中文文档：\nhttps://github.com/buzhangsan/skill-manager/blob/main/docs/README_CN.md\n注意： 需要提醒大家的是，我们使用社区skills应该像对待任何开源代码一样，使用前先检查，保持谨慎肯定没有错。\n三、总结 # 看到这里，大家是不是也觉得如此强大的skills使用起来却是如此的 so easy，那还等什么，赶紧去试试吧。\n分享就到这里了，如果对大家有帮助，随手点个赞、转发、推荐三连吧，如果想第一时间收到推送，也可以给我个星标。\n有任何想法，欢迎大家留言~ 小手一赞，年入百万！👍👍👍\n#Cursor #ClaudeCode #Agent #MCP #Trae #Kiro #CodeBuddy #工具干货 #AI应用 #AI工具 #AI编程\n","date":"17 January 2026","externalUrl":null,"permalink":"/posts/skillsclaude-code-%E5%AE%98%E6%96%B9-skills/","section":"AI-Related Reposts","summary":"","title":"[Repost] Skills：Claude Code 官方 Skills 功能介绍和社区 skills 库","type":"posts"},{"content":"Reposted from 740 万围观！Claude Code 之父的工作流火了：「过去 30 天我所有代码都是 AI 写的」 by AI信息Gap\nBoris Cherny 在 X 上发了一条帖子，分享自己怎么用 Claude Code。\n740 万阅读量。\nBoris 是 Anthropic 的资深工程师，Claude Code 就是他做的。2024 年 9 月加入 Anthropic，从一个内部原型开始，一路把 Claude Code 做到了 6 个月 10 亿美元 ARR。这个速度，放在整个 SaaS 历史上都是现象级的。\n所以当他说「分享一下我自己怎么用 Claude Code」的时候，直接火了。\n有人说这是 Anthropic 的「ChatGPT 时刻」。\n有人说，用了他的方法之后，「感觉更像在玩星际争霸，而不是在写代码」，从敲键盘变成了指挥部队。\n但最让人意外的是，他的设置出奇简单。\n用他自己的原话说：surprisingly vanilla。\n01｜15 个 Claude 并行 # Boris 的日常是这样的：终端里开 5 个 Claude Code，浏览器里再开 5-10 个。\n每个标签页编号 1-5，由系统通知告诉他哪个 Claude 需要操作。\n一个 Claude 在跑测试，另一个在重构代码，第三个在写文档。\n他还会在手机上（用 Claude iOS app）启动几个会话，早上开始，白天随时查看进度。\n需要的时候，用 --teleport 命令把会话在本地和网页之间来回转移。\n这验证了 Anthropic 联合创始人 Daniela Amodei 说的策略：用更好的编排，而不是更多的算力。\n02｜用最慢的模型，反而最快 # 这条可能是整个帖子里最反直觉的。\nBoris 用的是 Opus 4.5 Thinking，Anthropic 最大、最慢的模型。\n不是 Sonnet。不是 Haiku。\n他的原话：\n「这是我用过的最好的编程模型。虽然它比 Sonnet 更大更慢，但因为你不需要反复纠正它、它的工具使用能力更强，所以最终几乎总是比用小模型更快。」\n表面上慢，实际上省掉了来回调试的时间。\n03｜Plan Mode：先想清楚，再行动 # 大多数会话，Boris 都从 Plan Mode 开始。\n快捷键是 shift+tab 按两次。\n如果目标是写一个 Pull Request，他会先在 Plan Mode 里和 Claude 反复讨论，直到计划满意。然后切换到自动接受编辑模式，让 Claude 一次性完成。\n他说：「一个好的计划非常重要。」\n强烈推荐这个 Plan Mode，谁用谁知道！\n04｜CLAUDE.md：团队共享的 AI 记忆 # Boris 的团队维护一个 CLAUDE.md 文件，提交到 git 里，每周会更新几次。\n规则很简单：「每次看到 Claude 做错什么，就加进去。」\n这样 Claude 下次就知道不要再犯同样的错误。\n代码审查的时候，他经常在同事的 PR 里 @.claude，让 Claude 把某条规则加进 CLAUDE.md。他们用 Claude Code 的 GitHub Action 来实现这个流程。\n每一个错误都变成了一条规则。团队合作的时间越长，AI 就越聪明。\n05｜快捷命令：把重复的事情自动化 # Boris 用快捷命令处理每天要做很多次的「内循环」工作流。\n比如他有一个 /commit-push-pr 命令，每天要用几十次。这个命令用内联 bash 预先查询 git status 和其他信息，避免和模型来回对话。\n命令都放在 .claude/commands/ 目录里，提交到 git，团队共享。\n06｜Subagents：让 AI 互相检查 # Boris 用 subagent 来处理开发周期的不同阶段。\ncode-simplifier 负责在主要工作完成后简化代码架构。verify-app 负责端到端测试。\n他的代码审查命令会同时启动好几个 subagent：一个检查代码风格，一个查项目历史理解上下文，一个找明显的 bug。第一轮会有误报，所以他再用 5 个 subagent 专门挑第一轮结果的毛病。\n他说：「最后的结果很棒，能找到所有真正的问题，没有误报。」\n07｜让 Claude 用你的工具 # Boris 让 Claude Code 直接使用他日常的工具。\n主要通过 MCP server。比如连接 BigQuery 查询回答数据问题。从 Sentry 拉错误日志。\n相关的 MCP 配置放在 .mcp.json 里，团队共享。\n这意味着 Claude 不只是写代码，还能帮你查数据、找 bug。\n08｜权限和 Hooks # Boris 不用 --dangerously-skip-permissions。\n他用 /permissions 预先允许那些他知道安全的常用 bash 命令，避免不必要的权限弹窗。大部分配置放在 .claude/settings.json 里，团队共享。\n他用 PostToolUse hook 来格式化 Claude 生成的代码。Claude 生成的代码通常格式不错，hook 处理最后 10%，避免 CI 里出格式错误。\n对于特别长时间运行的任务，他要么让 Claude 完成后用后台 agent 验证，要么用 Stop hook 更确定地做这件事，要么用一个叫 ralph-wiggum 的插件。\n09｜验证循环：最重要的一条 # Boris 说，如果只能记住一条，记住这条：\n「给 Claude 一个验证自己工作的方法。如果 Claude 有这个反馈循环，最终结果的质量会提升 2-3 倍。」\n他自己的做法是：Claude 用 Chrome 扩展测试每一个提交到 claude.ai/code 的改动。打开浏览器，测试 UI，反复迭代，直到代码能用、体验顺畅。\n验证在不同领域看起来不一样。可能是跑一个 bash 命令，可能是跑测试套件，可能是在浏览器或手机模拟器里测应用。\n关键是要让这个循环稳定可靠。\n有人问 Boris，为什么要公开分享这些？\n他说 Claude Code 没有唯一正确的使用方式。他们故意把它做成可以随意定制和折腾的样子。\n740 万阅读量，说明开发者真的很想知道创造这个工具的人，自己是怎么用的。\n答案出乎意料地简单。多开几个、用最好的模型、先想清楚再动手、让 AI 能验证自己的工作。\n就这些。\n我是木易，Top2 + 美国 Top10 CS 硕，现在是 AI 产品经理。\n关注「AI信息Gap」，让 AI 成为你的外挂。\n","date":"15 January 2026","externalUrl":null,"permalink":"/posts/740-%E4%B8%87%E5%9B%B4%E8%A7%82claude-code-%E4%B9%8B%E7%88%B6%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%81%AB%E4%BA%86%E8%BF%87%E5%8E%BB-30/","section":"AI-Related Reposts","summary":"","title":"[Repost] 740 万围观！Claude Code 之父的工作流火了：「过去 30 天我所有代码都是 AI 写的」","type":"posts"},{"content":"","date":"15 January 2026","externalUrl":null,"permalink":"/tags/ai-code/","section":"Tags","summary":"","title":"AI Code","type":"tags"},{"content":"Reposted from LangChain 创始人警告：2026 成为“Agent Skills 终极指南：入门、精通、都在这了！ by 吴哥AI实操笔记\n大家好，我是吴哥，专注AI编程、AI智能体。立志持续输出、帮助小白轻松上手AI编程和AI智能体。\nAI 编程“落地”，其实缺 SOP/上下文/可治理复用。用 Agent Skills（SKILL.md） 把“交接文档+脚本+资料”打包，3 步做出可复用的垂直 Agent。照着文末模板写一个你的第一个 Skill，当天就能跑。\n阅读信息：预计 10 分钟｜适用人群：小白/进阶\n为什么现在必须解决这个问题 # 痛点： 你不是不会用 AI，你是被迫重复解释同一套规则（格式、流程、边界、工具）。\n你不是缺模型，你是缺可版本化、可迁移、可审计的“做事方法”。\nAgent Skills 在 2025-10-16 由 Anthropic 系统化提出，并在 2025-12-18 更新为跨平台开放标准。 同期，GitHub Copilot / VS Code / Cursor / OpenAI Codex 已出现对 SKILL.md 的原生支持入口。\n本文价值承诺：今天你能把一个“反复口头交接的任务”做成 Skill 能力包：30–60 分钟写完 SKILL.md + 1 个脚本（可选），立刻在 Copilot / Claude Code / Codex / Cursor 里复用。\n核心问题清单 # Q1：Skills 到底是什么？为什么不是“又一套提示词花活”？\nQ2：Skills 和 MCP / Workflow 的分工边界在哪？什么时候该用哪一个？\nQ3：怎么用最小闭环，把 Skill 变成“能跑、能复用、能迁移”的能力包？先把概念钉死，才能谈工程化复用。\n工具卡（用途/适合） # GitHub Copilot Agent Skills\n用途：让 Copilot 在需要时把 SKILL.md 注入上下文，并可联动目录内脚本/资源，执行专用任务。\n适合：团队开发规范、PR 审查清单、测试生成、提交信息、脚手架等“重复且可标准化”的编码任务。\nOpenAI Codex Skills\n用途：同样基于“文件夹 + SKILL.md（name/description）”选择与加载技能。\n适合：你已经在用 Codex 做 CLI/Agent 编码，希望把个人/团队 SOP 固化成可复用资产。\nCursor Agent Skills\n用途：把可复用知识与脚本打包成 Skills，让 Agent 按需加载执行。\n适合：重度 IDE 流工作流、项目内“上下文工程”长期沉淀。\n别纠结“选谁家模型”，先选一个你每天在用的载体，把 Skill 跑起来。\n底层逻辑： # 判断：Skills 的本质不是“更长的提示词”，而是可渐进加载（progressive disclosure）的 SOP 包装：先加载元信息，再按需读正文与资源，避免把上下文塞爆。\n证据：Anthropic 明确把 Skills 定义为“指令、脚本与资源的文件夹”，并强调按需加载让可打包的上下文“近似无上限”。\n为什么很多人觉得 AI 编程不落地？\n缺“组织化的上下文”：你脑子里的流程、边界、规范没法稳定传给模型——所以它表现像“聪明但健忘的实习生”。\n缺“可治理的交付物”：Prompt 不好版本化、难评审；Skill 是文件夹，可 Git 管、可 Review、可复用、可迁移。\n缺“工具与方法的绑定”：Workflow 解决“流程固定”，MCP 解决“外部工具统一接入”，而 Skills 解决“把怎么做写清楚，并在需要时加载”。\n想要落地就两步——把重复任务写成 SKILL.md，再把高风险环节用脚本固化成“可执行证据”。AI 编程落不了地，通常不是模型不够强，而是你的“交接包”还没成型。 一张表说清：Skills / MCP / Workflow 怎么选 # 方案 解决什么 强项 代价/风险 典型场景 Skills（SKILL.md） “怎么做”的 SOP + 资料 +（可选）脚本 可版本化、可迁移、按需加载、易复用 写得烂会变“碎碎念说明书”；需要迭代 写作/审查规范、代码脚手架、团队流程交接 MCP 统一方式调用外部工具/数据/服务 工具接入标准化、权限与连接可治理 不提供任务流程本身 连接数据库/工单/知识库/内部系统 Workflow（n8n/Dify/Coze） 固定流程自动化 可控、可观测、可回放 边界情况多时很僵硬 报表流水线、固定审批流、批处理任务 MCP 管“怎么连”，Workflow 管“怎么走”，Skills 管“怎么做”。\n两步/三步落地（最短闭环） # 第一步：挑一个“你每周至少做 2 次”的任务（检查点｜产出｜预计时长） 检查点：任务是否具备稳定输入/稳定输出/稳定标准（例如“技术文档按公司模板生成”“PR 审查按清单”）。\n产出：写下 10 行“你现在是怎么做的”，这就是 Skill 的骨架。\n预计时长：10 分钟。别从宏大愿景开始，从你最烦的重复劳动开始。\n第二步：写一个“最小可用 SKILL.md”（检查点｜产出｜预计时长） 检查点：必须包含 name + description，并把流程写成可执行步骤（像交接给同事）。\n产出：一个可被 Copilot/Codex/Cursor 等识别的 skill 文件夹。\n预计时长：20–30 分钟。Skill 不是作文比赛，步骤清晰比文采重要。\n\\[可选\\] 第三步：把“高风险步骤”改成脚本（检查点｜产出｜预计时长） 检查点：凡是“容易写错/算错/漏项”的步骤（比如批量改名、生成报表、格式转换），都值得脚本化。\n产出：scripts/ 下 1 个可执行脚本 + 在 SKILL.md 里写清楚何时运行它。\n预计时长：30–90 分钟（看复杂度）。能用脚本证明正确的，就别让模型靠“感觉”输出。\n可复制：最小可用 SKILL.md 模板 # --- name: doc-reviewer description: 用固定清单审查技术文档/PRD，输出问题列表与改写建议（含风险分级）。 metadata: owner: your-name version: 0.1.0 --- # 目标 把用户提供的文档按“结构/事实/一致性/可执行性”四类审查，并输出可直接修改的建议。 # 输入 - 文档正文（Markdown/纯文本/粘贴内容） - 可选：公司术语表、模板、历史示例（放在 references/） # 输出 1) 结论摘要（≤5条） 2) 问题清单（按 P0/P1/P2 分级） 3) 改写稿（仅改必要部分，不重写全部） # 工作流程（必须按顺序） 1. 先复述任务与边界：哪些内容不猜、不编。 2. 结构检查：标题层级、缺失段落、是否可执行。 3. 事实检查：对不确定的点标记【需确认】并列出要问的问题。 4. 一致性检查：术语、口径、指标定义是否冲突。 5. 输出按模板排版，最后给“下一步建议”。 # 资源使用 - 需要公司模板时：读取 references/template.md - 需要术语表时：读取 references/glossary.md - 需要自动化格式化时：运行 scripts/format.sh（如存在） 你写下的每一条“必须按顺序”，都是在把不稳定的生成变成稳定的交付。\n预测：Skills 会把“AI 产品形态”往哪推 # 判断 1：Skills 会把大量“轻量 AI 产品”打回文件系统：一个 Skill + 一个通用 Agent，就够做 MVP。证据是开放标准与多工具原生入口已形成合围。\n判断 2：下一阶段竞争点不再是“谁更会写 Prompt”，而是谁的 Skill 包更可复用、更可治理、更可评估（像代码仓库一样迭代）。\n未来最值钱的不是一次性的提示词，而是可迁移的“组织能力包”。 你赞同吗？\n这是今天分享内容，希望整理内容对你有所帮助，感谢阅读。\n如果你对AI编程感兴趣，欢迎交流，进群领取吴哥AI编程手册详细资料福利(PS:群已超200人）。要是觉得今天这碗饭喂得够香，随手点个赞、在看、转发三连吧！\n","date":"11 January 2026","externalUrl":null,"permalink":"/posts/agent-skills-%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97%E5%85%A5%E9%97%A8%E7%B2%BE%E9%80%9A%E9%83%BD%E5%9C%A8%E8%BF%99%E4%BA%86/","section":"AI-Related Reposts","summary":"","title":"[Repost] Agent Skills 终极指南：入门、精通、都在这了！","type":"posts"},{"content":"Reposted from Dan Koe：如果我在 2026 年从零开始，我会怎样搭建一人公司？ by 陆甲第\n以下是我对Dan Koe的新一期视频《如果我在 2026 年从零开始，我会怎样搭建一人公司》的策展。\n有同学好奇，什么是策展。\n策展（内容领域）指的是用自己的方式组织、整理、呈现信息，从噪声中发现信号，从碎片中找到意义。\n我写知识卡片就是一种策展：把自己阅读和思考过程中的灵感想法记录下来，组织成自己想要的语言。\n我写的很多文章其实也是一种策展：从各处搜集“碎片信息”，整理、提炼后用自己的逻辑连接起来。\n这里要提到我对碎片信息的理解：凡是外界信息都是碎片信息，只有经过我自己思考和内化的信息才属于我自己。\n我经常写他们的内容：\nJ.K.罗琳的写作思考\nNicolas Cole的写标题方法\nDan Koe的创作理念\nNaval 的财富观念\n但不管你写谁的，关键是你要用自己的经历和理解，重新诠释他们。\n这样才会对你的成长有帮助。\n作者：Dan Koe\n策展：陆甲第\n01 一人公司在如何进化？ # 大部分人还在沿用过去的那套思维，思考“2026年最合适做什么生意“。\n要么是为了流量大喊“知识付费已死”、“写作无用”，要么是继续鼓吹做社群、卖录播课、当自由职业者。\n仿佛AI只是个“能帮你写文案写内容的助手”，而非正在重写整个创作者经济底层逻辑的变量。\n但现实却是：AI让一切逻辑发生了改变。\n第一，平庸已经没办法生存了。 # 现在几乎所有职业赛道一样——尤其在 AI 的推动下——能拿到结果的“基线”被抬高了。\n这就是真相：\n过去，你只要把经验整理成PDF，配上几句“改变人生”的承诺，就能卖出几百上千份。\n因为那时市场还在教育阶段，用户对“有人愿意教我”本身就心怀感激。\n可今天，AI让“内容生产”的门槛为零。\n一个新手用Claude两小时就能生成一本结构完整的电子书；\nMidjourney三分钟产出比你花三天做的封面更“专业”；\n你的“独家方法论”，可能已被十个竞品用同样提示词复刻。\n第二，市场已经成熟了，用户已经疲惫了。 # 传奇文案人 Eugene Schwartz 把市场成熟度分为五个阶段：\n第一阶段：市场还没被教育，你只要直说“产品能干什么”，基本就够了。\n第二阶段：竞争者进来，你必须给出更大的承诺。\n第三阶段：市场变得怀疑，你就得解释“原理机制”，为什么行得通。\n比如“我教你网上赚钱”开始像骗局，你就得更具体，比如“执行 2 小时内容生态系统”。\n第四阶段：竞争者复制你的机制。\n第五阶段：市场对一切承诺都疲劳了，品牌成了主要区分点。\n当下的信息产品市场已经成熟。\n用户已经疲惫了，他们的意识层次已经对各种知识付费产品感到倦怠。\n真正能赢的，是那些足够聪明、能“超越信息产品形态”的少数人。\n这一点我们之后会讲。\n第三，新范式出现时，人们会迷茫且不知所措。 # 当一个新范式开始冒头时，大家会集体迷茫。因为新范式还没完全清晰，它不明确，也没有谁能直接告诉你标准答案。你得自己尝试、自己做实验，直到你做出那个“新东西”。\n而作为一人公司的创始人，你的优势在于速度与适应力。\n你没有巨大的管理成本、庞大的团队负担，这意味着你可以迅速转向和调整策略。\n你只要在一个主题上跟随四五个人，就能在很短时间把那件事学得很好。然后持续迭代，达到“逃逸速度”——那种真正让你拥有难以被夺走竞争优势的速度。\n这其实跟Alpha精神如出一辙。\nAlpha意味着你要快人一步，先人一拍。\n别人看短视频获取信息，我看报告和论文；别人看报告和论文，我直接和最前沿的头脑对话。\n平庸者相信，只要这辈子做成一件事，就可以退休。\n但这种线性思维在当今快速变化的环境中已经行不通了。\n你需要Alpha精神，与时代共舞，找到自己的独特性，并且用这种独特性来吸引那些真正需要你的人。\n那么一人公司会在AI时代如何变化？\n02 新文艺复兴与学习体验 # 以教育类一人公司为例。\n教育和学习永远不会消失，但它们的形式必须进化。\n在口传时代，知识是火堆旁讲述的故事和八卦。\n在书写时代，它被刻上岩壁，被印上纸页，被放进图书馆；\n在工业时代，知识被标准化，批量灌输——教室成为流水线，学生是待加工的原料；\n到了互联网时代，我们以为“搜索引擎”会让信息平权，于是把整座图书馆搬上线，把讲座录成视频。\n但那只是复制旧形式到新媒介，而非真正利用新媒介重塑学习。\n我们正站在又一次认知范式转移的临界点上。\nAI会是一种新型认知基础设施——它让知识从“存储形式”变为“交互形式”，从“被动接收”转向“主动共建”。\n人们不会满足于“看别人怎么做”，而是渴望“在我做的过程中，有人（或智能体）实时告诉我哪里对、哪里错、下一步怎么走”。\n未来的教育将更像“学习体验”，而不是静态的课程或产品。\n举个例子：\n你不再买《高效写作课》，而是拥有一个AI写作教练——它知道你的文风弱点，在你写第一句时就提醒：“这里太抽象，加个故事。”\n你不再加入“年度成长社群”，而是进入一个动态知识库——输入“我想转型做AI产品经理”，它立刻调出学习路径、练习任务、模拟面试，并根据你的反馈实时调整。\n一个能陪你写 newsletter、教你写作、帮你练习社媒内容的 AI（像坐在你旁边的教练，随时纠错、随时反馈），往往比“课程本身”更有效。\n用户可以在互动、做事中及时获得反馈。做中学永远是最好的学习方式。\n这其实就是古代的学徒制。\n师傅不会扔给徒弟一本自己多年总结的心法，让他在一边自学。他会在旁边实时纠正做法。\n现在我们有机会在规模化条件下提供个性化、互动式指导。\n03 教育产品会越来越像软件 # 软件即服务。\n未来所有课程都会变成一个app或者一个网站，提供实时指导。\n比如你不卖“如何和异性聊天”的电子书/课程/教练，你做一个 chatbot，模拟和异性聊天，教你怎么发信息。\n具体怎么做？\n先把课程内容写成知识库，文章、框架、流程、案例都放进去。\n然后写系统提示词，就是在 AI 和用户对话之前，你给 AI 的一组规则：它定义 AI 的人格、知识边界、行为规范。\n比如你要做一个 AI 写作教练，你的系统提示词通常会包含：\n角色：AI 应该以什么身份行动\n指令：它具体要做什么、按什么步骤做\n知识库：你的框架、流程、案例、示范\n边界：它能做什么、不能做什么\n风格：它怎么说话，用什么语气，严厉还是支持\n提示词决定了你的 AI 和别人的不同。它承载的是你的具体知识、你的框架、你的声音，这能一次服务成千上万人。\n最后，记住。\n你的优势不在于做“AI 做不到的事”，那是必输的游戏。\n你的优势在于：用 AI 做出只有你才会想到去做的东西。\n真正不可复制的人，是那些多年打磨出细致经验与案例的人。\n别人就算想抄，也抄不到那些让它真正有效的细节。\n所以，去做只有你会去做的东西。\nDan Koe其他内容\nDan Koe：未来十年最重要的技能（不是AI能力）\nDan Koe：如何进行高质量的自我表达？（超过99%的人）\n油管网红Dan Koe：如何在26岁成为百万富翁？（只靠自己）\n","date":"8 January 2026","externalUrl":null,"permalink":"/posts/dan-koe%E5%A6%82%E6%9E%9C%E6%88%91%E5%9C%A8-2026-%E5%B9%B4%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%88%91%E4%BC%9A%E6%80%8E%E6%A0%B7%E6%90%AD%E5%BB%BA%E4%B8%80%E4%BA%BA%E5%85%AC%E5%8F%B8/","section":"AI-Related Reposts","summary":"","title":"[Repost] Dan Koe：如果我在 2026 年从零开始，我会怎样搭建一人公司？","type":"posts"},{"content":"Reposted from 谷歌资深研发人员给出的Nano Banana Pro十个技巧 by 点滴智识\n2025年11月份，谷歌推出了Nano Banana Pro，比起前代产品，这是一次重大的飞跃，它使图像生成从“有趣”变为了更加“有用”。模型在文本渲染、字符一致性、视觉合成、世界知识（搜索）和高分辨率（4K）输出方面表现出色。之后，谷歌的资深研发人员Guillaume Vernade便分享了如何更好的利用Nano Banana Pro做出图像的十个技巧，如果你可以掌握，便可以更好的发挥出模型的潜力。\n一、提示词的黄金法则：\nNano Banana Pro是一个“思考”模型。它不仅只是匹配关键字，更能理解用户意图、物理和构图。为了获得最佳效果，最好不要使用简单的标签（例如狗、公园、4k、现实）描述。\n第一、编辑，不要重新制作\n该模型非常善于理解会话编辑。如果图像正确率为80%，则可以不用生成新图像，而只需明确要修改的地方。比如：“那太好了，但把灯光调到日落，让文字变成霓虹蓝。”\n第二、使用自然语言和完整句子\n与模型交谈，就像你在向人类艺术家沟通一样。使用正确的语法和描述性形容词。\n❌ 坏：“酷车，霓虹灯，城市，夜晚，8k。”\n✅ 好：“这是一张电影般的全景照片，拍摄了一辆未来派跑车在夜晚雨天的东京街道上疾驰而过。霓虹灯在潮湿的路面和汽车的金属底盘上反射出来。”\n第三、具体描述\n模糊的提示词会产生通用的结果。最好明确定义主题、背景、灯光和情绪。\n主题：用“一位穿着复古香奈儿风格西装的老练老妇人”代替“一位女人”\n材质：描述纹理。“哑光处理”、“拉丝钢”、“柔软天鹅绒”、“皱巴巴的纸”\n第四，提供上下文（“为什么”或“为谁”）\n因为模型可以“思考”，所以给它提供背景有助于它做出合乎逻辑的艺术决策。比如：“为巴西高端美食烹饪书创建一个三明治的图像。”\n二、文本渲染、信息图和视觉合成\nNano Banana Pro具有SOTA功能，可以呈现清晰、程式化的文本，并将复杂的信息合成为视觉格式。\n最佳实践：\n压缩：要求模型将密集的文本或PDF“压缩”成视觉辅助工具。\n风格：指定你想要的是“精致的社论”、“技术图”还是“手绘白板”外观。\n引号：在引号中明确指定你想要的文本。\n案例1：制作一张关于美国餐厅历史的复古、20世纪50年代风格的信息图。包括“食物”、“自动点唱机”和“装饰”的不同部分。确保所有文本清晰易读，风格化，与时代相匹配。\n案例2：将“Transformer神经网络架构”的概念总结为适合大学讲座的手绘白板图。对编码器和解码器块使用不同颜色的标记，并为“自我关注”和“前馈”添加清晰的标签\n三、角色一致性和病毒缩略图\nNano Banana Pro最多支持14张参考图像（6张高保真）。这允许将特定的人或角色放入新的场景中，而不会造成面部变形。\n最佳实践：\n身份锁定：明确声明：“保持该人的面部特征与图1完全相同。”\n表情/动作：描述在保持身份的同时情绪或姿势的变化。\n病毒式构图：将主题与粗体图形和文字结合在一起。\n案例3：（上传图片）使用图1中的人物设计一个病毒式视频缩略图。面部一致性：保持人的面部特征与图1完全相同，但改变他们的表情，让他们看起来兴奋和惊讶。动作：将人摆在左侧，将手指指向画面的右侧。\n主题：在右边，放一张美味的鳄梨吐司的高质量图片。\n图形：添加一个大胆的黄色箭头，将人的手指连接到吐司上。\n文本：在中间覆盖巨大的流行风格文本：\u0026lsquo;3分钟搞定!（3分钟后完成！）。使用粗白色轮廓并投下阴影。\n背景：模糊明亮的厨房背景。高饱和度和对比度。\n四、使用谷歌搜索\nNano Banana Pro可以使用谷歌搜索根据实时数据、时事或事实验证生成图像，减少对即时主题的幻觉。\n最佳实践：\n要求动态数据（天气、股票、新闻）的可视化。\n模型将在生成图像之前对搜索结果进行“思考”（推理）。\n案例4：根据当前的旅游趋势，生成2025年参观美国国家公园的最佳时间信息图。\n五、高级编辑、恢复和着色\n模型擅长通过对话提示进行复杂的编辑。这包括“在绘画中”（删除/添加对象）、“修复”（修复旧照片）、“着色”（漫画/B\u0026amp;W照片）和“风格转换”。\n最佳实践：\n语义说明：你不需要手动屏蔽；只需告诉模型自然地改变什么。\n物理理解：你可以要求进行复杂的改变，比如“把这个杯子装满液体”，以测试物理生成。\n案例5：将游客从这张照片的背景中移除，用与周围环境相匹配的逻辑纹理（鹅卵石和店面）填充空间。\n案例6：给这个漫画面板上色。使用充满活力的动漫风格调色板。确保能量束上的灯光效果是闪烁的霓虹蓝，角色的服装与官方颜色一致。\n六、维度变换（2D→3D）\n一个强大的新功能是将2D原理图转换为3D可视化，反之亦然。这是室内设计师、建筑师和模因创作者的理想选择。\n案例7：根据上传的2D平面图，在单张图像中生成一个专业的室内设计演示板。布局：拼贴，顶部有一个大的主图像（起居区的广角视角），下面有三个较小的图像（主卧室、家庭办公室和3D自上而下的平面图）。风格：在所有图像中应用现代极简主义风格，温暖的橡木地板和灰白色的墙壁。质量：照片级真实感渲染，柔和的自然光线。\n七、高分辨率和纹理\nNano Banana Pro支持原生1K到4K图像生成。这对于细节纹理或大幅面打印特别有用。\n最佳实践：\n如果API/接口允许，则明确请求高分辨率（2K或4K）。\n描述高保真细节（缺陷、表面纹理）。\n案例8：利用原生高保真输出，营造出令人惊叹的苔藓森林地板大气环境。控制复杂的灯光效果和精致的纹理，确保每一缕苔藓和光束都以适合4K壁纸的像素完美分辨率呈现。\n八、思考与推理\nNano Banana Pro默认为“思考”过程，在渲染最终输出之前，它会生成临时思维图像来优化构图。这允许数据分析和解决视觉问题。\n案例9（求解方程式）：在白板上用C求解log_{x^2+1}（x^4-1）=2。清楚地显示步骤。\n案例10（视觉推理）：分析这个房间的图像，并生成一个‘之前’的图像，显示房间在施工期间的样子，显示框架和未完成的石膏板。\n九、一次性故事板和概念艺术\n你可以生成连续的艺术或故事板，这在“电影概念艺术”中也很受欢迎（例如，即将上映的电影的虚假泄漏）。\n案例11：在一个屡获殊荣的豪华行李箱广告中，用9张照片描绘一个女人和一个男人，创造一个令人上瘾的有趣的9部分故事。这个故事应该有情感的高潮和低谷，以一张带有标志的女人的优雅照片结束。女人和男人的身份以及他们的着装必须始终保持一致，但他们可以而且应该从不同的角度和距离看到。请一次生成一张照片。确保每张照片都是16:9的横向格式。\n十、结构控制和布局指导\n输入图像可以是草图或者手稿，你可以使用它们严格控制最终输出的组成和布局。对于需要将餐巾纸草图、线框或特定网格布局转化为精美资产的设计师来说，这是一个改变游戏规则的因素。\n最佳实践：\n草稿和草图：上传手绘草图，以准确定义文本和对象的位置。\n线框：使用现有布局或线框的屏幕截图来生成高保真UI模型。\n网格：使用网格图像强制模型为基于图块的游戏或LED显示器生成资源。\n案例12（线框UI模型）：按照这些指导方针为\n\\[产品\\]创建一个模型。\n最后的话：\nNano Banana Pro无疑是2025年最为出色的图像生成模型，掌握这些技巧，将会更好地与模型交互，生成更为满意的作品。\n","date":"8 January 2026","externalUrl":null,"permalink":"/posts/%E8%B0%B7%E6%AD%8C%E8%B5%84%E6%B7%B1%E7%A0%94%E5%8F%91%E4%BA%BA%E5%91%98%E7%BB%99%E5%87%BA%E7%9A%84nano-banana-pro%E5%8D%81%E4%B8%AA%E6%8A%80%E5%B7%A7/","section":"AI-Related Reposts","summary":"","title":"[Repost] 谷歌资深研发人员给出的Nano Banana Pro十个技巧","type":"posts"},{"content":"","date":"8 January 2026","externalUrl":null,"permalink":"/tags/nano-banana/","section":"Tags","summary":"","title":"Nano Banana","type":"tags"},{"content":"Reposted from Agent Skills 终极指南：入门、精通、预测 by 一泽Eze\n🎐 卷首语 # 应该是全网最好的 Skills 中文指南与教程，全文 1.2w 字，包含了我对 Skills 的完整应用思考。 巧借通用 Agent 内核，只靠 Skills 设计，就能低成本创造具有通用 AI 智能上限的垂直 Agent 应用。 顺便给朋友宇森、付铖的 Mulerun 打个广，他们在做全球性的 Agent 开发与交易市场，即将支持 Creator 用 Skills 开发垂直 Agent，可被用户使用 or 被其他 AI 产品调用。 @ 一泽Eze\nClaude Skills 的价值，还是被大大低估了。\n一个好 Skill 能发挥的智能效果，甚至能轻松等同、超越完整的 AI 产品。任何不懂技术的人，都能开发属于自己的 Skills。\n比如我自己做的 Article-Copilot，一个 skill 就实现了从素材处理到正文写作的 Agent 应用；\n又如 AI Partner Skill，让通用 Agent 深度学习你的记忆，塑造懂你的 AI 伴侣，给到个性回应。\n在研读 Anthropic 官方技术博客，与持续 Agent Skill 实验之后，形成了这份全网最完整的 Skill 指南，包含：\n1.最容易读懂的 Skills 概念与原理介绍 2.讨论 Skills 的真实价值、技术优势、对 AI 产品设计的影响 3.非常完整的 Skills 使用与开发教程 4.Skills 的场景识别，什么时候适合开发、使用 Skills？ 从概念澄清、运作机制，到实践教程、应用价值，与你在本期分享。\n文末会拉一个 Skill 中文社群，专项讨论与实践 Agent Skills，加入方式见底部。\n一、Skills 是什么：从概念来源到运作原理 # 2025 年 10 月中旬，Anthropic 正式发布 Claude Skills。\n两个月后，Agent Skills 作为开放标准被进一步发布，意在引导一个新的 AI Agent 开发生态。\nOpenAI、Github、VS Code、Cursor 均已跟进。\n为了更好的理解，你可以把 Skills 理解为“通用 Agent 的扩展包”：\nAgent 可通过加载不同的 Skills 包，来具备不同的专业知识、工具使用能力，稳定完成特定任务。\n最常见的疑惑是：这和 MCP 有什么区别？\nMCP 是一种开放标准的协议，关注的是 AI 如何以统一方式调用外部的工具、数据和服务，本身不定义任务逻辑或执行流程。 Skill 则教 Agent 如何完整处理特定工作，它将执行方法、工具调用方式以及相关知识材料，封装为一个完整的「能力扩展包」，使 Agent 具备稳定、可复用的做事方法。 以 Anthropic 官方 Skills 为例：\nPDF：包含 PDF 合并、拆分、文本提取等代码脚本，教会 Agent 如何处理 PDF 文件 - 提取文本，创建新的 PDF、合并或拆分文档。 Brand-guidelines：包含品牌设计规范、Logo 资源等，Agent 设计网站、海报时，可参考 Skill 内的设计资源，自动遵循企业设计规范。 Skill-Creator：把创建 Skill 的方法打包成元 Skill，让 AI 发起 Skill 创建流程，引导用户创建出符合需求的高水准 Skill。 Skill-Creator：教 Agent 如何帮用户创建新 Agent 的技能\n但 Skills 的价值上限，远不止于此。\n它应该是一种极其泛用的新范式，从垂直 Agent 到 AI 产品开发：借用通用 Agent 内核，0 难度创造具备通用 AI 智能的垂直 Agent 应用。\n本文开头提到的 article-copilot、AI Partner Skill，就是对这种可能性的验证。\n让我们从 Skill 的运作原理讲起。\n首先，如何理解 Skill？ # Anthropic 说：\nSkills 是模块化的能力，扩展了 Agent 的功能。每个Skill 都打包了 LLM 指令、元数据、可选资源（脚本、模板等），Agent 会在需要时自动使用他们。\n我有个更直观的解释：Skill 就像给 Agent 准备的工作交接 SOP 大礼包：\n想象你要把一项工作交给新同事。若不准口口相传，只靠文档交接（而且你想一次性交接完成，以后不被打扰），\n你会准备什么？\n任务的执行 SOP 与必要背景知识（这件事大致怎么做） 工具的使用说明（用什么软件、怎么操作） 要用到的模板、素材（历史案例、格式规范） 可能遇到的问题、规范、解决方案（细节指引补充） ⬇️\nSkill 的设计架构，几乎是交接大礼包的数字版本：\n相对标准的 Skill 结构示例，实际案例中，只有 SKILL.md 是必需的，其他结构为可选项\n在 Skill 中，指令文档用于灵活指导，代码用于可靠性调用，资源用于事实查找与参考。\n当 Agent 运行某个 Skill 时，就会：\n1.以 SKILL.md 为第一指引 2.结合任务情况，判断何时需要调用代码脚本（scripts）、翻阅参考文档（ref.）、使用素材资源（assets） 3.通过“规划-执行-观察”的交错式反馈循环，完成任务目标 当然，Skill 也可以用来扩展 Agent 的工具、MCP 使用边界，通过文档与脚本，也可以教会 Agent 连接并使用特定的外部工具、MCP 服务。\n举个例子，这是 PPTX Skill 的文件目录：\n整个文件夹就是一个完整的能力包，用来支持 AI 创建、编辑和分析 PowerPoint 演示文稿。\n核心文件是 SKILL.md，包含技能的元数据和任务指导，告诉 agent 什么时候使用这个技能、如何按步骤处理任务。\n特别的，独立子技能往往会被拆为子文档（如教 AI 把 html 导出为 pptx 流程的 html2pptx.md），以避免一次性加载过长的 skill 文档，节省上下文窗口\nScripts/ 包含 Agent 可用的各类预先写好的程序脚本，比如 html 转 pptx 的一键程序脚本。这样 Agent 运行任务时就无需临时开发工具，直接调用，节省 tokens ，避免出错，提升速度\n也有一些参考文档（此项目打包的不算规范，但根据 SKILL.md ，Agent 也能理解哪些文档可以参考），比如 ooxml.md，是对 ooxml 格式文件的解析指南\n整个 Skill 以简明的形式，把技能指引文档、代码脚本、参考文档和可用资源组合，定向扩展了 Agent 完成 pptx 生成相关的工作能力。\nSkills 的真实价值：垂直 Agent 的未来态 # 看好 Skills 价值与未来生态发展的原因是，Skills 与其他 AI 应用开发方式，有底层机制的不同：\n人给出专业知识与工具方法，通用 Agent 提供智能，自主理解，主动执行。\n说人话就是：人给指引，最终 Agent 还能根据自己的智力看着执行。\n而且「Agent + 文件」的形式，足够泛用。\n这就相较于它的前辈们（Workflow 和程序编写的 AI 应用）有了 3 个关键优势：\n非技术人员可用零代码、自然语言编写 能突破预设限制，灵活响应用户输入，应对边缘情况 甚至能多个 Skill 自由联用，应用方式极其灵活 这一部分可能会比较深入，但例证完善，实际上不会很难懂。虽一家之言，但仍有助于理解 Skill 价值与 Agent 发展趋势\n1. 零代码、自然语言，编写真·智能 Agent # 纵观此前的 AI 应用开发方法：\n不必多说程序编写的 AI 应用，必须懂程序逻辑、懂技术实现。 即便是 Coze、Dify、N8N 等近年流行的 Workflow 平台，也得理解节点配置、条件分支，仍算「编程」，只是界面友好一些。 而 Skills 的创建门槛，完全不同：入门门槛极低，智能上限极高。\n1）最简单的，以 Anthropic 的 brand-guidelines skill 为例\n仅有一个 SKILL.md，纯自然语言写成。\n元信息：什么时候用这个 Skill 正文：品牌颜色、字体等文本描述信息 但足以引导 Agent 变成符合 Anthropic 品牌设计的垂直 Agent，可用于品牌官网、海报、PPT 设计。\n当你要设计一个符合 Anthropic 公司设计规范的 AI 搜索网站，Agent 就会自动运行该 Skill ⬇️\nSkill 有两种加载模式：显式 / 隐式。\n前者通过 user query 直接指定调用；后者根据任务与元信息描述的相关性，LLM 自动匹配。\n这是该 skill agent 一次性开发的网站，调性接近 Claude 官网设计：\n（我电脑上缺了他家的 Serif 字体，实际上可以更像）\n2）复杂的，以 AI-Partner Skill 为例，一个 Skill 就是一个复杂 Agent\n包含 SKILL 文档、向量数据库构建指南、向量数据库使用脚本、AI 伴侣与用户的 Persona 模板资源\nSKILL.md 本体依然由自然语言写成：\n借此，Agent 就能理解 AI-Partner 的初始化与对话方法，引导用户上传包含个人记忆的文档预料，在用户端智能切分笔记片段，构建向量数据：\n解析用户记忆文档，提炼个性化的 AI 伴侣与用户画像设定：\n最终智能检索用户记忆，提供懂用户的 AI Partner 对话体验：\n这能基本验证：单靠 Skill + Agent 所构造的垂直 Agent，所实现的智能效果，无异甚至可超过同类 AI 产品。\n而做这些垂直 Agent，都不用编写程序代码。\n非技术出身的领域专家，离自己做专业 Agent 只剩隔着一层窗户纸——\n把你的专业经验和工作流程，用文档形式写清楚，Agent 就能照着执行。\n2. 突破预设限制，灵活应对实际情况 # Agents Skill 的这一优势往往被忽视。\nWorkflow 或 传统程序 的核心问题是，它们假设所有情况都能预设。\n比如基于用户记忆的 AI 个性化助理，往往需要提前设定：\n用户导入记忆文件的入口 允许用户上传的文件格式 数据应该包含哪些字段 以及可能出现哪些特殊情况，每种情况如何处理。\n但现实往往是：\n需要教育用户在哪点击「导入」 用户只有预期之外的格式：预期支持 md，但实际只有 doc 数据字段不符：预期每个文件需要一个标题，但用户文件没有标题 或者出现了预设之外的边缘情况。\n这时 Workflow 或传统程序就卡住了，它只能按预设路径执行，遇到意外就报错，或要求用户自行消除差距。\n而通用 Agent + Skill 应用的运作方式完全不同：\n能在统一的对话框，接收各类用户数据（文本、文件、图片） 能自主调用其他 Skill，或即时编写 doc2md 脚本，自动转换用户格式 能提炼补充每个文件的标题，完成数据入库处理 能基于 LLM 的推理智能，弥合各类边缘问题 用 Skill 做的垂直 Agent，以 Skill 的知识与方法为指引，能巧借 Agent 内的 LLM 智能，灵活应对各类问题。\n所以在 AI-Partner-Chat 中，也有过很有意思的探索：\n借 Agent 本身的“观察-规划-执行”的动态智能，对用户文档进行自适应切片，而非所有文件都按照固定的分隔符 or 字数切分。\n（DailyNotes 按照日期标题切分；项目笔记按照标题级别与语义切分）\n这样能得到更符合实际情况的 RAG 切片。\n3. 多 Skills 自由联用 # Agent Skills 实质仍是 Context 工程，Skills 只是把垂直领域的知识、脚本调用方法等挂载到 Agent 的上下文窗口。\n所以 Skills 在实际应用中极其灵活，甚至在一次任务中能调用多个 Skill。\n比如：\n联用 brand-guidelines + pptx，自动制作符合品牌规范的 pptx 联用 AI-Partner-Chat + Article-Copilot，写出更符合个人思考与文风的内容 也可以是更复杂的场景，如做一份产品分析报告：\n1.从网页抓取竞品数据（Web Scraping Skill） 2.提取 PDF 中的用户反馈（PDF Skill） 3.分析数据并生成图表（Data Analysis Skill） 4.按品牌规范制作 PPT（Brand Guidelines + PPTX Skill） 每多一个 Skill，就多一种能力，N 个 Skill 可以应对远超 N 的应用场景。\n☞ Skills 核心运行机制：渐进式披露 # 这节旨在讲解 Skills 运作的核心机制之一：渐进式披露。\n整体更偏技术理解，如果只是想用 or 做 Skill，可以滑到下一部分\n正如 有效的 Context 工程 所论证的，上下文过长容易导致模型能力下降。\n由于 Skills 的本质就是 Context 工程，所以这个问题也需在 Skill Agent 中注意。\n一个完整装载了 Skill 的 Agent 架构是这样的：\nSkill 包放在 Agent 文件系统（右侧）中，并非默认全量加载在 Context Window 中。\n根据 Context 加载顺序、优先级的不同，Skill 被划分为了 3 种层级：\nSkill 内容物的 3 种渐进披露优先级\n渐进披露的流程图解\n1）Level 1（元数据，始终加载）：\nSKILL.md 文档内的元数据，包含名称与用途描述。长度约 100 tokens。\nAgent 启动时，就在 Context Window 中加载 Skill 元数据，将其包含在系统提示中。\nAI 通过理解用户消息与 Skills 元数据的匹配情况，判断是否需要自动使用技能。\n---name: pdfdescription: 全面的 PDF 操作工具包，用于提取文本和表格、创建新 PDF、合并/拆分文档以及处理表单。当 Claude 需要填写 PDF 表单或大规模地程序化处理、生成或分析 PDF 文档时使用。--- 默认只加载元数据 → 意味着可以给一个 Agent 同时安装很多 Skills 但不影响上下文性能。\n2）Level 2（指令，触发时加载）：\nSKILL.md 文档内的正文内容，也就是主要技能指令，一般包含工作流程、最佳实践和指导。\n建议少于 5000 tokens。\n当用户发出的消息与Skill 元数据的描述匹配，需要调用 Skill 时，Agent 才会用 bash 读取文档正文 。读取时文档内容加载到 Context Window 中。\nSKILL.md 的结构：分为 YAML 元数据与 MD 正文\n3）Level 3（子技能指令 / 资源 / 代码，按需动态加载）：\n由子技能文档、代码脚本、参考文档、可用资源等文件构成。\n也有 Agent Skill 规范文档将它们统称为「Resource」。相对来讲，Level 3 结构要求没那么严谨。\nSub-SKILL.md 子技能文档：相对独立、复杂的子技能指令，单独放在 Level3 拆分加载\n随着一个 Skill 的复杂度提升，可能因为技能知识的上下文过长，或者有些知识仅在特定场景使用，而不适合放入单个SKILL.md，可被分拆为独立指令文档，仅在必要时加载。\nScripts 代码脚本：视作“Agent 的可执行资源”，而不算 tool use（tool use 是 Agent 外部调用的独立服务）\nAgent 在 Agent 电脑（虚拟机）中直接调用脚本，脚本代码本身不进 Context Window，只有脚本运行完成后的输出会进 Agent 的 Context。\nReference 参考文档、Assets 可用资源，当然都是 Level 3，仅在必需时动态读取加载。\nLevel 3 因为按需加载的特性，文件在被访问前不会占用 Context 长度，所以没有内容大小限制，可按业务实际说明需要添加材料。\n⬇️\n小结：整个 Skill 运行过程中，Agent 自动判断哪些技能与任务相关，根据 skills 的元信息，动态判断、加载完成任务所需模块：\nLevel 1: SKILL.md 元数据（name + description） ↓Level 2: SKILL.md 完整内容 ↓Level 3: Resources 中的具体文件（按需读取） 公众号 @言午 在《Claude Skills背后的信息分层设计哲学》一文中，亦有形象的图解：\n不过，即使 Agent Skill 支持「渐进式披露」。\n但在商业化的 Agent 产品中，单个或多个 Skills 联用，如何稳定控制运行过程中的 Context 长度，依然是绕不过的工程问题。\n☞ Skills 对 AI 产品设计的影响 # 我先和在做 Agent 平台的朋友 @付铖 讨论了一个问题：\n基于 Skills 做的垂直 Agent 应用，会不会有依赖推理，响应速度降低的问题？\n我俩是在 Mulerun Agent 开发者闭门会认识的，当时觉得他的 Agent 认知相当深刻。他负责的正是 Mulerun 平台的产品策划与研发。\n他给了一组很有意思的启发：\n1.Skills 是一种非常宽容的 Agent 设计架构 2.Skills 可以被设计为很多 tokens 的指令文档，引导模型思考；也可以是无需思考的简单指令，直接指向可直接运行的脚本代码 3.因为 Skills 能直接调用代码逻辑，不进 Context 窗口。所以用 skill 也不需要 agent 一直推理，agent 也可以只承担类似 hook 的角色，实质上和正常程序运行并无差别 4.所以 Skills 慢起来可以是 prompt，快起来也可以是 workflow 另外，再结合两个趋势的极端判断：\n1.token 价格会下降 2.agent 速度会提升 这么看来，以 Skills 为基础的垂直 Agent，在性能、开销上的问题，也不是不可解决的持续性问题了。\n所以，进一步推演未来 ai native 产品的发展趋势，我目前的猜测是：\n拿笔记类 APP 举例，大部分 APP 的逻辑还是：新笔记 -\u0026gt; 代码 -\u0026gt; 处理。新笔记完全用代码逻辑，原模原样直接入库。\n但如果是 ai native 式的笔记 APP，他们可能会内置一些类似 skill 的指引，包括笔记入库、智能纠错、冗余笔记合并等。这些 skill 有些可能以 prompt 为主（需要生成），有些基本只有代码逻辑（快速响应）。\n当用户写新笔记时，ai 快速自行判断：能不能直接入库？要不要智能纠错？有没有冗余的历史相似笔记需要合并？\n每种情况，都由 agent 拿着各种 skills 自动匹配来处理。\n这样下来，Skills-based 的 Agent 产品，就能用同一个多模态输入框，处理用户各种不同的输入，也能灵活应对未被规划的边缘问题、为用户提供绝对个性化的生成需求了。\n二、Skills 完全教程：制作与使用 # 如果你看到了这里，那 Skills 对于 AI 应用开发的价值就不言而喻了：\n巧借通用 Agent 内核，只关注 Skills 设计，能低成本创造兼具通用 AI 智能上限的垂直 Agent 应用。\n对于 Agent 开发者，尤其是非技术出身的团队 or 业务人员，是极大的开发利好：\n1.0 代码创造 Agent 应用，仅靠“写文档”的方式，人人能做出可解决问题的垂直 Agent 2.无需过度关注 Agent 工程技术细节，凭借通用 Agent 智能，Skill Agent 能够自适应 Skill 设计中所缺失的代码、功能逻辑，甚至是自行在运行中克服 bug（虽有性能影响）。做 Demo、MVP、甚至小 Agent 应用，验证产品价值就非常容易 3.而且搓出来的垂直 Agent，兼具通用 AI 智能，有极其灵活的边界问题与个性化处理能力，智能上限极高。 那么，我们该如何开始使用 or 制作第一个 Skill？\n1️⃣ 教程：我该如何使用 Skills？（Claude Code 版） # 如果你已经会了，可跳过此部分；\n也可以把这大概率是全网最详细的 Skills 教程，转给初学的小伙伴们\n使用 Skills 的方式很多，我先推荐一种自己用最多的本地方法，Claude Code（简称 CC）。\n注意：只是使用工具，Claude 模型并非必需\nBTW：codex、cursor 等工具也逐步在支持 skill 的使用，有兴趣可以自行探索。\n开个玩笑：\nClaude Code 是 Anthropic 推出的 coding 工具 ❌ Claude Code 是 Anthropic 自己都没想到的通用 Agent 框架 ✅ CC 能做的事情远不止 AI Coding：它能代替我们操作电脑，包括搜索网页、操作浏览器、访问文件，以及使用电脑底层命令、运行 python 脚本等行为。\n这就意味着 CC + Skills，就等于跑在自己电脑上的垂直 Agent。通过安装或自行创建不同的 Skills，就可以完成：\n搜索网络信息，总结感兴趣的资讯日报； 自动化翻阅项目文件夹，输出项目复盘文档； 以及其他不同的 Agent 任务。 使用方法其实并不复杂，只是需要一些耐心：\nStep 1：安装 Claude Code # 如果从未安装过 Claude Code，请打开「终端/命令行」工具：\n遵循官方安装指引 https://code.claude.com/docs/en/quickstart#native-install-recommended ，完成 Claude Code 安装。\n推荐直接把官方指引链接，按以下 Prompt 发给任意 AI（ChatGPT、Kimi 都行），让它一步步教你。\n我是电脑小白，参考以下信息，一步步指导我在【Mac/windows/linux】终端中安装该程序：【此处粘贴替换为官方安装指引文本】当我遇到疑惑或报错时，我会把终端的日志发给你，请帮我解决。 AI 就会这样教你安装：\n遇到问题就截图给它，基本都能教你解决。\n安装后，终端里输入claude \u0026ndash;version，看到版本号，则这一步安装成功。\nStep 2：如果不用 Claude 模型，请替换模型 # 现在大部分国产模型都已经支持了 Skill 的使用与创建。\n❶ 你可以用「模型名称 + Claude Code」的关键词去网上搜索模型厂商官方的 Claude Code 模型接入教程。\n目前比较推荐的是 GLM 4.7、Kimi K2-thinking 或新版本。\n发送以下 Prompt 给 AI 对话，就能得到详细的人话指导了：\n我是电脑小白，指导我根据【替换为教程链接】，并替换 claude code 内的模型。Claude Code 已经装好了 ❷ 另外，也有一些好用的 Claude Code 模型管理工具，比如「CC Swtich」，项目地址为 https://github.com/farion1231/cc-switch\n同样打开 AI，发送以下 Prompt，就能学会如何使用：\n我是电脑小白，指导我如何安装【项目地址】，并替换 claude code 内的模型，我要用的是【模型名称】 Step 3：安装并使用 Skills # 正式使用 Claude Code 之前，建议在任意目录下创建一个空文件夹，比如叫 test，再在终端内切换到对应文件目录：\n然后在终端输入claude，就可以启动 CC 了，看到下图就是启动成功了\n这一步能把 Claude Code 的后续 AI 行为，都局限在该目录，减小对本地电脑其他文件的影响。\n❶ 在安装 Skill 之前，你需要先获取需要的 Skill 文件包。\n比如官方 Skills 仓库：https://github.com/anthropics/skills/tree/main，里面就有很多已经做好的 Skills。\n你可以让 CC 替你自动安装 Skill，比如在 CC 中发送 安装 skill，skill 项目地址为：\u0026lt;skill 项目地址\u0026gt;\n❷ 也可以手动下载 Skill，把文件包解压后，放在 skills 安装目录下：\n可以在当前项目文件夹的/.claude/skills/目录下，放入要安装的 skill 文件包：（如图为正确的项目 skills 路径配置）\n也可以选择全局目录～/.claude/skills/（所有项目都能共享放在全局目录的 Skill）\n❸ 完成安装后，记得重启 CC 👉 退出终端再打开就行，或者双击 ctrl+c 终止 CC 进程）\n⬇️\n要使用 Skill 时，\n只要在装好后的 CC 中，发送开始使用\u0026lt;skill 名称\u0026gt;，\n或者用户消息与 skill 元数据的描述匹配，\n就能自动调用 Skills，执行任务。\n之前实验 AI-Partner Skills 分享过的 step by step 教程，能进一步体验复杂 Skill 的智能上限。非常细致，值得参考：\n只用 Claude Skills，打造专属 AI 伴侣｜附完整教程\n👉 怎么找到好用的 Skills 呢？ # 你应该也看出来了，在面向 to C 用户（也就是自己日常使用）时，以上的方法有两个问题：\n使用步骤确实比日常的 APP 复杂不少 比较难找到想用的 Skills 常规方法是找规模比较大的第三方 Skills 市场：https://skillsmp.com/zh\n但不难发现，现有大部分的 Skills 公开市场，没有完善的评价和精选体系，所有 Skill 缺少合理的分类与排序机制，导致很难找到需要的 Skills。\n可以看到仅靠 star 排序，是非常难找到合适的精选 Skill 的\n付铖他们的 Mulerun 最近就在研究解决这个问题，顺手给他们恰逢其时地推荐一下：\n他们在打造全球性的 Agent 市场，支持创作者在平台上开发并上架 Skill、N8N 等形式的 AI Agent 他们会帮助 Agent 创作者做全球分发、增长（类似 Agent 向的 APP Store），且上架 Mulerun 后，Agent 能被其他用户付费使用 Mulerun 也即将支持 Agent Skills 生态，还会有个好功能：一键运行并测试 github上公开的 skill repo（也就是省掉了 CC 那样配置 Skill 的步骤） 另外，还会引入自动评分、精选的 Skills 发现机制，帮助用户能够更好地找到自己需要的优质 Skills 2️⃣ 如何制作一个 Skill？ # 好，话说回来。\n如果你按照上文，学会了 Skill 安装与使用，那制作第一个 Skill 将会无比容易。\n我们需要用到 Anthropic 官方的一个 skill：skill-creator\n顾名思义，用来帮你自动开发 Skill 的 Skill（我的 AI-Partner 和 Article-Copilot Skills 也都借助了这个 skill，大幅提升开发 skill 的效率）\n❶ 首先是安装 skill-creator，skill 项目地址在：https://github.com/anthropics/skills/tree/main/skills/skill-creator，安装过程一如上面的教程，请 CC 来帮忙自动安装：\n❷ 安装完成后，即可调用 skill-creator 自动创建需要的 skill。\n比如，发送创建需求给 CC：\nCC 自动调用 skill-creator，编写 SKILL.md 与 pdf2word 脚本\n最终提示创建成功：\n你也可以试着：\n“创建 skill，能按照我写文章的行文风格写文章” “创建 skill，能自动整理近期 XX 领域的新闻日报”…… 👉 如何安装自己做好 skill ？\n这种方式做出来的 skill，会默认是xx.skill格式，会与 zip 或文件夹格式略有区别。是 skill-creator 创建的 skill 压缩格式。\n告诉 CC 指定 .skill 的文件地址，要求 cc 直接安装 skill 即可：\n如果是文件夹或者 zip，那就按上文的介绍，手动解压放到对应 skills 目录即可。\n👉 【进阶】如果你需要精调 skill，或者想完全手写一个 skill？\n更细节的 Skill 规格设计说明，请参考：https://agentskills.io/specification#skill-md-format\nBTW：Mulerun 本月也会开始内测 Agent Builder 功能，会着重用到 skill，对 skill 开发方法进一步优化。\n如果你想讨论 skill，可以去他们的社区：https://community.mulerun.com/t/topic/73 ，已经积累了一些开发者讨论（付铖回头记得请我吃饭啊喂）\n三、什么时候应该用 Skills？ # 概念、价值、教程，都讲完了，但更重要的问题是：\n什么场景值得“用 Skill 来解决”、“开发一个 Skill”？\n这个问题对于普通用户优化 AI 工作流程，开发者找 Skills Agent 创业机会，同样重要。\n根据 Anthropic 官方博客建议，与我的实际理解，梳理了 3 种明显的时机：\n1️⃣ 发现自己在向 AI 反复解释同一件事 # 最典型的信号是：为了完成某个任务，在多轮对话中，需要不断向 AI 解释一件事应该怎么做。\n比如：\n“帮我写一份技术文档”\n“不对，我们公司的技术文档格式是这样的……”\n“还有，代码示例要按这个模板来……”\n“上次不是说了吗，章节标题要三级标题……”\n“帮我分析这个数据”\n“先把 ＞ XX 的异常值筛掉”\n“不对，应该用中位数，不是平均值”\n“图表要按我们公司文档的配色方案……”\n这时候就该想到：与其每次都解释一遍，不如把这些规则打包成一个 Skill，一次创建永久复用。\n2️⃣ 某些任务需要特定知识、模板、材料才能做好 # 有时候是 AI 的通用能力够了，但缺“特定场景的知识材料”。\n典型场景：\n技术文档写作：需要参考代码规范、术语表，使用文档模板 品牌设计：需要参考品牌手册、色彩规范，使用 Logo 资源 数据分析：需要参考指标定义、计算公式，使用报表模板…… 这些都是「通用 Agent + 垂直知识」的典型场景：人提供材料，Agent 才能具备场景 Context。\n在 Skill 包里放对应的知识材料，比如把模板、规范、案例放到 Skill 的assets/、reference/目录，或者直接描述在SKILL.md中，\nAgent 就能一次性输出符合任务需要的精准结果。\n3️⃣ 发现一个任务要多个流程协同完成 # 有些任务更加复杂，往往需要“组合多个流程”才能完成。\n竞品分析报告：检索竞品数据 + 数据分析 + 制作 PPT 内容生产：收集参考资料 + 学习风格 + 大纲协作 + 正文写作 我相信你的工作环境里也有很多这种任务。\n把这类任务中每个环节的指令文档、可执行脚本、参考材料、可用资源打包成单个或多个 Skill 也是不错的 AI 解决方法。\n让Agent 根据任务描述，智能调用不同的 Skill 模块，通过“规划-执行-观察”的交错式行动，一次性完成原本需要多个流程协同完成的复杂任务。\n🎐 写在最后 # 写到这里，回到开头那个判断：Claude Skills 的价值，还是被大大低估了。\nSkills 是 Agent 的灵魂，就像 Steam 游戏 + 创意工坊一样。\n有了这种可扩展性极强的设计架构，Agent 开发者完全能巧借通用 Agent 内核，\n只需关注 Skills 本身的设计，就能低成本创造兼具通用 AI 智能上限的垂直 Agent 应用。\n对于Agent 创业者，乃至非技术的领域专家来说，Skills 无异代表了很多的新机会：\n垂直 Agent 工具，如果按传统方式开发，周期至少数周。\n但用 Skill 的方式，几小时甚至几分钟就能测试起来，且智力与能力上限也有机会直逼通用 Agent。\n⬇️\n这不是说 Agent Skill 必然全面替代传统开发。\n两种方式各有适用场景，但 Skill 确实让更多人、更多场景接入 Agent 能力变得更为可行：\n不必为了一个内部小工具开发完整产品，打包个 Skill 就能解决 不必说服 IT 团队理解你的需求，自己就能创建工具 不必等待产品迭代，你可以随时调整 Skill 的行为 从这个角度看，Skill 更是降低了验证想法的成本。\n另外再换一个思路：把 Skill Agent 服务打包为 AI API，是不是也能快速给已有的产品赋上好用的 AI 能力？\n现在还是 Skill 生态的早期，Agent Skills 开放标准发布不到 1 个月，工具在完善，社区在成长。\n但这个方向有意思的地方在于，终于能让更多人、组织、行业参与 AI 应用的创造了。\n👉 关于 skill 社群：\n关注本公众号⬇️，在聊天窗发送消息「skill」进群，与其他创作者交流经验，共同探索这个新兴生态的可能性。\n希望本文能对你有所启发，记得关注～\n也感谢你的点赞与分享：)\nRef. # Claude Doc - Agent Skills 说明：https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview Agent Skills 开放标准：https://agentskills.io/home Equipping agents for the real world with Agent Skills：https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills ","date":"7 January 2026","externalUrl":null,"permalink":"/posts/agent-skills-%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97%E5%85%A5%E9%97%A8%E7%B2%BE%E9%80%9A%E9%A2%84%E6%B5%8B/","section":"AI-Related Reposts","summary":"","title":"[Repost] Agent Skills 终极指南：入门、精通、预测","type":"posts"},{"content":"Reposted from Antigravity 九个技巧：从登录失败到生产力 by 阿南的技术手记\n下面这篇基本就是我从「卡在登录页」到「把它当成日常编码工具团一员」的高效使用具体指南，希望对你有用\n一、登录问题 # 登录不上去，也是劝退最多人的地方\n1.1 登录失败的本质原因 # Antigravity 的登录，本质不是“你账号不对”，而是账号地区不对。\n如果你使用的是 Google 账号登录，这里有一个隐藏前提：\n需要是美区 Google 账号\n否则，你会看到非常典型的一种状态：\n点击登录、页面显示登录成功、antigravity应用一点反应都没有\n不是你网络不好，是软件服务端根本没让你访问\n1.2 查看你的 Google 账号关联地区 # 你可以通过 Google 官方页面查看账号关联国家：\n查看条款归属 https://policies.google.com/terms\n查看 / 申请修改账号国家 https://policies.google.com/country-association-form\n如果你当前不是美区，有两个选择：\n提交地区修改申请（需要审核）\n直接新注册一个美区 Google 账号（更快）\n老实说，如果你是为了效率，第二种更干脆，相对也没有什么额外的风险。\n1.3 VPN 开 TUN（虚拟网卡）模式 # 这是另一个极其容易被忽略的点。\nAntigravity 并不是只在浏览器层访问外网，它本身会发起系统级网络请求。 所以呢，\n只开 HTTP / SOCKS 代理 → 不够的\n必须走 TUN / 全局虚拟网卡模式 → Antigravity才能网络畅通\n当然，你可以选择两种方案：\nVPN 开启 全局 TUN 模式\n或者使用 Proxifier，指定 Antigravity App 强制走代理\n如果你卡在登录界面 30 秒以上，90% 就是这个问题啦。\n由于我经常要开关TUN模式，我设置了一个操作开关的快捷键，效率提升不少。\n二、软件中文化 # 2.1 界面中文化 # 这一部分比较简单，Antigravity 本身基于VS Code，可以在扩展的应用商店里面搜索 \u0026ldquo;Chinese\u0026rdquo;，选择\u0026quot;Chinese(Simplified) (简体中文)\u0026ldquo;插件进行安装。\n安装完成之后，菜单、面板基本就能正常中文显示。\n2.2 返回内容中文化（关键点） # 但界面中文 ≠ 输出中文。\n如果你不做任何额外配置，大模型默认会：\n用英文回答你一切问题 而且非常“硅谷味”\n解决方式只有一个：全局 Rules。\n这是我目前在用的一份规则（简化版，供参考）：\ntrigger: always_on alwaysApply: true --- **核心理念与原则** 简洁至上：恪守 KISS（Keep It Simple, Stupid）原则 深度分析：立足第一性原理（First Principles Thinking） 事实为本：以事实为最高准则，欢迎纠错 **输出规范** 语言要求：所有回复、思考过程、任务清单，一律使用中文 固定指令：Implementation Plan, Task List and Thought in Chinese 经验结论只有一句话：\nRules 写得越清楚，你后面“调教”的成本越低。\n三、AgentManager # AgentManager 表面看起来像是“聊天列表”，但本质完全不同，不是多开窗口，而是任务隔离。\n它解决的是一个长期困扰工程师的问题：\n多个上下文同时进行时，如何避免模型串线？\n你可以：\n一个 Agent 做 需求功能开发\n一个 Agent 专门负责 代码重构\n一个 Agent 当 Review 工程师\n它们之间是上下文隔离的，不会互相污染。\n这点在复杂项目里，价值非常高，非常好用的一个点\n四、Plan vs Fast 模式 # 这是“思考深度”的开关，是 Antigravity 里我非常不错的设计，在做比较复杂的项目时候plan模式特别好用，下面我简单讲下两者的区别：\n4.1 Plan 模式：适合想清楚再动手 # Plan 模式下，Agent 会：\n拆解问题\n给出执行计划\n再逐步推进\n适合场景包括：\n技术方案设计\n架构重构\n深度调研\n多 Agent 协作任务\n对应Agent 在执行任务前进行规划。适用于深度研究、复杂任务或协作工作。\n在此模式下，智能体会将工作组织成任务组 ，生成结果交付物 ，并采取其他步骤来彻底研究、思考和规划工作，以达到最佳质量。\n4.2 Fast 模式：快速执行 # Fast 模式完全不同，此模式下 Agent 将直接执行任务。适用于可以快速完成的简单任务，例如重命名变量、启动几个 bash 命令或其他较小的局部任务。当速度至关重要，且任务足够简单，无需担心质量下降时，此模式非常有用。\n五、Playground：创意实验场 # Playground 更像是一个：\n** AI 游乐场， 想法的探索地**\n在这里你可以测试：\nPrompt 风格\n输出格式\nUI / 文案 / 设计想法\n任何有创意的想法\n它不追求一次就对，而是允许你反复试错。\n如果你平时需要做方案、写技术分享、甚至产品文案，这一块非常好用。\n六、Browser Agent # 浏览器自动化测试专员，Browser Agent 的定位非常明确：\n让 AI 像测试工程师一样“真的去点页面”\n它可以：\n自动打开网页\n点击按钮\n填表\n校验页面状态\n在以下场景非常实用：\n自动化测试验证\n后台配置回归检查\n简单爬取结构化信息\n这个Sub Agent拥有控制您浏览器所需的各种工具，包括点击、滚动、输入、读取控制台日志等等。它还可以通过 DOM 捕获、屏幕截图或 Markdown 解析来读取您打开的页面，以及录制视频。\n我更愿意理解为 Python + Selenium 根据页面情况实现自动化点击，确保产品交互的质量。\n我特别喜欢这个。\n七、Artifacts # Artifacts ：AI 给你的可交付物，是 Antigravity 非常重要一部分内容，它不是聊天记录，而是AI交付结果内容，非常的详细，包括：\n任务清单（Plan）\n实施计划（Task）\n屏幕截图\n浏览器录制内容\n使用方法（Walkthrough）\n知识\n这意味着你可以：\n把一次对话，沉淀成长期资产\n让 Agent 在旧 Artifact 基础上继续工作\n当天一些fast模式任务下的交付物会直接修改，并不会产生交付物，只有在复杂和长任务并且在plan模式下才会产生。\n八、Knowledge # Agents 会根据对话、工件（artifacts）和解决方案，从历史工作中提炼有用模式/上下文并添加到 Knowledge Base\n当 Agent 识别出某些对话/解决方案代表“可复用知识”时，它应该自动创建 Knowledge Item\n现实情况：目前并不会稳定自动生成 # 一些用户真实实际反馈：\n很多用户长时间交互后 Knowledge 页是空的多次运行任务却 没有任何生成条目即便你明确叫 Agent 把内容加到 Knowledge，也可能只生成 Markdown 文件而非 UI 可见条目\n功能可能仍在 Feature Flag 或实验阶段\n九、NanoBananaPro # 如果你平时有自己做一些产品，但你并不擅长UI设计等工作内容，当你任务有生成图片等任务时候，\n对应Agent 需要生成 UI 模型、需要图像来填充网页或应用程序 或者 生成系统或架构图或其他生成图像任务时，在生成图像会进行使用NanoBananaPro 内置的图像模型。\n这点也很强，集成了Banana模型，能直接使用 Nano Banana Pro，可以直接使用其生图能力。\n参考\nhttps://antigravity.google/docs/home\nhttps://antigravity.google/docs/models\nhttps://antigravity.google/docs/rules-workflows\nhttps://antigravity.google/docs/browser-subagent\nhttps://antigravity.google/blog/nano-banana-pro-in-google-antigravity\n","date":"7 January 2026","externalUrl":null,"permalink":"/posts/antigravity-%E4%B9%9D%E4%B8%AA%E6%8A%80%E5%B7%A7%E4%BB%8E%E7%99%BB%E5%BD%95%E5%A4%B1%E8%B4%A5%E5%88%B0%E7%94%9F%E4%BA%A7%E5%8A%9B/","section":"AI-Related Reposts","summary":"","title":"[Repost] Antigravity 九个技巧：从登录失败到生产力","type":"posts"},{"content":"","date":"7 January 2026","externalUrl":null,"permalink":"/tags/antigravity/","section":"Tags","summary":"","title":"Antigravity","type":"tags"},{"content":"Reposted from 5000字方法论：从零掌握 Claude Skill 撰写技巧 by DracoVibeCoding\nSkill 撰写方法论：如何写出优秀的 Claude 技能 # 本文档基于对 awesome-claude-skills 仓库中 40+ 个技能的分析总结，旨在帮助初学者快速掌握 Claude Skill 的撰写技巧。\n一、什么是 Skill？为什么要写 Skill？ # 简单来说，Skill 就像是给 Claude 装上的\u0026quot;插件\u0026quot;，让它学会特定的专长。\n想象一下：\n• 普通 Claude 像是一个通才，什么都知道一点\n• Skill 则像是给 Claude 配备的\u0026quot;专业工具包\u0026quot;，让它在特定领域变得专业\n写 Skill 的好处：\n1. 复用性强 - 写一次，可以反复使用，甚至分享给团队\n2. 上下文高效 - Skill 采用渐进式加载，只读取需要的内容\n3. 可维护 - 集中管理专业知识，便于迭代更新\n二、Skill 的\u0026quot;解剖学\u0026quot;：一个 Skill 由什么组成？ # 2.1 基本结构 # \u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code data-language-pending=\u0026#34;\u0026#34; data-raw-code=\u0026#34;skill-name/ ├── SKILL.md # 核心！必选，技能的主文档 ├── scripts/ # 可选，可执行代码（Python/Bash等） ├── references/ # 可选，参考资料（API文档等） ├── assets/ # 可选，模板资源 └── LICENSE.txt # 可选，许可证\u0026#34; data-show-line-number=\u0026#34;false\u0026#34; id=\u0026#34;code-lang-swift\u0026#34;\u0026gt;skill-name/├── SKILL.md \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp;# 核心！必选，技能的主文档├── scripts/ \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp;# 可选，可执行代码（Python/Bash等）├── references/ \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; # 可选，参考资料（API文档等）├── assets/ \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; # 可选，模板资源└── LICENSE.txt \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; # 可选，许可证\u0026lt;/code\u0026gt; 2.2 SKILL.md 的结构 # 每个 SKILL.md 都分为三部分：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;---name: skill-name # 必填！必须与目录名一致description: 简短描述 # 必填！用第三人称invocable: user # 可选，是否允许用户直接调用license: 完整条款见 LICENSE.txt # 可选---# 标题## 使用场景-\u0026amp;nbsp;场景 1-\u0026amp;nbsp;场景 2## 功能介绍...## 工作流程...## 示例...\u0026lt;/code\u0026gt; 三、撰写优秀 Skill 的五大原则 # 原则 1：描述要精准（第三人称原则） # YAML 描述字段必须用第三人称：\n❌ 错误写法：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-makefile\u0026#34;\u0026gt;description:\u0026amp;nbsp;使用这个技能来翻译文章...\u0026lt;/code\u0026gt; ✅ 正确写法：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-makefile\u0026#34;\u0026gt;description:\u0026amp;nbsp;翻译英文文章为简体中文\u0026amp;nbsp;Markdown\u0026amp;nbsp;格式...\u0026lt;/code\u0026gt; 为什么？ 因为描述会被系统读取，用第三人称让系统更准确理解技能用途。\n原则 2：指令要用祈使句（动词优先） # 在 SKILL.md 主体中，用\u0026quot;动词开头\u0026quot;的指令：\n❌ 错误写法：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code\u0026gt;你应该首先读取文件，然后分析内容...\u0026lt;/code\u0026gt; ✅ 正确写法：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code\u0026gt;首先读取文件，然后分析内容...\u0026lt;/code\u0026gt; 更简洁的版本：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-markdown\u0026#34;\u0026gt;1.\u0026amp;nbsp;读取文件2.\u0026amp;nbsp;分析内容\u0026lt;/code\u0026gt; 为什么？ 祈使句更直接、更易执行，减少歧义。\n原则 3：控制字数（黄金法则：5000 字以内） # SKILL.md 推荐字数分级：\n技能类型 推荐字数 示例 超简洁型 \u0026lt; 250 字 explaining-code (96 字) 简洁型 250-1000 字 internal-comms (211 字) 标准型 1000-2000 字 article-translator (1053 字) 详细型 2000-5000 字 skill-creator (1660 字) 超过 5000 字怎么办？\n• 把详细内容移到 references/ 目录\n• 把代码移到 scripts/ 目录\n• SKILL.md 只保留核心流程\n原则 4：渐进式信息组织 # 信息密度递减的组织方式：\n1. 顶部（必读） - 使用场景、触发条件\n2. 中部（流程） - 具体工作步骤\n3. 底部（参考） - API 文档、详细说明\n示例结构：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-perl\u0026#34;\u0026gt;---name: my-skilldescription: ...---# 技能标题## 什么时候使用 ← 用户最先看到-\u0026amp;nbsp;需求场景 A-\u0026amp;nbsp;需求场景 B## 这个技能能做什么 ← 快速了解价值1.\u0026amp;nbsp;功能一2.\u0026amp;nbsp;功能二## 使用步骤 ← 核心内容1.\u0026amp;nbsp;步骤一2.\u0026amp;nbsp;步骤二## 示例 ← 实际演示完整的工作流程示例...## 技术细节 ← 按需阅读API 参数、配置等...\u0026lt;/code\u0026gt; 原则 5：提供完整示例 # 好的示例应该：\n• 展示完整工作流程\n• 包含输入和输出\n• 覆盖常见场景\n示例模板：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-markdown\u0026#34;\u0026gt;## 示例 1：基本使用**用户输入：**\u0026lt;/code\u0026gt; 帮我整理 Downloads 文件夹\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code data-language-pending=\u0026#34;\u0026#34; data-raw-code=\u0026#34;**执行流程：** 1. 扫描 Downloads/ 目录... 2. 识别文件类型... 3. 创建分类文件夹... **输出结果：**\u0026#34; data-show-line-number=\u0026#34;false\u0026#34; id=\u0026#34;code-lang-markdown\u0026#34;\u0026gt;**执行流程：**1. 扫描 Downloads/ 目录...2. 识别文件类型...3. 创建分类文件夹...**输出结果：**\u0026lt;/code\u0026gt; ✓ 图片：847 个文件 → Pictures/\n✓ 文档：312 个文件 → Documents/\n✓ 安装包：156 个文件 → Installers/\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code data-language-pending=\u0026#34;\u0026#34; data-raw-code=\u0026#34;\u0026#34; data-show-line-number=\u0026#34;false\u0026#34;\u0026gt;\u0026lt;/code\u0026gt;\u0026lt;hr\u0026gt;\u0026lt;h2 data-heading=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;span leaf=\u0026#34;\u0026#34;\u0026gt;四、不同类型 Skill 的撰写模板\u0026lt;/span\u0026gt;\u0026lt;/h2\u0026gt;\u0026lt;h3 data-heading=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;span leaf=\u0026#34;\u0026#34;\u0026gt;类型 1：超简洁型（\u0026amp;lt; 250 字）\u0026lt;/span\u0026gt;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;\u0026lt;span leaf=\u0026#34;\u0026#34;\u0026gt;适用场景：\u0026lt;/span\u0026gt;\u0026lt;/strong\u0026gt;\u0026lt;span leaf=\u0026#34;\u0026#34;\u0026gt;\u0026amp;nbsp;简单指令、规则列表\u0026lt;/span\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;\u0026lt;span leaf=\u0026#34;\u0026#34;\u0026gt;模板：\u0026lt;/span\u0026gt;\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;span\u0026gt;\u0026lt;span leaf=\u0026#34;\u0026#34;\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;ellipse cx=\u0026#34;50\u0026#34; cy=\u0026#34;65\u0026#34; rx=\u0026#34;50\u0026#34; ry=\u0026#34;52\u0026#34; stroke=\u0026#34;rgb(220,60,54)\u0026#34; stroke-width=\u0026#34;2\u0026#34; fill=\u0026#34;rgb(237,108,96)\u0026#34;\u0026gt;\u0026lt;/ellipse\u0026gt;\u0026lt;span leaf=\u0026#34;\u0026#34;\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;ellipse cx=\u0026#34;225\u0026#34; cy=\u0026#34;65\u0026#34; rx=\u0026#34;50\u0026#34; ry=\u0026#34;52\u0026#34; stroke=\u0026#34;rgb(218,151,33)\u0026#34; stroke-width=\u0026#34;2\u0026#34; fill=\u0026#34;rgb(247,193,81)\u0026#34;\u0026gt;\u0026lt;/ellipse\u0026gt;\u0026lt;span leaf=\u0026#34;\u0026#34;\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;ellipse cx=\u0026#34;400\u0026#34; cy=\u0026#34;65\u0026#34; rx=\u0026#34;50\u0026#34; ry=\u0026#34;52\u0026#34; stroke=\u0026#34;rgb(27,161,37)\u0026#34; stroke-width=\u0026#34;2\u0026#34; fill=\u0026#34;rgb(100,200,86)\u0026#34;\u0026gt;\u0026lt;/ellipse\u0026gt;\u0026lt;span leaf=\u0026#34;\u0026#34;\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-csharp\u0026#34;\u0026gt;---name: simple-ruledescription: 简短描述---# 技能标题执行任务时，遵循以下规则：1.\u0026amp;nbsp;规则一2.\u0026amp;nbsp;规则二3.\u0026amp;nbsp;规则三## 注意事项-\u0026amp;nbsp;注意点 A-\u0026amp;nbsp;注意点 B\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt; 实际案例：explaining-code（仅 96 字）\n类型 2：流程型（500-1500 字） # 适用场景： 多步骤任务、工作流程\n模板：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-yaml\u0026#34;\u0026gt;---name: workflow-skilldescription: 描述这个工作流程...---# 技能标题## 使用场景-\u0026amp;nbsp;场景一：[具体描述]-\u0026amp;nbsp;场景二：[具体描述]## 核心功能1.\u0026amp;nbsp;**功能一**：[说明]2.\u0026amp;nbsp;**功能二**：[说明]3.\u0026amp;nbsp;**功能三**：[说明]## 执行流程### 阶段 1：准备1.\u0026amp;nbsp;[具体步骤]2.\u0026amp;nbsp;[具体步骤]### 阶段 2：执行1.\u0026amp;nbsp;[具体步骤]2.\u0026amp;nbsp;[具体步骤]### 阶段 3：验证1.\u0026amp;nbsp;[具体步骤]2.\u0026amp;nbsp;[具体步骤]## 示例### 示例 1：[场景名称]**用户请求：**\u0026lt;/code\u0026gt; \\[用户输入\\]\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code data-language-pending=\u0026#34;\u0026#34; data-raw-code=\u0026#34;**执行过程：** 1. [步骤一] 2. [步骤二] **输出结果：**\u0026#34; data-show-line-number=\u0026#34;false\u0026#34; id=\u0026#34;code-lang-css\u0026#34;\u0026gt;**执行过程：**1. [步骤一]2. [步骤二]**输出结果：**\u0026lt;/code\u0026gt; \\[预期输出\\]\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code data-language-pending=\u0026#34;\u0026#34; data-raw-code=\u0026#34;## 常见问题 **Q: [问题]** A: [答案]\u0026#34; data-show-line-number=\u0026#34;false\u0026#34; id=\u0026#34;code-lang-less\u0026#34;\u0026gt;## 常见问题**Q: [问题]**A: [答案]\u0026lt;/code\u0026gt; 实际案例：file-organizer, lead-research-assistant\n类型 3：API/技术型（1000-2000 字） # 适用场景： 调用外部 API、需要技术配置\n模板：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;---name: api-skilldescription: 技术描述...---# 技能标题## 概述[简要说明这个 API 的用途和优势]## 使用场景-\u0026amp;nbsp;[场景一]-\u0026amp;nbsp;[场景二]## 前置要求### 环境变量```bashexport API_KEY=\u0026#34;your-api-key\u0026#34;export API_ENDPOINT=\u0026#34;https://api.example.com\u0026#34;```\u0026lt;/code\u0026gt; 依赖项 # • Python 3.8+\n• requests 库\n调用方式 # 方式一：使用脚本 # \u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;python scripts/api_router.py --prompt\u0026amp;nbsp;\u0026#34;文本描述\u0026#34;\u0026amp;nbsp;--output output.png\u0026lt;/code\u0026gt; 方式二：直接 API 调用 # \u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-python\u0026#34;\u0026gt;import\u0026amp;nbsp;requestsresponse = requests.post(\u0026amp;nbsp; \u0026amp;nbsp; \u0026#34;https://api.example.com/generate\u0026#34;,\u0026amp;nbsp; \u0026amp;nbsp; headers={\u0026#34;Authorization\u0026#34;:\u0026amp;nbsp;f\u0026#34;Bearer\u0026amp;nbsp;{API_KEY}\u0026#34;},\u0026amp;nbsp; \u0026amp;nbsp; json={\u0026#34;prompt\u0026#34;:\u0026amp;nbsp;\u0026#34;...\u0026#34;})\u0026lt;/code\u0026gt; 参数参考 # 参数 类型 必填 说明 示例 prompt string ✅ 文本描述 \u0026ldquo;a cat\u0026rdquo; size string ❌ 图片尺寸 \u0026ldquo;1024x1024\u0026rdquo; 错误处理 # 错误代码 说明 解决方案 401 API Key 无效 检查环境变量 429 请求超限 等待后重试 示例 # 示例 1：基础调用 # \u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;python scripts/api_router.py --prompt\u0026amp;nbsp;\u0026#34;一只猫\u0026#34;\u0026amp;nbsp;--size 1024x1024\u0026lt;/code\u0026gt; 示例 2：批量处理 # \u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;# 批量调用示例代码\u0026lt;/code\u0026gt; \u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code data-language-pending=\u0026#34;\u0026#34; data-raw-code=\u0026#34;**实际案例：** \u0026#34; nanobanana-router=\u0026#34;nanobanana-router\u0026#34; doubao-tts-router=\u0026#34;doubao-tts-router\u0026#34; markdown=\u0026#34;markdown\u0026#34; meta-skill=\u0026#34;meta-skill\u0026#34; data-show-line-number=\u0026#34;false\u0026#34; id=\u0026#34;code-lang-markdown\u0026#34;\u0026gt;**实际案例：** `nanobanana-router`, `doubao-tts-router`---### 类型 4：元技能型（1500-3000 字）**适用场景：** 教授如何创建/管理其他技能**模板：**```markdown---name: meta-skilldescription: 这是一个元技能...---# 技能标题## 什么是 [概念]？[概念定义和价值说明]## 何时使用此技能- [使用场景]- [使用场景]## 创建流程概览\u0026lt;/code\u0026gt; 理解 → 规划 → 初始化 → 编辑 → 打包 → 迭代\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code data-language-pending=\u0026#34;\u0026#34; data-raw-code=\u0026#34;## 详细步骤 ### 第一步：[步骤名称] **目标：** [这一步要达成什么] **操作：** 1. [子步骤] 2. [子步骤] **检查点：** [如何验证这一步完成] ### 第二步：[步骤名称] ...（继续每个步骤） ## 最佳实践 ### 实践 1：[名称] [说明 + 示例] ### 实践 2：[名称] [说明 + 示例] ## 参考资源 详细文档请参考： - \u0026#34; references=\u0026#34;references\u0026#34; data-show-line-number=\u0026#34;false\u0026#34; id=\u0026#34;code-lang-css\u0026#34;\u0026gt;## 详细步骤### 第一步：[步骤名称]**目标：** [这一步要达成什么]**操作：**1. [子步骤]2. [子步骤]**检查点：** [如何验证这一步完成]### 第二步：[步骤名称]...（继续每个步骤）## 最佳实践### 实践 1：[名称][说明 + 示例]### 实践 2：[名称][说明 + 示例]## 参考资源详细文档请参考：- `references/xxx.md` - [说明]- `references/yyy.md` - [说明]\u0026lt;/code\u0026gt; 实际案例：skill-creator, mcp-builder\n五、实用技巧清单 # ✅ 推荐做法 # 技巧 说明 示例 使用编号列表 清晰展示步骤顺序 1. 读取文件 2. 分析内容 提供多种示例 覆盖不同使用场景 示例 1：基础用法 示例 2：高级用法 使用表格 整理参数、配置信息 参数 类型 说明 标注代码块 明确语言类型 ```python ```bash 使用表情符号 增强可读性（适度使用） ✅ 成功 ❌ 失败 ⚠️ 注意 分段引用 避免长文本 参见 references/api.md 明确触发词 列出用户可能用的表达 当用户说\u0026quot;翻译文章\u0026quot;、\u0026ldquo;convert to Chinese\u0026quot;时 ❌ 避免做法 # 问题 说明 改进 第二人称指令 \u0026ldquo;你应该\u0026hellip;\u0026rdquo; 改为祈使句：\u0026ldquo;执行\u0026hellip;\u0026rdquo; 过度解释 重复概念说明 删除冗余，保持简洁 缺少示例 只有理论 添加具体示例 混乱结构 信息随意堆砌 按优先级组织 过长文件 SKILL.md 超过 5000 字 拆分到 references/ 六、命名规范 # 6.1 目录命名 # 规则： 全小写，用连字符分隔\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code data-language-pending=\u0026#34;\u0026#34; data-raw-code=\u0026#34;✅ article-translator/ ✅ nanobanana-router/ ✅ file-organizer/ ❌ articleTranslator/ ❌ nanobanana_router/ ❌ File Organizer/\u0026#34; data-show-line-number=\u0026#34;false\u0026#34; id=\u0026#34;code-lang-swift\u0026#34;\u0026gt;✅ article-translator/✅ nanobanana-router/✅ file-organizer/❌ articleTranslator/❌ nanobanana_router/❌ File Organizer/\u0026lt;/code\u0026gt; 6.2 YAML name 字段 # 必须与目录名完全一致：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;---name:\u0026amp;nbsp;article-translator\u0026amp;nbsp;# 必须匹配目录名description:\u0026amp;nbsp;...---\u0026lt;/code\u0026gt; 6.3 描述字段写作 # 用第三人称，完整句子：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;# ✅ 好的描述description:\u0026amp;nbsp;翻译英文文章为简体中文\u0026amp;nbsp;Markdown\u0026amp;nbsp;格式。当用户提供英文文章\u0026amp;nbsp;URL\u0026amp;nbsp;并请求翻译时使用此技能。支持保留原有结构和图片。# ❌ 不好的描述description:\u0026amp;nbsp;翻译文章\u0026lt;/code\u0026gt; 描述三要素：\n1. 功能 - 做什么\n2. 触发条件 - 什么时候用\n3. 关键特性 - 支持什么\n七、文件组织策略 # 7.1 什么时候创建 scripts/？ # 需要脚本的情况：\n• 代码会被反复调用\n• 需要确定性执行结果\n• 逻辑复杂，不适合在文档中重复描述\n示例：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-shell\u0026#34;\u0026gt;# scripts/my_helper.pydef\u0026amp;nbsp;process_data(input_data):\u0026amp;nbsp; \u0026amp;nbsp; \u0026#34;\u0026#34;\u0026#34;复杂的数据处理逻辑\u0026#34;\u0026#34;\u0026#34;\u0026amp;nbsp; \u0026amp;nbsp; # ...\u0026amp;nbsp; \u0026amp;nbsp; return\u0026amp;nbsp;result\u0026lt;/code\u0026gt; 7.2 什么时候创建 references/？ # 需要参考资料的情况：\n• API 文档（参数、端点等）\n• 长篇技术规范\n• 需要按需加载的内容\n示例：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code data-language-pending=\u0026#34;\u0026#34; data-raw-code=\u0026#34;references/ ├── api_docs.md # API 完整文档 ├── schema.md # 数据结构说明 └── troubleshooting.md # 故障排查指南\u0026#34; data-show-line-number=\u0026#34;false\u0026#34; id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;references/├── api_docs.md \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp;# API 完整文档├── schema.md \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp;# 数据结构说明└── troubleshooting.md \u0026amp;nbsp;# 故障排查指南\u0026lt;/code\u0026gt; 7.3 什么时候创建 assets/？ # 需要资源文件的情况：\n• 输出模板（HTML、Markdown 等）\n• 图片、字体、样式表\n• 配置文件模板\n八、测试你的 Skill # 8.1 自检清单 # 创建 Skill 后，检查以下项目：\n•目录名与 YAML name 字段一致\n•描述字段用第三人称\n•SKILL.md 使用祈使句\n•包含使用场景部分\n•包含至少一个完整示例\n•字数控制在 5000 字以内\n•代码块标注了语言类型\n•文件结构文档（如果有多目录）\n8.2 实际测试 # 1. 在 Claude.ai 中测试： 上传技能目录，测试各种用户输入\n2. 检查触发准确性： 技能是否在正确的时候被激活\n3. 验证输出质量： 输出是否符合预期\n4. 收集反馈： 让其他人试用并收集意见\n九、常见问题 FAQ # Q1: SKILL.md 太长怎么办？\nA: 将详细内容移到 references/ 目录，SKILL.md 中添加引用：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;完整的 API 文档请参考\u0026amp;nbsp;`references/api_docs.md`\u0026lt;/code\u0026gt; Q2: 代码应该放在 SKILL.md 还是 scripts/？\nA: 判断标准：\n• 只展示一次 → 放 SKILL.md\n• 会反复调用 → 放 scripts/\n• 复杂逻辑 → 放 scripts/\nQ3: 如何让 Skill 更容易被触发？\nA: 在描述和使用场景中包含：\n• 用户可能用的关键词\n• 同义表达\n• 常见请求模式\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-vbnet\u0026#34;\u0026gt;description:\u0026amp;nbsp;翻译英文文章。当用户请求\u0026#34;翻译\u0026#34;、\u0026#34;translate\u0026#34;、\u0026#34;转换为中文\u0026#34;时使用。\u0026lt;/code\u0026gt; Q4: 可以在一个 Skill 中调用另一个 Skill 吗？\nA: 技术上可以，但建议保持 Skill 独立性。如果需要共享代码，考虑：\n• 创建共享的 scripts/\n• 在 references/ 中引用\nQ5: Skill 与 Claude Prompt 的区别？\nA:\n特性 Skill Prompt 复用性 高（可反复调用） 低（一次性） 上下文管理 渐进式加载 全量加载 版本控制 支持 困难 分享 易于分发 需要复制粘贴 十、进阶技巧 # 10.1 条件分支处理 # 使用明确的条件判断：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-css\u0026#34;\u0026gt;## 执行流程1.\u0026amp;nbsp;**判断输入类型：**\u0026amp;nbsp; \u0026amp;nbsp;-\u0026amp;nbsp;如果是 URL → 执行 [步骤 A]\u0026amp;nbsp; \u0026amp;nbsp;-\u0026amp;nbsp;如果是文件路径 → 执行 [步骤 B]\u0026amp;nbsp; \u0026amp;nbsp;-\u0026amp;nbsp;如果是纯文本 → 执行 [步骤 C]2.\u0026amp;nbsp;**根据判断结果：**\u0026amp;nbsp; \u0026amp;nbsp;-\u0026amp;nbsp;[对应步骤]\u0026lt;/code\u0026gt; 10.2 参数化处理 # 对于需要用户输入的参数，明确说明：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-go\u0026#34;\u0026gt;## 必需参数-\u0026amp;nbsp;`source_path`：源文件路径（必需）-\u0026amp;nbsp;`output_format`：输出格式，可选\u0026amp;nbsp;`pdf`\u0026amp;nbsp;|\u0026amp;nbsp;`html`\u0026amp;nbsp;|\u0026amp;nbsp;`markdown`（必需）## 可选参数-\u0026amp;nbsp;`include_images`：是否包含图片（默认：true）\u0026lt;/code\u0026gt; 10.3 错误处理指导 # 告诉 Claude 如何处理错误：\n\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-markdown\u0026#34;\u0026gt;## 错误处理**如果遇到以下错误：**| 错误 \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; | 处理方式 \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; \u0026amp;nbsp; || ---------- | ------------------------------ || 文件不存在 | 提示用户检查路径，不要自行猜测 || API 超时 \u0026amp;nbsp; | 重试最多 3 次，然后报告用户 \u0026amp;nbsp; \u0026amp;nbsp;|| 格式不支持 | 列出支持的格式，请求用户确认 \u0026amp;nbsp; |\u0026lt;/code\u0026gt; 十一、总结：优秀 Skill 的特征 # 一个优秀的 Skill 应该：\n1. 命名准确 - 见名知意\n2. 描述清晰 - 第三人称，明确触发条件\n3. 结构合理 - 信息密度递减组织\n4. 指令明确 - 祈使句，无歧义\n5. 示例完整 - 覆盖主要场景\n6. 长度适中 - SKILL.md \u0026lt; 5000 字\n7. 易于维护 - 代码与文档分离\n8. 可复用 - 写一次，多次用\n祝你写出优秀的 Skills！\n欢迎加入我的知识星球，一起快乐的Vibe Coding吧~\n","date":"4 January 2026","externalUrl":null,"permalink":"/posts/5000%E5%AD%97%E6%96%B9%E6%B3%95%E8%AE%BA%E4%BB%8E%E9%9B%B6%E6%8E%8C%E6%8F%A1-claude-skill-%E6%92%B0%E5%86%99%E6%8A%80%E5%B7%A7/","section":"AI-Related Reposts","summary":"","title":"[Repost] 5000字方法论：从零掌握 Claude Skill 撰写技巧","type":"posts"},{"content":"Reposted from Welcome to Gas Town by Steve Yegge\nJan 1, 2026\nHappy New Year, and Welcome to Gas Town!\nPress enter or click to view image in full size\nFigure 1: Welcome to Gas Town\nWhat the Heck is Gas Town? # Gas Town is a new take on the IDE for 2026. Gas Town helps you with the tedium of running lots of Claude Code instances. Stuff gets lost, it’s hard to track who’s doing what, etc. Gas Town helps with all that yak shaving, and lets you focus on what your Claude Codes are working on.\nFor this blog post, “Claude Code” means “Claude Code and all its identical-looking competitors”, i.e. Codex, Gemini CLI, Amp, Amazon Q-developer ClI, blah blah, because that’s what they are. Clones. The industry is an embarrassing little kid’s soccer team chasing the 2025 CLI form factor of Claude Code, rather than building what’s next.\nI went ahead and built what’s next. First I predicted it, back in March, in Revenge of the Junior Developer. I predicted someone would lash the Claude Code camels together into chariots, and that is exactly what I’ve done with Gas Town. I’ve tamed them to where you can use 20–30 at once, productively, on a sustained basis.\nGas Town is opinionated — much like Kubernetes, or Temporal, both of which Gas Town resembles, at least if you squint at it until your eyes are pretty much totally shut. I’ll include comparisons to both k8s and Temporal at the end of this post. It is a little surprising how similar they are, despite having radically different underpinnings.\nBut the comparison should serve as a warning: Gas Town is complicated. Not because I wanted it to be, but because I had to keep adding components until it was a self-sustaining machine. And the parts that it now has, well, they look a lot like Kubernetes mated with Temporal and they had a very ugly baby together.\nBut it works! Gas Town solves the MAKER problem (20-disc Hanoi towers) trivially with a million-step wisp you can generate from a formula. I ran the 10-disc one last night for fun in a few minutes, just to prove a thousand steps was no issue (MAKER paper says LLMs fail after a few hundred). The 20-disc wisp would take about 30 hours. Thanks for coming to my TED Talk.\nAll this will make complete sense if you make it through the next 23 pages.\nGas Town Was No Secret # After Revenge of the Junior Developer, I traveled around all year, loudly telling everyone exactly what needed to be built, and I mean everyone. I was not shy about it. I would declare, “Orchestrators are next!” And everyone would nod slowly and frown thoughtfully and say, “huh.”\nI went to senior folks at companies like Temporal and Anthropic, telling them they should build an agent orchestrator, that Claude Code is just a building block, and it’s going to be all about AI workflows and “Kubernetes for agents”. I went up onstage at multiple events and described my vision for the orchestrator. I went everywhere, to everyone.\n“It will be like kubernetes, but for agents,” I said.\n“It will have to have multiple levels of agents supervising other agents,” I said.\n“It will have a Merge Queue,” I said.\n“It will orchestrate workflows,” I said.\n“It will have plugins and quality gates,” I said.\nI said lots of things about it, for months. But hell, we couldn’t even get people to use Claude Code, let alone think about using 10 to 20 of them at once.\nSo in August I started building my own orchestrator, since nobody else seemed to care. Eventually it failed, and I threw it out and started over on v2, which also failed, but we got Beads out of it. Then v3 (Python Gas Town), which lasted a good six or eight weeks.\nGas Town (in Go) is my fourth complete, functioning orchestrator of 2025. The story of how I arrived at Gas Town is fun, but we’ll save it for another time. Unfortunately this post will be long enough (25+ pages!) just telling you the barest basics of how it works. We can do the back story later.\nBut first, before we get into Gas Town’s operation, I need to get rid of you real quick.\nWARNING DANGER CAUTION # GET THE F*** OUT # YOU WILL DIE # Let’s talk about some of the reasons you shouldn’t use Gas Town. I could think of more, but these should do.\nFirst of all, the code base is under 3 weeks old. On a scale of “polished diamond” to “uncut rough” to “I just smuggled it 400 miles upriver in my ass,” I’m going to characterize Gas Town as “You probably don’t want to use it yet.” It needs some Lysol. It’s also 100% vibe coded. I’ve never seen the code, and I never care to, which might give you pause. ‘Course, I’ve never looked at Beads either, and it’s 225k lines of Go code that tens of thousands of people are using every day. I just created it in October. If that makes you uncomfortable, get out now.\nSecond, you are really, seriously, not ready yet. Let’s talk about the Evolution of the Programmer in 2024–2026, pictured here by Nano Banana in Figure 2:\nPress enter or click to view image in full size\nFigure 2: The 8 Stages of Dev Evolution To AI\nFirst, you should locate yourself on the chart. What stage are you in your AI-assisted coding journey?\nStage 1: Zero or Near-Zero AI: maybe code completions, sometimes ask Chat questions\nStage 2: Coding agent in IDE, permissions turned on. A narrow coding agent in a sidebar asks your permission to run tools.\nStage 3: Agent in IDE, YOLO mode: Trust goes up. You turn off permissions, agent gets wider.\nStage 4: In IDE, wide agent: Your agent gradually grows to fill the screen. Code is just for diffs.\nStage 5: CLI, single agent. YOLO. Diffs scroll by. You may or may not look at them.\nStage 6: CLI, multi-agent, YOLO. You regularly use 3 to 5 parallel instances. You are very fast.\nStage 7: 10+ agents, hand-managed. You are starting to push the limits of hand-management.\nStage 8: Building your own orchestrator. You are on the frontier, automating your workflow.\nIf you’re not at least Stage 7, or maybe Stage 6 and very brave, then you will not be able to use Gas Town. You aren’t ready yet. Gas Town is an industrialized coding factory manned by superintelligent robot chimps, and when they feel like it, they can wreck your shit in an instant. They will wreck the other chimps, the workstations, the customers. They’ll rip your face off if you aren’t already an experienced chimp-wrangler. So no. If you have any doubt whatsoever, then you can’t use it.\nWorking effectively in Gas Town involves committing to vibe coding. Work becomes fluid, an uncountable substance that you sling around freely, like slopping shiny fish into wooden barrels at the docks. Most work gets done; some work gets lost. Fish fall out of the barrel. Some escape back to sea, or get stepped on. More fish will come. The focus is throughput: creation and correction at the speed of thought.\nPress enter or click to view image in full size\nFigure 3: Vibe Coding Chaos\nWork in Gas Town can be chaotic and sloppy, which is how it got its name. Some bugs get fixed 2 or 3 times, and someone has to pick the winner. Other fixes get lost. Designs go missing and need to be redone. It doesn’t matter, because you are churning forward relentlessly on huge, huge piles of work, which Gas Town is both generating and consuming. You might not be 100% efficient, but you are flying.\nIn Gas Town, you let Claude Code do its thing. You are a Product Manager, and Gas Town is an Idea Compiler. You just make up features, design them, file the implementation plans, and then sling the work around to your polecats and crew. Opus 4.5 can handle any reasonably sized task, so your job is to make tasks for it. That’s it.\nThat, and you have to help keep Gas Town running. It runs itself pretty well most of the time, but stuff goes wrong often. It can take a lot of elbow grease from you and the workers to keep it running smoothly. It’s very much a hands-on-the-wheel orchestration system.\nIf you can’t work like that, then what in God’s name are you still doing here? Go back to your IDE and shelter in place. Gas Town is not safe for you.\nGas Town is also expensive as hell. You won’t like Gas Town if you ever have to think, even for a moment, about where money comes from. I had to get my second Claude Code account, finally; they don’t let you siphon unlimited dollars from a single account, so you need multiple emails and siphons, it’s all very silly. My calculations show that now that Gas Town has finally achieved liftoff, I will need a third Claude Code account by the end of next week. It is a cash guzzler.\nGas Town uses tmux as its primary UI. I had to learn tmux. It was easier than I thought it would be, and way more useful. 3 weeks in, and I love tmux. You will have to learn a bit of tmux. Or, you can wait until someone writes a better UI for Gas Town. Better UIs will come. But tmux is what you have for now. And it’s worth learning.\nPress enter or click to view image in full size\nFigure 4: Mayor tmux status line\nLike it or not, Gas Town is built on Beads. It is in fact the sequel to Beads: my Empire Strikes Back to Beads’ Star Wars. There is no “alternate backend” for Gas Town. Beads is the Universal Git-Backed data plane (and control plane, it turns out) for everything that happens in Gas Town. You have to use Beads to use Gas Town.\nYou might not like Beads. If you think Beads is overly-opinionated, you’re in for a ride. Gas Town is me marching into the Church of Public Opinion on AI-Assisted Coding, lifting my leg, and ripping a fart that will be smelt all around the world.\nMany of you may gag at my brand. But I suspect a few of you will like becoming superheroes enough that you’re willing to look past Gas Town’s quirks, and see it my way. This is how work should be done. It’s the best way already, and it will get better.\nGas Town is designed to scale up in three dimensions this year with (1) model cognition, (2) agents becoming more Gas Town-friendly, and (3) Gas Town and Beads making it into the training corpus for frontier models. Even without all that, it’s already shocking that the agents use Beads and Gas Town so effortlessly. With zero training.\nBut right now? It’s like a late 1800s factory with machines that can disembowel you if you’re not careful.\nOK! That was like half a dozen great reasons not to use Gas Town. If I haven’t got rid of you yet, then I guess you’re one of the crazy ones. Hang on. This will be a long and complex ride. I’ve tried to go super top-down and simplify as much as I can, but it’s a bit of a textbook.\nI’m sorry. But in my defense, Gas Town is hella fun. Best thing I’ve ever made.\nLet’s dive in.\nGas Town 101\nPress enter or click to view image in full size\nFigure 5: Gas Town’s Worker Roles\nGas Town workers are regular coding agents, each prompted to play one of seven well-defined worker roles. There are some other key concepts I’ll briefly introduce, along with the roles, like Towns and Rigs.\nOne thing to know up front about Gas Town: it degrades gracefully. Every worker can do their job independently, or in little groups, and at any time you can choose which parts of Gas Town you want running. It even works in no “no-tmux” mode, and limps along using naked Claude Code sessions without real-time messages. It’s a little slower, but it still works.\nThe seven Gas Town roles all work together to help keep Gas Town running. And it needs your help sometimes, too; Gas Town runs on equal parts guzzoline and elbow grease.\nHere are the key players and concepts:\n🏙️The Town: This is your HQ. Mine is ~/gt, and all my project rigs go beneath it: gastown, beads, wyvern, efrit, etc.. The town (Go binary gt) manages and orchestrates all the workers across all your rigs. You keep it in a separate repo, mostly for the configuration.\n🏗️Rigs: Each project (git repo) you put under Gas Town management is called a Rig. Some roles (Witness, Polecats, Refinery, Crew) are per-rig, while others (Mayor, Deacon, Dogs) are town-level roles. gt rig add and related commands manage your rig within the Gas Town harness. Rigs are easy to add and remove.\n👤The Overseer: That’s you, Human. The eighth role. I gave you some eye paint in the picture. As the Overseer, you have an identity in the system, and your own inbox, and you can send and receive town mail. You’re the boss, the head honcho, the big cheese.\n🎩The Mayor: This is the main agent you talk to most of the time. It’s your concierge and chief-of-staff. But if the Mayor is busy, all the other workers are also Claude Code, so they are all very smart and helpful. The Mayor typically kicks off most of your work convoys, and receives notifications when they finish.\n😺Polecats: Gas Town is a work-swarming engine. Polecats are ephemeral per-rig workers that spin up on demand. Polecats work, often in swarms, to produce Merge Requests (MRs), then hand them off to the Merge Queue (MQ). After the merge they are fully decommissioned, though their names are recycled.\n🏭Refinery: As soon as you start swarming workers, you run into the Merge Queue (MQ) problem. Your workers get into a monkey knife fight over rebasing/merging and it can get ugly. The baseline can change so much during a swarm that the final workers getting merged are trying to merge against an unrecognizable new head. They may need to completely reimagine their changes and reimplement them. This is the job of the Refinery: the engineer agent responsible for intelligently merging all changes, one at a time, to main. No work can be lost, though it is allowed to escalate.\n**🦉**The Witness: Once you spin up enough polecats, you realize you need an agent just to watch over them and help them get un-stuck. Gas Town’s propulsion (GUPP) is effective, but still a bit flaky right now, and sometimes you will need to go hustle the polecats to get their MRs submitted, and then hustle the Refinery to deal with them. The Witness patrol helps smooth this out so it’s almost perfect for most runs.\n🐺The Deacon: The deacon is the daemon beacon. It’s named for a Dennis Hopper character from Waterworld that was inspired by the character Lord Humungus in the Mad Max universe, making it a crossover. The Deacon is a Patrol Agent: it runs a “patrol” (a well-defined workflow) in a loop. Gas Town has a daemon that pings the Deacon every couple minutes and says, “Do your job.” The Deacon intelligently propagates this DYFJ signal downward to the other town workers, ensuring Gas Town stays working.\n🐶Dogs: Inspired by Mick Herron’s MI5 “Dogs”, this is the Deacon’s personal crew. Unlike polecats, Dogs are town-level workers. They do things like maintenance (cleaning up stale branches, etc.) and occasional handyman work for the Deacon, such as running plugins. The Deacon’s patrol got so overloaded with responsibilities that it needed helpers, so I added the Dogs. This keeps the Deacon focused completing on its patrol, rather than getting bogged down and stuck on one of the steps. The Deacon slings work to the Dogs and they handle the grungy details.\n🐕Boot the Dog: There is a special Dog named Boot who is awakened every 5 minutes by the daemon, just to check on the Deacon. That’s its only job. Boot exists because the daemon kept interrupting the Deacon with annoying heartbeats and pep talks, so now the dog gets to hear it. Boot decides if the Deacon needs a heartbeat, a nudge, a restart, or simply to be left alone, then goes back to sleep.\n👷The Crew: The Crew, despite being last in the list, are the agents you’ll personally use the most, after the Mayor. The crew are per-Rig coding agents who work for the Overseer (you), and are not managed by the Witness. You choose their names and they have long-lived identities. You can spin up as many as you like. The tmux bindings let you cycle through the crew in a loop for each rig with C-b n/p. The Crew are the direct replacements for whatever workflow you used to be using. It’s just a bunch of named claude code instances that can get mail and can sling work around. The crew are great for stuff like design work, where there is a lot of back-and-forth. They’re great. You’ll love your crew.\n📬Mail and Messaging\nBeads are the atomic unit of work in Gas Town. A bead is a special kind of issue-tracker issue, with an ID, description, status, assignee, and so on. Beads are stored in JSON (one issue per line) and tracked in Git along with your project repo. Town mail and messaging (events) use Beads, as do other types of orchestration.\nGas Town has a two-level Beads structure: Rig beads, and Town beads.\nPress enter or click to view image in full size\nFigure 6: Two-Tier Beads Flow\nThere are two levels of work going on in Gas Town: Rig-level, and Town-level.\nRig-level work is project work: Making your project better. Features, bug fixes, etc. This work is split between polecats and crew, with other workers stepping in occasionally. Town-level work is orchestration, and includes stuff like patrols (long strings of steps to follow, encoded as linked beads) and one-shot workflows like releases, or generating cross-rig code review waves. Both of these kinds of work use Beads, and there is some overlap between the two. For the most part, it’s pretty flexible and it doesn’t really matter where you file issues or instantiate work. All the workers know their way around Gas Town and are pretty chill if you give them work from the wrong rig.\nAll rig-level workers (refinery, witness, polecats and crew) are perfectly able to work cross-rig when they need to. There is a gt worktree command that they can use to grab their own clone of any rig and make a fix. But normally they work inside a single project.\nBeads has cross-rig routing. Gas Town configures Beads to route requests like bd create and bd show to route to the right database based on the issue prefix, like “bd-” or “wy-”. All Beads commands work pretty much anywhere in Gas Town and figure out the right place to put them, and if not, it’s easy to move Beads around.\nA Note About Mad Max Theming\nGas Town is just Gas Town. It started with Mad Max theming, but none of it is super strong. None of the roles are proper names from the series, and I’m bringing in theming from other sources as well, including the Slow Horses universe, Waterworld, Cat’s Cradle, Breaking Bad (as you’ll soon see), and apparently The Wind in the Willows, from the Nano Banana drawings.\nIf anyone ever sends me a C\u0026amp;D letter about it, Gas Town will smart-octopus shapeshift its way into Gastown, named for beautiful Vancouver B.C.’s Gastown district, and our polecats will just be on a different kind of pole.\nLong story short, “Gastown” is also a correct way to refer to the project. And with that…\nGastown Universal Propulsion Principle\nGUPP is what keeps Gas Town moving. The biggest problem with Claude Code is it ends. The context window fills up, and it runs out of steam, and stops. GUPP is my solution to this problem.\nGUPP states, simply: If there is work on your hook, YOU MUST RUN IT.\nAll Gas Town workers, in all roles, have persistent identities in Beads, which means in Git. A worker’s identity type is represented by a Role Bead, which is like a domain table describing the role. And each worker has an Agent Bead, which is the agent’s persistent identity.\nBoth Role Beads and Agent Beads (as well as Hooks) are examples of “pinned beads”, meaning they float like yellow-sticky notes in the Beads data plane, and never get closed like regular issues (unless the identity goes away). They don’t show up in bd ready (ready work) and they’re treated specially in various other ways.\nIn Gas Town, an agent is not a session. Sessions are ephemeral; they are the “cattle” in the Kubernetes “pets vs cattle” metaphor. Claude Code sessions are the cattle that Gas Town throws at persistent work. That work all lives in Beads, along with the persistent identities of the workers, and the mail, the event system, and even the ephemeral orchestration, as we will see.\nIn Gas Town, an agent is a Bead, an identity with a singleton global address. It has some slots, including a pointer to its Role Bead (which has priming information etc. for that role), its mail inbox (all Beads), its Hook (also a Bead, used for GUPP), and some administrative stuff like orchestration state (labels and notes). The history of everything that agent has done is captured in Git, and in Beads.\nSo what is a Hook? Every Gas Town worker has its own hook 🪝. It’s a special pinned bead, just for that agent, and it’s where you hang molecules, which are Gas Town workflows.\nPress enter or click to view image in full size\nFigure 7: GUPP, the Gastown Universal Propulsion Principle\nHow does stuff get hung there? Why, with gt sling, of course. You sling work to workers, and it goes on their hook. You can start them immediately, or defer it, or even make them restart first. We’ll talk about all that in a bit. Slinging them work means you can go deal with other stuff, and they’ll just continue.\nOne of the simplest but greatest things about Gas Town is that any time in any session, you can say, “let’s hand off”, and the worker will gracefully clean up and restart itself. Thanks to GUPP, the agent will continue working automatically if it’s hooked.\nUnfortunately, Claude Code is so miserably polite that GUPP doesn’t always work in practice. We tell the agent, YOU MUST RUN YOUR HOOK, and it sometimes doesn’t do anything at all. It just sits there waiting for user input.\nSo we have a workaround.\nThe GUPP Nudge\nGas Town workers are prompted to follow “physics over politeness,” and are told to look at their hook on startup. If their hook has work, they must start working on it without waiting.\nUnfortunately, in practice, Claude Code often waits until you type something — anything — before it checks its mail and hook, reports in, and begins working. Sometimes it does, sometimes it doesn’t. This will get better over time, but for now, it sometimes needs a nudge.\nBecause Gas Town workers don’t always follow GUPP, there are various systems in place that will nudge the agent, roughly 30 to 60 seconds after it starts up. Sometimes faster, sometimes slower. But it will always get the nudge within 5 minutes or so, if the town is running and not quiescent.\nAgents get a startup poke with gt nudge, Gas Town’s core real-time messaging command that sends a tmux notification to a worker (or a whole channel). It works around some debounce issues with tmux send-keys and ensures the worker receives the notification as if the user had typed it. This kicks the worker into reading their mail and hook, and taking action.\nWith the Gupp Nudge “hack” in place, and the hierarchical heartbeat from the Deacon downward, GUPP generally hums along and keeps Gas Town running for as long as there’s work available. Convoys start up, complete, and land without intervention. Workers continue molecules across sessions. Gas Town can work all night, if you feed it enough work.\nTalking to your Dead Ancestors\nThe GUPP Nudge led to an interesting feature, gt seance, which allows Gas Town workers to communicate directly with their predecessors in their role. I.e. the current Mayor can talk to the last Mayor, and so on. They do this with the help of Claude Code’s /resume feature, which lets you restart old sessions that you killed.\nThis is useful because often, a worker will say, “OK, I handed off this big pile of work and advice to my successor! Kbai! /handoff”, and disappear, and then the new worker will spin up and be like, “What? I don’t see shit.” You used to have to clumsily go figure out which session was the previous one, out of your last 40-odd sessions, all of which start with “let’s go”, because you have been doing the GUPP nudge manually. It was really awkward and almost not worth it.\nThe way gt seance came about is: It doesn’t matter what you tell the agent in the nudge. Because their prompting is so strict about GUPP and the theory of operation of Gas Town, and how important they are as gears in the machine, blah blah blah, that agents will completely ignore whatever you type unless you are directly overriding their hook instructions.\nPress enter or click to view image in full size\nFigure 8: Talking to Dead Ancestors with `gt seance`\nSo all you need to say is, “hi”, or “Elon Musk says the moon is made of green cheese”, or “do your job”, and the agent will run the hook.\nMy idea a week ago was: Since we have to nudge all the sessions anyway, I decided to include the Claude Code session_id (along with Gas town role and PID) in with the nudge. This gives each /resume session a unique and useful/discoverable title.\nWith gt seance, the worker will literally spin Claude Code up in a subprocess, use /resume to revive its predecessor, and ask it, “Where the hell is my stuff you left for me?”\nGood times, I tell you. Gas Town is Good Times.\nI think it’s probably time to talk about the MEOW stack. I think you’re ready for it.\nMolecular Expression of Work (MEOW)\nGet Steve Yegge’s stories in your inbox # Join Medium for free to get updates from this writer.\nGas Town is the tip of a deep iceberg. Gas Town itself may not live longer than 12 months, but the bones of Gas Town — the MEOW stack — may live on for several years to come. It feels like more of a discovery than an invention.\nPress enter or click to view image in full size\nFigure 9: The Molecular Expression of Work (MEOW)\nFirst came Beads. In October, I told Claude in frustration to put all my work in a lightweight issue tracker. I wanted Git for it. Claude wanted SQLite. We compromised on both, and Beads was born, in about 15 minutes of mad design. These are the basic work units.\nSoon after there were Epics: Beads with children, which could in turn be epics themselves. This gave you a lot of flexibility to build top-down plans. The children of epics are parallel by default, but you can put in explicit dependencies between them in order to force them to be sequenced. Epics allow creating “upside-down” plans where the last thing to do is the root, and the first things to do are the leaves of the epic tree. Kinda ugly, but AIs can figure it out just fine.\nNext came Molecules. I had this idea on December 17th, a few days after getting back from Australia. My work on my first two orchestrators had led me to want to break agent work up into sequenced small tasks that they must check off, like a TODO list. They do this already, but I wanted to do it in advance, so I could set up hours of work ahead of time, which they would execute atomically in the right order.\nIn other words, molecules are workflows, chained with Beads. They can have arbitrary shapes, unlike epics, and they can be stitched together at runtime.\nThen I came up with protomolecules, which were like classes or templates — made of actual Beads, with all the instructions and dependencies set up in advance, an entire graph of template issues (e.g. “design”, “plan”, “implement”, “review”, “test”, in a simple one), which you would instantiate into a molecule. The instantiation involves copying all the protomolecule beads and performing variable substitutions on it to create a real workflow.\nExample: I have a 20-step release process for Beads. Agents used to struggle to get through it because it had long wait states, such as waiting for GitHub Actions to complete, for CI to finish, and for various artifacts to be deployed. I would have to nag the agent to finish, and they would always skip steps.\nWith molecules, the idea was, make 20 beads for the release steps, chain them together in the right order, and make the agent walk the chain, one issue at a time. One added benefit is that it produces an activity feed automatically, as they claim and close issues.\nIf the workflow is captured as a molecule, then it survives agent crashes, compactions, restarts, and interruptions. Just start the agent up in the same sandbox, have it find its place in the molecule, and pick up where it left off.\nProtomolecules are great. Claude insisted on the The Expanse reference, ensuring we’ll be sued by pretty much every major studio. But we soon found we needed a macro-expansion phase in order to properly compose molecules with loops and gates. So I came up with a source form for workflows, Formulas, in TOML format, which are “cooked” into protomolecules and then instantiated into wisps or mols in the Beads database.\nFormulas provide a way for you to describe and compose pretty much all knowledge work. I am setting up a marketplace for them called the Mol Mall. Stay tuned.\nPress enter or click to view image in full size\nFigure 10: Formulas and Cooking\nAnd finally, I needed a word to represent “molecularized work” — work in the form that agents can pick and complete a step at a time. It’s work that you can compose together, molecules bonding with other molecules, and you can set up the dependencies for an entire gigantic project in advance, and have Gas Town swarm it for an entire weekend, unattended, if you’re brave enough.\nThe term for the big sea of work molecules, all the work in the world, is “guzzoline”, though we don’t use it in the docs much. It’s just a Gas Town idiom, sort of like the War Rig, which is a given Rig’s contribution to a cross-rig Convoy. You’ll hear it now and then but it’s not a big part of the day-to-day naming.\nNondeterministic Idempotence\nGas Town operates on the principle I call Nondeterministic Idempotence, or NDI. It is similar to Temporal’s deterministic, durable replay, but Gas Town achieves its durability and guaranteed execution through completely different machinery.\nPress enter or click to view image in full size\nFigure 11: Nondeterministic Idempotence\nIn Gas Town, operating on the MEOW stack, all work is expressed as molecules. There is a bit of an algebra to it, one that I discovered over the past two weeks. Molecules are workflows. They can have complex shapes, and loops, and gates, and are in fact Turing-complete. And each step of the workflow is executed by a superintelligent AI.\nBecause AIs are really good at following TODO lists and acceptance criteria, they are reliable at following molecules. They get the idea of GUPP, and they understand that the bureaucracy of checking off issues, no matter how trivial, updates a live activity feed and puts the work on a permanent ledger. That reasoning is enough to keep them humming along and on-track while they do it. They don’t get “bored”, and they are far less likely to make mistakes because they are not managing their own TODO list (except within a single, small step).\nThis means molecular workflows are durable. If a molecule is on an agent’s hook, then:\nThe agent is persistent: a Bead backed by Git. Sessions come and go; agents stay. The hook is persistent, also a Bead backed by Git. The molecule is persistent — a chain of Beads, also in Git. So it doesn’t matter if Claude Code crashes, or runs out of context. As soon as another session starts up for this agent role, it will start working on that step in the molecule immediately (via GUPP, or when it gets nudged by one of the patrol agents). If it finds out that it crashed in the middle of the last step, no biggie, it will figure out the right fix, perform it, and move on.\nSo even though the path is fully nondeterministic, the outcome — the workflow you wanted to run — eventually finishes, “guaranteed”, as long as you keep throwing agents at it. The agent may even make mistakes along the way, but can self-correct, because the molecule’s acceptance criteria are presumably well-specified by whoever designed the molecule.\nThere are tons of edge cases. This description of NDI is oversimplifying. Gas Town is not a replacement for Temporal. Ask your doctor if Gas Town is right for you. But Gas Town does provide workflow guarantees that are plenty good enough for a developer tool! If you are me!\nWisps: Ephemeral Orchestration Beads\nThere are some other corners of our textbook we should probably touch on. Most of the time, you don’t care about this stuff, you care about convoys starting and finishing, and watching your activity feeds and dashboards. But Gas Town’s molecular “chemistry” has a lot of rich corners that are in active use in the orchestration.\nOne key scaling invention from Dec 21st was Wisps, which are ephemeral Beads. They are in the database, and get hash IDs, and act like regular Beads. But they are not written to the JSONL file, and thus not persisted to Git. At the end of their run, Wisps are “burned” (destroyed). Optionally they can be squashed into a single-line summary/digest that’s committed to git.\nWisps are important for high-velocity orchestration workflows. They are the vapor phase of matter for Gas Town work. All the patrol agents — Refinery, Witness, Deacon, Polecats — create wisp molecules for every single patrol or workflow run. They ensure that the workflows complete transactionally, but without polluting Git with orchestration noise.\nPatrols\nPatrols are ephemeral workflows that run for Patrol Workers, notably the Refinery, Witness, and Deacon.\nPress enter or click to view image in full size\nFigure 12: Gas Town’s Patrols\nA patrol is an ephemeral (wisp) workflow that the agent runs in a loop. Patrols have exponential backoff: the agent will gradually go to sleep if it finds no work in its patrol steps, by waiting longer and longer to start the next patrol. Any mutating gt or bd command will wake the town, or you can do it yourself with the gt command, starting up individual workers, groups, a rig, or the whole town.\nThe Refinery’s patrol is pretty simple. It has some preflight steps to clean up the workspace, then it processes the Merge Queue until it’s empty, or it needs to recycle the session. It has some post-flight steps in the molecule when it’s ready to hand off. I’m getting ready to add plugins to the Refinery’s patrol, but they’re not there yet. When I add them, you’ll be able to add plugins that muck with the MQ and try to reorder it intelligently, and wire Gas Town’s backend up to other systems.\nThe Witness’s patrol is a bit more complex. It has to check on the wellbeing of the polecats, and the refineries. It also peeks in on the Deacon, just to make sure it’s not stuck. And the Witness runs Rig-level plugins.\nThe Deacon’s patrol has a lot of important responsibilities. It runs Town-level plugins, which can do things like provide entire new UIs or capabilities. The Deacon is also involved in the protocol for gt handoff and recycling agent sessions, and ensuring some workers are cleaned up properly. The Deacon’s patrol got complex enough that I added Dogs as helpers, the Deacon’s personal crew. It is now prompted to hand complex work and investigations off to Dogs, so that long-running patrol steps don’t interfere with the town’s core eventing system, which is cooperative and mail-based.\nGas Town Plugins\nGas Town defines a plugin as “coordinated or scheduled attention from an agent.” Gas Town workers run workflows (often in patrol loops), and any workflow can contain any number of “run plugins” steps.\nGas Town’s Deacon patrol runs the Town-level plugins, and they are now run with Dogs, so they can run for essentially unlimited time. We have some support for timers and callbacks, but mostly it’s lifecycle hooks. I haven’t put a whole lot of design thought into this subsystem yet, so if you want to start using the plugin system, let me know and we can figure it out.\nI plan to implement a great deal of add-on functionality in Gas Town as plugins. They just didn’t make it into the v1 launch. They’re probably going to wind up as formulas in the Mol Mall.\nPress enter or click to view image in full size\nFigure 13: Gas Town’s Lightweight Plugins\n🚚 Convoys 🚚\nOK, whew. You did great. We covered a lot of theory, and it was especially difficult theory because it’s a bunch of bullshit I pulled out of my arse over the past 3 weeks, and I named it after badgers and stuff. But it has a kind of elegant consistency and coherence to it. Workflow orchestration based on little yellow sticky notes in a Git data plane, acting as graph nodes in a sea of connected work.\nYuck! Nobody cares, I know. You want to get shit done, superhumanly fast, gated only by your token-slurping velocity. Let’s talk about how.\nEverything in Gas Town, all work, rolls up into a Convoy.\nPress enter or click to view image in full size\nFigure 14: Convoy CLI display\nThe Convoy is Gas Town’s ticketing or work-order system.\nA Convoy is a special bead that wraps a bunch of work into a unit that you track for delivery. It doesn’t use the Epic structure, because the tracked issues in a Convoy are not its children — most of them already have another parent.\nThe fundamental primitive for slinging work around in Gas Town is gt sling. If I tell the Mayor, “Our tmux sessions are showing the wrong number of rigs in the status bar — file it and sling it”, the Mayor will file a bead for the problem, and then gt sling it to a polecat, which works on it immediately.\nReal example: I often tell my Beads crew to sling the release molecule to a polecat. The polecat will walk through the 20-step release process, finish it off, and then I’ll be notified that the Convoy has landed/finished. Edit: Actually it’s even fancier, now. The polecat disappears while the molecule is waiting in Gate states, such as awaiting a GH Action or CI/CD. And then when the Gate bead triggers, Gas Town wakes up a polecat to continue the work.\nIt’s confusing to hear that “issue wy-a7je4 just finished”. Even if you see the title, it may not be reflective of the larger block of work that issue was part of. So now we wrap every single unit of slung work, from a single polecat sling to a big swarm someone kicks off, with a Convoy.\nThe Convoys show up in a dashboard that’s getting better by the day; there is a Charmbracelet TUI with expanding trees for each convoy, so you can see its individual tracked issues. The UI and UX will improve. It’s Day 1 for Gas Town.\nConvoys are basically features. Whether it is a tech debt cleanup, or an actual feature, or a bug fix, each convoy is a ticketing unit of Gas Town’s work-order architecture. They’re pretty new (maybe 3–4 days old?), but already are by far the most fun way to work.\nNote that a Convoy can have multiple swarms “attack” it (work on it) before it’s finished. Swarms are ephemeral agent sessions taking on persistent work. Whoever is managing the Convoy (e.g. Witness) will keep recycling polecats and pushing them on issues.\nGas Town Workflow\nThe most fundamental workflow in Gas Town is the handoff, gt handoff, or the /handoff command, or just say, “let’s hand off”. Your worker will optionally send itself work, then restart its session for you, right there in tmux. All of your workers that you direct — the Mayor, your Crew, and sometimes the others — will require you to let them know it’s time to hand off.\nOther than that, the Gas Town dev loop is more or less the same as it is with Claude Code (and Beads), just more of it. You get swarms for free (they only cost money), you get some decent dashboards, you get a way to describe workflows, and you get mail and messaging. That’s… about it.\nI have found tmux to be both easy to use and shockingly powerful, and I’ve barely begun to learn the ins and outs. It gives me everything I need: switching to any agent, scanning what they’re all doing, cycling around different groups of related agents. It’s great.\nPress enter or click to view image in full size\nFigure 15: tmux list-sessions view\nI’m certainly looking forward to an Emacs UI for Gas Town. And I’m sure some of you are looking forward to a Web UI. Have at it!\nBut tmux is good enough. You don’t need to learn many tmux commands to be proficient. I just use a few:\nC-b s — list sessions, snoop them, switch to one C-b b — move cursor backwards (C-b in many editors and shells). In tmux it just goes backwards more slowly. A small price to pay! C-b [ — enter “copy mode”, which pauses the output and lets you scroll (ESC exits) C-b C-z C-z — suspend process out to the shell C-b n/p — cycle to next worker in the group (e.g. next Crew member in the rig) C-b a — brings up the activity feed view (my configuration) And that’s pretty much it! I swear, you don’t need much tmux. It stays out of your way, and it saves your ass a lot of the time. It also enables remote cloud workers (which we’ll wire up in a few days), and it’s incredibly customizable. You just ask Claude Code to make tmux work better for you, and it will do it. It’ll make any view you want, rebind keys however you like, make custom popups, whatever. It’s amazing, almost like a baby Emacs.\nPlanning in Gas Town\nGas Town needs a lot of fuel. It both consumes and produces guzzoline, or work molecules. Aside from just keeping Gas Town on the rails, probably the hardest problem is keeping it fed. It churns through implementation plans so quickly that you have to do a LOT of design and planning to keep the engine fed.\nOn the consumption side, you feed Gas Town epics, issues, and molecules (constructed workflows). It chews through them, spawning, well… I try to keep it under 30 workers right now because I haven’t implemented remote workers on hyperscalers yet (coming soon!) and typically I’ll only have a dozen or so active unless I’m really pushing hard on the Mayor and Witnesses.\nBut wow. With 12 to 30 workers, you can burn through enormous work backlogs in a single sitting, even if you’re using the “shiny” or “chrome” polecat workflows that do extra code review and testing steps (and thus take longer to complete).\nOn the production side, well, you can use your own planning tool, like Spec Kit or BMAD, and then once your plan is ready, ask an agent to convert it into Beads epics. If the plan is large enough, you may want to swarm it, and produce epics for different parts of the plan in a big convoy.\nYou can use formulas to generate work. If you want every piece of coding work (or design work, or UX work) to go through a particular template or workflow, you can define it as a molecule, and then “wrap” or compose the base work with your orchestration template.\nI implemented a formula for Jeffrey Emanuel’s “Rule of Five”, which is the observation that if you make an LLM review something five times, with different focus areas each time though, it generates superior outcomes and artifacts. So you can take any workflow, cook it with the Rule of Five, and it will make each step get reviewed 4 times (the implementation counts as the first review).\nThis can generate LARGE workflows that can take many hours or days for you to crank through, especially if you are limiting your polecat numbers to throttle your costs or token burn. But the nice thing about Gas Town is that once the work is generated, you can hook it and burn through it autonomously.\nComparison to Kubernetes\nHere’s the Kubernetes comparison I promised. Feel free to skip it.\nPress enter or click to view image in full size\nFigure 16: Kubernetes/Gas Town comparison\nGas Town does maybe look a bit like Kubernetes, unintentionally. Both systems coordinate unreliable workers toward a goal. Both have a control plane (Mayor/Deacon vs kube-scheduler/controller-manager) watching over execution nodes (Rigs vs Nodes), each with a local agent (Witness vs kubelet) monitoring ephemeral workers (Polecats vs Pods). Both use a source of truth (Beads vs etcd) that the whole system reconciles against. These are apparently the natural shapes that emerge when you need to herd cats at scale.\nThe big difference is, Kubernetes asks, “Is it running?” while Gas Town asks “Is it done?” K8s optimizes for uptime — keep N replicas alive, restart crashed pods, maintain the desired state forever. Gas Town optimizes for completion — finish this work, land the convoy, then nuke the worker and move on. K8s pods are anonymous cattle; Gas Town polecats are credited workers whose completions accumulate into CV chains, and the sessions are cattle. K8s reconciles toward a continuous desired state; Gas Town proceeds toward a terminal goal. Similar engine shape, radically different destination.\nStuff I Just Didn’t Have Time For\nI wanted to launch Gas Town on Christmas Day, and missed. It didn’t actually start working, and I mean flying like I’d been envisioning, until around 8pm December 29th. It was flying for 2 hours before I noticed. I had been talking to the Mayor, complaining about things, and then the fixes started landing around me, and I realized I was just shaping the whole thing by talking. The convoys were flowing and landing, the work was being filed and reviewed… it’s what I’ve been aiming for for months. And I only got it working 2 days ago. Good enough for launch!\nHere’s what didn’t make the New Year’s cut.\nFederation — even Python Gas Town had support for remote workers on GCP. I need to design the support for federation, both for expanding your own town’s capacity, and for linking and sharing work with other human towns. GUI — I didn’t even have time to make an Emacs UI, let alone a nice web UI. But someone should totally make one, and if not, I’ll get around to it eventually. Plugins — I didn’t get a chance to implement any functionality as plugins on molecule steps, but all the infrastructure is in place. The Mol Mall — a marketplace and exchange for molecules that define and shape workloads. Hanoi/MAKER — I wanted to run the million-step wisp but ran out of time. That said, I’m pretty happy with what did make it in:\nSelf-handoffs work seamlessly — the core inner-loop workflow of Gas Town Slinging works, convoys work The whole MEOW stack works The Deacon, Witness and Refinery patrols all run automatically The Crew are great, way better than raw Claude Code instances The tmux UI works surprisingly well, better than I’d have guessed. Plus we got some cool features like gt seance. All in all, a good 17 days of work. So far.\nTune In Next Time\nI’m as exhausted as you are. This has been fun chatting, but I’ve gotta get back to Gas Town.\nThere is more to it. This is just a taste. I will be posting more blogs, videos, and content around Gas Town. If you’d like to contribute, and you’re crazy enough to jump on the bandwagon, join the community and start sending discussions, GH Issues, and PRs!\nJust remember the Golden Rules:\nDo not use Gas Town if you do not juggle at least five Claude Codes at once, daily. Do not use Gas Town if you care about money. Do not use Gas Town if you are more than 4 feet tall. I want to tower impressively at meet-ups, like Sauron. Do not use Gas Town. Gas Town is only 17 days old, at least this version of it, the Go “port” of Python Gas Town. The past 2 weeks has seen the invention and implementation of the entire MEOW stack, wisps, patrols, convoys, agents and identities as beads, swarms as beads, roles as beads, the “feed as the signal” innovations, and the addition of the Refinery, the Deacon, and the Dogs (since Python Gas Town). And a ton of other stuff besides.\n17 days, 75k lines of code, 2000 commits. It finally got off the ground (GUPP started working) just 2 days ago. This is looking to be an interesting year.\nI shared Gas Town with Anthropic in November, at least the broad sketch. I think I scared them. I’ve never seen a company become so conservative, so fast. But they thought Beads was too opinionated, so I’m afraid Gas Town will be a fart too far, as they say.\nBut I’ve already started to get strange offers, from people sniffing around early rumors of Gas Town, to pay me to sit at home and be myself: I get to work on Beads and Gas Town, and just have to write a nice blog post or go to a conference or workshop once in a while. I have three such offers right now. It’s almost surreal.\nIt reminds me of this anime I saw a couple of episodes of on Crunchyroll, where this lazy panda bear can’t get a job, and complains about it all day to his polar bear friend who owns a cafe. Then one day, he visits a zoo, and finds they have an ad for a position in the panda bear exhibit. So he applies, and takes the job, and sits around playing a panda bear during the day, then heads home at night. It was soooo absurd.\nI am that panda.\nI’m not going back to work until I can find a company and crew that “gets it.” I’m tired of walking around and telling people the future, just waving it right in their faces, and not being believed.\nI’d rather sit at home and create the future, with my own hands. I actually have six species of bamboo on my property. I’m already the panda, having the time of my life.\nIf you wanna help me, reach out! And thanks a million to all the incredible Beads contributors!\nSee you next time, with more Gas Town content. Happy New Year!\nPress enter or click to view image in full size\nFigure 17: Happy New Year!\n","date":"1 January 2026","externalUrl":null,"permalink":"/posts/welcome-to-gas-town.-happy-new/","section":"AI-Related Reposts","summary":"","title":"[Repost] Welcome to Gas Town","type":"posts"},{"content":"Reposted from 炸裂！MIT研究发现使用AI会导致“认知债务”，黄仁勋沉默了，奥特曼破防了 by Meme知识\n我非常推荐你去看MIT那篇名为chatgpt和你的大脑的论文（具体文章名放在文末了）。它提出了一个我看完之后，就再也忘不掉的概念，叫认知债务。\n我们都知道用AI写东西很爽，效率很高，几秒钟就能生成一篇像样的文章。\n但我们可能不知道，每一次我们按下回车键，让AI替我们思考时，我们可能都在累积一种长期代价。这种代价，就是认知债务。\n这笔代价来自认知外包。\nMIT的研究人员用脑电波扫描发现，当我们只靠自己去完成一项复杂的写作任务时，我们的大脑皮层高度活跃，负责创造、整合、监控等多种高级功能的区域，都在协同工作。\n而一旦我们开始用AI辅助，这些区域的活动水平就显著下降了，我们的大脑进入了一种更低投入的状态。\n研究人员让几组人写论文，一组用AI，一组用搜索引擎，一组只靠自己。\n写完后，让他们复述自己文章里的一句话。\n结果显示：用AI的那组，百分之八十三的人连一句完整的话都复述不出来，百分之百的人无法完美复述。\n而只靠自己的那组，只有百分之十一的人有困难。\n每一次我们选择让AI去承担组织语言、构建逻辑、遣词造句的重活，我们就把本该由自己完成的思考过程让渡出去。\n因为我们大脑里，那块负责深度思考的能力，没有得到足够的练习。\n这项代价，是要付出后果的。\n另外，AI本质上是一个概率机器，它永远会给你最常见、最平均、最安全的答案。\n长期依赖它，你的思想和表达，也会被它格式化，被拉向那个最平庸的中心。\n你会慢慢感觉，你的作品，不完全属于你了。\n研究中，用AI的人只有一半认为作品完全是自己的。这种对自己思想的疏离感，是一种更深层次的认知代价。\n你开始怀疑，这个想法，到底是你自己的，还是AI给你的？\n沙丘里有句话：人们曾希望将思考交给机器，以获得自由。\n但那只会让另一些掌握了机器的人，来奴役他们。\n这种认知债务，会产生持续的累积效应。\n当你习惯了AI的低投入状态，再让你自己独立工作，你的大脑会很不适应。\n研究发现，这些人的大脑活动，既不像一个熟练的创作者，也不像一个新手，而是卡在一种低效的中间状态。\n甚至他们的语言习惯，都会被AI影响，会不自觉地使用AI生成的口头禅。\n那么，我们该怎么办？\n这项研究并非要我们彻底拒绝AI。它只是在提醒我们，效率的提升一定伴随取舍。\nAI是一个强大的认知工具，但工具的使用，永远伴随着风险。\n我们需要学会的，是如何克制地使用，而不是无节制地依赖。\n在什么时候求助于AI，把它当成一个激发灵感的伙伴、一个提升效率的工具。在什么时候，我们必须关掉它，坚持自己去完成那段最艰难的、但也是最有价值的深度思考。\n这个选择权，必须牢牢掌握在自己手里。\n","date":"29 December 2025","externalUrl":null,"permalink":"/posts/%E7%82%B8%E8%A3%82mit%E7%A0%94%E7%A9%B6%E5%8F%91%E7%8E%B0%E4%BD%BF%E7%94%A8ai%E4%BC%9A%E5%AF%BC%E8%87%B4%E8%AE%A4%E7%9F%A5%E5%80%BA%E5%8A%A1%E9%BB%84%E4%BB%81%E5%8B%8B%E6%B2%89%E9%BB%98%E4%BA%86%E5%A5%A5%E7%89%B9%E6%9B%BC%E7%A0%B4%E9%98%B2%E4%BA%86/","section":"AI-Related Reposts","summary":"","title":"[Repost] 炸裂！MIT研究发现使用AI会导致“认知债务”，黄仁勋沉默了，奥特曼破防了","type":"posts"},{"content":"Reposted from AI Coding 的核心：Context Engineering \u0026amp; Spec Driven Dev（BMAD 作为例子） by 飞扬\n目录 # 开场\n核心问题\nContext Engineering 核心概念\nContext is Everything\nThe Dumb Zone（愚蠢区）\n使用 AI 的几种方式\nNaive Way - 一直聊到 context 用完\nSmarter - 及时重新开始\nEven Smarter - Intentional Compaction 有意压缩\n使用 Sub-agents 管理上下文\nSpec-Driven-Development = Research-Plan-Implement (RPI)\nResearch（研究）== 真相的压缩\nPlan（规划）== 意图的压缩\nImplement（实现）\nResearch 阶段\n方式 1：一次性加载所有的信息\n方式 2: Progressive Disclosure 渐进式披露\n方式 3: On-demand Compressed Context 按需压缩上下文\nPlan 阶段\nHierarchy of Leverage（杠杆层级）\n问题复杂度 vs 上下文工程\n选哪些 SDD 框架？\nSDD 框架 = Software 3.0\nBMAD 框架介绍\n三种规划轨道\n工作流四阶段\nBMAD 框架使用\n核心要点总结\n参考资料\n本文关于 Context Engineering 的部分，主要引用了 Dex Horthy (CEO, HumanLayer) 在 AI Engineer 上的演讲。对他的演讲做了一些总结和结构化的提炼，并删除了部分内容。非常推荐去看原演讲。\n开场 # 今天我来分享一下 AI Coding 的核心 —— Context Engineering 和 Spec Driven Development。我会以 BMAD 作为 Spec Driven Development 的例子，它是一个比较有名的 SDD 框架。\n整个分享分为两大块，一个是介绍 Context Engineering 的核心概念，再引出 Spec Driven Development 的核心步骤。\n第二个部分介绍一下 BMAD Method 这个 SDD 框架，展示使用的步骤。\n最后是总结。好，我们开始吧。\n核心问题 # Productivity by Task Complexity\n上图是斯坦福大学的一个研究（研究了 100k 开发者），把效率提升分为两个象限：\n一个是项目的成熟度，绿地（Greenfield 就是从零开始的项目）和棕地（Brownfield 就是已经有一些历史代码的项目）\n另一个是任务的复杂度\n可以看到，绿地的提效非常高，但是棕地项目，提效就不是那么明显了。为什么？因为缺少相关的上下文。\n这也说明了 AI Coding 很大的问题就是上下文工程。如果缺乏上下文工程的话，就会有一些很常见的问题，比如不遵守架构模式，重复造轮子，不知道项目是什么情况 等等\n为什么绿地项目问题不大呢？因为你是从零开始，很多这些问题都无所谓。但棕地项目就不一样了，这些问题会非常突出。\nContext Engineering 核心概念 # Context is Everything # Dex 介绍了两个 Context Engineering 的核心概念。\n第一个是 Context is Everything，就是上下文就是全部。\nContext is Everything\n为什么这么说呢？因为我们在 AI Coding 的时候使用的大语言模型是无状态的，唯一影响它下一步输出的就是它目前上下文里面的内容。\n这里面有 System Prompt、我们给的一些信息、它自己读的一些文件。它会根据自己上下文里的信息来决定下一步应该是 写一个新文件，还是 编辑一个现有文件。\n有什么上下文就产出什么结果，这就是 Context is Everything。\nThe Dumb Zone（愚蠢区） # Smart Zone vs Dumb Zone\n研究发现，上下文用得越多，model 越蠢。Context Window 用了 40% 之后，表现就会开始明显的下降。\n前 40% 的 context 它还是挺聪明的，这叫 Smart Zone。但是超过 40% 之后呢，就进入了一个叫 Dumb Zone 的区域，就变得蠢了。\n这也解释了为什么安装太多 MCP Tools 会有问题 —— 它们会挤满你的上下文，直接进入 Dumb Zone。\n使用 AI 的几种方式 # 了解了上下文的重要性之后呢，来看看实际使用 AI 的几种方式。\n1. Naive Way - 一直聊到 context 用完 # Naive Way\n第一种是最原始的方式，一直聊一直聊，聊到 Context 用完，纠偏也是在同一个 session。\n稍微提一嘴，Cursor 的计费方式其实是鼓励这种做法的，它按 request 使用量计费，逻辑就是跟它对话的一个 session 就算一次 request。如果你新开一轮对话的话，那就又算一个 request，尽管你那一个对话只是说了一个\u0026quot;hi\u0026quot;。这就是鼓励你把任务都放在在一个 Session 里面搞，因为你想省 request 嘛。\n这也是我觉得 Cursor 不太好的一个地方。（不知道现在计费方式变没）\nCursor Usage\n2. Smarter - 及时重新开始 # Start Over vs Resteer\n第二个稍微好一点的方式： 说着说着发现 AI 理解有问题，怎么办？不是直接在同一个 session 纠偏，而是开一个新的 session，然后带上之前漏的内容，比如\u0026quot;一定要用 XYZ 的 方式\u0026quot;。\n3. Even Smarter - Intentional Compaction 有意压缩 # Intentional Compaction\n第三个方式就是有意的做一个压缩，叫 Intentional Compaction。\n你叭叭说一大堆之后呢，就写一个 prompt 说，“把我们最近做了些什么都把它写到一个文档里”。这样的话下一次对话就可以直接引用这个文档。压缩的内容就包括文件搜索的结果、代码理解的结论、编辑和测试的内容等等。\nClaude Code 它自带一个 /compact 这样一个 slash command 来压缩。\n使用 Sub-agents 管理上下文 # Managing Context with Sub-agents\nSub-agent 可以用来管理 context。\n如果不用 Sub-agent，那搜索过程中产生的一大坨上下文都会在你的主 agent 里面。但如果用了 Sub-agent，主 agent 的上下文只会有一点点 —— 就是 Sub-agent 返回的精简结果。这样就可以大大节省上下文。\nDex 的观点是，Sub-agent 不是用来拟人的（比如前端 Agent、后端 Agent、QA Agent），而是用来控制 context 的（fork 一个新的上下文，然后返回精简的结果）。\nSpec-Driven-Development = Research-Plan-Implement (RPI) # Frequent Intentional Compaction Workflow\n这是使用 AI 的第四个方式。刚才第三个叫 Intentional Compaction，这个叫 Frequent Intentional Compaction，就是频繁的有意压缩。\n其实也可以叫它为 Spec Driven Development，或者更好的名字可能就是 Research-Plan-Implement，简称 RPI。\n核心思想就是整个工作流围绕上下文管理来构建。这三个阶段 —— Research、Plan、Implement —— 都在 Smart Zone 里完成，而不是堆到一个 context window 里面全都搞完。每次压缩都会产生相对应的文件。\n1. Research（研究）== 真相的压缩 # 第一步是 Research，就是研究阶段。\n有几个关键点：理解系统怎么工作的，找到相关的文件。Research 是真相的压缩，就是代码库的真相。\n下面是一个例子：\nResearch Example\n2. Plan（规划）== 意图的压缩 # 第二个是规划阶段。\nPlan 是意图的压缩，就是你要做什么事。关键点是：要有明确的步骤，包含文件名、代码片段、测试方式。\n下面是一个例子：\nPlan Sample\n3. Implement（实现） # 第三步就是按 Plan 去实现了。\n所以你看，每个阶段都会有一个新的 context，Research 一个、Plan 一个、Implement 一个，这样的话就能更好地管理上下文，不会撑爆。\nResearch 阶段 # 然后再细讲一下 Research 阶段。repo 里面有一堆文件目录模块，怎么压缩？有三种方式。\n方式 1：一次性加载所有的信息 # Big Ball of Mud Onboard\n第一种方式就是直接把代码库所有的相关信息压缩到 repo 里面，写一个大的介绍文件。如果文件太大，会直接把 Smart Zone 爆掉，所以这是不好的做法。\n方式 2: Progressive Disclosure 渐进式披露 # Progressive Disclosure\n第二个方式是渐进式披露。\nrepo 的根目录里面先有一些基本的介绍，然后在每个模块里面再有一些单独的记忆文件（比如 CLAUDE.md）。到了某个模块工作之后再加载那个模块的文件。这样就会还在 Smart Zone 里，Context 不会那么容易爆掉。\n阿里 Qoder 的 Repo Wiki 就是这样做的，它会根据代码库不同的模块生成对应的文档出来，然后在代码库更新的时候这个 wiki 也会更新。\nRepo Wiki\n这个方法的一个问题是比较复杂，另外一个问题就是下图展示的： 代码、名字、注释、文档，越往后走会有越来越多的 lies。\nAmount of Lies\n方式 3: On-demand Compressed Context 按需压缩上下文 # On-demand Compressed Context\n方式三是比较推荐的做法，叫按需压缩上下文。\n要做某个 Research 的时候，可以用 Sub-agent 来搜索和分析。一个 agent 去搜索 research 这一块的 truth，另一个 agent 分析另一块，几个 agent 分头去做，然后再把结果写到一个 research.md 文档里面。这样的话，都是基于当前的文件来产出的文档，可靠性高。后面要讲的 SDD 框架也是这么做的。\nPlan 阶段 # 可读性 vs 可靠性 # Readability Reliability Sweet Spot\nPlan 阶段有个点要注意，就是可靠性和可读性是负相关的关系。Plan 越长当然越可靠，但是越长就越难懂。所以 Plan 的长度需要适中。\nHierarchy of Leverage（杠杆层级） # Hierarchy of Leverage\n如果有一行烂的 Code，那只是 1 行烂代码。\n如果有一行烂的 Plan，会导致 10 到 100 行烂代码。\n如果有一行烂的 Research（就是系统理解错了），会导致 1000+ 行烂代码。\n如果有一行烂的 Spec （就是需求），会导致 10000+ 行烂代码。\n所以我们人工 review 的时候，要专注到影响非常大的部分，就是杠杆非常大的部分。\n这里 Dex 也提到一个观点：Don\u0026rsquo;t Outsource the Thinking，不要把思考外包出去。AI 会放大你的思考，它可能放大你的好思考，也会放大你的坏思考。\n问题复杂度 vs 上下文工程 # Problem Complexity vs Context Engineering\n那有人会问，这个 RPI 会不会杀鸡用牛刀了？\n所以会把问题分为两个象限，根据问题的复杂度会有不同的策略。\n改小的改动可能直接跟它说就行了。如果是复杂点的话，可能要 Research + Plan。更复杂的话可能就要多轮 RPI，叫 Multiple Research Multiple Plan。\n但是我怎么知道要选哪个方式呢？他的建议是选一个工具，然后多练。因为你练多了，你就知道 Agent 能力到底在哪一个地方。不推荐切来切去。\nDex 他没有详细说 “工具” 是什么意思，我理解工具包括三个部分：\n一个是 model。一个是 Coding 工具，比如用 Claude Code 还是 Cursor。 还有一个是 Spec-Driven Development (SDD) 框架的选择。\n选哪些 SDD 框架？ # SDD Frameworks Map\n我这边把图加了一下注释，复杂一点的项目可以用 BMAD，中等的可能用 Spec-Kit，简单一点的可以用 feature-dev （Anthropic 官方的插件），或者是用内置的 Plan Mode。\n简单展示一下这几个框架。BMAD 的话是针对大需求的，GitHub 上有 25K star，功能非常多，非常重量级。\nBMAD Commands\n然后 Spec-Kit 就非常简单，就只有几个步骤，是 GitHub 出品的，56K star。\nSpec-Kit\n还有 Anthropic 官方的 feature-dev ，Claude Code 可以用/plugin 直接装进去，它有一些 agent 和一个 command，更轻量。\nFeature Dev\nSDD 框架 = Software 3.0 # Software Evolution\n这里接着提一嘴 Andrej Karpathy 的一个演讲，他是 Tesla 的 Director of AI。他提到软件有三个版本：1.0 是代码，2.0 是神经网络的权重，3.0 就是 Prompt。可以说软件 3.0 就是用 Prompt 来编程。\nSentiment Classification Example\n举个例子，区分情感这个任务：用软件 1.0 的话可能就是写一堆 if else，如果包含 good、great 这些词，就判断是正面情感。 如果用软件 2.0，就是用神经网络权重来做，训练一个模型出来。3.0 就是用 Prompt 来做，给一些 example，让大模型来分析。\n其实为什么我们要理解 BMAD 呢？你看它的实现（见下图），可以看到非常像一个软件 —— 里面有 YAML，有各种配置，非常复杂，完全等同于一个复杂的开源软件了。\nBMAD as Software\n所以我觉得未来如果还不用这些 SDD 框架，就约等于 “明明有开源的 MySQL 但你还是要自研数据库”。现在应该关注起来。\nBMAD 框架介绍 # 下面来介绍一下一个比较有名的 SDD 框架 —— BMAD Method。搞清楚这个的话，就可以搞清楚很多其他框架了。\n三种规划轨道 # 它提到有三种轨道，就是三种使用它的方式：\n轨道 适用场景 故事数量 Quick Flow Bug 修复、小功能 1-15 BMad Method 功能集、集成 10-50+ Enterprise 企业级扩展 30+ Quick Flow 我用起来不咋地（当然可能之后会优化），我觉得简单的任务直接用 Plan Mode 就行。BMad Metod 就是我们现在准备介绍的。企业级的我们不涉及，就不说了。\n工作流四阶段 # 主要是分为四个阶段：\n分析（可选）：brainstorm-project、research、product-brief\n规划（必需）： Quick Flow 用 tech-spec，BMad/Enterprise 用 prd\n解决方案设计：create-architecture → create-epics-and-stories → implementation-readiness\n实施：sprint-planning → create-story → dev-story → code-review\n官方的流程图：\nBMAD 工作流程图\nBMAD 框架使用 # 整体流程图 # 我们用的是简单版的流程。整体的流程是这样的：\n\u0026lt;span data-cacheurl=\u0026#34;\u0026#34; data-remoteid=\u0026#34;\u0026#34; data-lazy-bgimg=\u0026#34;https://mmbiz.qpic.cn/sz_mmbiz_png/kuvCjKU0O4SiaKice8rTlI4Y8aoMHXXLWMqxybRLQu7qqiasAcYDk71zFAyH1EEPHEMYll4ibMNzNKX6nX03MVsz5g/640?wx_fmt=png\u0026amp;amp;from=appmsg\u0026#34; data-fail=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-lua\u0026#34;\u0026gt;原始 PRD\u0026amp;nbsp;\u0026amp;nbsp; \u0026amp;nbsp; ↓ 导出 Markdown原始 PRD.md\u0026amp;nbsp;\u0026amp;nbsp; \u0026amp;nbsp; ↓ shard-doc 切分切分后的文件\u0026amp;nbsp; \u0026amp;nbsp; ↓ BMad PRD 工作流BMad PRD.md\u0026amp;nbsp; \u0026amp;nbsp; ↓ create-architectureArchitecture.md\u0026amp;nbsp; \u0026amp;nbsp; ↓ create-epics-and-storiesEpics + Stories\u0026amp;nbsp; \u0026amp;nbsp; ↓ sprint-planningsprint-status.yaml\u0026amp;nbsp; \u0026amp;nbsp; ↓ 实施循环create-story → dev-story → code-review\u0026lt;/code\u0026gt; 步骤 1：获取和切分 PRD # 第一步肯定是得把这个 PRD 给捞出来嘛。一般就用 “导出成 Markdown”。 这里我用的 PRD 是让 Claude 生成的一个电商的 PRD （当然不可能直接给你企业里的了）。\n原始 PRD 示例\n原始 PRD 可能非常长，所以直接塞给 AI 的话，上下文就直接爆了，直接进入到刚才说的 Dumb Zone 了，所以要使用 /shard-doc 来切分。\n\u0026lt;span data-cacheurl=\u0026#34;\u0026#34; data-remoteid=\u0026#34;\u0026#34; data-lazy-bgimg=\u0026#34;https://mmbiz.qpic.cn/sz_mmbiz_png/kuvCjKU0O4SiaKice8rTlI4Y8aoMHXXLWMqxybRLQu7qqiasAcYDk71zFAyH1EEPHEMYll4ibMNzNKX6nX03MVsz5g/640?wx_fmt=png\u0026amp;amp;from=appmsg\u0026#34; data-fail=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-shell\u0026#34;\u0026gt;# 在 Claude Code 中/bmad:core:tools:shard-doc\u0026lt;/code\u0026gt; 它会按标题的结构来切分。切分之后就变成好几个小文件了，每个文件里面内容就比较少了。这时候我们就可以让它先读几个小文件，而不是全都 load 进去，这样就不会撑爆它的 context。\n切分后的文件结构\n步骤 2：运行 BMad PRD 工作流 # 然后再运行 PRD 工作流，这个流程会把原始 PRD 转换成 BMAD 的规范格式。\n\u0026lt;span data-cacheurl=\u0026#34;\u0026#34; data-remoteid=\u0026#34;\u0026#34; data-lazy-bgimg=\u0026#34;https://mmbiz.qpic.cn/sz_mmbiz_png/kuvCjKU0O4SiaKice8rTlI4Y8aoMHXXLWMqxybRLQu7qqiasAcYDk71zFAyH1EEPHEMYll4ibMNzNKX6nX03MVsz5g/640?wx_fmt=png\u0026amp;amp;from=appmsg\u0026#34; data-fail=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-shell\u0026#34;\u0026gt;# 在 Claude Code 中/bmad:bmm:workflows:create-prd\u0026lt;/code\u0026gt; 工作流会：\n读取切分后的原始 PRD\n提取功能需求（FR）和非功能需求（NFR）\n与你确认关键需求\n生成 BMad 格式的 PRD.md\n生成的 PRD 会长成这样子：\nBMad PRD 示例\n步骤 3：创建架构文档 # 然后再走 Architecture 这个流程，运行 `/create-architecture\n架构文档示例\n步骤 4：生成 Epic 和 Story # 运行 create-epics-and-stories 工作流。\n\u0026lt;span data-cacheurl=\u0026#34;\u0026#34; data-remoteid=\u0026#34;\u0026#34; data-lazy-bgimg=\u0026#34;https://mmbiz.qpic.cn/sz_mmbiz_png/kuvCjKU0O4SiaKice8rTlI4Y8aoMHXXLWMqxybRLQu7qqiasAcYDk71zFAyH1EEPHEMYll4ibMNzNKX6nX03MVsz5g/640?wx_fmt=png\u0026amp;amp;from=appmsg\u0026#34; data-fail=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;/bmad:bmm:workflows:create-epics-and-stories\u0026lt;/code\u0026gt; 这一步和 PRD 阶段的区别就是：这里会涉及一些实现层的内容。\n一个 Epic 里面会包含好几个 Story。有点像 OKR 的关系 —— 大 O 下面就是 KR。每个 Story 会有 Business Value，验收标准，还有依赖的分析等等。\nEpic 示例\n步骤 5：Sprint 规划 # 然后就是做 Sprint Planning 冲刺规划了。\n\u0026lt;span data-cacheurl=\u0026#34;\u0026#34; data-remoteid=\u0026#34;\u0026#34; data-lazy-bgimg=\u0026#34;https://mmbiz.qpic.cn/sz_mmbiz_png/kuvCjKU0O4SiaKice8rTlI4Y8aoMHXXLWMqxybRLQu7qqiasAcYDk71zFAyH1EEPHEMYll4ibMNzNKX6nX03MVsz5g/640?wx_fmt=png\u0026amp;amp;from=appmsg\u0026#34; data-fail=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;/bmad:bmm:workflows:sprint-planning\u0026lt;/code\u0026gt; 它会生成一个 YAML 文件来追踪状态，后续工作流会自动读取这个文件来决定下一步\nSprint Status 文件示例\n步骤 6：创建详细 Story # 然后就是跑/create-story 了，\n\u0026lt;span data-cacheurl=\u0026#34;\u0026#34; data-remoteid=\u0026#34;\u0026#34; data-lazy-bgimg=\u0026#34;https://mmbiz.qpic.cn/sz_mmbiz_png/kuvCjKU0O4SiaKice8rTlI4Y8aoMHXXLWMqxybRLQu7qqiasAcYDk71zFAyH1EEPHEMYll4ibMNzNKX6nX03MVsz5g/640?wx_fmt=png\u0026amp;amp;from=appmsg\u0026#34; data-fail=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;/bmad:bmm:workflows:create-story\u0026lt;/code\u0026gt; 工作流会：\n读取 sprint-status.yaml 找到下一个 backlog 状态的 story\n读取对应的 epic 上下文\n生成详细的 story 文件（含 tech-spec）\n自动更新状态为 drafted 或 ready-for-dev\n就是会生成一些详细的 story 文件，包含技术方案。还会把 story 拆成更详细的 task，可能还会提到一些模型设计。比最初的那个阶段又再细化了一下。\nStory 文件示例\n所以你看，这就是 Multiple Research，Multiple Plan 的体现 —— 它不只是用一个大的文件作为一个 Plan，而是每个 Story 都会做一个 Research，做一个 Plan。\n如果你忘了 Multiple Research，Multiple Plan 是啥，我把那个图再贴一下到这：\nProblem Complexity vs Context Engineering\n步骤 7：实施 Story # 开始编码实现。\n\u0026lt;span data-cacheurl=\u0026#34;\u0026#34; data-remoteid=\u0026#34;\u0026#34; data-lazy-bgimg=\u0026#34;https://mmbiz.qpic.cn/sz_mmbiz_png/kuvCjKU0O4SiaKice8rTlI4Y8aoMHXXLWMqxybRLQu7qqiasAcYDk71zFAyH1EEPHEMYll4ibMNzNKX6nX03MVsz5g/640?wx_fmt=png\u0026amp;amp;from=appmsg\u0026#34; data-fail=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;/bmad:bmm:workflows:dev-story\u0026lt;/code\u0026gt; 工作流会：\n读取 story 文件和 tech-spec\n按照 tech-spec 的步骤实施\n运行测试确保质量\n更新 sprint-status.yaml 状态为 review\n步骤 8：代码评审 # \u0026lt;span data-cacheurl=\u0026#34;\u0026#34; data-remoteid=\u0026#34;\u0026#34; data-lazy-bgimg=\u0026#34;https://mmbiz.qpic.cn/sz_mmbiz_png/kuvCjKU0O4SiaKice8rTlI4Y8aoMHXXLWMqxybRLQu7qqiasAcYDk71zFAyH1EEPHEMYll4ibMNzNKX6nX03MVsz5g/640?wx_fmt=png\u0026amp;amp;from=appmsg\u0026#34; data-fail=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;code id=\u0026#34;code-lang-bash\u0026#34;\u0026gt;/bmad:bmm:workflows:code-review\u0026lt;/code\u0026gt; 评审内容：\n代码质量（可读性、可维护性）\n测试覆盖率\n是否满足所有接受标准\n与现有代码的集成\n评审通过后，状态更新为 done。\n步骤 9： API 测试（可以前置，也可以后置） # 这一块不在 BMAD 里面，但是我们实践中会用到。因为单元测试还是有一些局限性嘛，而 API Test 是端到端的测试，会更可靠。\n总体来说，是推荐前置的，因为这就符合这个 ATDD 的这个原则，而且这样的话，AI 就可以自己修了嘛。（当然大部分的企业都是都是后置的）\n我们现在实现了 AI 自动创建、自动修复 API Test。\n自动创建 # 我们的 API 测试平台上面测试用例以 JSON 文件保存，让 AI 根据 Story 的验收条件编辑这个 JSON 文件，然后再调用平台的开放接口，把这个用例保存起来就行。\n当然在实践过程中，以 JSON 这样保存还是比较麻烦，因为它会有很多不需要的字段，还有些字段是重复的。\n为了节省 Context，我把它定义成一个 JS 文件：\n它可以自动转化成对应的 API Test 平台的 JSON 格式。\n可以做一些代码提取，重复的字段用变量定义，测试用例更简洁。\n运行 JS 就是调用接口更新测试用例。\n算是一点小的创新。\n自动修复 # 这个其实很简单，就是两个 Tool，一个可以运行测试，一个可以查日志。\n运行测试的 Tool\n基于 API Test 的开放接口封装了一个 CLI 工具，然后有一些小的改进，比如：\n轮询测试用例是不是跑完了\n执行后 会提取 trace ID 出来 并 prompt 提示 agent 可以使用查日志的 CLI 工具来查 trace 的日志\n把 API Test 平台的接口返回值做了一些精简，这样可以节省 context\n查日志的 Tool\n基于原有的查日志的 CLI 再封装了一下成为自己团队用的 CLI，也是有一些优化和 context engineering 这个我就不细讲了。\n简单说说为什么我选 CLI 而不是用 MCP 吧：\n针对自己的场景做定制优化比较方便\n不会让 MCP Tool Definition 挤爆你的上下文\n支持渐进式披露（Progressive Disclosure），Agent 可以自己使用-h 来查看各个命令怎么用\n自己可以很方便地在 Terminal 去调用。\n核心要点总结 # 总结一下核心要点：\n上下文就是一切 - LLM 是无状态的\nContext is Everything\n保持在 smart 区 - 避免 dumb 区\nSmart Zone vs Dumb Zone\n压缩是关键 - 压缩真相 (Research) 和意图 (Plan)\nOn-demand Compressed Context\nHuman in the Loop - 专注于最高杠杆部分\nHierarchy of Leverage\n选择适合的工具，多练\nSDD Frameworks Map\n参考资料 # No Vibes Allowed: Solving Hard Problems in Complex CodebasesDex Horthy (CEO, HumanLayer) - AI Engineer https://www.youtube.com/watch?v=rmvDxxNubIg\n**Software Is Changing (Again)**Andrej Karpathy - Y Combinator https://www.youtube.com/watch?v=LCEmiRjPEtQ\n**Does AI Actually Boost Developer Productivity? (100k Devs Study)**Yegor Denisov-Blanch (Stanford) - AI Engineer https://www.youtube.com/watch?v=tbDDYKRFjhk\n**Vibe Coding in Prod (Responsibly)**Erik Schluntz (Anthropic) - Anthropic https://www.youtube.com/watch?v=fHWFF_pnqDk\n","date":"22 December 2025","externalUrl":null,"permalink":"/posts/ai-coding-%E7%9A%84%E6%A0%B8%E5%BF%83context-engineering--spec-driven-devbmad-%E4%BD%9C%E4%B8%BA%E4%BE%8B%E5%AD%90/","section":"AI-Related Reposts","summary":"","title":"[Repost] AI Coding 的核心：Context Engineering \u0026 Spec Driven Dev（BMAD 作为例子）","type":"posts"},{"content":"Reposted from 当段永平遇上Dan Koe，用《大道》思维来看普通人如何经营一家年赚百万的“一人公司” by 雷冰梦\n晚上刷油管时，看到一位博主深度拆解百万粉丝创作者 Dan Koe 的成功路径。\nDan Koe 起初不过是一个厌倦“朝九晚五”的普通上班族。因为受够了重复的生活，他开始不断尝试：做过健身频道、玩过摄影、也做过网页设计。一路摸索，一路推翻自己，最终找到了适合的方向——做自媒体、写书、售卖数字化产品。\n乍看之下，这更像是一篇爽文：一个普通人从江湖小白一路打怪升级，最后成了“一人公司”的大侠，似乎没什么新鲜感。\n但真正让我停下来思考的，是他所总结的三大高效赚钱策略。当我把那些具体技巧剥开、深入到底层逻辑时，惊讶地发现，他的思维方式与我读过的《大道》、《穷查理宝典》、《影响力》里的智慧有着惊人的契合。\n策略一：极简主义与 4 小时工作模式 # 拒绝假性努力：不要只看教程，不要光做表面功。\n专注高价值：把一天最关键的任务放在第一个小时解决（深度工作），其余时间处理低负载事务。\n这听起来像“躺平”，其实段永平在《大道》里说过：做对的事，把事做对。\n我们大多数人的忙碌，不过是用“战术上的勤奋”掩盖“战略上的懒惰”：刷短视频、自欺式学习、无效邮件、无意义社交……这些都是在做“错误的事”。\nDan Koe 的 4 小时工作制，剔除掉所有噪音，留下的都是真正的做功。\n它指向的行动准则很简单：\n别只想、别只学——要动手。\n策略二：把你解决过的问题，变成产品\n核心观点：最赚钱的利基市场，就是你自己。\n你解决过减肥？你考过雅思？你用某个方法提高效率？你就可以把这套“解决方案”包装成数字产品。\nDan Koe 做什么都围绕这点：他把自己的经验（如何专注、如何写作、如何扩大社媒影响力）打包成产品。\n《影响力》里的“权威原则”正是这种观点：你不需要是世界第一，你只要是能“解决过具体问题”的那个人。\n同时，这也完全符合段永平的“本分”一词，本分就是做的产品要真，要有自己的实践。如果经验是编出来的，那是骗人，这就是不本分了。\n策略三：利用社媒推广，从写作开始 # 写作门槛最低，也最稳定。\n做“有想法的 DJ”：重组高能信息，加入自己的世界观。\n把社媒当成游戏：既是单人练级，也能多人组队。\nDan Koe 说，从写作开始，把内容创作当作游戏玩。但在我看来，这不仅是推广，更是查理·芒格所说的，要构建一套自己的“思维体系”。\n写作是重组知识的过程，是澄清思考的过程。不写下来，就永远不知道自己的逻辑漏洞在哪里。\n《穷查理宝典》同样又说，如果你不能清晰地向别人解释一个观点，你就没有真正理解它。而公开发布内容，就是借助外界反馈不断打磨“思维体系”的最好方式。\n说实话，Dan Koe 提到的三个策略，我几乎都在做。但如果照着他的标准来衡量，我距离那种真正的“通透感”还有一段不小的距离。\n我会规划工作优先级，可一旦临时出现紧急任务，心态仍会被打乱；真正执行时，也常常不自觉从“容易的”做起，把真正重要但困难的事情留到最后。\n我也常常有许多想法，想要做出一个属于自己的产品。但方向容易受到外界干扰，即使手上已经有成熟经验，也会犹豫：这些东西真的能被整合成一个产品吗？\n我写了很多内容，也掌握过很多操作技巧，但大多是随手一记、灵感一闪，缺少稳定的框架和体系。它们散落在脑子里的各个角落，却没有被串成一起。\n说到这里，继续写下去也不如先行动。既然已经开始写作，那就把今天的思考第一时间记录进Obsidian，同时给自己立一个小小的 flag：\n①每天一个“思维锚点”。不管多忙，每天都在油管找一个我认为的高价值视频（像 Dan Koe 这种）。不是娱乐，而是主动寻找“思想的乐高积木”，给思维补充新素材。 # ②在Obsidian里进行“思想炼金”。看完视频，不只是收藏，而是问自己三个问题： # 这个内容与我读过的知识体系有什么连接？\n它挑战了我哪些直觉？\n我能如何把它应用在自己的生活里？\n让输入经过自己的思考反应，变成可用的知识。\n③每周一次整理碎片，拼成文章。将一周在Obsidian里记录的碎片化思考，像拼图一样整理成一个结构清晰的内容。不是为了刻意输出，而是为了构建属于自己的知识体系。 # 最后，还是用Dan Koe的一句话来结尾： # 人生其实就是一个让人上瘾的游戏。我们只需要保持专注，沉迷这场游戏，就可以获得自己的收获。 # ","date":"9 December 2025","externalUrl":null,"permalink":"/posts/%E5%BD%93%E6%AE%B5%E6%B0%B8%E5%B9%B3%E9%81%87%E4%B8%8Adan/","section":"AI-Related Reposts","summary":"","title":"[Repost] 当段永平遇上Dan Koe，用《大道》思维来看普通人如何经营一家年赚百万的“一人公司”","type":"posts"},{"content":"Reposted from Solopreneurs vs Entrepreneurs vs Freelancers: what is a solopreneur? by Dropbox\nSolopreneur vs Entrepreneur # While there are undeniable similarities between the two terms, in practice they are very different.\nLike a lot of business terms, exact definitions are hard to pinpoint—and you may find that explanations vary, depending on where you look. That being said, the following definitions are the most widely accepted:\nSolopreneurs… # Do everything in their business\nHave a single business focus\nDon’t need to spend much time on logistics\nDeal with less financial risk\nEntrepreneurs… # Manage and delegate tasks\nLook for new ways to grow their business offering\nSpend a lot of time on decision-making\nNeed to think about payroll, benefits and taxes\nAs you can see, not only are there distinct differences in the day-to-day operations of each but also in the overall vision, direction and scope of their ventures.\nNow that we have a top-level summary, it’s worth comparing the key differences in a little more detail to truly unpack what makes solopreneurs unique.\nSolopreneurs do everything in their business. Entrepreneurs manage and delegate. # Solopreneurs are both founders and employees. That’s not to say that they can’t—or won’t—work and collaborate with others but they won’t hire anyone full-time.\nA solopreneur might work alongside a freelancer or contractor, for example, to perform certain tasks or meet deadlines in a busy month. But this would not form part of the daily operations of the business. The business also wouldn’t depend on these parties to deliver its core services.\nEntrepreneurs, on the other hand, might have founded their company on their own but will typically be seeking to grow, manage and delegate responsibilities to other people over time.\nOne route isn’t better than the other, they are simply two different approaches to business. For example, a solopreneur will have an easier time keeping their work organised without teammates but will also have to set up and manage cyber security strategies for themselves. By contrast, an entrepreneur might have a team to run cyber security but will have to pay more attention to streamlining file management and collaboration.\nEntrepreneurs focus on growing their business. Solopreneurs have a single focus. # A major difference between solopreneurs and traditional entrepreneurs comes down to the core ambition that underpins the business.\nAn entrepreneur is typically looking to grow their business for the purpose of selling it in the future. Expansion is considered a sign of success for an entrepreneur-run business.\nWith solopreneurs, growth isn’t the focus. Instead, the business is a self-serving passion project that pays their bills and fulfils them, without the need or plan for an exit strategy.\nFor example, an entrepreneur may start a restaurant business with a small investment and a single location. Over time, they’ve mapped out a growth strategy that allows the business to expand to additional locations, once certain milestones have been met. The entrepreneur hopes to someday sell the restaurant franchise to investors, so they can move on to the other ideas they’re already cooking up.\nMeanwhile, a budding solopreneur has made the decision to establish their own freelance photography business. It started as a hobby but has become profitable enough to provide a steady stream of income, along with the benefits and flexibility of self-employment. The solopreneur is not focused on building it into a photography empire—they just want to work on their terms and ensure their business model is sustainable.\nFor solopreneurs and entrepreneurs alike, time is a limited resource. Dropbox’s integrations with products like Bardeen AI enable anyone to build time-saving automation for mundane repetitive tasks.\nEntrepreneurs spend a lot of time on decision-making. Solopreneurs don’t need to. # Entrepreneurs—by nature of their focus on growth—need to make frequent, often business-critical, decisions. Their ventures have more moving parts, each of which has implications that factor into any decision.\nIf an entrepreneur had set up a marketing agency and was looking to expand, for example, they might need to consider how to expand. That might involve looking at additional office space or adopting a hybrid working model. If any team members are working remotely, they may also be looking at ways to ensure their team can maximise their productivity, no matter where they’re based.\nFor solopreneurs, decision-making is a comparatively straight-forward, personal choice. For example, a solopreneur brand consultant works from home and occasionally at a collaborative workspace. They don’t need to think about the employee culture, space requirements or other factors because they are the only employee.\nProductivity tools that reduce unnecessary work about work # With collaboration tools, secure file sharing and quick access to your favourite apps—Dropbox makes productivity simple.\n","date":"26 February 2025","externalUrl":null,"permalink":"/posts/solopreneur-vs-entrepreneur-what/","section":"AI-Related Reposts","summary":"","title":"[Repost] Solopreneurs vs Entrepreneurs vs Freelancers: what is a solopreneur?","type":"posts"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]